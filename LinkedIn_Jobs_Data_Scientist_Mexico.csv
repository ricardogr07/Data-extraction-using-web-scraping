Title,Company,Location,Remote,SeniorityLevel,EmploymentType,Industries,DatePosted,NumApplicants,JobFunction1,JobFunction2,JobFunction3,Description,Url,JobID,ShortDescription,TechStack,YoE,MinLevelStudies,English,MinYoE,Agile Methodologies,Back-End Development,Big Data Tools,Cloud Platforms,Containerization and Orchestration,Data Analysis,Data Engineering,Data Modeling,Data Visualization,Database Management,Front-End Development,Infrastructure as Code (IaC) and Automation,Machine Learning,Networking,Python,Testing and Quality Assurance,Other
AI/ML and MLOps Field Engineer,Canonical,Monterrey Metropolitan Area,REMOTE,Entry level,Full-time,"Technology, Information and Internet",2024-09-01 11:24:41.937682,25,Engineering,Information Technology,,"Canonical is a leading provider of open source software and operating systems to the global enterprise and technology markets. Our platform, Ubuntu, is very widely used in breakthrough enterprise initiatives such as public cloud, data science, AI, engineering innovation and IoT. Our customers include the world's leading public cloud and silicon providers, and industry leaders in many sectors. The company is a pioneer of global distributed collaboration, with 1000+ colleagues in 70+ countries and very few roles based in offices. Teams meet two to four times yearly in person, in interesting locations around the world, to align on strategy and execution. The company is founder led, profitable and growing. We are hiring an AI/ML and MLOps Field Engineer to help global companies embrace AI in their business, using the latest open source capabilities on public and private cloud infrastructure, Linux and Kubernetes. Our team applies expert insights to real-world customer problems, enabling the enterprise adoption of Ubuntu, Kubeflow, MLFlow, Feast, DVC and related analytics, machine learning and data technologies. We are working to create the world's best open source data platform, covering traditional SQL databases and today's NoSQL data stores, as well as the machinery which turns data into insights and executable models. The people who love this role are software engineers who enjoy customer conversations and solving customer problems during the presales cycle. They are are developers who like to solve customer problems through architecture, presentations and training. Ubuntu is used by pretty much every enterprise in the world, in every industry. This is a fantastic opportunity to learn about the open source technology landscape and develop your business technology insights. You will see first hand in various industries how Linux - and Ubuntu in particular - is shaping innovation and changing the world for the better. This role is particularly suited to candidates with a technical background who are business minded and driven by commercial success. This role is on our global Field Engineering team and will work closely with enterprise sales leads. We are specifically looking for people interested in solving the most difficult problems in modern data architectures. Training LLMs on multiple K8s clusters deployed on a hybrid cloud infrastructure with GPU sharing across multiple teams? Processing 10M events in real time for financial transactions? Object detection on 10k parallel 4K video streams? These are the problems we solve day to day. Location: Most of our colleagues work from home. We are growing teams in EMEA, Americas and APAC time zones, so can accommodate candidates from almost any country. What your day will look like The global Field Engineering team members are Linux and cloud solutions architects for our customers, designing private and public cloud solutions fitting their workload needs. They are the cloud consultants who work hands-on with the technologies by deploying, testing and handing over the solution to our support or managed services team at the end of a project. They are also software engineers who use Python to develop Kubernetes operators and Linux open source infrastructure-as-code. Work across the entire Linux stack, from kernel, networking, storage, to applications Architect cloud infrastructure solutions like Kubernetes, Kubeflow, OpenStack, and Spark Deliver solutions either on-premise or in public cloud (AWS, Azure, Google Cloud) Collect customer business requirements and advise them on Ubuntu and relevant open source applications Grow a healthy, collaborative engineering culture in line with the company values Deliver presentations and demonstrations of Ubuntu Pro and AI/ML capabilities to prospective and current clients Liaise with product teams to give them feedback on requirements to influence roadmap Work collaboratively with your sales team to reach our common targets Global travel up to 25% of time for internal and external events and 25% to customer meetings What we are looking for in you Exceptional academic track record from both high school and university Undergraduate degree in a technical subject or a compelling narrative about your alternative chosen path Experience in data engineering, MLOps, or big data solutions deployment Experience with a relevant programming language, like Python, R, or Rust. Confidence to respectfully speak up, exchange feedback, and share ideas without hesitation Track record of going above-and-beyond expectations to achieve outstanding results Demonstrated personal interest in continuous learning and development Practical knowledge of Linux, virtualisation, containers and networking Business-minded technology thinker and problem solver Knowledge of cloud computing concepts & leaders, such as Kubernetes, AWS, Azure, GCP Interest in large-scale enterprise open source - private clouds, machine learning and AI, data and analytics Intermediate level Python programming skills Passion for technology evidenced by personal projects and initiatives The work ethic and confidence to shine alongside motivated colleagues Professional written and spoken English with excellent presentation skills Experience with Linux (Debian or Ubuntu preferred) Excellent interpersonal skills, curiosity, flexibility, and accountability A dynamic person who loves to jump in new projects and interact with people Appreciative of diversity, polite and effective in a multi-cultural, multi-national organisation Thoughtfulness and self-motivation Result-oriented, with a personal drive to follow up and meet commitments Ability to travel internationally, for company events up to two weeks long, and customer or industry meetings What you'll learn Architect and deploy AI/ML infrastructures, data processing pipelines and multi-cluster distributed training Wide range of open source applications and skills Work directly with customers in a range of different businesses Real-life and hands-on exposure to a wide range of emerging technologies and tools What we offer colleagues We consider geographical location, experience, and performance in shaping compensation worldwide. We revisit compensation annually (and more often for graduates and associates) to ensure we recognise outstanding performance. In addition to base pay, we offer a performance-driven annual bonus or commission. We provide all team members with additional benefits, which reflect our values and ideals. We balance our programs to meet local needs and ensure fairness globally. Distributed work environment with twice-yearly team sprints in person Personal learning and development budget of USD 2,000 per year Annual compensation review Recognition rewards Annual holiday leave Maternity and paternity leave Employee Assistance Programme Opportunity to travel to new locations to meet colleagues Priority Pass, and travel upgrades for long haul company events About Canonical Canonical is a pioneering tech firm at the forefront of the global move to open source. As the company that publishes Ubuntu, one of the most important open source projects and the platform for AI, IoT and the cloud, we are changing the world of software. We recruit on a global basis and set a very high standard for people joining the company. We expect excellence - in order to succeed, we need to be the best at what we do. Most colleagues at Canonical have worked from home since its inception in 2004. Working here is a step into the future, and will challenge you to think differently, work smarter, learn new skills, and raise your game. Canonical is an equal opportunity employer We are proud to foster a workplace free from discrimination. Diversity of experience, perspectives, and background create a better work environment and better products. Whatever your identity, we will give your application fair consideration.",https://mx.linkedin.com/jobs/view/ai-ml-and-mlops-field-engineer-at-canonical-4013780012,4013780012,"We are hiring an AI/ML and MLOps Field Engineer to help global companies embrace AI, using the latest open source capabilities on private and public cloud infrastructure. The role involves designing cloud infrastructure solutions, deploying and testing technologies, and developing Kubernetes operators using Python. It requires experience in data engineering or big data solutions deployment and a strong background in cloud computing concepts such as Kubernetes and AWS.","Python, R, Rust, Kubernetes, AWS, Azure, Google Cloud, Linux, OpenStack, Spark, MLFlow, Feast, DVC, SQL, NoSQL",,Undergraduate Student,True,,0,0,1,1,1,0,0,0,0,1,0,1,1,0,1,0,0
Senior Machine Learning Engineer,Rent-A-Center,Monterrey Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Retail,2024-09-01 11:24:41.937682,28,Engineering,Information Technology,,"Objetivo: Diseñar flujos, automatizar procesos y generar infraestructura sostenible para el manejo, tratamiento, almacenamiento y manipulación general de los datos. Despliegue y mantenimiento continuo de modelos de aprendizaje automático en entornos de producción. Experiencia: Tres años de experiencia en puestos similares. Uso y manejo de Spark. Uso y manejo de Databricks. Uso y manejo de pipelines como Airflow o similares. Uso y manejo de Python. Uso y manejo de Git. Experiencia desarrollando data lakes. Experiencia desarrollando feature stores (actualizables automáticamente y con la menor latencia posible). Uso y manejo de pipelines para deployment, preferentemente con AWS. Experiencia con herramientas generales de AWS. Conocimiento: Trabajo previo con Azure. Líder de proyecto de desarrollo de infraestructura. Uso y manejo de Tensorflow. Uso y manejo de Kafka. Conocimiento de herramientas de Oracle. Conocimiento de Snowflake.",https://mx.linkedin.com/jobs/view/senior-machine-learning-engineer-at-rent-a-center-4009749330,4009749330,"The objective is to design workflows, automate processes, and generate sustainable infrastructure for data management, processing, storage, and general handling. Continuous deployment and maintenance of machine learning models in production environments.","Spark, Databricks, Airflow, Python, Git, AWS, Azure, Tensorflow, Kafka, Oracle, Snowflake",3 years,,False,3.0,0,0,1,1,0,0,0,0,0,1,0,1,0,0,1,0,0
Senior Machine Learning Engineer,Kuona,Monterrey Metropolitan Area,REMOTE,Mid-Senior level,Full-time,"Technology, Information and Internet",2024-08-25 11:24:41.937682,25,Engineering,Information Technology,,"We’re Kuona (kuona.ai), an AI technology company that empowers consumer products and retailers to live up to their revenue goals and empowers our clients to maximize their sales and profitability through the dynamic optimization of prices, promotions, and inventories. Our AI-powered platform helps top brands like Coca-Cola and Oxxo to maximize their profits and optimize inventories. We are looking for people who are world-class, curious, innovative, bright, and work to be better every single day! We are seeking a solution-oriented Senior Machine Learning Engineer to join our product analytics team. This fully remote role offers the opportunity to develop and deploy models that enhance our user experience across all product areas. You will work with large datasets, build models to describe and predict market behavior and generate insights that shape key decisions and investment strategies. In this position, you will face a wide range of problem-solving scenarios, from strategic to real-time, requiring extensive data collection and analysis. We need someone who can apply advanced data science skills and has experience with analytical programming languages, especially Python and the pandas library. The ideal candidate is mature, experienced, and capable of taking on challenges independently with minimal supervision. For the current position, we can only consider candidates living within México, Colombia, Argentina. Key Responsibilities: Develop advanced analytics and predictive models from design through implementation in areas such as pricing, promotion, and inventory management. Collaborate with data and software engineers to deploy scalable models across the company's ecosystem. Build models and algorithms end-to-end, starting from brainstorming and data exploration to implementing production-ready code. Write production-ready code to implement data pipelines and machine learning models. Identify, diagnose, and recommend projects to improve performance. Design product experiments, interpret results to draw detailed and impactful conclusions, and conduct root cause analysis. Work with data infrastructure and product engineering teams to define data collection needs. Provide recommendations to assist quick product ideation and feature launch decisions. Requirements: 5+ years of experience in analytics, data science, or equivalent, applying quantitative, statistical, and machine learning techniques to solve practical product problems. 5+ years of experience building machine learning systems and analyzing large datasets using modern tools. At least 2 advanced years of experience working with the pandas library. Proficiency in Python, SQL, and data visualization tools. Ability to extract business insights and identify stories behind the data. Experience analyzing and conducting hypothesis-driven experimentation and A/B testing. Comfortable translating ambiguous problems and requirements into data-driven analyses. Strong critical thinking and problem-solving skills using analytical and quantitative methodologies. Teamwork and leadership skills. Fluent in spoken and written English. Your experience with Kuona: Creativity: We like that all team members can propose and create new features Self-management: Since we are a very horizontal company, we require that team members can decide for themselves what to work on and define priorities Opportunities to learn: We offer all our employees a wide opportunity to learn things that you probably wouldn't be exposed to in a corporate environment. High Impact: You will be involved in the growth and evolution of the company, all your contributions will be of high impact on the overall results. We value our culture: We are fully committed to prioritizing great results for our clients and an amazing employee experience for our people. Ability to work anywhere / Flexibility: We provide everyone the opportunity to design your day and execute your projects with flexibility and focus on your well-being. Benefits: Competitive base compensation Health insurance Life insurance Flexible time off and 12 holidays Work from home policy including a laptop and support for your home office needs Opportunity to join a diverse, passionate, and fun team Kuona provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.",https://mx.linkedin.com/jobs/view/senior-machine-learning-engineer-at-kuona-4002809612,4002809612,"We are seeking a solution-oriented Senior Machine Learning Engineer to develop and deploy models that enhance user experience across all product areas. The role involves working with large datasets, building predictive models, and generating insights to shape key decisions. You will collaborate with data and software engineers to deploy scalable models, write production-ready code for data pipelines, and design product experiments while interpreting results. The candidate should have experience in analytics, data science, and machine learning techniques, particularly with Python and the pandas library.","Python, Pandas, SQL, Data Visualization Tools, Machine Learning, A/B Testing",5+ years,,True,5.0,0,0,0,0,0,1,0,0,1,1,0,0,1,0,1,0,0
Senior Data Scientist,Axented,Monterrey Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Software Development,2024-08-25 11:24:41.937682,25,Engineering,Information Technology,,"We are seeking a solution-oriented Senior Data Scientist to join our product analytics team. This fully remote role offers the opportunity to develop and deploy models that enhance our user experience across all product areas. You will work with large datasets, build models to describe and predict market behavior and generate insights that shape key decisions and investment strategies. In this position, you will face a wide range of problem-solving scenarios, from strategic to real-time, requiring extensive data collection and analysis. We need someone who can apply advanced data science skills and has experience with analytical programming languages, especially Python and the pandas library. The ideal candidate is mature, experienced, and capable of taking on challenges independently with minimal supervision. For the current position, we can only consider candidates living within México. Requirements 5+ years of experience in analytics, data science, or equivalent, applying quantitative, statistical, and machine learning techniques to solve practical product problems. 5+ years of experience building machine learning systems and analyzing large datasets using modern tools At least 2 advanced years of experience working with the Pandas library. Proficiency in Python, SQL, and data visualization tools. Ability to extract business insights and identify stories behind the data. Experience analyzing and conducting hypothesis-driven experimentation and A/B testing. Comfortable translating ambiguous problems and requirements into data-driven analyses. Strong critical thinking and problem-solving skills using analytical and quantitative methodologies. Teamwork and leadership skills. Fluent in spoken and written English. Responsibilities Develop advanced analytics and predictive models from design through implementation in areas such as pricing, promotion, and inventory management. Collaborate with data and software engineers to deploy scalable models across the company's ecosystem. Build models and algorithms end-to-end, starting from brainstorming and data exploration to implementing production-ready code. Write production-ready code to implement data pipelines and machine learning models. Identify, diagnose, and recommend projects to improve performance. Design product experiments, interpret results to draw detailed and impactful conclusions, and conduct root cause analysis. Work with data infrastructure and product engineering teams to define data collection needs. Provide recommendations to assist quick product ideation and feature launch decisions. Benefits Competitive base compensation Health insurance Life insurance Flexible time off and 12 holidays Work from home policy including a laptop and support for your home office needs Opportunity to join a diverse, passionate, and fun team",https://mx.linkedin.com/jobs/view/senior-data-scientist-at-axented-4024136275,4024136275,"We are seeking a solution-oriented Senior Data Scientist to join our product analytics team. This fully remote role offers the opportunity to develop and deploy models that enhance user experience across all product areas by working with large datasets, building models to describe and predict market behavior, and generating insights. The candidate must apply advanced data science skills, especially in Python and the pandas library, with a focus on machine learning and data analysis. Responsibilities include developing predictive models, collaborating with engineers, and providing data-driven recommendations.","Python, SQL, Pandas, Machine Learning, Data Visualization, A/B Testing, Statistical Analysis",5+ years,,True,5.0,0,0,0,0,0,1,0,0,0,1,0,0,1,0,1,0,0
Senior Machine Learning Engineer,Axented,Monterrey Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Software Development,2024-08-25 11:24:41.937682,25,Engineering,Information Technology,,"We are seeking a solution-oriented Senior Machine Learning Engineer to join our product analytics team. This fully remote role offers the opportunity to develop and deploy models that enhance our user experience across all product areas. You will work with large datasets, build models to describe and predict market behavior and generate insights that shape key decisions and investment strategies. In this position, you will face a wide range of problem-solving scenarios, from strategic to real-time, requiring extensive data collection and analysis. We need someone who can apply advanced data science skills and has experience with analytical programming languages, especially Python and the pandas library. The ideal candidate is mature, experienced, and capable of taking on challenges independently with minimal supervision. For the current position, we can only consider candidates living within México. Requirements 5+ years of experience in analytics, data science, or equivalent, applying quantitative, statistical, and machine learning techniques to solve practical product problems. 5+ years of experience building machine learning systems and analyzing large datasets using modern tools At least 2 advanced years of experience working with the Pandas library. Proficiency in Python, SQL, and data visualization tools. Ability to extract business insights and identify stories behind the data. Experience analyzing and conducting hypothesis-driven experimentation and A/B testing. Comfortable translating ambiguous problems and requirements into data-driven analyses. Strong critical thinking and problem-solving skills using analytical and quantitative methodologies. Teamwork and leadership skills. Fluent in spoken and written English. Responsibilities Develop advanced analytics and predictive models from design through implementation in areas such as pricing, promotion, and inventory management. Collaborate with data and software engineers to deploy scalable models across the company's ecosystem. Build models and algorithms end-to-end, starting from brainstorming and data exploration to implementing production-ready code. Write production-ready code to implement data pipelines and machine learning models. Identify, diagnose, and recommend projects to improve performance. Design product experiments, interpret results to draw detailed and impactful conclusions, and conduct root cause analysis. Work with data infrastructure and product engineering teams to define data collection needs. Provide recommendations to assist quick product ideation and feature launch decisions.",https://mx.linkedin.com/jobs/view/senior-machine-learning-engineer-at-axented-4003533968,4003533968,"We are seeking a solution-oriented Senior Machine Learning Engineer to develop and deploy models that enhance user experience across all product areas. This role involves working with large datasets, building models to describe and predict market behavior, and generating insights for key decisions. The candidate will apply advanced data science skills, including experience with analytical programming languages, especially Python and the pandas library. Responsibilities include developing advanced analytics, collaborating with data and software engineers, writing production-ready code, and conducting product experiments.","Python, Pandas, SQL, Data Visualization Tools, Machine Learning, A/B Testing",5+,,True,5.0,0,0,0,0,0,1,0,0,1,1,0,0,1,0,1,0,0
AI Python Developer Sr,Accenture México,Monterrey Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Business Consulting and Services,2024-09-13 11:24:41.937682,37,Engineering,Information Technology,,"DARE TO BE A PART OF THE CHALLENGE! COME AND JOIN OUR TEAM TOGETHER WE CAN MAKE THE DIFFERENCE! Did you know that Accenture is leading the digital transformation in the World? Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Our main purpose is to collaborate with our clients, so they can become high-performance businesses. Accenture is present in more than 200 cities, 49 countries and approximately 732,000 employees worldwide. We Offer Career development according to your profile and interests. Work in one of the best companies and feel proud. Access to an innovative methodology and tools. Direct contact with experts worldwide. Use of work schemes and cutting-edge technologies. Constant training. Work environment based on teamwork and collaboration. Participation in International Projects Skills: +5 years of experience Python SQL AWS Requirements: Expert proficiency in Machine Learning Expert proficiency in Python Software Development Advanced proficiency in Python Frameworks",https://mx.linkedin.com/jobs/view/ai-python-developer-sr-at-accenture-m%C3%A9xico-4001918826,4001918826,"We are looking for candidates with over 5 years of experience in Python, SQL, and AWS. The requirements include expert proficiency in Machine Learning and software development, as well as advanced proficiency in Python frameworks.","Python, SQL, AWS, Machine Learning, Python Frameworks",5+ years,,True,5.0,0,0,0,1,0,0,0,0,0,1,0,0,1,0,1,0,0
"Python and Kubernetes Software Engineer - Data, AI/ML & Analytics",Canonical,Monterrey Metropolitan Area,REMOTE,Entry level,Full-time,"Technology, Information and Internet",2024-09-01 11:24:41.937682,25,Engineering,Information Technology,,"Canonical is a leading provider of open source software and operating systems to the global enterprise and technology markets. Our platform, Ubuntu, is very widely used in breakthrough enterprise initiatives such as public cloud, data science, AI, engineering innovation and IoT. Our customers include the world's leading public cloud and silicon providers, and industry leaders in many sectors. The company is a pioneer of global distributed collaboration, with 1000+ colleagues in 70+ countries and very few roles based in offices. Teams meet two to four times yearly in person, in interesting locations around the world, to align on strategy and execution. The company is founder led, profitable and growing. We are hiring Python and Kubernetes Specialist Engineers focused on Data, AI/ML and Analytics Solutions to join our teams building open source solutions for public cloud and private infrastructure. As a software engineer on the team, you'll collaborate on an end-to-end data analytics and mlops solution composed of popular, open-source, machine learning tools, such as Kubeflow, MLFlow, DVC, and Feast. You may also work on workflow, ETL, data governance and visualization tools like Apache SuperSet, dbt, and Temporal, or data warehouse solutions such as Apache Trino, or ClickHouse. Your team will own a solution from the analytics and machine learning space, and integrate with the solutions from other teams to build the world's best end-to-end data platform. These solutions may be run on servers or on the cloud, on machines or on Kubernetes, on developer desktops, or as web services. We serve the needs of individuals and community members as much as the needs of our Global 2000 and Fortune 500 customers; we make our primary work available free of charge and our Pro subscriptions are also available to individuals for personal use at no cost. Our goal is to enable more people to enjoy the benefits of open source, regardless of their circumstances. Location: This initiative spans many teams that are home-based in EMEA, Americas and APAC time zones, so we can accommodate candidates in almost any location. We believe in distributed collaboration but we also try to ensure that colleagues have company during their work hourse! Successful candidates will join a team where most members and your manager are broadly in the same time zone so that you have the benefits of constant collaboration and discussion. What your day will look like Develop your understanding of the entire Linux stack, from kernel, networking, and storage, to the application layer Design, build and maintain solutions that will be deployed on public and private clouds and local workstations Master distributed systems concepts such as observability, identity, tracing Work with both Kubernetes and machine-oriented open source applications Collaborate proactively with a distributed team of engineers, designers and product managers Debug issues and interact in public with upstream and Ubuntu communities Generate and discuss ideas, and collaborate on finding good solutions What we are looking for in you Professional or academic software delivery using Python or Golang Exceptional academic track record from both high school and university Undergraduate degree in a technical subject or a compelling narrative about your alternative chosen path Confidence to respectfully speak up, exchange feedback, and share ideas without hesitation Track record of going above-and-beyond expectations to achieve outstanding results Passion for technology evidenced by personal projects and initiatives The work ethic and confidence to shine alongside motivated colleagues Professional written and spoken English with excellent presentation skills Experience with Linux (Debian or Ubuntu preferred) Excellent interpersonal skills, curiosity, flexibility, and accountability Appreciative of diversity, polite and effective in a multi-cultural, multi-national organisation Thoughtfulness and self-motivation Result-oriented, with a personal drive to meet commitments Ability to travel twice a year, for company events up to two weeks long Additional Skills That Would Be Nice To Have The following skills may be helpful to you in the role, but we don't expect everyone to bring all of them. Hands-on experience with machine learning libraries, or tools. Proven track record of building highly automated machine learning solutions for the cloud. Experience with container technologies (Docker, LXD, Kubernetes, etc.) Experience with public clouds (AWS, Azure, Google Cloud) Working knowledge of cloud computing Passionate about software quality and testing Experience working on an open source project What we offer colleagues We consider geographical location, experience, and performance in shaping compensation worldwide. We revisit compensation annually (and more often for graduates and associates) to ensure we recognise outstanding performance. In addition to base pay, we offer a performance-driven annual bonus or commission. We provide all team members with additional benefits, which reflect our values and ideals. We balance our programs to meet local needs and ensure fairness globally. Distributed work environment with twice-yearly team sprints in person Personal learning and development budget of USD 2,000 per year Annual compensation review Recognition rewards Annual holiday leave Maternity and paternity leave Employee Assistance Programme Opportunity to travel to new locations to meet colleagues Priority Pass, and travel upgrades for long haul company events About Canonical Canonical is a pioneering tech firm at the forefront of the global move to open source. As the company that publishes Ubuntu, one of the most important open source projects and the platform for AI, IoT and the cloud, we are changing the world of software. We recruit on a global basis and set a very high standard for people joining the company. We expect excellence - in order to succeed, we need to be the best at what we do. Most colleagues at Canonical have worked from home since its inception in 2004. Working here is a step into the future, and will challenge you to think differently, work smarter, learn new skills, and raise your game. Canonical is an equal opportunity employer We are proud to foster a workplace free from discrimination. Diversity of experience, perspectives, and background create a better work environment and better products. Whatever your identity, we will give your application fair consideration.",https://mx.linkedin.com/jobs/view/python-and-kubernetes-software-engineer-data-ai-ml-analytics-at-canonical-4011644941,4011644941,"We are hiring Python and Kubernetes Specialist Engineers focused on Data, AI/ML, and Analytics Solutions to build open source solutions for public cloud and private infrastructure. As a software engineer, you'll collaborate on an end-to-end data analytics and MLOps solution using popular open-source machine learning tools. You will work on workflow, ETL, data governance, and visualization tools, or data warehouse solutions. Your team will own a solution in the analytics and machine learning space and integrate it with other solutions to build a comprehensive data platform. Candidates should have professional or academic software delivery experience using Python or Golang, a strong academic track record, and an undergraduate degree in a technical subject. Experience with Linux, machine learning libraries, container technologies, and public clouds is preferred.","Python, Golang, Kubernetes, MLFlow, Kubeflow, DVC, Feast, Apache SuperSet, dbt, Temporal, Apache Trino, ClickHouse, Linux",,Undergraduate Student,True,,0,1,1,0,1,0,0,0,0,0,0,0,1,0,1,0,0
Senior Data Scientist,Launch Potato,Monterrey Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Advertising Services,2024-09-08 11:24:41.937682,25,Engineering,Information Technology,,"WHO ARE WE? Launch Potato is a digital media company with a portfolio of brands and technologies. As The Discovery and Conversion Company, Launch Potato is a leading connector of advertisers to customers at all parts of the consumer journey, from awareness to consideration to purchase. The company is headquartered in vibrant downtown Delray Beach, Florida, with a unique international team across over a dozen countries. Launch Potato's success comes from a diverse, energetic culture and high-performing, entrepreneurial team. As a result, the company is always looking for like-minded teammates and partners. (This role will heavily focus on building machine learning models. This is NOT an engineering/data engineering position.) MUST HAVE: Experience within the performance marketing/lead gen industries. Professional experience designing, implementing, optimizing, and testing end-to-end Multi-Armed Bandit (MAB) and recommendation systems. EXPERIENCE: A minimum of 4 years experience in a hands-on, in-the-weeds data science position. YOUR ROLE You will be developing deep personalization models for our users and complex optimization algorithms to bridge our customer experiences with new products/services. Your direct contribution will impact how we connect hundreds of thousands of customers to hundreds of advertisers together daily and will drive significant consumer impact while increasing revenue. You will play a pivotal role in the growth of our data science team and will be an instrumental resource as we continue to build a team of data scientists and machine learning engineers that can increase customer engagement and stickiness on our sites while improving the quality of the leads to our partners. This is an extremely hands-on and in-the-weeds Data Science role where you will be heavily immersed in the data and coding part of the solution implementation. You will design and oversee integrating state-of-the-art machine learning solutions across the company’s products. This role will be responsible for strategic planning of Machine Learning initiatives with the Product, Engineering, Performance and Business Intelligence teams, analysis of potential impact and prioritization of those projects. SUCCESS LOOKS LIKE Innovate, create, and design ML solutions to various business problems such as: Design, implement and continuously improve Multi-Armed Bandit solutions to optimize decisions/options in place of multiple AB-tests. Utilizing Large Language Models in content personalization across various verticals. Recommendation systems to serve ads, offers, questions, etc. Collaborate with stakeholders across the company including but not limited to Analytics, Engineering, Product and Business Leads to improve model infrastructure, tracking and monitoring. Provide data science support at different project stages, including the implementation of ML solutions by collaborating with Data Engineers and MLOps. Being hands-on and in-the-weeds in the data, coding part of the solution implementation. What You Need To Succeed 4+ years of related work experience in the field of Data Science & Machine learning. 2+ years of experience in the Marketing/Advertising Industry. Solid background in Machine Learning and Statistics. Professional experience designing and implementing Multi-Armed Bandit (MAB) solutions and recommendation systems. Proficiency in SQL, Python and working with Data Science tools (e.g., git, kubernetes, Docker, etc.). Structure and clarify any ambiguity for the team, i.e., divide complex projects into sprints and coordinate implementation across multiple teams and individuals. Experience creating ML solutions within cloud services (AWS/GCP). Experience with ML model development lifecycle. Experience with data visualization (preferably Looker). Experience managing a team of data scientists and machine learning researchers (including career development). Ability to communicate clearly, think independently, provide direction, and effectively communicate with technical and non-technical stakeholders. NICE TO HAVES Experience with LLMs and Deep learning models to develop business and data science solutions. Want to make your impact in a profitable, high-growth company? Apply now! Since day one, we've been committed to having a diverse, inclusive team and culture. We are proud to be an Equal Employment Opportunity company. We value diversity, equity, and inclusion. We do not discriminate based on race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",https://mx.linkedin.com/jobs/view/senior-data-scientist-at-launch-potato-4019303841,4019303841,"This role focuses on building machine learning models, requiring expertise in designing, implementing, optimizing, and testing end-to-end Multi-Armed Bandit (MAB) and recommendation systems. The candidate will develop deep personalization models and complex optimization algorithms that bridge customer experiences with products/services. The position involves collaboration with various teams to innovate ML solutions to business problems, improve model infrastructure, and provide data science support at different project stages.","Python, SQL, Machine Learning, Statistics, Git, Kubernetes, Docker, AWS, GCP, Looker",4+,,True,4.0,0,0,0,1,1,0,0,0,1,1,0,1,1,0,1,0,0
"Senior Artificial Intelligence/Machine Learning Engineer - Remote, Latin America",Bluelight Consulting | DevOps & Software Development,Monterrey Metropolitan Area,REMOTE,,Full-time,IT Services and IT Consulting,2024-09-08 11:24:41.937682,25,Engineering,Information Technology,,"Bluelight Consulting is a leading software consultancy dedicated to designing and developing innovative technology that enhances users' lives. With a steadfast commitment to delivering exceptional service to our clients, Bluelight excels in its focus on quality and customer satisfaction. Our mission is not only to create cutting-edge applications but also to foster a collaborative and enriching work environment where each team member can grow and thrive. With a presence across the United States and Central/South America, Bluelight is in an exciting phase of expansion, continually seeking exceptional talent to join its dynamic and diverse community. We are looking for a skilled individual to join our rapidly growing team at Bluelight Consulting. This position is ideal for someone who thrives in a fast-paced, dynamic environment where everyone's opinions and efforts are valued and appreciated. You will have the opportunity to contribute to challenging and meaningful projects, developing high-quality applications that stand out in the market. We value continuous learning, personal growth, and hard work, offering a collaborative environment that promotes professional development. If you are passionate about software development and eager to be part of a growing software consultancy, we invite you to apply and join us on this exciting journey. What we are looking for Strong background in computer science or engineering with 3+ years of experience Knowledge of machine learning, deep learning, and natural language processing Experience with LLMs like GPT and LLama3 Proficient in Python and familiar with TensorFlow or PyTorch Good problem-solving skills and ability to work independently and in a team Experience with AI voice programs/products Proficient in cloud services (AWS, Azure, Google Cloud) and container technologies (Docker, Kubernetes) Strong communication skills for explaining technical ideas to various audiences Ability to manage product specifications from concept to production Understanding of software design principles, including optimization and performance tuning Company Benefits Competitive salary and bonuses, including performance-based salary increases Generous paid-time-off policy Technology / Office stipend Health Coverage Flexible working hours Work remotely Continuing education, training, conferences Company-sponsored coursework, exams, and certifications Being a consultant in our team is a fun, challenging, and rewarding career choice. Your contributions are highly valued by clients, and the work you do often has a direct and significant impact on their business. You will have the opportunity to work on a variety of projects for our incredible clients, which will accelerate your career growth. You’ll collaborate with modern technologies and work alongside some of the best professionals in the industry! If you’re eager to be part of an exciting, challenging, and rapidly growing consultancy, we encourage you to apply.",https://mx.linkedin.com/jobs/view/senior-artificial-intelligence-machine-learning-engineer-remote-latin-america-at-bluelight-consulting-devops-software-development-4018830256,4018830256,"We are looking for a skilled individual with a strong background in computer science or engineering and 3+ years of experience. The role involves knowledge of machine learning, deep learning, and natural language processing, along with experience using large language models like GPT and LLaMA. Proficiency in Python, familiarity with TensorFlow or PyTorch, and experience with AI voice programs/products are required. Candidates should be proficient in cloud services (AWS, Azure, Google Cloud) and container technologies (Docker, Kubernetes). Strong problem-solving skills, communication abilities, and understanding of software design principles are essential.","Python, TensorFlow, PyTorch, AWS, Azure, Google Cloud, Docker, Kubernetes, Machine Learning, Deep Learning, Natural Language Processing",3+ years,Bachelor,True,3.0,0,0,0,1,1,0,0,0,0,0,0,0,1,0,1,0,0
Senior Machine Learning Researcher,Launch Potato,Monterrey Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Advertising Services,2024-09-08 11:24:41.937682,25,Other,,,"WHO ARE WE? Launch Potato is a digital media company with a portfolio of brands and technologies. As The Discovery and Conversion Company, Launch Potato is a leading connector of advertisers to customers at all parts of the consumer journey, from awareness to consideration to purchase. The company is headquartered in vibrant downtown Delray Beach, Florida, with a unique international team across over a dozen countries. Launch Potato's success comes from a diverse, energetic culture and high-performing, entrepreneurial team. As a result, the company is always looking for like-minded teammates and partners. (This role will heavily focus on building machine learning models. This is NOT an engineering/data engineering position.) MUST HAVE: Experience within the performance marketing/lead gen industries. Professional experience designing, implementing, optimizing, and testing end-to-end Multi-Armed Bandit (MAB) and recommendation systems. EXPERIENCE: A minimum of 4 years experience in a hands-on, in-the-weeds data science position. YOUR ROLE You will be developing deep personalization models for our users and complex optimization algorithms to bridge our customer experiences with new products/services. Your direct contribution will impact how we connect hundreds of thousands of customers to hundreds of advertisers together daily and will drive significant consumer impact while increasing revenue. You will play a pivotal role in the growth of our data science team and will be an instrumental resource as we continue to build a team of data scientists and machine learning engineers that can increase customer engagement and stickiness on our sites while improving the quality of the leads to our partners. This is an extremely hands-on and in-the-weeds Data Science role where you will be heavily immersed in the data and coding part of the solution implementation. You will design and oversee integrating state-of-the-art machine learning solutions across the company’s products. This role will be responsible for strategic planning of Machine Learning initiatives with the Product, Engineering, Performance and Business Intelligence teams, analysis of potential impact and prioritization of those projects. SUCCESS LOOKS LIKE Innovate, create, and design ML solutions to various business problems such as: Design, implement and continuously improve Multi-Armed Bandit solutions to optimize decisions/options in place of multiple AB-tests. Utilizing Large Language Models in content personalization across various verticals. Recommendation systems to serve ads, offers, questions, etc. Collaborate with stakeholders across the company including but not limited to Analytics, Engineering, Product and Business Leads to improve model infrastructure, tracking and monitoring. Provide data science support at different project stages, including the implementation of ML solutions by collaborating with Data Engineers and MLOps. Being hands-on and in-the-weeds in the data, coding part of the solution implementation. What You Need To Succeed 4+ years of related work experience in the field of Data Science & Machine learning. 2+ years of experience in the Marketing/Advertising Industry. Solid background in Machine Learning and Statistics. Professional experience designing and implementing Multi-Armed Bandit (MAB) solutions and recommendation systems. Proficiency in SQL, Python and working with Data Science tools (e.g., git, kubernetes, Docker, etc.). Structure and clarify any ambiguity for the team, i.e., divide complex projects into sprints and coordinate implementation across multiple teams and individuals. Experience creating ML solutions within cloud services (AWS/GCP). Experience with ML model development lifecycle. Experience with data visualization (preferably Looker). Experience managing a team of data scientists and machine learning researchers (including career development). Ability to communicate clearly, think independently, provide direction, and effectively communicate with technical and non-technical stakeholders. NICE TO HAVES Experience with LLMs and Deep learning models to develop business and data science solutions. Want to make your impact in a profitable, high-growth company? Apply now! Since day one, we've been committed to having a diverse, inclusive team and culture. We are proud to be an Equal Employment Opportunity company. We value diversity, equity, and inclusion. We do not discriminate based on race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",https://mx.linkedin.com/jobs/view/senior-machine-learning-researcher-at-launch-potato-4019302943,4019302943,"This role will focus on building machine learning models, specifically designing and implementing Multi-Armed Bandit (MAB) and recommendation systems. The candidate will be responsible for developing deep personalization models and complex optimization algorithms to enhance customer experiences. Key responsibilities include innovating machine learning solutions for business problems, collaborating with various stakeholders, providing data science support, and managing a team of data scientists. The position requires a hands-on approach to data and coding in solution implementation.","Python, SQL, Data Science Tools, Git, Kubernetes, Docker, AWS, GCP, Looker",4+ years,,True,4.0,0,0,0,1,1,1,0,0,1,1,0,1,0,0,1,0,0
Data Engineering Intern,Kuona,Monterrey Metropolitan Area,REMOTE,,Internship,"Technology, Information and Internet",2024-09-08 11:24:41.937682,61,Information Technology,,,"We are Kuona ( kuona.a i) , an AI technology company that empowers consumer products and retailers to live up to their revenue goals and empowers our clients to maximize their sales and profitability through the dynamic optimization of prices, promotions, and inventories. Our AI-powered platform helps top brands like Coca-Cola and Oxxo maximize their profits and optimize inventories. We are looking for people who are world-class, curious, innovative, bright, and work to be better every single day! We are currently looking for a Data Engineering Intern. With training, guidance, monitoring, and support from the team and team leader, this role is focused on finding and developing solutions that help Kuona build and maintain complex data pipelines and analytical solutions that deepen relationships with customer-provided information. Responsibilities: Ensure that the quality of presented data is reliable and aligned with its source quality, and be familiar with various data sources and/or flat files for generating solutions. This role collaborates with the data engineering and data science teams to drive and optimize analytical solutions and internal data systems. Contribute to data analysis and integration. Provide support for enhancing and addressing issues with developed and integrated systems, among other related tasks in the area. Required Technical Experience: Desirable experience in data engineering, business intelligence, or engineering. Desirable experience analyzing and integrating data using Python and SQL to extract and transform data according to business rules and requirements. Desirable knowledge in Pandas, Relational and NoSQL databases, and AWS. Desirable knowledge in Airflow and AWS Glue. Desirable experience with large-scale data warehouses, web APIs, and database platforms for integrating internal and external data sources. Your experience with Kuona: Creativity: We like that all team members can propose and create new features Self-management: Since we are a very horizontal company, we require that team members can decide for themselves what to work on and define priorities Opportunities to learn: We offer all our employees a wide opportunity to learn things you probably wouldn't be exposed to in a corporate environment. High Impact: You will be involved in the growth and evolution of the company, and all your contributions will be of high impact on the overall results. We value our culture: We are fully committed to prioritizing great results for our clients and an amazing employee experience for our people. Ability to work anywhere / Flexibility: We provide everyone the opportunity to design your day and execute your projects with flexibility and focus on your well-being. Kuona provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.",https://mx.linkedin.com/jobs/view/data-engineering-intern-at-kuona-4014199772,4014199772,"We are currently looking for a Data Engineering Intern focused on finding and developing solutions that help build and maintain complex data pipelines and analytical solutions. Responsibilities include ensuring data quality, collaborating with data engineering and data science teams, contributing to data analysis and integration, and providing support for enhancing existing systems. Desirable technical experience includes working with Python and SQL for data extraction and transformation, knowledge in Pandas, relational and NoSQL databases, AWS, Airflow, and AWS Glue.","Python, SQL, Pandas, Relational databases, NoSQL, AWS, Airflow, AWS Glue",,,True,,0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0
Tech Support Data Engineer,Boldr,Monterrey Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Non-profit Organizations and Primary and Secondary Education,2024-08-16 11:24:41.937682,44,Engineering,,,"Working hours: US Business hours What Is Your Role This role is part of the team of Customer Engineers in Professional Services, and we're seeking highly talented individuals to join and grow our team. This is the intersection where the product has to meet customer needs and create value. You are a customer-facing data engineer who loves to see technology and data used in ways that ensure our projects' and customers' success. You have great attention to detail and are very proactive in seeking potential roadblocks to success. You have great people skills and know how to manage the trust and expectations of a customer. What Will You Do Customer Engineers are the customer facing technical owners of our existing customer relationships and data driven deliverables on the company's platform You will work hands-on with our technology stack and collaborate with several teams such as Product Engineering and Customer Engagement in order to deliver on all customer technical requests. You will be responsible for regularly interacting with our customers to gather requirements (e.g. weekly meetings, email, etc), and for scoping and prioritizing the incoming work. This can include: Designing Solutions - translate business requirements into technical solutions using SQL, scripting, codebase configurations, etc Setting up ETL pipelines across disparate data sources, and creating a unified Data Model Setting up/enabling new product features & ingest/export integrations Implementing the company's platform and its various components for our new customers Helping answer customer questions, and troubleshooting where necessary Participating in the on-call rotation You will also be: Finding out sustainable ways of addressing repeatable issues, and building tools for automation Contributing with documentation and building our customer specific configuration knowledge base A source of feedback for our product team, full stack and backend engineering teams Requirements BS degree in Computer Science, Engineering, Mathematics, Economics, Statistics, Information Management or similar 2+ years in a technical role that involves managing and manipulating large data sets, such as ETL, Data Warehousing, Analytics, Data Science etc 2+ years in a client-facing role that involves being a point-of-contact for technical and non-technical users Proficient in one programming language and working knowledge of SQL and Unix command line tools Working Knowledge of Github, and AWS infrastructure Excellent problem solving skills Strong Communication skills Improvement mindset, through processes, tools and/ or documentation Strong professionalism & work ethic Nice to have: Working knowledge of Java and/or Scala Marketing technology industry & relevant vendor knowledge Benefits Law Benefits Private Health Insurance Paid Time Off Training Life insurance Mental Health Support Learning and Development Programs",https://mx.linkedin.com/jobs/view/tech-support-data-engineer-at-boldr-3994915995,3994915995,"This role is part of the team of Customer Engineers in Professional Services, seeking highly talented individuals to join and grow the team. As a customer-facing data engineer, you will translate business requirements into technical solutions using SQL and other technologies, set up ETL pipelines, implement the company's platform for new customers, and manage customer relationships. You will also contribute to documentation and provide feedback to product teams.","SQL, Unix, ETL, Data Warehousing, Data Science, GitHub, AWS, Java, Scala",2+ years,Bachelor,True,2.0,0,0,0,1,0,1,1,0,0,1,0,1,0,0,0,0,0
Jr. Data Scientist,Arca Continental,Monterrey Metropolitan Area,HYBRID,Associate,Full-time,Food and Beverage Services,2024-08-25 11:26:01.950696,200,Information Technology,Sales,,"Nuestra compañía Arca Continental es una empresa dedicada a la producción, distribución y venta de bebidas no alcohólicas de las marcas propiedad de The Coca-Cola Company, así como botanas saladas bajo las marcas Bokados en México, Inalecsa en Ecuador y Wise en los Estados Unidos. Con una destacada trayectoria de más de 98 años, Arca Continental es la segunda embotelladora de Coca-Cola más grande de América Latina y una de las más importante del mundo. En su franquicia de Coca-Cola, la empresa atiende a una población de más de 119 millones en la región norte y occidente de México, así como en Ecuador, Perú, la región norte de Argentina y la región suroeste de Estados Unidos. Arca Continental cotiza en la Bolsa Mexicana de Valores bajo el símbolo ""AC"". Misión del puesto Buscamos un Científico de Datos Junior con una sólida base en programación y pasión por los datos. Tu objetivo será utilizar tus habilidades de programación para analizar y extraer insights de bases de datos, desarrollar y dar mantenimiento a modelos de machine learning , y mantener soluciones existentes para varios países de LATAM en conjunto con el equipo de Ciencia de Datos. Responsabilidades clave Desarrollar soluciones analíticas que resuelvan de manera óptima las problemáticas del negocio, para mejorar los procesos actuales y facilitar la toma de decisiones. Presentar insights con equipos técnicos y stakeholders Asegurar la mejora continua y el mantenimiento de los desarrollos, buscando siempre mayor eficiencia en términos de calidad, costo y tiempo. Analizar información sobre el seguimiento continuo del desarrollo productivo y la adopción de los desarrollos para mejorar su interacción con los usuarios finales. Trabajar en conjunto con el equipo de Ciencia de Datos para mejorar los procesos clave de la organización mediante el uso de tecnología y soluciones innovadoras. Cualificaciones y requerimientos Recién egresado en áreas cuantitativas (Ingeniería, Matemáticas, Física). Haber llevado cursos de algoritmos y programación en la carrera profesional. Sólidos conocimientos de programación con Python, pensamiento algorítmico y razonamiento lógico. Conocimiento teórico y práctico de modelos tradicionales de Machine Learning (regresión, clasificación, clustering) y métricas de evaluación. Habilidades de comunicación efectiva, organización de actividades y alta atención al detalle. Idiomas: Inglés Avanzado (tanto conversacional como escrito). Características deseables Experiencia con modelos de forecast o series de tiempo. Conocimiento de procesos de empresas tipo retail. Fundamentos en IA generativa y Deep learning. Nuestro compromiso Arca Continental es una empresa que ofrece igualdad de oportunidades. Las decisiones de contratación se toman sin distinción de raza o etnia, color, religión, nacionalidad, sexo, orientación sexual, identidad de género, edad, discapacidad, estatus de veterano protegido o alguna otra característica protegida por la ley. Nunca solicitaremos ningún tipo de pago para procesar su solicitud de empleo ni en ninguna otra etapa del proceso de selección. Nunca le envíe dinero a nadie que sugiera que puede darle empleo en Arca Continental. Si sospecha que ha recibido una oferta fraudulenta, repórtelo con las autoridades correspondientes.",https://mx.linkedin.com/jobs/view/jr-data-scientist-at-arca-continental-4002846143,4002846143,"We are looking for a Junior Data Scientist with a solid programming foundation and a passion for data. Your objective will be to use your programming skills to analyze and extract insights from databases, develop and maintain machine learning models, and maintain existing solutions for various Latin American countries in collaboration with the Data Science team. Key responsibilities include developing analytical solutions to optimally solve business challenges, presenting insights to technical teams and stakeholders, ensuring continuous improvement and maintenance of developments, and working together with the Data Science team to enhance key organizational processes using technology and innovative solutions.","Python, Machine Learning, Data Analysis, Algorithms, Deep Learning",,Bachelor,True,,0,0,0,0,0,1,0,0,0,0,0,0,1,0,1,0,0
Data Scientist (Consultant),NEORIS,Monterrey Metropolitan Area,HYBRID,Entry level,Full-time,IT Services and IT Consulting,2024-09-08 11:26:01.950696,88,Engineering,Information Technology,,"En NEORIS es un acelerador Digital que ayuda a las compañías a entrar en el futuro, teniendo 20 años de experiencia como Socios Digitales de algunas de las mayores compañías del mundo. Somos más de 4,000 profesionales en 11 países, con nuestra cultura multicultural de startup en donde cultivamos innovación, aprendizaje continuo para crear soluciones de alto valor para nuestros clientes. Estamos En Búsqueda De Data Scientist Consultant Data Scientist Consultant con al menos 2 años de experiencia. El candidato ideal tendrá una sólida comprensión de estadística y matemática, experiencia en el desarrollo con Python y SQL, y una pasión por convertir datos en información procesable. Deseable conocimiento en temas de pricing. Principales Responsabilidades Recopilar, procesar y analizar grandes volúmenes de datos de diversas fuentes. Desarrollar y mantener modelos predictivos y de machine learning. Realizar análisis estadísticos para identificar tendencias, patrones y oportunidades de mejora. Crear visualizaciones de datos efectivas para comunicar hallazgos a equipos no técnicos. Colaborar con equipos multidisciplinarios para definir y resolver problemas de negocio. Documentar procesos, metodologías y resultados de análisis. Contribuir a la mejora continua de los procesos y herramientas de análisis de datos. Monterrey esquema híbrido Requerimientos Egresado de carrera como Ing en matemáticas, estadística, actuaria o afines. Maestría en Computo estadístico (CIMAT) 2 años de experiencia laboral como Data Scientist. Experiencia en programación con Python, incluyendo bibliotecas como pandas, numpy, scikit-learn y matplotlib. Conocimiento sólido de SQL para la consulta y manipulación de bases de datos. Comprensión profunda de conceptos estadísticos y su aplicación en el análisis de datos. Capacidad para comunicar resultados complejos de manera clara y concisa a audiencias técnicas y no técnicas. Fuertes habilidades analíticas y de resolución de problemas. Ser curioso y proactivo, con un fuerte deseo de aprender y explorar nuevas tecnologías y metodologías. Grado en Estadística, Matemáticas, Ciencias de la Computación, Ingeniería o un campo relacionado. Deseable conocimiento en temas de pricing. Inglés conversacional (Avanzado o Intermedio B2). Localización: Monterrey (esquema híbrido) Ofrecemos Esquema 100% Nominal Prestaciones de Ley Paquete de Beneficios Programa Bienestar Plan de desarrollo profesional Colaboración multicultural Te invitamos a conocernos en http://www.neoris.com, Facebook, LinkedIn, Twitter o Instagram: @NEORIS. Hector Antonio Hernandez Sanchez",https://mx.linkedin.com/jobs/view/data-scientist-consultant-at-neoris-3997049604,3997049604,"NEORIS is looking for a Data Scientist Consultant with at least 2 years of experience. The ideal candidate will have a solid understanding of statistics and mathematics, experience in development with Python and SQL, and a passion for turning data into actionable information. Responsibilities include collecting, processing, and analyzing large volumes of data from various sources, developing and maintaining predictive and machine learning models, performing statistical analysis to identify trends and opportunities for improvement, and creating effective data visualizations to communicate findings to non-technical teams.","Python, SQL, pandas, numpy, scikit-learn, matplotlib",2,,True,2.0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0
Data Scientist,Chubb,Monterrey Metropolitan Area,HYBRID,Entry level,Full-time,Insurance,2024-09-10 11:26:01.950696,62,Engineering,Information Technology,,"Job Description Machine Learning Engineer Summary: We are seeking a talented and motivated Machine Learning Engineer to join our team. The ideal candidate will have at least 3 years of experience in the field, with a strong background in machine learning, data science, and software engineering. You will be responsible for designing, developing, and deploying machine learning models to solve complex problems and enhance our products and services. Key Responsibilities: Design, develop, and implement machine learning models and algorithms. Collaborate with cross-functional teams to understand business requirements and translate them into technical solutions. Perform data preprocessing, feature engineering, and model validation. Optimize and scale machine learning models for production. Monitor and maintain deployed models, ensuring their performance and accuracy over time. Conduct experiments to evaluate model performance and identify areas for improvement. Stay up-to-date with the latest developments in machine learning and artificial intelligence. Document processes, models, and methodologies for reproducibility and knowledge sharing. Qualifications: Bachelor’s or Master’s degree in Computer Science, Data Science, Mathematics, Statistics, or a related field. At least 3 years of experience as a Machine Learning Engineer or in a similar role. Proficiency in programming languages such as Python, R, or Java. Experience with machine learning frameworks and libraries (e.g., TensorFlow, PyTorch, scikit-learn). Strong understanding of statistical analysis and data mining techniques. Familiarity with data preprocessing, feature engineering, and model evaluation. Experience with big data technologies (e.g., Hadoop, Spark) is a plus. Knowledge of cloud platforms (e.g., AWS, Azure, GCP) for deploying machine learning models. Excellent problem-solving skills and attention to detail. Strong communication skills, with the ability to explain complex technical concepts to non-technical stakeholders. Preferred Skills: Experience with MLFlow for experiment tracking and model management. Proficiency in using PySpark for big data processing. Strong SQL skills for database querying and manipulation. Knowledge of model serving techniques and tools for deploying machine learning models at scale. Familiarity with DevOps practices and tools for CI/CD in machine learning. Understanding of software development best practices, including version control and testing. Qualifications Machine Learning Engineer Summary: We are seeking a talented and motivated Machine Learning Engineer to join our team. The ideal candidate will have at least 3 years of experience in the field, with a strong background in machine learning, data science, and software engineering. You will be responsible for designing, developing, and deploying machine learning models to solve complex problems and enhance our products and services. Key Responsibilities: Design, develop, and implement machine learning models and algorithms. Collaborate with cross-functional teams to understand business requirements and translate them into technical solutions. Perform data preprocessing, feature engineering, and model validation. Optimize and scale machine learning models for production. Monitor and maintain deployed models, ensuring their performance and accuracy over time. Conduct experiments to evaluate model performance and identify areas for improvement. Stay up-to-date with the latest developments in machine learning and artificial intelligence. Document processes, models, and methodologies for reproducibility and knowledge sharing. Qualifications: Bachelor’s or Master’s degree in Computer Science, Data Science, Mathematics, Statistics, or a related field. At least 3 years of experience as a Machine Learning Engineer or in a similar role. Proficiency in programming languages such as Python, R, or Java. Experience with machine learning frameworks and libraries (e.g., TensorFlow, PyTorch, scikit-learn). Strong understanding of statistical analysis and data mining techniques. Familiarity with data preprocessing, feature engineering, and model evaluation. Experience with big data technologies (e.g., Hadoop, Spark) is a plus. Knowledge of cloud platforms (e.g., AWS, Azure, GCP) for deploying machine learning models. Excellent problem-solving skills and attention to detail. Strong communication skills, with the ability to explain complex technical concepts to non-technical stakeholders. Preferred Skills: Experience with MLFlow for experiment tracking and model management. Proficiency in using PySpark for big data processing. Strong SQL skills for database querying and manipulation. Knowledge of model serving techniques and tools for deploying machine learning models at scale. Familiarity with DevOps practices and tools for CI/CD in machine learning. Understanding of software development best practices, including version control and testing.",https://mx.linkedin.com/jobs/view/data-scientist-at-chubb-3987318831,3987318831,"We are seeking a talented and motivated Machine Learning Engineer to join our team. The ideal candidate will have at least 3 years of experience in the field, with a strong background in machine learning, data science, and software engineering. You will be responsible for designing, developing, and deploying machine learning models to solve complex problems and enhance our products and services. Key responsibilities include designing and implementing machine learning models and algorithms, collaborating with cross-functional teams, performing data preprocessing, optimizing models for production, and monitoring deployed models for performance. The candidate should also stay up-to-date with the latest developments in machine learning and document processes for knowledge sharing.","Python, R, Java, TensorFlow, PyTorch, scikit-learn, Hadoop, Spark, AWS, Azure, GCP, MLFlow, PySpark, SQL",3,Bachelor,True,3.0,0,0,1,1,0,0,0,0,0,1,0,0,1,0,1,0,0
Senior AI Application Engineer,Bain & Company,Monterrey Metropolitan Area,HYBRID,,Full-time,Business Consulting and Services,2024-09-08 11:26:01.950696,25,Engineering,,,"*Applications must be submitted in English* WHAT MAKES US A GREAT PLACE TO WORK We are proud to be consistently recognized as one of the world's best places to work, a champion of diversity and a model of social responsibility. We are currently ranked the #1 consulting firm on Glassdoor’s Best Places to Work list, and we have maintained a spot in the top four on Glassdoor's list for the last 13 years. We believe that diversity, inclusion and collaboration is key to building extraordinary teams. We hire people with exceptional talents, abilities and potential, then create an environment where you can become the best version of yourself and thrive both professionally and personally.  We are publicly recognized by external parties such as Fortune, Vault, Mogul, Working Mother, Glassdoor and the Human Rights Campaign for being a great place to work for diversity and inclusion, women, LGBTQ and parents. WHO YOU’LL WORK WITH As a member of Bain’s Advanced Analytics Group, you’ll join a talented team of diverse and inclusive analytic and engineering professionals who are dedicated to solving complex challenges for our clients. We work closely with our generalist consultants and clients to develop data-driven strategies and innovative solutions. Our collaborative and supportive work environment fosters creativity and continuous learning, enabling us to consistently deliver exceptional results. WHAT YOU’LL DO As a Senior Software Engineer, you will apply technical solutions to cutting-edge problems across various industries. You will be part of a diverse engineering team, participating in the full engineering life cycle. This includes designing, developing, optimizing, and deploying new software engineering solutions and infrastructure for the production scale of the world’s largest companies. Collaborate closely with general consulting teams to identify software solutions to client business problems and execute those solutions Provide technical guidance to external clients and internal stakeholders in Bain Play a key role in delivering technical solutions for client cases (from solution architecture to hands-on development work) Participate in the full software development life cycle including designing, writing documentation and unit/integration tests, and conducting code reviews for engineering solutions Participate in expert client advisory services that require knowledge in software engineering with distributed systems, AI, and application architecture Develop and refine reusable common frameworks, models, and components to solve common software engineering challenges across industries and business functions Implement and promote best practices in software engineering, sharing insights with team members about theoretical and technical advancements Contribute to industry-leading innovations that translate into great impact for our clients in casework Stay current with emerging trends and technologies in cloud computing, data analysis, and software engineering Travel is required (30%) ABOUT YOU Bachelor's degree in Computer Science or a related technical field Master's degree in Computer Science, Engineering, or a related technical field is a plus Relevant academic or industry experience in web development, programming languages, version control, software design pattern, infrastructure and deployment, integration and unit testing implementation 4 years minimum experience Working knowledge (2-3 years) of Python** Experience with server-side frameworks and technologies such as FastAPI, Node.js, Flask. Experience with Cloud platforms and services (AWS, Azure, GCP, etc.) E xperience with administering and managing Kubernetes clusters (EKS, GCP, or AKS) Experience with DevOps, CI/CD, Github Actions Strong computer science fundaments in data structures, algorithms, automated testing, object-oriented programming, performance complexity, and implications of computer architecture on software performance. Knowledge of data architecture, database schema design, database scalability and SQL Knowledge of client-side technologies such as React, Angular, Vue.js, HTML and CSS Awareness of agile development methodologies and principles Strong interpersonal and communication skills, including the ability to explain and discuss technicalities of solutions, algorithms and techniques with colleagues and clients from other disciplines Curiosity, proactivity and critical thinking Ability to collaborate with people at all levels and with multi-office/region teams",https://mx.linkedin.com/jobs/view/senior-ai-application-engineer-at-bain-company-4007871620,4007871620,"As a Senior Software Engineer, you will apply technical solutions to cutting-edge problems across various industries. This includes designing, developing, optimizing, and deploying new software engineering solutions and infrastructure for large-scale production. You will work closely with general consulting teams to identify software solutions to client business problems, provide technical guidance, and participate in all stages of the software development life cycle. Responsibilities include developing reusable frameworks, implementing best practices in software engineering, and staying current with emerging trends and technologies.","Python, FastAPI, Node.js, Flask, AWS, Azure, GCP, Kubernetes, DevOps, CI/CD, Github Actions, React, Angular, Vue.js, HTML, CSS, SQL",4+,Bachelor,True,4.0,0,1,0,1,1,0,0,0,0,1,1,1,0,0,1,0,0
"Principal, AI Application Engineer",Bain & Company,Monterrey Metropolitan Area,HYBRID,,Full-time,Business Consulting and Services,2024-09-08 11:26:01.950696,25,Engineering,,,"*Applications must be submitted in English* WHAT MAKES US A GREAT PLACE TO WORK We are proud to be consistently recognized as one of the world's best places to work, a champion of diversity and a model of social responsibility. We are currently ranked the #1 consulting firm on Glassdoor’s Best Places to Work list, and we have maintained a spot in the top four on Glassdoor's list for the last 13 years. We believe that diversity, inclusion and collaboration is key to building extraordinary teams. We hire people with exceptional talents, abilities and potential, then create an environment where you can become the best version of yourself and thrive both professionally and personally.  We are publicly recognized by external parties such as Fortune, Vault, Mogul, Working Mother, Glassdoor and the Human Rights Campaign for being a great place to work for diversity and inclusion, women, LGBTQ and parents. WHO YOU'LL WORK WITH As a member of Bain’s Advanced Analytics Group, you’ll join a talented team of diverse and inclusive analytic and engineering professionals who are dedicated to solving complex challenges for our clients. We work closely with our generalist consultants and clients to develop data-driven strategies and innovative solutions. Our collaborative and supportive work environment fosters creativity and continuous learning, enabling us to consistently deliver exceptional results. WHAT YOU'LL DO As an Expert Manager, Software Engineering, you will lead the development and application of technical solutions to address complex problems in various industries. You will guide a diverse engineering team through the entire engineering life cycle. Your responsibilities will include designing, developing, optimizing, and deploying cutting-edge software engineering solutions and infrastructure at the production scale required by the world’s largest companies. Collaborate closely with and influence general consulting teams to identify software solutions to client business problems, and to appropriately scope, prioritize and execute those solutions A technical leader responsible for end-to-end technical solution delivery on client cases (from solution architecture to hands-on development work) Lead key parts of the software development life cycle, including architecture design, writing clean code, conducting code reviews, writing documentation, unit/integration tests, identifying issues and resolutions Participate in expert client advisory activities that require deep expertise in software engineering with distributed systems, AI and application architecture Collaborate on (or lead) the development of re-usable common frameworks, model and components that can be highly leveraged to address common software engineering problems across industries and business functions Work with the team and other senior leaders to create a great working environment that attracts other great engineers Coach engineering teams at our clients and partners to raise their capabilities and ensure that our work is successfully deployed to the highest standards Drive best demonstrated practices in software engineering, and share learnings with team members in AAG about theoretical and technical developments in software engineering Drive industry-leading innovations that translate into great impact for our clients in case work Act as PD Advisor as needed Participate in recruiting and onboarding for other team members Travel is required (30%) ABOUT YOU Master's degree in Computer Science, Engineering, or a related technical field Relevant professional hands-on experience in web development, programming languages, version control, software design pattern, infrastructure and deployment, integration and unit testing implementation Commercial acumen and understanding of business models 7 years minimum experience 4 years minimum at Lead or Staff level, or equivalent Track record of leading and collaborating on strategic initiatives Experience in shipping production, applications and data analytics products Expert knowledge (5+ years) of Python** Deep experience with additional server-side frameworks and technologies such as FastAPI, Node.js, Flask. Experience with Cloud platforms and services (AWS, Azure, GCP, etc.) Experience working in accordance with DevSecOps principles, and familiarity with industry deployment best practices using CI/CD tools, MLOps, LLMOps and infrastructure as code (Jenkins, Docker, Kubernetes, and Terraform) Strong computer science fundaments in data structures, algorithms, automated testing, object-oriented programming, performance complexity, and implications of computer architecture on software performance. Experience with data architecture, database schema design, database scalability and SQL Experience with client-side technologies such as React, Angular, Vue.js, HTML and CSS Understanding of data security and privacy regulations, key topics in cybersecurity, authentication and authorization mechanisms (including cloud IAM) Experience working according to agile principles Strong interpersonal and communication skills, including the ability to explain and discuss technicalities of solutions, algorithms and techniques with colleagues and clients from other disciplines Curiosity, proactivity and critical thinking Ability to collaborate with people at all levels and with multi-office/region teams Ability to work independently and juggle priorities to thrive in a fast paced and ambiguous environment, while also collaborating as part of a team in complex situations",https://mx.linkedin.com/jobs/view/principal-ai-application-engineer-at-bain-company-4007146382,4007146382,"As an Expert Manager in Software Engineering, you will lead the development and application of technical solutions to address complex problems across various industries. You will guide a diverse engineering team throughout the entire engineering life cycle, designing, developing, optimizing, and deploying cutting-edge software engineering solutions at the scale required by major companies. Responsibilities include collaborating with consulting teams to identify software solutions, leading the software development life cycle, participating in expert client advisory activities, and driving best practices in software engineering. You will also be involved in recruiting and onboarding new team members, with 30% travel required.","Python, FastAPI, Node.js, Flask, AWS, Azure, GCP, Jenkins, Docker, Kubernetes, Terraform, React, Angular, Vue.js, HTML, CSS, SQL","7 years minimum, 4 years at Lead or Staff level",Masters,True,4.0,0,1,0,1,1,0,0,0,0,1,1,1,0,0,1,0,0
Data Engineer / Visualization,NEORIS,Monterrey Metropolitan Area,HYBRID,Entry level,Full-time,IT Services and IT Consulting,2024-09-14 11:26:01.950696,25,Information Technology,,,"En NEORIS es un acelerador Digital que ayuda a las compañías a entrar en el futuro, teniendo 20 años de experiencia como Socios Digitales de algunas de las mayores compañías del mundo. Somos más de 4,000 profesionales en 11 países, con nuestra cultura multicultural de startup en donde cultivamos innovación, aprendizaje continuo para crear soluciones de alto valor para nuestros clientes. Data Engineer Visualizations con más de 2.5 años de experiencia para unirse a nuestro equipo de tecnología. Responsabilidades Encargado de la ingeniería de datos y visualización para el proyecto de Treceability, con una visión global. Requisitos Ingeniero de Datos para el proyecto de Treceability, Conocimiento en Modelado de Datos, en Ingesta de Datos y visualización. Ingeniero de Datos para el proyecto de Treceability Conocimiento en Modelado de Datos, en Ingesta de Datos y visualización +2-3 años SQL DB +1 año Experiencia en Snowfalake DB, deseable +1 año Experiencias en Ingesta de Datas vis ETLs, o Replicadores Five Tran o Informatica +2 años Experiencia en Power BI. + Ofrecemos 100% Nominal Legal Benefits Benefits Package Wellness Program Professional development plan Multicultural collaboration Come and meet us on: http://www.neoris.com , on Facebook, LinkedIn, Twitter, or Instagram @NEORIS. Hector Antonio Hernandez Sanchez / sanchez.hector@neoris.com",https://mx.linkedin.com/jobs/view/data-engineer-visualization-at-neoris-4025921741,4025921741,"We are looking for a Data Engineer for the Traceability project, responsible for data engineering and visualization with a global perspective. The candidate should have knowledge in Data Modeling, Data Ingestion, and visualization, with over 2-3 years of experience in SQL DB, 1 year of experience in Snowflake DB, and over 2 years of experience in Power BI. Experience with ETL data ingestion or replicators like FiveTran or Informatica is also desired.","SQL, Snowflake, Power BI, ETL, Data Modeling",2-3,,False,2.0,0,0,0,0,0,1,1,1,1,1,0,0,0,0,0,0,0
Data Engineer,Azkait,Monterrey Metropolitan Area,HYBRID,,Full-time,"Technology, Information and Internet",2024-07-17 11:26:01.950696,25,Information Technology,,,"AZKAIT es una empresa Mexicana que busca y conecta el mejor talento IT con empresas Latinoamericanas y de Estados Unidos. Estamos en la búsqueda de tu talento como Data Engineer. Requisitos: Data Engineer Como Data Engineer trabajarás junto a una importante empresa multinacional de soluciones comerciales de consultoría y de servicios de TI. Requisitos: A partir de 4 años de experiencia como Data Engineer Inglés conversacional (se hará evaluación) Licenciatura o Ingeniería concluida Skills: Python Pyspark y Hive SQL Airflow Azure Snowflake (básico) Responsabilidades: Trabajar en soluciones de ingeniería de datos, perfilar datos, desarrollar una ingesta eficiente y construir capas de datos semánticos. Gestión de flujo de trabajo y canalización de datos: Airflow, Azure DataFlow, etc. Servicio DataBricks Servicios en la nube y herramientas de análisis de datos: Databricks, Snowflake, Azure ADLS Gen2, Azure/GCP Beneficios: Esquema de contratación 100% nómina Sueldo competitivo de hasta $90,000 mensuales brutos Modalidad de trabajo híbrido SGMM para el colaborador y su familia directa Seguro de Vida Vales de despensa PTU de ley Aguinaldo de 30 días Vacaciones de ley Certificaciones gratuitas Lugar de trabajo: Modalidad de trabajo híbrido Es importante contar con disponibilidad para presentarse en las oficinas más cercanas ubicadas en: CDMX, Querétaro, Nuevo León, Jalisco",https://mx.linkedin.com/jobs/view/data-engineer-at-azkait-3954350879,3954350879,"As a Data Engineer, you will work with a significant multinational company providing consulting and IT services. The responsibilities include working on data engineering solutions, profiling data, developing efficient ingestions, and building semantic data layers. You will also manage workflows and data pipelines using tools like Airflow and Azure DataFlow.","Python, Pyspark, Hive SQL, Airflow, Azure, Snowflake, Databricks, Azure ADLS Gen2, GCP",4+ years,Bachelor,True,4.0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0
Data Engineer,SEIDOR Analytics,Monterrey Metropolitan Area,HYBRID,Entry level,Full-time,Information Technology & Services,2024-09-13 11:26:01.950696,25,Information Technology,,,"En SEIDOR Analytics buscamos perfiles de Data Engineer para incorporarse a nuestro equipo de México. ¿Qué es lo que necesitas para formar parte de nuestro TEAM? ✔Experiencia comprobable en posición similar ✔Conocimientos de herramientas de base de datos, datawarehousing y ETL ✔Experiencias con alguna de las siguientes tecnologías: SAP (SAP Datawarehouse Cloud, SAP Analytics Cloud, SAP BW, HANA, etc.) / Cloud Analytics (Azure / AWS / Snowflake) ✔Inglés (no excluyente) ✔Comunicación efectiva, orientación al cliente y trabajo en equipo serán competencias valoradas para este perfil ✔Estar ubicados en Monterrey o CDMX. ¿Qué ofrecemos? ✔Formar parte de un gran equipo internacional, con más de 20 años de experiencia en Analytics, orientado al logro y al cliente. ✔Día libre de cumpleaños ✔Obsequios en fechas especiales ✔Clases de inglés in company ✔Capacitación continua y posibilidad de certificarte con nuestros partners. Envíanos tu CV a: talent@seidoranalytics.com para conocerte, contarte sobre la propuesta y nuestros beneficios.",https://mx.linkedin.com/jobs/view/data-engineer-at-seidor-analytics-4025659981,4025659981,"In SEIDOR Analytics, we are looking for Data Engineer profiles to join our team in Mexico. You need proven experience in a similar position, knowledge of database tools, data warehousing, and ETL. Experience with technologies such as SAP (SAP Datawarehouse Cloud, SAP Analytics Cloud, SAP BW, HANA, etc.) / Cloud Analytics (Azure / AWS / Snowflake) is required. English is not mandatory. Effective communication, customer orientation, and teamwork will be valued skills for this profile.","SAP, SAP Datawarehouse Cloud, SAP Analytics Cloud, SAP BW, HANA, Azure, AWS, Snowflake, ETL, Data Warehousing",Proven experience required,,False,,0,0,0,1,0,1,1,0,0,0,0,0,0,0,0,0,0
Data Analyst,Dematic,Monterrey Metropolitan Area,HYBRID,Associate,Full-time,"Transportation, Logistics, Supply Chain and Storage",2024-09-08 11:26:01.950696,116,Purchasing,Analyst,,"Company Overview Dematic is an intralogistics innovator who designs, builds, and supports intelligent, automated solutions for manufacturing, warehouse and distribution environments for customers powering the future of commerce. With engineering centers, manufacturing facilities and service centers located in more than 25 countries, Dematic’s global network of 8,000 employees have helped achieve more than 6,000 worldwide customer installations for some of the world’s leading brands. Headquartered in Atlanta, Georgia, Dematic is a member of KION Group, a global leader in industrial trucks, supply chain solutions and related services, and a leading provider of warehouse automation. Job Summary Dematic member of KION Group is seeking a qualified candidate for the role of Data Analyst, Global Data Management to join our organization to drive consistent, complete, and accurate data and high-quality procurement decision-making. The Analyst’s primary responsibility is to enable improved procurement performance by conducting analysis on procurement data. The candidate will work within the Global Procurement Functions – Governance & Process Excellence group supporting Category Leads as well as other Procurement colleagues to meet the company’s business requirements. In this role, the Analyst will assist Procurement colleagues in multiple KION sites across North America, and Europe, with high-quality procurement master data including supplier information, spend breakdown, procurement saving initiatives primarily. This is What You Will do in This Role: Maintain standard and governance across Business Units on data management Receive and document Business Intelligence and reporting requirements from stakeholders }Provide procurement data and reporting to the Procurement organization to identify synergies between business and operating units and support decision making process Provide accurate, reliable and updated data to obtain category KPIs to support strategy implementation Ensure data availability and readiness to timely support strategic decisions and CTO flight plan implementation Provide good quality and reliable data to analyze KION supplier base to identify opportunities Keep key procurement data up to date in procurement tools Identify and extract relevant data and run analysis Rollout KION Procurement Data Business Intelligence dashboards Define target and actions to measure data in terms of accuracy, completeness, consistency, timeliness, integrity, uniqueness What We are Looking For: Bachelor’s Degree in Engineering, Computer Science, Supply Chain, Accounting, Finance or Statistics , or related. 3+ years’ experience in Procurement, Supply Chain, Finance or Business Familiarity with purchasing and supply chain management and procurement processes Advanced analytical skills with expertise in Microsoft Excel (MS Excel) – Pivot table minimum, Power Point and Business Intelligence (BI) tools like Power BI, Tableau or Qlik Experience with Snowflake or other SQL Database system Experience in working with SAP Module MM, knowledge for FI module (Preferred) Manipulate large data sets through standard analytics software packages and applications Capability with data inquiry / investigation Data consolidation & presentation skills. Ability to analyze, synthesize information from diverse sources, present findings clearly / concisely, and communicate that analysis effectively to business partners Strong communicator and ability to manage/prioritize multiple key activities simultaneously Self-driven individual, able to work with minimal direction to consistently look for opportunities Work cross-functionally in a culturally diverse environment and quickly build strong rapport and relationships with Procurement partners, including interaction with Senior Leaders and working across multiple regions/time",https://mx.linkedin.com/jobs/view/data-analyst-at-dematic-4015082180,4015082180,"Dematic is seeking a qualified candidate for the role of Data Analyst, Global Data Management to drive consistent, complete, and accurate data for high-quality procurement decision-making. The primary responsibility is to enable improved procurement performance by conducting analysis on procurement data. The Analyst will assist Procurement colleagues across multiple KION sites with high-quality procurement master data and provide accurate data and reporting to support decision-making processes.","Microsoft Excel, Power BI, Tableau, Qlik, Snowflake, SQL, SAP MM, SAP FI",3+ years,Bachelor,True,3.0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0
Data Engineer,Chubb,Monterrey Metropolitan Area,HYBRID,Entry level,Full-time,Insurance,2024-09-15 11:26:01.950696,43,Information Technology,,,"Job Description With you, Chubb is better! Are passionate with data infrastructure, metrics and coding? Do you love creating pipelines to support business? Would you like to be a member of a fun working environment where your innovative projects make a real impact? Then, check this outstanding opportunity in our new Technology Hub in Mexico – CBSM (Chubb Business Services Monterrey) as a Data Engineer. If you are a tech lover and are raring to develop your career join our growing, pioneer, diverse team within one of the largest companies in the world, we would love to hear from you! The Opportunity Your Responsibilities for this role may include, but are not limited to: Conceptualize, support, and drive the data architecture for multiple large-scale projects as well as recommend solutions to improve processes. Integrate data from various sources and build robust, multi-functional data assets to support analytics. Responsible for data asset design, development, integration, and optimization. Must love coding – prepare to spend more than 80% of the time on hands-on development with groundbreaking technologies. Gatekeeper of end-to-end applications and frameworks ranging from system programming to micro-services to simple front-end applications Build pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts. Moreover, clean, unify and organize messy and complex data sets for easy access and analysis. Collaborate with others to understand data needs, representing key data insights in a meaningful way. Ability to own complete project or a subject area delivery while leading team members in a scrum setting. Design, build, and launch collections of sophisticated data models and visualizations that support multiple use cases across different products or domains. Solve our most exciting data integration problems, applying optimal ETL patterns, frameworks, query techniques, sourcing from structured and unstructured data sources. Be the point of reference for solving a challenging technical problem Knowledge, Skills, And Abilities At least 4 years of data/software engineering experience including data analysis, design and integration/ETL. Good knowledge of Informatica Intelligent Cloud Services (IICS) Strong knowledge of Python Experience with SQL Bonus points for PySpark Databricks Snowflake NoSQL Data Modelling Our team makes a difference, every time. For this reason, we offer in return! We offer hybrid working model, explicit, structured career development, a competitive salary package, annual bonus, private medical cover, monthly allowance for lunch, continuous learning experiences, work in a fun, lively environment with mentoring from our groundbreaking senior mentors. Integrity. Client Focus. Respect. Excellence. Teamwork Our core values instruct how we live and work. We’re an ethical and honest company that’s wholly committed to its clients. A business that’s engaged in mutual trust and respect for its employees and partners. A place where colleagues perform at the highest levels. And a working environment that’s collaborative and encouraging. Diversity & Inclusion. At Chubb, we consider our people our chief competitive advantage and as such we treat colleagues, candidates, clients, and business partners with equality, fairness, and respect, regardless of their age, disability, race, religion or belief, gender, sexual orientation, marital status or family circumstances. We strive to achieve an environment where all colleagues feel comfortable performing to their full potential and are recognized for their contributions. Many voices, One Chubb!",https://mx.linkedin.com/jobs/view/data-engineer-at-chubb-3897093237,3897093237,"As a Data Engineer, you will conceptualize, support, and drive the data architecture for multiple large-scale projects, recommend solutions to improve processes, integrate data from various sources, and build robust, multi-functional data assets to support analytics. You will spend over 80% of your time on hands-on development with technologies, build pipelines, dashboards, and systems for easier development of data artifacts, and collaborate with others to understand data needs.","Python, SQL, Informatica Intelligent Cloud Services (IICS), PySpark, Databricks, Snowflake, NoSQL, ETL, Data Modelling",4,,True,4.0,0,0,1,0,0,0,1,0,0,1,0,0,0,0,1,0,0
Data Platform Engineer Manager,Accenture México,Monterrey Metropolitan Area,HYBRID,Mid-Senior level,Full-time,Business Consulting and Services,2024-09-13 11:26:01.950696,25,Engineering,Information Technology,,"DARE TO BE A PART OF THE CHALLENGE! COME AND JOIN OUR TEAM TOGETHER WE CAN MAKE THE DIFFERENCE! Did you know that Accenture is leading the digital transformation in the World? Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Our main purpose is to collaborate with our clients, so they can become high-performance businesses. Accenture is present in more than 200 cities, 49 countries and approximately 732,000 employees worldwide. We Offer Career development according to your profile and interests. Work in one of the best companies and feel proud. Access to an innovative methodology and tools. Direct contact with experts worldwide. Use of work schemes and cutting-edge technologies. Constant training. Work environment based on teamwork and collaboration. Participation in International Projects Skills: +12 years of experience Python SQL AWS S3 Data Management background Qlik Replicate Informatica Scala (Spark) Knowledge: Cloud Silicon Firmware Engineering Python Programming Language Data Architecture Principles Platform Engineering",https://mx.linkedin.com/jobs/view/data-platform-engineer-manager-at-accenture-m%C3%A9xico-3990355001,3990355001,"Accenture is leading the digital transformation globally by providing a broad range of services in strategy, consulting, digital, technology, and operations. The role involves working with cutting-edge technologies, participating in international projects, and accessing innovative methodology and tools.","Python, SQL, AWS S3, Qlik Replicate, Informatica, Scala, Spark",12+ years,,True,12.0,0,0,1,1,0,0,0,0,1,1,0,0,0,0,1,0,0
Security Engineer Leader (Data Protection & Identities),The Home Depot México,Monterrey Metropolitan Area,HYBRID,Mid-Senior level,Full-time,Retail,2024-09-10 11:26:01.950696,25,Information Technology,,,"The Home Depot México está en búsqueda de talento para la posición de Security Engineer Leader (Data Protection & Identities) con sede en San Pedro Garza García, N.L. Objetivo del puesto: Asegurar la confidencialidad, integridad y disponibilidad de los activos de información y los sistemas encargados de almacenar, procesar y transmitir estos activos de información. A través de una metodología de robustecimiento y aseguramiento de aplicativos, una estrategia de prevención de fuga de información. Principales Funciones: Responsable de la gestión de identidad y accesos (Identity Access Management). Supervisión, gestión y revisión de controles y políticas de accesos y permisos. Protección de datos y encriptación (Data Protection). Implementar y mantener reglas o controles de protección de datos y asegurar cumplimiento con la regulaciones existentes en México. Herramientas de gestión de password y accesos RSA y CyberArk. Gestión de soluciones de seguridad de accesos así como, soluciones o herramientas de accesos privilegiados (CyberArk). Gestión de soluciones de encripción (voltage), monitoreo de alertas DLP (Data Lost Protection). Gestión de certificados (internos/externos). Gestión de herramientas de protección y encripción de bases de datos. Apoyar el proceso de Auditoría y Certificación de las diversas normas, leyes y regulaciones a las que está sujeto THDM. Requisitos: Carrera profesional terminada en Ing. En Negocios y Tecnología o similares. Inglés avanzado. Experiencia en puesto similares de 3 a 5 años. Conocimiento en ciclo de vida de las identidades (IAM). Conocimiento en gestión de accesos privilegiados (CyberArk, RSA). Práctica de protección y fuga de información (DLP). Herramientas de encriptación (Voltage). Si cumples con el perfil y esta oportunidad es de tu interés, ¡postúlate por este medio! Todos nuestros procesos de reclutamiento y selección son incluyentes y libres de discriminación; sin importar género, edad, nacionalidad, raza, cultura, religión, estado civil, creencias, discapacidad, orientación sexual, identidad y expresión de género.",https://mx.linkedin.com/jobs/view/security-engineer-leader-data-protection-identities-at-the-home-depot-m%C3%A9xico-4020466138,4020466138,"The Home Depot México is seeking a Security Engineer Leader (Data Protection & Identities) to ensure the confidentiality, integrity, and availability of information assets and systems responsible for storing, processing, and transmitting this information. This includes managing identity and access (Identity Access Management), overseeing controls and access policies, protecting data and encryption (Data Protection), and ensuring compliance with regulations in Mexico.","Identity Access Management, Data Protection, RSA, CyberArk, DLP, Voltage",3 to 5 years,Bachelor,True,3.0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
Data Analyst,Chubb,Monterrey Metropolitan Area,HYBRID,Entry level,Full-time,Insurance,2024-09-08 11:26:01.950696,25,Information Technology,,,"Job Description Overview: Chubb's North America data delivery team provides business insights, data management, and business and data analysis to North America. As a Data Analyst, you will be responsible for conducting a detailed analysis of various data sources to identify trends, patterns, and insights that will support strategic decision-making. Additionally, you will perform quality assurance tasks to ensure data accuracy and integrity across our systems. The ideal candidate will possess strong analytical skills, advanced knowledge of querying languages, and a keen eye for detail. Role Summary: Partner with business teams to analyze requirements and identify data sources needed for analytics/reporting applications with medium level complexity Establish open data standards, metadata management policies and data classifications. Conduct full data lifecycle analysis to develop new insights for analytics and reporting dashboards Partner with business and tech teams to develop testing requirements, procedures and corrective actions to ensure data products meet quality standards Provide recommendations to address data quality issues with source systems. Communicate approaches with cross functional teams Establish open data standards, metadata management policies and data classifications Responsibilities: Comprehend and adhere to all data security policies and procedures Create data tools for analytics and data scientist team members Build analytical tools to provide actionable insights into key business KPIs, etc Work with data engineers to optimize pipelines for scalability and data delivery Qualifications Functional Competencies Working knowledge with data and analytics framework supporting data lakes, warehouses, marts, reporting, etc Experience with data tools for visualizations, analytics and reporting Knowledge of testing policies, procedures and the role testing performs within the software development lifecycle Strong analytical skills with ability to research, assess and develop observations/findings Ability to communicate findings, approaches to cross functional teams and stakeholders. Technical competencies 3+ years' hands-on experience with a data science background Some programming skills in Java, Python and SQL Clear hands-on experience with database systems - Cloud technologies (e.g. AWS, Azure, Google), in-memory database systems (e.g. HANA, Hazel cast, etc) and other database systems - traditional RDBMS (e.g. Teradata, SQL Server, Oracle), and NoSQL databases (e.g. Cassandra, MongoDB, DynamoDB) Education, Knowledge, Experience: Background in SQL, databases and/or data science OR BS/MS in software engineering, computer science, mathematics Experience working with global teams is a must. English proficiency is a must.",https://mx.linkedin.com/jobs/view/data-analyst-at-chubb-4018776894,4018776894,"As a Data Analyst, you will be responsible for conducting a detailed analysis of various data sources to identify trends and insights that support strategic decision-making. Additionally, you will ensure data accuracy and integrity across systems. This role involves partnering with business teams to analyze requirements, establishing data standards and classifications, and developing testing requirements to ensure quality standards of data products. Responsibilities include creating data tools, building analytical tools, and working with data engineers to optimize pipelines for scalability and delivery.","Java, Python, SQL, AWS, Azure, Google Cloud, HANA, Hazelcast, Teradata, SQL Server, Oracle, Cassandra, MongoDB, DynamoDB",3+ years,Bachelor,True,3.0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0
Data Engineer Analyst,NEORIS,Monterrey Metropolitan Area,HYBRID,Entry level,Full-time,IT Services and IT Consulting,2024-09-14 11:26:01.950696,25,Information Technology,,,"NEORIS is a Digital accelerator that helps companies enter the future, having 20 years of experience as Digital Partners of some of the largest companies in the world. We are more than 4,000 professionals in 11 countries, with our multicultural startup culture where we cultivate innovation and continuous learning to create high-value solutions for our clients. We are looking for a Data Engineer Analyst: (Hybrid position in Monterrey) Controls and coordinates the approved commercial data process with rules, information, data, KPIs, times and actions to improve. Advise and manage all commercial efforts aimed at improving the experience of our clients in the Business processes. Main Responsibilities Reporting systematic errors and other data issues related to the data and information under governance Making corrections to data or data systems Identifying root causes of recurring errors and reporting these for potential remediation Reporting incidents of non-compliance to approved data governance policies and procedures Recommending new data governance policies and procedures or modifications to existing data governance policies and procedures based on new or emerging business practices that impact the data and information under governance Actively promote and communicate data governance to all USA Data Community members Provide necessary data-related training Design and implement procedures and standards as to ensure conformance with the data governance policies Collect and organize data specifications and metadata, such as: Business glossary, Data dictionaries, Data quality rules, Business rules including regulatory compliance, Reference data management, Data Issue tracking Promote Data Culture and Data Sharing Behavior across business units. Enforce Safe and Responsible Behaviors in the Data Mgmt. Processes Enforce Data Sharing practices. Review and ensure proper Data Assets Mgmt. Supervise proper practices to make sure Data Completeness and Integrity in the Data creation., Data processing and Data archiving. Observe and enforce local (global and legal normative and Information Security policies Requirements Fluent English and Spanish Academic Background: Analytics master’s degree or similar, 2 - 3 years in data management areas or similar Areas of expertise: Business / Operation, Process & IT, Analytics, adoption of digital tools Technical Skills required by role: Software skills for data collection and presentation, Advanced Excel, Statistical programming knowledge, Ability to articulate data-driven decisions, ability to summarize and present data, well versed in the latest innovations and trends in the market related to data manipulation product and services. Programming languages: SQL and Python or similar. Soft Skills: Self-motivated, highly engaged, problem solving, motivated for digital technology, managing uncertainty, critical thinking, time management of projects and relationships We Offer 100% nominal scheme. Professional Growth Dynamic work environment Benefits plan. Legal benefits Development Opportunities We invite you to get to know us at http://www.neoris.com, Facebook, LinkedIn, Twitter or Instagram: @NEORIS. Arantza Cervantes",https://mx.linkedin.com/jobs/view/data-engineer-analyst-at-neoris-4025921745,4025921745,"We are looking for a Data Engineer Analyst who controls and coordinates the approved commercial data process with rules, information, KPIs, and actions to improve the client experience in business processes. Responsibilities include reporting errors, managing data governance, and promoting data culture.","SQL, Python, Advanced Excel, Statistical programming",2 - 3,Masters,True,2.0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,1,0,0
Data Platform Engineer Senior Analyst,Accenture México,Monterrey Metropolitan Area,HYBRID,Mid-Senior level,Full-time,Business Consulting and Services,2024-09-13 11:26:01.950696,55,Engineering,Information Technology,,"DARE TO BE A PART OF THE CHALLENGE! COME AND JOIN OUR TEAM TOGETHER WE CAN MAKE THE DIFFERENCE! Did you know that Accenture is leading the digital transformation in the World? Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Our main purpose is to collaborate with our clients, so they can become high-performance businesses. Accenture is present in more than 200 cities, 49 countries and approximately 743,000 employees worldwide. Offer Career development according to your profile and interests. Work in one of the best companies and feel proud. Access to an innovative methodology and tools. Direct contact with experts worldwide. Use of work schemes and cutting-edge technologies. Constant training. Work environment based on teamwork and collaboration. Participation in International Projects Mandatory Skills: +4 years of experience Your primary skill in Python will be utilized to develop and maintain the platform. Utilize AWS development skills to optimize the performance of the data platform. Activities: As a Mid Level Data Platform Engineer, you will be responsible for designing, building, and maintaining clients data platform. You will work closely with the data science and machine learning teams to ensure the platform meets their needs.",https://mx.linkedin.com/jobs/view/data-platform-engineer-senior-analyst-at-accenture-m%C3%A9xico-3875043968,3875043968,"As a Mid Level Data Platform Engineer, you will be responsible for designing, building, and maintaining clients' data platform, working closely with data science and machine learning teams to ensure the platform meets their needs.","Python, AWS, Data Platform, Machine Learning",4+ years,,True,4.0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,1,0,0
Azure Data Engineer,Sequoia Connect,Monterrey Metropolitan Area,HYBRID,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-08 11:26:01.950696,25,Information Technology,,,"Our client is a global leader in next-generation digital services and consulting. They enable clients in more than 50 countries to navigate their digital transformation. With over four decades of experience in managing the systems and workings of global enterprises, they expertly steer their clients through their digital journey. They do it by enabling the enterprise with an AI-powered core that helps prioritize the execution of change. They also empower the business with agile digital at scale to deliver unprecedented levels of performance and customer delight. Their always-on learning agenda drives their continuous improvement through building and transferring digital skills, expertise, and ideas from their innovation ecosystem. We are currently searching for an Azure Data Engineer: Responsibilities: Work on a hybrid model in any of our client’s locations (Mexico City, Guadalajara, or Monterrey). Provide production support and development in a data engineering environment. Design, implement, and maintain robust and scalable data pipelines on Azure. Troubleshoot performance issues, identify root causes and apply fixes. Implement and manage CI/CD pipelines for data engineering projects using Azure DevOps. Requirements: 3+ years of experience designing, implementing, and maintaining data pipelines on Azure with services such as Azure Data Factory, Azure SQL Data Warehouse, Azure Analysis Services, or Azure Databricks/Synapse/Fabric. 2+ years of experience in data platform design/architecture with a multi-layered approach. 2+ years of experience in troubleshooting performance issues. 3+ years of experience in SQL. Ability to implement CI/CD pipelines for data engineering projects. Languages Advanced Oral English. Native Spanish. Note: Hybrid (Guadalajara, Mexico City, Monterrey) If you meet these qualifications and are pursuing new challenges, Start your application to join an award-winning employer. Explore all our job openings | Sequoia Career’s Page: https://www.sequoia-connect.com/careers/.",https://mx.linkedin.com/jobs/view/azure-data-engineer-at-sequoia-connect-4017678551,4017678551,"We are currently searching for an Azure Data Engineer responsible for providing production support and development in a data engineering environment. The role includes designing, implementing, and maintaining robust and scalable data pipelines on Azure, troubleshooting performance issues, and implementing CI/CD pipelines for data engineering projects using Azure DevOps.","Azure Data Factory, Azure SQL Data Warehouse, Azure Analysis Services, Azure Databricks, Azure Synapse, SQL, Azure DevOps, CI/CD",3+ years,,True,3.0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,0,0,0
Senior Data Engineer,Endava,Monterrey Metropolitan Area,HYBRID,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-08-16 11:26:01.950696,25,Information Technology,,,"Company Description Technology is our how. And people are our why. For over two decades, we have been harnessing technology to drive meaningful change. By combining world-class engineering, industry expertise and a people-centric mindset, we consult and partner with leading brands from various industries to create dynamic platforms and intelligent digital experiences that drive innovation and transform businesses. From prototype to real-world impact - be part of a global shift by doing work that matters. Job Description Our data team has expertise across engineering, analysis, architecture, modeling, machine learning, artificial intelligence, and data science. This discipline is responsible for transforming raw data into actionable insights, building robust data infrastructures, and enabling data-driven decision-making and innovation through advanced analytics and predictive modeling. As a Data Engineer at Endava you will be responsible for designing, implementing, and managing the data infrastructure of the projects. You will be work closely with data scientists, software engineers, and other stakeholders to ensure the availability, usability, and integrity of data. Responsibilities: Designing, building, and deploying solutions that increase product reliability and organizational efficiency Motivating and guiding the creation of effective CI/CD pipelines Providing mentorship and insight into DevSecOps best-practices Working with product teams to expose their requirements and support the above Improving reliability via root cause analyses, post-mortems, and using code to prevent recurrence Implementing effective monitoring and security scanning Assisting support teams in resolving issues Demonstrating and evangelizing state of the art technologies and practices that can be used to build and improve better workflows Discovering and implementing automation to reduce manual support requirements Providing emergency after-hours support if needed Qualifications Degree or diploma in Computer Sciences or related fields, or equivalent work experience 8-10 years of experience as a software engineer and writing Infrastructure-and Configuration-as-Code Excellent English written and verbal communication skills Highly proficient in AWS design and architecture Professional level AWS Certification a significant asset Highly experienced with Terraform and or AWS CloudFormation Experience with Infrastructure- and Configuration-as-Code Experience with CI/CD pipeline systems such as Jenkins and GitLab Experience with Git in a multi-team environment Some experience with containers and containers-as-a-service systems, such as EKS Experience with log aggregation systems such as Splunk, Datadog, or Sumo Logic Experience with APM solutions and infrastructure monitoring solutions an asset Desire to push themselves and learn new things Additional Information Discover some of the global benefits that empower our people to become the best version of themselves: Finance: Competitive salary package, share plan, company performance bonuses, value-based recognition awards, referral bonus; Career Development: Career coaching, global career opportunities, non-linear career paths, internal development programmes for management and technical leadership; Learning Opportunities: Complex projects, rotations, internal tech communities, training, certifications, coaching, online learning platforms subscriptions, pass-it-on sessions, workshops, conferences; Work-Life Balance: Hybrid work and flexible working hours, employee assistance programme; Health: Global internal wellbeing programme, access to wellbeing apps; Community: Global internal tech communities, hobby clubs and interest groups, inclusion and diversity programmes, events and celebrations.",https://mx.linkedin.com/jobs/view/senior-data-engineer-at-endava-3977692343,3977692343,"As a Data Engineer, you will be responsible for designing, implementing, and managing the data infrastructure of projects, collaborating with data scientists and software engineers to ensure data availability, usability, and integrity. You will design and deploy solutions to enhance product reliability and efficiency, create effective CI/CD pipelines, and mentor best practices in DevSecOps. Your role includes improving reliability through root cause analyses, implementing monitoring and security scanning, and supporting teams in issue resolution.","AWS, Terraform, AWS CloudFormation, CI/CD, Jenkins, GitLab, Git, EKS, Splunk, Datadog, Sumo Logic",8-10 years,,True,8.0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0
Data Platform Engineer Senior,Accenture México,Monterrey Metropolitan Area,HYBRID,Mid-Senior level,Full-time,Business Consulting and Services,2024-09-13 11:26:01.950696,33,Engineering,Information Technology,,"DARE TO BE A PART OF THE CHALLENGE! COME AND JOIN OUR TEAM TOGETHER WE CAN MAKE THE DIFFERENCE! Did you know that Accenture is leading the digital transformation in the World? Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Our main purpose is to collaborate with our clients, so they can become high-performance businesses. Accenture is present in more than 200 cities, 49 countries and approximately 732,000 employees worldwide. We Offer Career development according to your profile and interests. Work in one of the best companies and feel proud. Access to an innovative methodology and tools. Direct contact with experts worldwide. Use of work schemes and cutting-edge technologies. Constant training. Work environment based on teamwork and collaboration. Participation in International Projects Mandatory Skills: +4 years of experience Your primary skill in Python will be utilized to develop and maintain the platform. Utilize AWS development skills to optimize the performance of the data platform Activities: Responsibilities As a Mid Level Data Platform Engineer, you will be responsible for designing, building, and maintaining clients data platform. You will work closely with the data science and machine learning teams to ensure the platform meets their needs.",https://mx.linkedin.com/jobs/view/data-platform-engineer-senior-at-accenture-m%C3%A9xico-3875043971,3875043971,"As a Mid Level Data Platform Engineer, you will be responsible for designing, building, and maintaining clients' data platforms. You will utilize your primary skill in Python to develop and maintain the platform, while also applying AWS development skills to optimize performance. You will work closely with data science and machine learning teams to ensure the platform meets their needs.","Python, AWS, Data Platforms, Machine Learning",4+,,True,4.0,0,0,0,1,0,1,1,0,0,0,0,0,1,0,1,0,0
Data Governance and Management Engineer,Arca Continental,Monterrey Metropolitan Area,HYBRID,Associate,Full-time,Food and Beverage Services,2024-09-12 11:26:01.950696,25,Information Technology,,,"Nuestra compañía Arca Continental es una empresa dedicada a la producción, distribución y venta de bebidas no alcohólicas de las marcas propiedad de The Coca-Cola Company, así como botanas saladas bajo las marcas Bokados en México, Inalecsa en Ecuador y Wise en los Estados Unidos. Con una destacada trayectoria de más de 98 años, Arca Continental es la segunda embotelladora de Coca-Cola más grande de América Latina y una de las más importante del mundo. En su franquicia de Coca-Cola, la empresa atiende a una población de más de 119 millones en la región norte y occidente de México, así como en Ecuador, Perú, la región norte de Argentina y la región suroeste de Estados Unidos. Arca Continental cotiza en la Bolsa Mexicana de Valores bajo el símbolo ""AC"". Misión del puesto Diseñar, implementar y gestionar soluciones de Administración de Datos (Maestros, Transaccionales, de Referencia y Metadata) desde la perspectiva Técnica como de Gobierno de Datos, atendiendo los requerimientos de negocio y garantizando el ciclo de vida de los mismos en los diferentes dominios de AC (Clientes, Productos, etc.), para que la información requerida pueda ser utilizada para decisiones basadas en hechos, asegurando calidad, disponibilidad e integridad. Responsabilidades clave Implementar y Asegurar, Mejoras técnicas en los procesos para asegurar el correcto funcionamiento del Gobierno de Datos Diseñar y Documentar, Estándares y Reglas para el correcto funcionamiento del Ciclo de vida de los datos, considerando particularidades de cada una de las unidades de negocio dentro de AC Asegurar y mantener, La efectiva operación de las soluciones de calidad y administración para los procesos de datos maestros con la finalidad de garantizar el mantenimiento de la información de acuerdo con los estándares establecidos siempre impulsando la cultura Data Driven. Implementar y Desarrollar, Herramientas que permitan implementar el Gobierno de Datos dentro de AC, ya sean Data Catalog, MDM, Data Quality en todas las Unidades de Negocio de AC. Cualificaciones y requerimientos Título Universitario es requerido, preferentemente carreras de sistemas o afines Idiomas: Inglés Avanzado (Lectura, Escritura y Conversacional) Conocimiento avanzado en herramientas de Gestión de Datos e Información, como Administración de Datos Maestros / MDM, Calidad de Datos, Catalogo de Datos, Gobierno de Datos, etc. Conocimiento técnico avanzado en fuentes de datos de SAP (ECC, S/4, CRM, etc) Capacidad para modelar y comunicar ideas complejas a diferentes audiencias (interacción con equipos multidisciplinarios). Habilidad para administrar problemas de alta complejidad y analizarlos desde diferentes puntos de vista. Trabajo en equipo, planeación y gestión de proyectos. Características deseables Conocimiento de los procesos de negocio (Comercial, Cadena de Suministro, Finanzas) es un plus. Experiencia en la industria de Fast-Moving Consumer Goods Experiencia en proyectos globales. Nuestro compromiso Arca Continental es una empresa que ofrece igualdad de oportunidades. Las decisiones de contratación se toman sin distinción de raza o etnia, color, religión, nacionalidad, sexo, orientación sexual, identidad de género, edad, discapacidad, estatus de veterano protegido o alguna otra característica protegida por la ley. Nunca solicitaremos ningún tipo de pago para procesar su solicitud de empleo ni en ninguna otra etapa del proceso de selección. Nunca le envíe dinero a nadie que sugiera que puede darle empleo en Arca Continental. Si sospecha que ha recibido una oferta fraudulenta, repórtelo con las autoridades correspondientes.",https://mx.linkedin.com/jobs/view/data-governance-and-management-engineer-at-arca-continental-4022944549,4022944549,"The mission of the position is to design, implement, and manage Data Management solutions (Master, Transactional, Reference, and Metadata) from both a Technical and Data Governance perspective, addressing business requirements and ensuring their lifecycle across different domains. Key responsibilities include implementing technical improvements for effective Data Governance, designing and documenting standards and rules for data lifecycle management, ensuring the operation of data quality solutions, and developing tools for Data Governance across AC's business units.","Data Management, MDM, Data Quality, Data Governance, SAP (ECC, S/4, CRM), Data Catalog",,Masters,True,,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0
Data Engineer,NEORIS,Monterrey Metropolitan Area,HYBRID,Entry level,Full-time,IT Services and IT Consulting,2024-09-01 11:26:01.950696,62,Information Technology,,,"NEORIS es una aceleradora Digital que ayuda a las empresas a entrar al futuro, contando con 20 años de experiencia como Digital Partners de algunas de las empresas más grandes del mundo. Contamos con más de 4.000 profesionales en 11 países, con nuestra cultura startup multicultural donde cultivamos la innovación, el aprendizaje continuo para crear soluciones de alto valor para nuestros clientes. Estamos buscando Data Engineer Sr Descripción General Carreras de Ingeniería (Computación, Electrónica, Mecatrónica, etc.), Matemáticas Aplicadas, Actuaría, Física, Matemáticas, o carreras afines. Monterrey Nuevo León, México. Posición híbrida. Inglés intermedio avanzado Conocimiento en Modelado de Datos, en Ingesta de Datos, Deseable conocimiento en temas Logistica y SAP Requerimientos +3 Años SQL DB +1 Año Experiencia en Snowflake DB +2 Años Experiencias en Ingesta de Datas vis ETLs, o Replicadores Five Tran o Informatica +2 años Experiencia en Power BI. + SAP deseable Deseable conocimiento en temas Logistica y SAP Responsable de +2 personas Fivetran ETL, Power Bi, Snowflake Data Warehouse, Sql (Importante) Ofrecemos Esquema 100% Nominal Prestaciones de Ley Paquete de Beneficios Programa Bienestar Plan de desarrollo profesional Colaboración multicultural Te invitamos a conocernos en http://www.neoris.com, Facebook, LinkedIn, Twitter o Instagram: @NEORIS. Andrea Arantza Cervantes Romero",https://mx.linkedin.com/jobs/view/data-engineer-at-neoris-3977451215,3977451215,"We are looking for a Senior Data Engineer with a background in Engineering (Computer, Electronics, Mechatronics, etc.), Applied Mathematics, Actuarial Science, Physics, Mathematics, or related fields. The role is hybrid based in Monterrey, Nuevo León, Mexico. The ideal candidate should have intermediate to advanced English skills, experience in Data Modeling, Data Ingestion, and preferably knowledge in Logistics and SAP.","SQL, Snowflake, ETL, Fivetran, Informatica, Power BI, SAP",3+ years,,True,3.0,0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,0,0
Data Engineer Senior,NEORIS,Monterrey Metropolitan Area,HYBRID,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-08 11:26:01.950696,47,Information Technology,,,"NEORIS es un acelerador Digital que ayuda a las compañías a entrar en el futuro, teniendo 20 años de experiencia como Socios Digitales de algunas de las mayores compañías del mundo. Somos más de 4,000 profesionales en 11 países, con nuestra cultura multicultural de startup en donde cultivamos innovación, aprendizaje continuo para crear soluciones de alto valor para nuestros clientes. Principales Responsabilidades Estamos en búsqueda de Data Engineer Senior: Ingeniero de Datos SR para Modelado de Datos, Ingesta de Datos, Visualización de Datos Requerimientos +3 Años SQL DB +1 Año Experiencia en Snowflake DB +2 Años Experiencias en Ingesta de Datas vis ETLs, o Replicadores Five Tran o Informatica +2 años Experiencia en Power BI Posición híbrida en MTY Inglés intermedio B2, fluido. Deseable: Deseable conocimiento en temas Financieros, contables, y SAP Ofrecemos Esquema 100% Nominal Prestaciones de Ley Paquete de Beneficios Programa Bienestar Plan de desarrollo professional Colaboración multicultural Te invitamos a conocernos en http://www.neoris.com, Facebook, LinkedIn, Twitter o Instagram: @NEORIS. Andrea Arantza Cervantes Romero",https://mx.linkedin.com/jobs/view/data-engineer-senior-at-neoris-3931873676,3931873676,"We are looking for a Senior Data Engineer for Data Modeling, Data Ingestion, and Data Visualization.","SQL, Snowflake, ETL, Five Tran, Informatica, Power BI",3+ years,,True,3.0,0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,0,0
Data Scientist Intern,Siemens,Monterrey Metropolitan Area,ON-SITE,Internship,Full-time,Automation Machinery Manufacturing,2024-09-11 11:27:40.933821,193,Other,,,"We are looking for dedicated and talented people who tackle ever-changing challenges, customer needs, and questions from colleagues with clever concepts and creativity. We embrace change and work with curious minds re-inventing the future of work. Join us and let us focus together on what’s truly important: making lives better with new ideas and the latest technology around the world. Why you’ll love working for Siemens! Freedom and a healthy work- life balance– Embrace our flexible work environment with flex hours, telecommuting and digital workspaces. Solve the world’s most significant problems – Be part of exciting and innovative projects. Engaging, challenging, and fast evolving, cutting edge technological environment. Opportunities to advance your career and mentorship programs on a local and global scale. Contribute to our social responsibility initiatives focused on access to education, access to technology and sustaining communities and make a positive impact on the community. Participate in our celebrations, social events and offsite business events. Opportunities to contribute your innovative ideas and get rewards for them! Diversity and inclusivity focused. We are looking for a highly motivated and talented Data Scientist to join our team. The ideal candidate will be passionate about data analysis, statistical modeling, and creating data-driven solutions that drive the success of our company. What will you do? Perform complex data analysis to identify trends, patterns, and opportunities for improvement. Develop machine learning models for business decision making. Collaborate with other teams to understand and define data analysis requirements. Prepare and clean data for analysis. Communicate analysis results effectively through reports and presentations. Stay abreast of the latest trends in data science and related technologies. What will you need to succeed? Current student in Data Science, Statistics, Mathematics, Computer Engineering, or related field. Previous experience in data analysis and statistical modeling. Solid knowledge of data analysis tools such as Python, R, Pandas, Numpy, SciPy, Scikit-learn, Matplotlib and TensorFlow or similar tools. Experience using machine learning libraries and frameworks. Ability to effectively communicate technical results to non-technical audiences. Strong problem-solving skills and attention to detail. Ability to work as a team and adapt to a constantly changing business environment. Equal Employment Opportunity Statement Siemens is an Equal Opportunity and Affirmative Action Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to their race, color, creed, religion, national origin, citizenship status, ancestry, sex, age, physical or mental disability, marital status, family responsibilities, pregnancy, genetic information, sexual orientation, gender expression, gender identity, transgender, sex stereotyping, protected veteran or military status, and other categories protected by federal, state or local law. Location: Santa Catarina, Nuevo Leon",https://mx.linkedin.com/jobs/view/data-scientist-intern-at-siemens-4005909465,4005909465,"We are looking for a highly motivated and talented Data Scientist to join our team. The ideal candidate will be passionate about data analysis, statistical modeling, and creating data-driven solutions. Responsibilities include performing complex data analysis, developing machine learning models, collaborating with teams to define data requirements, preparing data for analysis, and effectively communicating results.","Python, R, Pandas, Numpy, SciPy, Scikit-learn, Matplotlib, TensorFlow, Machine Learning",,Undergraduate Student,True,,0,0,0,0,0,0,0,0,1,0,0,0,1,0,1,0,0
ML Engineer (Engineer Software Development),NEORIS,Monterrey Metropolitan Area,ON-SITE,Entry level,Full-time,IT Services and IT Consulting,2024-09-10 11:27:40.933821,42,Engineering,Information Technology,,"En NEORIS es un acelerador Digital que ayuda a las compañías a entrar en el futuro, teniendo 20 años de experiencia como Socios Digitales de algunas de las mayores compañías del mundo. Somos más de 4,000 profesionales en 11 países, con nuestra cultura multicultural de startup en donde cultivamos innovación, aprendizaje continuo para crear soluciones de alto valor para nuestros clientes. Principales Responsabilidades Estamos en búsqueda de ML Engineer: Soporte de Despliegue de los Modelos que construye el equipo de Ciencia de Datos. Mantenimiento y monitoreo de las aplicaciones en producción, seguimiento a troubleshooting. Requerimientos Graduados en Informática / Ingeniería en sistemas / Masters o especialización en Data Mining / Data Science / Machine Learning / AI / Computer Vision (deseable) +4 años background Desarrollo (Python) +4 años en tecnologías de almacenamiento ( Snowflake, SQL ) +3 años Web services technologies (Creación Microservicios con FastAPI, Django, Flask) Preferably FastAPI +2 años usando herramientas en la nube (Azure, AWS, GCP) / Tecnologías de orquestración o Deploy de modelos (+2 modelos) Docker Contexto de Tecnologías en la Nube (Azure, AWS, GCP) +2 años CI/CD (Pruebas Unitarias, Automatización de Deploy) +2 años aplicando modelos predictivos/prescriptivos (Machine Learning) Mantenimiento y Monitoreo aplicaciones en producción Participación en definición de Arquitecturas de Soluciones / Conocimiento de Mejores Prácticas Ingles conversacional (B2 / C1) Experiencia lidereando equipos remotos multiculturales / Experiencia en Logistics Maestrías, Certificaciones y Cursos sugeridos: IA, Machine Learning, Deep Learning, Cursos Programación, Python / R Soft skills: Solución Problemas (Inteligencia Lógica & Matemática), Atención al detalle, Proactividad, Autoaprendizaje & Autoinvestigación, Trabajo en Equipo, Articulado (buena comunicación oral, escrita), Analítico, Autoadministrado, Perfil Técnico, Innovador, Creativo, Enfocado a resultados y soluciones. Monterrey esquema híbrido, / Otros estados remoto Ofrecemos Esquema 100% Nominal Prestaciones de Ley Paquete de Beneficios Programa Bienestar Plan de desarrollo professional Colaboración multicultural Te invitamos a conocernos en http://www.neoris.com, Facebook, LinkedIn, Twitter o Instagram: @NEORIS. Andrea Arantza Cervantes Romero",https://mx.linkedin.com/jobs/view/ml-engineer-engineer-software-development-at-neoris-4002146229,4002146229,"We are seeking a Machine Learning Engineer to support the deployment of models built by the Data Science team. Responsibilities include maintaining and monitoring applications in production and troubleshooting issues. Candidates should have a background in Python development, experience with storage technologies like Snowflake and SQL, and familiarity with web service technologies such as FastAPI, Django, and Flask. Knowledge of cloud tools (Azure, AWS, GCP) is preferred, along with CI/CD experience.","Python, Snowflake, SQL, FastAPI, Django, Flask, Azure, AWS, GCP, Docker","4+ years in development, 4+ years in storage technologies, 3+ years in web services, 2+ years in cloud tools, 2+ years in CI/CD, 2+ years applying predictive/prescriptive models",Bachelor,True,2.0,0,1,0,1,1,0,0,0,0,1,0,0,0,0,1,0,0
AI Engineer,NEORIS,Monterrey Metropolitan Area,ON-SITE,Entry level,Full-time,IT Services and IT Consulting,2024-09-08 11:27:40.933821,106,Engineering,Information Technology,,"En NEORIS es un acelerador Digital que ayuda a las compañías a entrar en el futuro, teniendo 20 años de experiencia como Socios Digitales de algunas de las mayores compañías del mundo. Somos más de 4,000 profesionales en 11 países, con nuestra cultura multicultural de startup en donde cultivamos innovación, aprendizaje continuo para crear soluciones de alto valor para nuestros clientes. Estamos en búsqueda de AI Engineer: Monterrey híbrido/otros estados remoto Requerimientos Licenciatura o maestría en ciencias de la computación, ingeniería de software, inteligencia artificial, aprendizaje automático o un campo relacionado Experiencia en programación con lenguajes como Python o similares. Conocimiento profundo de las bibliotecas y marcos de trabajo de IA y aprendizaje automático como Scikit Learn, TensorFlow, PyTorch, Keras, etc. Experiencia en el desarrollo y la implementación de modelos de IA generativa Uso de langchain Uso de Bases de datos vectorizadas como Redis, Search AI. Familiaridad con las técnicas de procesamiento de datos y los algoritmos de aprendizaje automático. Familiaridad con herramientas de cloud (AWS, GCP o Azure), preferentemente Azure Manejo de colas (PUB/SUB, Queues ) Web apps (app services o azure/ lambda functions) Experiencia o al menos entendimiento de cómo funciona Docker para realizar paquetes de aplicaciones Experiencia con las bases de datos SQL y NoSQL. (SQL server, CosmosDB. MongoDB) Experiencia en llevar un proyecto end to end ( analisis hasta producción) Fluidez en inglés, tanto escrito como hablado. Deseable: Azure Bots (deseable) Re-entrenamiento de modelos de Generative AI (deseable) Certificaciones (opcional): Certificaciones en inteligencia artificial, aprendizaje automático o ciencia de datos de instituciones reconocidas pueden ser beneficiosas."" Ofrecemos Esquema 100% nómina. Crecimiento Profesional Ambiente laboral dinámimico Plan de beneficios. Prestaciones de ley Oportunidades de Desarrollo Te invitamos a conocernos en http://www.neoris.com, Facebook, LinkedIn, Twitter o Instagram: @NEORIS. Arantza Cervantes",https://mx.linkedin.com/jobs/view/ai-engineer-at-neoris-3984233060,3984233060,"We are looking for an AI Engineer in Monterrey, with hybrid or remote work options. Requirements include a bachelor's or master's degree in computer science, software engineering, artificial intelligence, machine learning, or a related field. Experience in programming with languages like Python or similar, deep knowledge of AI and machine learning libraries and frameworks such as Scikit Learn, TensorFlow, PyTorch, Keras, etc. Experience in the development and implementation of generative AI models. Use of langchain and vectorized databases like Redis, Search AI. Familiarity with data processing techniques and machine learning algorithms. Familiarity with cloud tools (AWS, GCP, or Azure), preferably Azure. Knowledge of queue management (PUB/SUB, Queues) and web apps (app services or Azure/lambda functions). Experience or at least understanding of how Docker works for application packaging. Experience with SQL and NoSQL databases (SQL Server, CosmosDB, MongoDB). Experience in carrying out an end-to-end project (from analysis to production). Fluency in English, both written and spoken.","Python, Scikit Learn, TensorFlow, PyTorch, Keras, Redis, Search AI, AWS, GCP, Azure, Docker, SQL, NoSQL",,Bachelor,True,,0,0,0,1,1,0,0,0,0,1,0,0,1,0,1,0,0
Sr. Data Scientist,Arca Continental,Monterrey Metropolitan Area,ON-SITE,Associate,Full-time,Food and Beverage Services,2024-08-25 11:27:40.933821,79,Information Technology,Sales,,"Sr Data Scientist - Forecast and Segmentation Team Arca Continental is the second largest Coca-Cola bottler in Latin America, with presence in 5 countries. We are looking for a Sr Data Scientist willing to take their skills to the next level. In this position you will be responsible for supporting, improving and creating next generation solutions across the organization. Please apply if you are a Data Scientist with a passion for crunching data, finding insights, taking models to production and have a business/product sense. Responsibilities You will be part of our success by: Design, deliver and iterate highly scalable code in close collaboration with the data engineering team, adhering to established standards of quality for documentation and coding. Apply statistical and machine learning techniques to problems related to forecasting and customer segmentation/classification to add value to our products. Take into production trained models and modeling pipelines in an agile framework. Serve as a mentor to Jr Data Scientists on your team. Design experiments, analyze results and produce trustworthy conclusions from them; present findings to stakeholders. Required Qualifications Bachelor’s degree in Computer Science, Mathematics, Engineering or related field, or a proven track of projects/courses for at least 1 year. At least 12 months of experience working with business centered, applied data science projects. Advanced coding skills for production-ready code in Python and SQL. Advanced experience in machine learning libraries like scikit-learn and Spark ML. Demonstrated knowledge of the theory behind traditional machine learning algorithms. Experience in or desire to learn big data technologies like Spark. Professional written and spoken English. Preferred Qualifications Experience in application deployment in cloud-based infrastructure (e.g. AWS, Azure, GCP). Experience in sale/demand forecasting. Knowledge of agile project development techniques (e.g. Scrum). Experience with deep learning models and frameworks. Passion for data-driven decision making. Employment Type Full-time, hybrid. Location Monterrey Area, Nuevo Leon, Mexico Contact Brissa Romero, brissa.romero@arcacontal.com",https://mx.linkedin.com/jobs/view/sr-data-scientist-at-arca-continental-4002829402,4002829402,"We are looking for a Sr Data Scientist willing to improve and create next generation solutions across the organization. Responsibilities include designing highly scalable code in collaboration with the data engineering team, applying statistical and machine learning techniques for forecasting and customer segmentation, and mentoring Jr Data Scientists. You will also design experiments, analyze results, and present findings to stakeholders.","Python, SQL, scikit-learn, Spark ML, AWS, Azure, GCP, Agile Methodologies, Scrum",1,Bachelor,True,1.0,1,0,1,1,0,0,0,0,0,1,0,0,1,0,1,0,0
Data Scientist Sr,NEORIS,Monterrey Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-01 11:27:40.933821,25,Engineering,Information Technology,,"NEORIS is a Digital accelerator that helps companies enter the future, having 20 years of experience as Digital Partners of some of the largest companies in the world. We have more than 4,000 professionals in 11 countries, with our multicultural startup culture where we cultivate innovation, continuous learning to create high-value solutions for our clients. We Are Looking For a Data Scientist Sr We are seeking a highly skilled and experienced Senior Data Scientist to join our dynamic team. The ideal candidate will lead core data-based projects to provide cutting-edge solutions to our business supply chain, support and mentor junior and experienced talent, and translate business needs into technical requirements or solutions. If you are passionate about data science and have a proven track record of delivering impactful results, we would love to hear from you. Main Responsibilities Project Leadership: Lead and manage core data-based projects aimed at optimizing and innovating our business supply chain processes. Mentorship: Support and mentor junior and experienced data scientists, fostering a collaborative and growth-oriented environment. Business Translation: Understand business needs and translate them into technical requirements or solutions, ensuring alignment with organizational goals. Data Analysis: Perform data manipulation, cleaning, and wrangling to prepare datasets for analysis. Machine Learning: Develop, implement, and evaluate machine learning models to solve complex business problems. Collaboration: Work closely with cross-functional teams to integrate data-driven solutions into business operations. Reporting: Communicate findings and insights to stakeholders through reports, dashboards, and presentations. Hybrid manner Monterrey, other locations remote (México) Requirements Educational Background: Bachelor's degree in a scientific or engineering field is required. A Master's or PhD is desirable. Experience: Minimum of 5+ years of work experience in data science. Technical Skills: Proficiency in Python for data analysis and machine learning. Strong experience querying SQL and NoSQL databases. Expertise in data manipulation, cleaning, and wrangling. Solid background in probability and statistics. Experience with machine learning models’ development and evaluation. Experience deploying data-based products as a solution to business needs. Familiarity with version control systems, particularly Git. Relevant exposure to libraries such as Pandas, NumPy, SciPy, Scikit-Learn, FastAPI, Streamlit. Familiarity with cloud services Azure/AWS/GCP. Analytical Skills: Strong problem-solving skills and the ability to think critically and analytically. Communication: Excellent verbal and written communication skills in english, with the ability to convey complex technical concepts to non-technical stakeholders. Desirable: Advanced Degrees: A Master's or PhD in a relevant field is highly desirable. Industry Experience: Previous experience in supply chain analytics or a related field. Tools & Technologies: Familiarity with additional data science tools and technologies such as R, Hadoop, Spark, or cloud platforms (AWS, Azure, GCP). Certifications: Relevant certifications in data science, machine learning, or related areas. Publications & Contributions: Contributions to the data science community through publications, open-source projects, or conference presentations. We Offer 100% Nominal Scheme Legal Benefits Benefits Package Wellness Program Professional development plan Multicultural collaboration Come and meet us on: http://www.neoris.com, on Facebook, LinkedIn, Twitter, or Instagram @NEORIS. Andrea Arantza Cervantes Romero",https://mx.linkedin.com/jobs/view/data-scientist-sr-at-neoris-3997051344,3997051344,"We are seeking a highly skilled and experienced Senior Data Scientist to lead core data-based projects, support and mentor junior talent, and translate business needs into technical requirements. Responsibilities include performing data analysis, developing and evaluating machine learning models, and collaborating with cross-functional teams to integrate data-driven solutions into business operations.","Python, SQL, NoSQL, Pandas, NumPy, SciPy, Scikit-Learn, FastAPI, Streamlit, Azure, AWS, GCP, Git",5+ years,Bachelor,True,5.0,0,1,0,1,0,0,0,0,0,1,0,1,1,0,1,0,0
Computer Vision Software Developer,SICK Sensor Intelligence,Monterrey Metropolitan Area,ON-SITE,Associate,Full-time,Automation Machinery Manufacturing,2024-09-12 11:27:40.933821,25,Information Technology,Engineering,,"***This position is in our SICK, Monterrey MX office. Located in the Valle Oriente area. The person will work in office Monday through Friday. ABOUT SICK: SICK is a leading global provider of intelligent sensors, systems and services for factory, logistics and process automation applications. With more than 1,000 patents, innovation and technology are at its core. This focus on innovation and “Sensor Intelligence” have allowed SICK to develop products and solutions for every phase of production in the automotive, packaging, electronics, food and beverage, consumer goods, storage and conveyor, robotics, material handling, oil and gas, chemical, power, maritime industries and more. In addition, SICK’s focus on Sensor Intelligence allows us to make Industry 4.0, or the Industrial Internet of Things, a reality for their customers. POSITION SUMMARY: As a Computer Vision software developer with SICK, you will be part of the Americas Engineering Hub team to develop and implement machine vision algorithms and solutions to proactively address a target industry or reactively on request to support a customer’s quality control project. You will collaborate closely with the sales and technical staffs in the North and South America region throughout the project life cycle. The computer vision technology stack that you will be working with consists of multiple platforms including OpenCV, Halcon, Python Machine Learning, convolutional neural network, tensor flow, C#, C++, .NET, Lua, ROS, ROS2. RESPONSIBILITIES: Implement 2D & 3D image processing such as extracting features, patterns, OCR, image stitching, point cloud analysis and tools development. Develop algorithm for quality inspection, anomaly detection and robot guidance. Sensor fusion: integration and calibration of different sensors (Mono/Stereo cameras, IMUs, depth cameras, time of flight camera, LiDAR, Laser Triangulation camera etc.) Integration of hardware - sensors, integration machine and software algorithms into a high-throughput low-latency pipeline. Write efficient, modular and easy to read code, review code from others. Support on-site project commissioning and deployment. Create technical documentations for internal and external use. QUALIFICATIONS: Bachelor’s degree in computer science, data science, engineering, or a related field. 2 years of experience in computer vision software development in an industrial automation environment. Work experience in OpenCV, TensorFlow, .NET, ROS, ROS2 or other computer vision platforms. Work experience in computer vision algorithms for OCR, Patten Matching, Point Cloud and Image rectification. Proficiency with C#, C++ and Python. Knowledge of computer vision frameworks, libraries, data structures, data modelling, and software development. Experience with AI technologies including Machine Learning and Deep Learning. Experience in working with 2D & 3D industrial cameras and devices. Writing and communicate in English fluently. Knowledge of DevOps methodologies and CI/CD principles and automation tools is a big plus. CORE COMPETENCIES: Ethics and Integrity Personal Growth and Learning, Customer Focus, Personal Accountable, Building Effective Relationships. How to Apply: ***While we commit to reviewing all applications. Only those selected for the next steps in the employment process will be contacted by a Recruiter. Thank you for the time you have invested in applying at SICK. Please email the following to matt.vanahn@sick.com English and Spanish version of your resume. Cover letter if desired. Salary expectations.",https://mx.linkedin.com/jobs/view/computer-vision-software-developer-at-sick-sensor-intelligence-4023705078,4023705078,"As a Computer Vision software developer, you will develop and implement machine vision algorithms and solutions to support quality control projects. Your responsibilities include implementing 2D & 3D image processing, developing algorithms for quality inspection, and integrating various sensors into a high-throughput pipeline. You will collaborate closely with sales and technical teams throughout the project lifecycle.","OpenCV, Halcon, Python, C#, C++, .NET, Lua, ROS, ROS2, TensorFlow, Machine Learning, Deep Learning",2,Bachelor,True,2.0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0
Prompt Engineer AI Data Engineer,Innova Solutions,Monterrey Metropolitan Area,ON-SITE,Entry level,Full-time,IT Services and IT Consulting,2024-09-09 11:27:40.933821,25,Engineering,Information Technology,,"As a AI Data Engineer, you will be: We are seeking a highly skilled Senior AI Data Engineer with specialized expertise in Generative AI models, particularly in configuring and optimizing LLMs such as Azure's ChatGPT, Llama, Mistral, and others. The ideal candidate will excel in prompt engineering, configuring contexts, and working with vector databases. This role will involve deploying and managing AI models within Azure Functions and containerized environments. Configure, deploy, and optimize generative AI models, focusing on LLMs like Azure's ChatGPT, Llama, Mistral, etc. Develop and refine prompt engineering strategies to enhance AI model performance and accuracy. Customize and configure AI model contexts to align with specific business requirements and objectives. Manage and integrate vector databases, ensuring seamless data flow and accessibility for AI models. Utilize Azure Functions and containerization techniques to deploy and maintain AI solutions. Work closely with cross-functional teams to integrate AI solutions into broader business processes. Stay updated on the latest advancements in generative AI and LLM technologies to continually enhance our AI capabilities. Candidate Must have skills: 5+ years of experience in a data engineering role. Extensive experience with LLMs such as OpenAI, Llama, Mistral, and others. Proven track record in deploying and configuring generative AI models, specifically within Azure environments. Strong ability to design and implement effective prompt engineering strategies. Experience with vector databases and their integration into AI systems. Proficiency in deploying AI solutions using Azure Functions and containerization (Docker, Kubernetes). Familiarity with various AI tools and frameworks, along with a solid understanding of software development best practices. Advanced English proficiency Good to have skills: Experience with machine learning models beyond generative AI, including traditional predictive models. Familiarity with DevOps tools and practices for continuous integration and deployment. Additional experience with other cloud platforms like AWS or Google Cloud Soft Skills: Excellent analytical and problem-solving abilities. Strong communication skills, with the ability to convey complex technical concepts to non-technical stakeholders. Proven ability to work effectively in a collaborative team environment. Flexibility to adapt to new challenges and evolving technologies Qualified candidates should APPLY NOW for immediate consideration! Please hit APPLY to provide the required information, and we will be back in touch as soon as possible.",https://mx.linkedin.com/jobs/view/prompt-engineer-ai-data-engineer-at-innova-solutions-4021571528,4021571528,"As a Senior AI Data Engineer, you will be responsible for configuring and optimizing generative AI models, particularly LLMs such as Azure's ChatGPT, Llama, and Mistral. You will develop and refine prompt engineering strategies, manage and integrate vector databases, utilize Azure Functions and containerization techniques, work closely with cross-functional teams, and stay updated on advancements in generative AI and LLM technologies.","Generative AI, LLMs, Azure Functions, Docker, Kubernetes, Vector Databases, OpenAI, Mistral, Llama",5+ years,,True,5.0,0,0,0,1,1,0,0,0,0,1,0,0,0,0,0,0,0
Data Monitoring Engineer (Mexico),MSIGHTS,Monterrey Metropolitan Area,ON-SITE,Entry level,Full-time,Internet Publishing,2023-12-20 11:27:40.933821,26,Engineering,Information Technology,,"Company Overview Founded in 2004, MSIGHTS (msights.com) provides cloud-based marketing data integration services to some of the world’s most sophisticated global advertisers. As marketing channels proliferate, so do the data sources marketers must examine in order to quantify results and guide strategy. MSIGHTS services make marketers more efficient and successful by providing a single view of overall marketing performance with actionable insights on what works and what doesn’t. The MSIGHTS Platform automatically collects and reconciles disparate data, making it immediately available to fuel a wide variety of analytical and visualization tools. Job Summary Monitor all daily operations throught the data value chain QA data based on boards and daily data intake Interest in data (Trending, rules, behavior) As part of the MSIGHTS Technology team, this position requires a great capacity to innovate, take initiative, an ability to consistently deliver above expectation, a passion for continuous improvement, and a willingness to work hard and be rewarded Responsibilities And Duties Will need to work perform daily data operations at specific times (early morning shift or late night shift) Monitor daily intake of data throughits various channels (API, Email, FTP) and solve problems as they arise Daily QA of data to spot inconsistencies, unusual, trending or errors and communicate findings The candidate is required to document, generate ideas, follow established work porcedures and methodologies Qualifications And Skills 1+ years of IT related experience SQL Serverknowledge is a necessity Postgre SQL, SSIS, or AWS Services (Athena, Spectrum, GLUE) are desirable Must be a self-starter, willing to take the initiative and propose innovation in MSIGHTS products and/or processes Strong communications skills — both written and verbal — and the ability to work well with an internal team Must be detail-oriented, committed to quality, responsable, punctual, and client-focused, all while being flexible and entrepreneurial in a fast-paced international work environment Analytical and problem-solving skills, and experience applying these skills to resolve potential issues Bachelor’s Degree or equivalent Powered by JazzHR TcfYc39JO1",https://mx.linkedin.com/jobs/view/data-monitoring-engineer-mexico-at-msights-3787755081,3787755081,"Monitor daily operations through the data value chain, QA data based on boards and daily data intake. This position requires a great capacity to innovate, take initiative, and deliver above expectations while being committed to continuous improvement.","SQL, PostgreSQL, SSIS, AWS Services (Athena, Spectrum, GLUE), API, Email, FTP",1+ years,Bachelor,True,1.0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0
ESPECIALISTA EN BI,EnviaFlores.com,Monterrey Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,"Internet Marketplace Platforms and Technology, Information and Internet",2024-09-01 11:27:40.933821,163,Analyst,"Administrative,",Research,"Estamos en el negocio de construir la marca más confiable de envío de regalos que inspire a nuestros clientes a festejar y conectarse en México y países afines. Nuestros clientes confían en nosotros porque ofrecemos una experiencia memorable donde cada detalle cuenta, desde la realización del pedido hasta la entrega. Buscamos Especialista en BI Responsabilidades: Desarrollo de KPIs hacia otras áreas para eficientizar y reducir gastos que ayuden a alcanzar el business plan. Transformación de datos crudos a bases de datos estructuradas, utilizando diversas técnicas (Python, SQL, Macros) para modelos o tableros para su seguimiento continuo . Colaboración con el área de Data Arquitect para la homologación y limpieza de todos los datos de la compañía Proveer soluciones digitales a problemas que surgen en el día a día (tickets) del negocio para la toma de decisiones. Identificar y eliminar el uso de tableros obsoletos o KPIs duplicados para reducir la memoria diaria de extracción y evitar riesgos operativos. Control de las altas/bajas/permisos de los usuarios que se tienen en Tableau Creación de alertas automáticas cuando ciertas métricas estén alcanzando su límite permitido. Colaboración con todas las áreas de la compañía para desarrollar dashboards interactivos que mejoren la eficiencia del usuario. Análisis y evaluación de casos de negocio con datos cuantitativos. Utilizar herramientas externas para la automatización de procesos/archivos de diversos clientes. Requisitos: Licenciatura concluida en Actuaría, Transformación digital, Tecnología de la información. 2 a 4 años en experiencia de análisis e inteligencia de datos. conocimientos en: Excel, SQL, python, Power Bi, tableau. 1 a 2 años de conocimiento en fiananzas e IT (deseable).",https://mx.linkedin.com/jobs/view/especialista-en-bi-at-enviaflores-com-4010270253,4010270253,"We are looking for a BI Specialist. Responsibilities include developing KPIs to optimize and reduce costs that help achieve the business plan, transforming raw data into structured databases using various techniques (Python, SQL, Macros) for models or dashboards for continuous monitoring. Collaborating with the Data Architect area to standardize and clean all company data, providing digital solutions to daily business problems for decision-making. Identifying and eliminating the use of obsolete dashboards or duplicate KPIs to reduce daily extraction memory and avoid operational risks. Managing user permissions in Tableau, creating automatic alerts when certain metrics reach their allowed limits, and collaborating with all company areas to develop interactive dashboards that enhance user efficiency. Analyzing and evaluating business cases with quantitative data and using external tools for process/file automation for various clients.","Python, SQL, Excel, Power BI, Tableau, Macros",2-4,Bachelor,False,2.0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,1,0,0
Data Engineering Intern,Kuona,Monterrey Metropolitan Area,ON-SITE,Internship,Internship,"Technology, Information and Internet",2024-09-08 11:27:40.933821,25,Information Technology,,,"We are Kuona ( kuona.a i) , an AI technology company that empowers consumer products and retailers to live up to their revenue goals and empowers our clients to maximize their sales and profitability through the dynamic optimization of prices, promotions, and inventories. Our AI-powered platform helps top brands like Coca-Cola and Oxxo maximize their profits and optimize inventories. We are looking for people who are world-class, curious, innovative, bright, and work to be better every single day! We are currently looking for a Data Engineering Intern. With training, guidance, monitoring, and support from the team and team leader, this role is focused on finding and developing solutions that help Kuona build and maintain complex data pipelines and analytical solutions that deepen relationships with customer-provided information. Responsibilities Ensure that the quality of presented data is reliable and aligned with its source quality, and be familiar with various data sources and/or flat files for generating solutions. This role collaborates with the data engineering and data science teams to drive and optimize analytical solutions and internal data systems. Contribute to data analysis and integration. Provide support for enhancing and addressing issues with developed and integrated systems, among other related tasks in the area. Required Technical Experience Desirable experience in data engineering, business intelligence, or engineering. Desirable experience analyzing and integrating data using Python and SQL to extract and transform data according to business rules and requirements. Desirable knowledge in Pandas, Relational and NoSQL databases, and AWS. Desirable knowledge in Airflow and AWS Glue. Desirable experience with large-scale data warehouses, web APIs, and database platforms for integrating internal and external data sources. Your Experience With Kuona Creativity: We like that all team members can propose and create new features Self-management: Since we are a very horizontal company, we require that team members can decide for themselves what to work on and define priorities Opportunities to learn: We offer all our employees a wide opportunity to learn things you probably wouldn't be exposed to in a corporate environment. High Impact: You will be involved in the growth and evolution of the company, and all your contributions will be of high impact on the overall results. We value our culture: We are fully committed to prioritizing great results for our clients and an amazing employee experience for our people. Ability to work anywhere / Flexibility: We provide everyone the opportunity to design your day and execute your projects with flexibility and focus on your well-being. Kuona provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.",https://mx.linkedin.com/jobs/view/data-engineering-intern-at-kuona-4016149298,4016149298,"We are currently looking for a Data Engineering Intern. This role is focused on finding and developing solutions that help build and maintain complex data pipelines and analytical solutions. Responsibilities include ensuring data quality, collaborating with data engineering and data science teams, contributing to data analysis and integration, and providing support for enhancing and addressing issues with integrated systems.","Python, SQL, Pandas, Relational Databases, NoSQL, AWS, Airflow, AWS Glue","Desirable experience in data engineering, business intelligence, or engineering.",,True,,0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0
Data Engineer (Monterrey),i-Consulting,Monterrey Metropolitan Area,ON-SITE,Entry level,Full-time,Information Technology & Services,2024-09-01 11:27:40.933821,25,Information Technology,,,"Overview.- The Resource Description role is focused on ensuring that technical systems and equipment operate optimally for end users. This includes diagnosing and resolving technical issues, implementing new technology solutions, and upgrading systems to enhance efficiency and functionality. The role also involves creating documentation, training users, and generating reports on system usage, status, and incidents. Requirements.- Experience in creating reports, dashboards, and data queries. Proficiency in script creation, testing, and quality assurance for global end-user configurations. Ability to create end-user guides and training materials for Global Service Centers (GSC) and Field Service Operations (FSO). Strong documentation skills for processes and presentation generation. Expertise in analyzing and resolving issues in end-user environments (Windows 11, O365, System Center Client, Intune). Qualifications.- Proven ability to present project progress and make informed decisions based on technical requirements. Strong troubleshooting skills for resolving technical incidents in end-user environments. Experience running pilot tests for end-user solutions. Competence in training support groups on the use of tools and technologies in end-user environments. Education.- Bachelor's degree in Information Technology, Computer Science, or a related field. Additional certifications in relevant technologies (e.g., Microsoft Certified: Modern Desktop Administrator Associate) are a plus. #DATA #Queries #DataEngineers #TechSupport #ITSolutions #EndUserExperience #TechTroubleshooting #SystemImplementation #ITTraining #TechDocumentation #Windows11 #O365 #Intune #ITCareer #TechJobs #SystemUpgrades",https://mx.linkedin.com/jobs/view/data-engineer-monterrey-at-i-consulting-4013716973,4013716973,"The Resource Description role is focused on ensuring that technical systems and equipment operate optimally for end users. This includes diagnosing and resolving technical issues, implementing new technology solutions, and upgrading systems to enhance efficiency and functionality. The role also involves creating documentation, training users, and generating reports on system usage, status, and incidents.","Windows 11, O365, System Center Client, Intune, Data Queries, Scripting, Quality Assurance, Documentation",,Bachelor,True,,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0
Data Engineers Python,"GSPANN Technologies, Inc",Monterrey Metropolitan Area,ON-SITE,Entry level,Full-time,Information Technology & Services,2024-07-17 11:27:40.933821,25,Information Technology,,,"SQL, Python, PySpark, Databricks, AWS Description GSPANN seeks seasoned Data Engineers to join our team in Mexico. As we march ahead on a tremendous growth trajectory, we seek passionate and talented professionals to join our growing family. Who We Are GSPANN has been in business for over a decade, with over 2000 employees worldwide, and servicing some of the largest retail, high technology, and manufacturing clients in North America. We provide an environment that enables career growth while still interacting with company leadership. Visit Why GSPANN for more information. Location: Monterrey or Remote in Mexico Role Type: Full Time Published On: 26 June 2024 Experience: 7+ Years Share this job Description GSPANN seeks seasoned Data Engineers to join our team in Mexico. As we march ahead on a tremendous growth trajectory, we seek passionate and talented professionals to join our growing family. Role and Responsibilities Analyze, code, test, build, release, and maintain data pipelines or ETL-related systems. Participate in the design of the above-mentioned system with the principal engineer and Architect. Work with multiple sourcing teams when it comes to data ingest. Implement processes to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it. Select and implement the right technical tools and processes within the boundary defined by the client. Perform data analysis required to troubleshoot data-related issues and assist in the resolution of data issues. Collaborate with Product Analysts and Visualization Engineers during solution implementation. Write documentation and tutorials, as well as provide guidance. Be part of the support process with the rest of the squad. Coach and mentor more junior colleagues from the squad. Participate actively in the relative community of practice, helping shape Nike’s engineering culture, standards, and best practices, advocating for engineering excellence and innovation. Work with product owner and scrum master to understand requirements. Collaborate with the Lead Engineer to understand requirements, define scope, and estimate the level of effort. Ensure that your peers in the team have the full context and understanding of requirements and create valuable solutions. Establish trust and build strong and effective partnerships with technical leaders and architects in various functions across regions/global locations. Partner effectively with your peers to ensure delivery and positive results. Skills And Experience A degree in Computer Science, Information Systems, or other relevant subject area related to information technology. 3+ years of hands-on experience in technical architecture, design, development, and testing of data warehouse and big data solutions 3+ years of experience in implementing, testing, deploying, and troubleshooting data pipelines using any of these: PySpark, Apache Spark, Databricks, and Data Lake in cloud environments such as AWS or Microsoft Azure. 3+ years of experience in a complex matrix organization within a global IT environment, having a diverse and complex landscape. 3+ years of experience in developing CI/CD pipelines using Git, Terraform, and Jenkins. Prior experience working on multiple projects using Agile Methodologies (SAFE). Hands-on with applying pattern-based architecture, governance, security, and global process standards to system changes and deployments. Expertise in practicing DevOps principles for observability, reliability, and scalability. Diverse experience in databases, designs, constructs, and utilities. Comfortable working in a multi-tasking, fast-paced, results-oriented environment. Excellent verbal and written communication and collaboration skills to effectively communicate with both business and technical IT teams across global locations. Passion for building trust, coaching, teaching, mentoring, and learning.",https://mx.linkedin.com/jobs/view/data-engineers-python-at-gspann-technologies-inc-3967872045,3967872045,"GSPANN seeks seasoned Data Engineers to analyze, code, test, build, release, and maintain data pipelines or ETL-related systems. Responsibilities include collaborating with teams on data ingest, monitoring data quality, troubleshooting data-related issues, and ensuring effective communication with stakeholders. The position involves implementing CI/CD pipelines, applying DevOps principles, and mentoring junior colleagues while participating in agile methodologies.","SQL, Python, PySpark, Databricks, AWS, Microsoft Azure, Git, Terraform, Jenkins",7+ Years,Masters,True,7.0,0,0,1,1,0,0,0,0,0,1,0,1,0,0,1,0,0
Test Engineer - Lenovo Data Center Group,Lenovo,Monterrey Metropolitan Area,ON-SITE,Entry level,Full-time,IT Services and IT Consulting,2024-09-12 11:27:40.933821,25,Engineering,Information Technology,,"We are Lenovo. We do what we say. We own what we do. We WOW our customers. Lenovo is a US$57 billion revenue global technology powerhouse, ranked #248 in the Fortune Global 500, and serving millions of customers every day in 180 markets. Focused on a bold vision to deliver Smarter Technology for All, Lenovo has built on its success as the world’s largest PC company with a full-stack portfolio of AI-enabled, AI-ready, and AI-optimized devices (PCs, workstations, smartphones, tablets), infrastructure (server, storage, edge, high performance computing and software defined infrastructure), software, solutions, and services. Lenovo’s continued investment in world-changing innovation is building a more equitable, trustworthy, and smarter future for everyone, everywhere. Lenovo is listed on the Hong Kong stock exchange under Lenovo Group Limited (HKSE: 992) (ADR: LNVGY). This transformation together with Lenovo’s world-changing innovation is building a more inclusive, trustworthy, and smarter future for everyone, everywhere. To find out more visitwww.lenovo.com, and read about the latest news via ourStoryHub. Job Title: Test Engineer - Lenovo Data Center Group General Description: We are looking for Test engineer with a background in functional testing for a position in Lenovo’s ISG Product Assurance team. The role will require experience with new feature validation on servers, options, enterprise software and server OS’s. Testing will include error injection, using test scripts and automation, data capture, and assisting with debug efforts. This role will be responsible for execution test plans and test cases indented to ensure quality delivery of new Lenovo ThinkSystem servers and FW functions. Applicants must have a background in one or more of the following: UEFI, systems management features, networking or storage. The applicants should have some experience in several of the following areas: error injection, testing and validation. The role requires the ability to apply this knowledge to execute test plans, find defects and document them. Job Responsibilities: Execution of test plans on Lenovo servers Defect documentation / discover Server configuration and installation Network / SAN setup Identify automation opportunities and drive automation development activities Working with development on defect debug efforts Skills / Qualifications: Strong English is required Experience in any of the following: Working knowledge of server OS’s (RedHat, SuSE, Windows, VMWare) Understanding of servers basics Understanding on network basics Additional skills a plus: Basics on networking IPv6 / V4, Virtualization, InfiniBand, etc. Basics on Intel and AMD architecture Fault injection Server architecture Programming / scripting Automation development Test Case / plan development VMWare virtualization NetAPP Storage We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, religion, sexual orientation, gender identity, national origin, status as a veteran, and basis of disability or any federal, state, or local protected class. WD00070705 https://lenovo.avature.net/en_US/careers/JobDetail?jobId=60173 Skills / Qualifications: Strong English is required Experience in any of the following: Working knowledge of server OS’s (RedHat, SuSE, Windows, VMWare) Understanding of servers basics Understanding on network basics Additional skills a plus: Basics on networking IPv6 / V4, Virtualization, InfiniBand, etc. Basics on Intel and AMD architecture Fault injection Server architecture Programming / scripting Automation development Test Case / plan development VMWare virtualization NetAPP Storage We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, religion, sexual orientation, gender identity, national origin, status as a veteran, and basis of disability or any federal, state, or local protected class. WD00070705 https://lenovo.avature.net/en_US/careers/JobDetail?jobId=60173 We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, religion, sexual orientation, gender identity, national origin, status as a veteran, and basis of disability or any federal, state, or local protected class.",https://mx.linkedin.com/jobs/view/test-engineer-lenovo-data-center-group-at-lenovo-4022882442,4022882442,"We are looking for a Test Engineer with a background in functional testing for a position in Lenovo’s ISG Product Assurance team. The role will require experience with new feature validation on servers, options, enterprise software, and server OS’s. Responsibilities include executing test plans, defect documentation, server configuration and installation, network/SAN setup, and identifying automation opportunities. Applicants must have experience in UEFI, systems management features, networking, or storage, and the ability to apply this knowledge to execute test plans and find defects.","RedHat, SuSE, Windows, VMWare, IPv4, IPv6, InfiniBand, Intel architecture, AMD architecture, Automation development, Test Case development",,,True,,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
Data Engineer,Dexian México,Monterrey Metropolitan Area,ON-SITE,Mid-Senior level,Contract,IT Services and IT Consulting,2024-09-11 11:27:40.933821,25,Information Technology,,,"Responsibilities Create and maintain optimal data pipeline architecture, Assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS �big data� technologies. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Work with data and analytics experts to strive for greater functionality in our data systems. Qualifications for Data Engineer Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Experience building and optimizing �big data� data pipelines, architectures and data sets. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Strong analytic skills related to working with unstructured datasets. Build processes supporting data transformation, data structures, metadata, dependency and workload management. A successful history of manipulating, processing and extracting value from large disconnected datasets. Working knowledge of message queuing, stream processing, and highly scalable �big data� data stores. Strong project management and organizational skills. Experience supporting and working with cross-functional teams in a dynamic environment. Leverage data and software engineering techniques, data science to create business value through data accessibility (includes data ingestion, data preparation and analytics processing) Identifying, acquiring, cleansing/preparing, storing data and developing reusable data products aligned with defined architecture patterns Enabling data scientists, making data available for advanced analytics models, and contributing to advanced analytics models Working with data analysts and architects to scale and deploy solutions including models, documentation, training, integration Required Technical Skills Proficiency in building out scalable and reliable ETL pipelines and processes to ingest data from variety of data sources including but not limited to SharePoint, REST API, Blob Storage . Proficiency in Azure PaaS offerings and data engineering target architecture, including but not limited to Azure SQL database, Azure Data Factory, Azure Synapse, Azure Databrick, Azure Functions, Data lake, Azure Log Analytics. Proficiency in large dataset transformation using Python Proficiency in relational databases and SQL, including but not limited to stored procedures, indexes, functions and triggers. Proficiency in Azure DevOps CI/CD and Git Repository. Deep understanding in data model design and relational database normalization Familiarity with Non SQL databases. E.g Cosmos DB INTERESADOS Si cumples con los requisitos, compartir CV en inglés Desarrollo de proyecto remoto para empresa basada en US Puesto remoto para profesionales viviendo en México Puedes compartir el CV por este medio o a la siguiente cuenta de correo: cesar.montufar@dexian.com Prestaciones superiores",https://mx.linkedin.com/jobs/view/data-engineer-at-dexian-m%C3%A9xico-4021369240,4021369240,"The responsibilities include creating and maintaining optimal data pipeline architecture, assembling large and complex data sets, identifying and implementing internal process improvements, and building the infrastructure for data extraction, transformation, and loading from various data sources. You will also build analytics tools to provide actionable insights, work with stakeholders to assist with technical data issues, and create data tools for analytics and data scientists. Qualifications include advanced SQL knowledge, experience with big data pipelines, strong analytic skills, and proficiency in Azure PaaS offerings and data engineering architecture.","SQL, AWS, Python, Azure SQL Database, Azure Data Factory, Azure Synapse, Azure Databricks, Azure Functions, Data Lake, Azure Log Analytics, Azure DevOps, Git, Cosmos DB",,,True,,0,0,1,1,0,0,0,0,0,1,0,1,0,0,1,0,0
Data Engineer,Dematic,Monterrey Metropolitan Area,ON-SITE,Entry level,Full-time,"Transportation, Logistics, Supply Chain and Storage",2024-09-14 11:27:40.933821,25,Information Technology,,,"What We Offer: Career Development Competitive Compensation and Benefits Pay Transparency Global Opportunities Learn More Here: https://www.dematic.com/es-mx/about/careers/ Dematic provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training. What we offer: Company Overview Dematic Corporation is a leading supplier of integrated automated technology, software, and services to optimize the supply chain. Dematic belongs to the KION Group. The KION Group is among the world's leading suppliers of industrial trucks and supply chain solutions. We currently have more than 41,000 employees and approximately €11,100 million in revenue. Our portfolio encompasses industrial trucks, such as forklift trucks and warehouse trucks, as well as integrated automation technology and software solutions for the optimization of supply chains, including all related services. Across more than 100 countries worldwide, the KION Group's solutions improve the flow of material and information within factories, warehouses, and distribution centers. Tasks and Qualifications: The Role KION is expanding its global Big Data Analytics & AI Platform that supports a large variety of different use cases from explorative Data Analytics through Machine Learning Projects or Power BI dashboards. This position is meant to be the IT counterpart for those projects. We are looking for a highly skilled and experienced Data Engineer as an extension to the Analytics Team. The KION Analytics Platform is KION’s cloud data platform for analytics, data science and AI use cases. It holds data from various source systems and provides services and infrastructure for data analysts and data scientists to kickstart their projects. Among others, the platform comprises of following services: Azure DataLake Azure Data Factory Azure Databricks Dremio GCP VertexAI Power BI We are making sure all projects have the adequate data and tools they need to provide further insights to grow and optimize KION’s Business. Responsibilities To be successful in this demanding role, your proven track record will enable you to deliver against the following key performance areas: Design, develop and operate robust data pipelines in Azure Data Factory and Databricks Build data transformations in Databricks and Dremio based on business needs Develop and implement data quality and data governance frameworks Support and advise a variety of projects on big data Collaborate with data analysts and scientists to ensure data availability, accuracy, and quality Advice and consult business partners to use data efficiently Develop and maintain scalable and efficient ETL processes User support, incident and change management for applications and services Operate and support KION Analytics Platform architecture and corresponding toolset Monitor and analyze data and metrics of the platform Create and maintain documentation and training materials for platform users Qualifications Minimum of 2 years’ experience in data engineering, data management, or related field Good understanding of data, databases, and data lakes in general Experience with cloud-based data storage and processing platforms (e.g., AWS, Azure, Google Cloud Platform) Strong proficiency in a programming language (preferably Python, SQL, Powershell, Bash) Experience with IoT Data and related technologies (e.g., Kafka) Proficiency in professional software development (testing, Git, CI/CD) Experience with creating solutions within a collaborative, cross-functional team environment Good problem-solving skills and the ability to troubleshoot complex data issues Motivation to think out of the box coupled with a hands-on mentality Proven track record of delivering value from data Strong communication skills (English required C1/C2) Self-starter, detail oriented, excellent time-management/schedule skills, ability to meet deadlines, desire to learn Resume/CV must be submitted in English Willingness to travel up to 10% internationally",https://mx.linkedin.com/jobs/view/data-engineer-at-dematic-4024622626,4024622626,"The role is focused on expanding the global Big Data Analytics & AI Platform, which supports various use cases from explorative Data Analytics to Machine Learning Projects and Power BI dashboards. The Data Engineer will design, develop, and operate robust data pipelines, implement data quality frameworks, collaborate with data analysts, and manage cloud data architecture. The position requires a strong track record in data engineering and experience with various cloud-based data storage platforms.","Azure DataLake, Azure Data Factory, Azure Databricks, Dremio, GCP VertexAI, Power BI, Python, SQL, Powershell, Bash, Kafka",2,,True,2.0,0,0,1,1,0,0,0,0,1,1,0,0,0,0,1,0,0
Data Engineer,"GSPANN Technologies, Inc",Monterrey Metropolitan Area,ON-SITE,Entry level,Full-time,Information Technology & Services,2024-07-17 11:27:40.933821,25,Information Technology,,,"Java, Databricks, ETL, Data Lake, Database Design, Big Data Description We are looking for a Data Engineer to join our global workforce. Our dynamic team offers valuable opportunities and a tangible career support system for your professional and personal development. Who We Are GSPANN has been in business for over a decade, with over 2000 employees worldwide, and servicing some of the largest retail, high technology, and manufacturing clients in North America. We provide an environment that enables career growth while still interacting with company leadership. Visit Why GSPANN for more information. Location: Monterrey or Remote in Mexico Role Type: Full Time Published On: 25 June 2024 Experience: 7+ Years Share this job Description We are looking for a Data Engineer to join our global workforce. Our dynamic team offers valuable opportunities and a tangible career support system for your professional and personal development. Role and Responsibilities Lead the design, development, and maintenance of scalable customer data platform architectures. Collaborate with engineers, marketers, and product managers to ensure seamless integration and alignment of the CDP with business objectives. Implement robust data pipelines, APIs, and reverse ETL for real-time and batch data processing. Identify data sources, build data mappings, and conduct transformational logic between systems to enable data migration. Ensure high data quality and adherence to data privacy and security guidelines. Evaluate and incorporate new technologies and tools to enhance the capabilities of the CDP, building efficient integration to consume and provide data to third-party platforms. Skills And Experience Bachelor’s or Master’s degree in Computer Science, Information Technology, or a related field. Minimum of 7 years of experience in software development, focusing on backend engineering and data-intensive applications. Strong programming skills in Java. 1-2 years of experience implementing any Customer Data Platforms (CDP) such as Segment, RudderStack, Hightouch, or mParticle. Proficient in SQL and NoSQL databases. Hands-on experience with AWS cloud platforms. Ability to collaborate efficiently with cross-functional teams, including product owners, technology teams, and marketing partners. Excellent written and oral communication skills. Experience with big data technologies such as Kafka, Hadoop, or Spark is desirable.",https://mx.linkedin.com/jobs/view/data-engineer-at-gspann-technologies-inc-3967865934,3967865934,"We are looking for a Data Engineer to lead the design, development, and maintenance of scalable customer data platform architectures, collaborating with various teams to ensure alignment with business objectives, implementing robust data pipelines, and ensuring high data quality and security.","Java, SQL, NoSQL, AWS, Kafka, Hadoop, Spark, ETL, Data Lake, APIs",7+,Bachelor,True,7.0,0,0,1,1,0,0,1,0,0,1,0,0,0,0,0,0,0
Senior Engineer - Data Engineering (MONTERREY),Slalom Build,Monterrey Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,Information Technology & Services,2024-09-08 11:27:40.933821,25,Engineering,Information Technology,,"Who You’ll Work With At Slalom Build we co-create custom software, data and cloud products with clients who are ready to accelerate their digital transformation. We're passionate about technology, compelled by its potential as we help create the digital products, experiences, and technology-driven organizations that drive true change. We’re thrilled by the opportunity to build the future we want to see, with anyone willing to join us. Slalom Build’s Data Engineering Capability Is Focused On Injecting Intelligence Into Products, Engineering Systems That Support Learning And Insight And Creating Innovative Data Products. Within Data Engineering We Help Customers Build World-class Products Through Effective Use Of Data Engineering consisting of streaming / real-time data solutions, modern data platforms, and data systems within products (e.g.., database systems, graph databases, key-value stores, document databases and transactional systems) Data visualization Machine learning and artificial intelligence What You’ll Do Slalom Build’s Data Engineering capability is comprised of passionate, flexible technologists who love to practice and hone their craft. As tools evolve and technologies emerge, we work to stay in front of innovations in data platform development and delivery. As a Senior Data Engineer for Slalom Build, you will work in teams with minimal oversight and direction to deliver innovative solutions on Amazon Web Services, Microsoft Azure, and Google Cloud Platform using core cloud data warehouse tools, distributed processing engines, event streaming platforms, and other modern data related technologies. In addition to building the next generation of data platforms, you will be working with some of the most forward-thinking organizations in data and analytics. You will typically work under the direction of a Solution Architect to help design and implement components of our clients’ data platform solution. You’ll also participate in design sessions, be experienced at breaking down complex development tasks, and be responsible for the timely and quality completion of development items assigned to you and the data engineers reporting to you. We are looking for candidates who are interested in working in a hybrid environment as we build the foundation and grow our team in Mexico. We offer a flexible working environment to balance the need to work independently, with days that may require in-person collaboration at our office. What You’ll Bring As a Senior Engineer in the Data Engineering capability, you will bring a curious mindset to your client’s engagement, a thirst for knowledge and a hunger for fearless experimentation in new and interesting ways to meet our clients’ most pressing data challenges. You are self-starter, effective in breaking down large problems into smaller ones, and eager to regularly share what you learn with others within your projects and in the broader Builder community. You Will Have An Insatiable Need For Becoming The Best At What You Do And Have Hands-on Experience With Data Platforms And Programming Languages As You Explore The Range Of Technologies We Help Our Clients With, Including Big Data Platforms (Apache Spark, Presto, Amazon EMR) Cloud Data Warehouses (Amazon Redshift, Snowflake, Google BigQuery) Object Oriented Coding (Java, Python) NoSQL Databases (DynamoDB, Cosmos DB, MongoDB) Container Management Systems (Kubernetes, Amazon ECS) Artificial Intelligence / Machine Learning (Amazon Sagemaker, Azure ML Studio) Streaming Data Ingestion and Analytics (Amazon Kinesis, Apache Kafka) Visual Analytics (Tableau, PowerBI) Modern Data Workflows (Apache Airflow, dbt, Dagster) About Us Slalom Build is a highly scalable, high-velocity Build as a Service firm. We work with clients in a flexible, collaborative, and repeatable methodology to create custom technology solutions for their most impactful initiatives and to accelerate their digital transformation journey. Over 1500 Builders strong, distributed across the globe, our innovation hubs attract the type of people who contribute to thriving teams. By placing builders in close proximity to clients – as well as their cultural and technology cohorts – we can assure the quality, versatility, and speed that product delivery demands, along with the elasticity and scale to tailor to individual client needs. Slalom Build leverages a foundation of innovation inherited from Slalom, a Seattle based firm that set out in 2001 to disrupt and redefine management consulting. Now 13,000+ professionals strong around the globe, Slalom is deeply engaged with some of the world’s most influential, change-making enterprises. Learn more at slalombuild.com or slalom.com",https://mx.linkedin.com/jobs/view/senior-engineer-data-engineering-monterrey-at-slalom-build-4018794281,4018794281,"As a Senior Data Engineer for Slalom Build, you will work with minimal oversight to deliver innovative solutions on cloud platforms, using core cloud data warehouse tools and modern data technologies. You will participate in design sessions, break down complex development tasks, and ensure timely and quality completion of assigned items. You will bring a curious mindset, hands-on experience with data platforms, and be eager to experiment with new technologies to solve data challenges.","Amazon Web Services, Microsoft Azure, Google Cloud Platform, Apache Spark, Presto, Amazon EMR, Amazon Redshift, Snowflake, Google BigQuery, Java, Python, DynamoDB, Cosmos DB, MongoDB, Kubernetes, Amazon ECS, Amazon Sagemaker, Azure ML Studio, Amazon Kinesis, Apache Kafka, Tableau, PowerBI, Apache Airflow, dbt, Dagster",,,True,,0,0,1,1,1,0,0,0,1,1,0,0,0,0,1,0,0
Azure Data Engineer,Infosys,Monterrey Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-13 11:27:40.933821,25,Information Technology,,,"We are looking for an Azure Data Eng to work on hybrid model on any of Infosys Locations (Mexico City, Guadalajara and Monterry) in a Production Support + Development project with one of the top companies in Silicon Valley . Expertise Required: Very good communication skills + English Level. At least 3 years of experience in designing, implementing, and maintaining robust and scalable data pipelines on Azure using services such as Azure Data Factory, Azure SQL Data Warehouse, Azure Analysis Services or any of the Azure Databricks/Synapse/Fabric. At least 2 years of experience in data platforms – with multi layered approach, Design/Architecture setup is needed. At least 2 years of experience in troubleshooting performance issues, identifying root cause and applying fixes. At least 3 years of experience in SQL. Ability to implement and manage CI/CD pipelines for data engineering projects, leveraging tools like Azure DevOps. EEO/About Us : About Us Infosys is a global leader in next-generation digital services and consulting. We enable clients in more than 50 countries to navigate their digital transformation. With over four decades of experience in managing the systems and workings of global enterprises, we expertly steer our clients through their digital journey. We do it by enabling the enterprise with an AI-powered core that helps prioritize the execution of change. We also empower the business with agile digital at scale to deliver unprecedented levels of performance and customer delight. Our always-on learning agenda drives their continuous improvement through building and transferring digital skills, expertise, and ideas from our innovation ecosystem. Infosys provides equal employment opportunities to applicants and employees without regard to race; color; sex; gender identity; sexual orientation; religious practices and observances; national origin; pregnancy, childbirth, or related medical conditions; status as a protected veteran or spouse/family member of a protected veteran; or disability.",https://mx.linkedin.com/jobs/view/azure-data-engineer-at-infosys-4020124696,4020124696,"We are looking for an Azure Data Engineer to work in a hybrid model in any of Infosys Locations (Mexico City, Guadalajara, and Monterrey) in a Production Support + Development project with a top Silicon Valley company. The role requires excellent communication skills and proficiency in English. The candidate should have at least 3 years of experience in designing, implementing, and maintaining robust and scalable data pipelines on Azure, using services such as Azure Data Factory, Azure SQL Data Warehouse, and Azure Analysis Services or any of Azure Databricks/Synapse/Fabric. Additionally, 2 years of experience in data platforms with a multi-layered approach is needed, along with design/architecture setup experience. The candidate should also have 2 years of experience in troubleshooting performance issues. Proficiency in SQL for at least 3 years, as well as the ability to implement and manage CI/CD pipelines for data engineering projects using tools like Azure DevOps, is required.","Azure Data Factory, Azure SQL Data Warehouse, Azure Analysis Services, Azure Databricks, Azure Synapse, Azure DevOps, SQL",3+,,True,3.0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,0,0,0
"Senior, Data Engineer",Schneider Electric,Monterrey Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,Automation Machinery Manufacturing,2024-09-08 11:27:40.933821,25,Information Technology,,,"Schneider Electric has an opportunity for a Senior Data Engineer in our Monterrey, MX location. The Data Engineer will develop, maintain, and improve data delivery through North America (NAM) Data Excellence platform. The right person in this role will support improvements in data architecture, metric definition, and processes to support business data and analytical initiatives. Our Data Engineers provide guidance and support to team members in the Data Services team and our business partners. About Us Schneider Electric creates connected technologies that reshape industries, transform cities, and enrich lives. Our 135,000+ employees thrive in more than 100 countries. From the simplest of switches to complex operational systems, our technology, software, and services improve how our customers manage and automate their operations. Help us deliver solutions that ensure Life Is On everywhere, for everyone, and at every moment. http://www.youtube.com/watch?v=YtExntUe89c Great People Make Schneider Electric a Great Company. Key responsibilities include: Collaborate with team members to conceptualize, design, and deliver enterprise and departmental data solutions to support business intelligence, data warehousing, reporting, and machine learning requirements. Implement reliable and scalable solutions to meet the service levels associated with mission-critical solutions. Participate in and enhance our DevOps practice to ensure highly available solutions and quick issue resolution. Translate business requirements into data pipelines and data stores to support business requirements. Perform assessments (Proof of Concepts) of the latest tools and technologies. Work with Data and Solution Architects to define and implement migration strategies from legacy systems to cloud architecture and technologies. Provide team feedback to optimize the delivery of our solutions. Education Bachelor’s degree related to Computer Science or Information Technology or equivalent Benefits Competitive salary Comprehensive health benefits Retirement savings plan Professional development opportunities We know skills and competencies show up in many ways and can be based on your life experience. If you do not necessarily meet all the requirements that are listed, we still encourage you to apply for the position. Qualifications Required qualifications: 5+ years of experience with modern programming languages such as Python, Scala, or Java. 3+ years of experience developing data-related solutions on cloud platforms such as Amazon Web Services (AWS). Demonstrated experience with primary AWS services such as EC2, Lambda, EMR, S3, IAM policies, CloudWatch, Cloud Formation, SES Demonstrated experience with Cloud Services for data handling and database technologies (DMS, Kafka, Spark, Redshift, Athena, Hadoop, Airflow, etc.). Knowledge of Data Management, Integration, and Data Quality tools, such as Alteryx, Trifecta, Informatica Power Center, Informatica Cloud, and Oracle Data Integrator. Command of advanced SQL queries and programming. Experience contributing to and following best practices for architecture, design, and implementation. Have an eye for operational transparency and resiliency at every application layer. Proven analytical and problem-solving abilities. Ability to assimilate information, quickly discern the most relevant facts, and recommend creative, practical design solutions. Ability to think outside the box is a real asset. Experience with DevOps tools and processes and CI/CD are an asset. Excellent communication, presentation, influencing, and reasoning capabilities. Solid understanding of data modeling, ETL processes, and data warehousing concepts. We know skills and competencies show up in many ways and can be based on your life experience. If you do not necessarily meet all the requirements that are listed, we still encourage you to apply for the position. Schedule: Full-time Req: 00922Q",https://mx.linkedin.com/jobs/view/senior-data-engineer-at-schneider-electric-4015117029,4015117029,"The Data Engineer will develop, maintain, and improve data delivery through the North America Data Excellence platform, support improvements in data architecture and processes, and collaborate to deliver data solutions for business intelligence and machine learning. Responsibilities include implementing scalable solutions, enhancing DevOps practices, translating business requirements into data pipelines, and working on migration strategies to cloud technologies. Required qualifications include experience with modern programming languages, cloud platforms, data handling tools, and advanced SQL queries.","Python, Scala, Java, AWS, EC2, Lambda, EMR, S3, IAM policies, CloudWatch, Cloud Formation, SES, Kafka, Spark, Redshift, Athena, Hadoop, Airflow, Alteryx, Informatica Power Center, Informatica Cloud, Oracle Data Integrator, SQL",5+,Bachelor,True,5.0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0
Data Engineer (SQL),BAT,Monterrey Metropolitan Area,ON-SITE,Associate,Full-time,Data Infrastructure and Analytics,2024-09-10 11:27:40.933821,54,Information Technology,,,"BAT is evolving at pace - truly like no other organization. To achieve the ambition, we have set for ourselves, we are looking for colleagues who are ready to live our ethos every day. Come be a part of this journey! BAT MEXICO IS LOOKING FOR A DATA ENGINEER (SQL) SENIORITY LEVEL: Junior Level FUNCTION: Digital Business Solutions (DBS) LOCATION: Monterrey ROLE POSITIONING AND OBJECTIVES This role is part of the DBS function. The role is responsible for support the US team in data integration, data architecture and process optimization tasks. Reports to: Data Engineer Lead Reporting Level: Managerial Geographic Scope: US WHAT YOU WILL BE ACCOUNTABLE FOR Integrates end to end data pipelines to take data from data source to target data repositories ensuring the quality and consistency of data. Understand Data Architecture concepts. Drive performance analysis and optimization tasks over SQL database objects like Store Procedures and Views. Coordinates issue resolution with multi-functional teams and vendors. Serves as a productive project team member delivering high quality results for work you are doing. Assists the project manager by assisting sharing work plans, effort estimates and delivery timelines for work you're leading. Drive collaborative reviews of design, code, data, features implementation performed by other data engineers in support of maintaining data engineering standards. CAN THIS BE YOUR FUTURE ROLE? Are you willing to develop your career in a fast paced global company? ESSENTIAL EXPERIENCE, SKILLS AND KNOWLEDGE Bachelor's Degree or equivalent experience in Computer Science/Engineering or related. +2 years working experience preferred. Experience with partners and requirements gathering/implementation. Intermediate knowledge (as minimum) over SQL (CTEs, Historical data management, Store Procs, Views, Functions, Logs, etc). Experience developing extract, transform, load (ETL) pipelines using Databricks, PySpark and Cloud Storage. Experience with Python. Extensive experience with data engineering tools, languages, frameworks to mine, cleanse and explore data. Experience Control-Versioning coding such as Git. Experience with Cloud technologies (ex. Azure, AWS, GCP, Teradata, Snowflake). Advance English proficiency written and verbal. BENEFICIAL Experience with Databricks: MachineLearning (MLFlow); SQL Warehousing / Delta tables; Unity Catalog; Event/Driver Logs analysis. PySpark RDDs (Resilient Distributed Dataset) and MLOPS (Azure DevOps). AWS Redshift, Teradata, Snowflake and Knowledge over Programming Object-Oriented concepts. Productionalize the full pipeline including and ETL workflows (e.g., training/test pipeline). Experience with orchestration toolsets (e.g. Airflow, Tidal). Experience with software development applying best-practice methodologies and frameworks such as Agile, Scrum, etc. WE ARE BAT At BAT we are committed to our Purpose of creating A Better Tomorrow. This is what drives our people and our passion for innovation. See what is possible for you at BAT. Global Top Employer with 53,000 BAT people across more than 180 markets Brands sold in over 200 markets, made in 44 factories in 42 countries Newly established Tech Hubs building world-class capabilities for innovation in 4 strategic locations Diversity leader in the Financial Times and International Women’s Day Best Practice winner Seal Award winner – one of 50 most sustainable companies BELONGING, ACHIEVING, TOGETHER Collaboration, diversity and teamwork underpin everything we do here at BAT. We know that collaborating with colleagues from different backgrounds is what makes us stronger and best prepared to meet our business goals. Come bring your difference!",https://mx.linkedin.com/jobs/view/data-engineer-sql-at-bat-4020485728,4020485728,"This role is responsible for supporting the US team in data integration, data architecture, and process optimization tasks. The Data Engineer will integrate end-to-end data pipelines, ensure data quality and consistency, and perform performance analysis and optimization tasks over SQL database objects. Additionally, the role requires collaboration with multi-functional teams and delivering high-quality results while assisting in project management tasks.","SQL, Databricks, PySpark, Cloud Storage, Python, Git, Azure, AWS, GCP, Teradata, Snowflake, Airflow",2+ years,Bachelor,True,2.0,0,0,1,1,0,0,0,0,0,1,0,1,0,0,1,0,0
Procurement Data Engineer III,Johnson Controls,Monterrey Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,Industrial Machinery Manufacturing,2024-09-14 11:27:40.933821,25,Information Technology,,,"Johnson Controls is a global diversified technology and multi industrial leader serving a wide range of customers in more than 150 countries. Our 130,000 employees create intelligent buildings, efficient energy solutions, integrated infrastructure and next generation transportation systems that work seamlessly together to deliver on the promise of smart cities and communities. Our commitment to sustainability dates back to our roots in 1885, with the invention of the first electric room thermostat. We are committed to helping our customers win and creating greater value for all of our stakeholders through strategic focus on our buildings and energy growth platforms. For additional information, please visit www.johnsoncontrols.com or follow us @johnsoncontrols on Twitter. What you will do? Join us in the Procurement Execution Center (PEC) as a Data Engineer as part of a is a diverse team of data and procurement individuals. In this role, you will be responsible for deploying supporting the E2E management of our data, including: ETL/ELT, DW/DL, data staging, data governance, and manage the different layers of data required to ensure a successful BI & Reporting for the PEC. This role will work with multiple types of data, spreading across multiple functional areas of expertise, including Fleet, MRO & Energy, Travel, Professional Services, among others. How you will do it? Serve as the main technical resource for any data-related requirement Demonstrate an ability to communicate technical knowledge through project management and contributions to product strategy Deploy data ingestion processes through Azure Data Factory to load data models as required into Azure Synapse. Build and design complex ETL/ELT processes with Azure Data Factory (ADF) and/or Python, which once deployed, will require to be executed daily and weekly. Assemble large, complex data sets that meet functional / non-functional business requirements. Build the infrastructure required for optimal ETL/ELT of data from a wide variety of data sources using Azure SQL and ADF. Develop data models that enable DataViz, Reporting and Advanced Data Analytics, striving for optimal performance across all data models. Maintain conceptual, logical, and physical data models along with corresponding metadata. Manages the DevOps pipeline deployment model, including automated testing procedures Deploys data stewardship and data governance across our data warehouse, to cleanse and enhance our data, using knowledge bases and business rules. Ensure compliance to system architecture, methods, standards, practices and participate in their creation Clearly articulate and effectively influence both business and technical teams Performs the necessary data ingestion, cleansing, transformation, and coding of business rules to support annual Procurement bidding activities. Support the deployment of a global data standard for Logistics. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Support Rate Repository management as required (including Rate Card uploads to our DW). Other Procurement duties as assigned. What are we looking for? Bachelor’s degree in related field (Engineering, Computer Science, Data Science or similar) 4+ years of relevant experience in BI Engineering, data modeling, data engineering, software engineering or other relevant roles. Advanced working SQL knowledge and experience working with relational databases. Knowledge in DW/DL concepts, data marts, data modeling, ETL/ELT, data quality/stewardship, distributed systems and metadata management. Experience building and optimizing data pipelines, architectures, and data sets. Azure Data Engineering certification preferred (DP-203) ETL/ELT development experience (3+ years). SSIS or ADF are preferred. Ability to resolve ETL/ELT problems by proposing and implementing tactical/Strategic solutions. Strong project management and organizational skills. Experience with object-oriented function scripting languages: Python, Scala, C#, etc. Experience with NoSQL databases is a plus to support the transition from On-Prem to Cloud. Excellent problem solving, critical thinking, and communication skills Relevant experience with Azure DevOps (CI/CD, git/repo management) Due to the global nature of the role, proficiency in English language is a must. Johnson Controls does not request pregnancy or HIV testing as a requirement for admission, permanence or promotion.",https://mx.linkedin.com/jobs/view/procurement-data-engineer-iii-at-johnson-controls-4024652565,4024652565,"Join the Procurement Execution Center as a Data Engineer responsible for managing the end-to-end data process including ETL/ELT, data staging, and governance. You will deploy data ingestion processes using Azure Data Factory, build complex ETL/ELT processes, and create data models for analytics. Your role includes maintaining data models, managing DevOps pipeline deployment, and supporting global data standards.","Azure Data Factory, Azure Synapse, Azure SQL, Python, SQL, ETL, ELT, SSIS, NoSQL, Azure DevOps",4+,Bachelor,True,4.0,0,0,0,1,0,0,1,0,0,1,0,0,0,0,1,0,0
"Senior, Data Engineer",Oil and Gas Job Search Ltd,Monterrey Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,Oil and Gas,2024-09-08 11:27:40.933821,25,Information Technology,,,"Schneider Electric has an opportunity for a Senior Data Engineer in our Monterrey, MX location. The Data Engineer will develop, maintain, and improve data delivery through North America (NAM) Data Excellence platform. The right person in this role will support improvements in data architecture, metric definition, and processes to support business data and analytical initiatives. Our Data Engineers provide guidance and support to team members in the Data Services team and our business partners. About Us Schneider Electric creates connected technologies that reshape industries, transform cities, and enrich lives. Our 135,000+ employees thrive in more than 100 countries. From the simplest of switches to complex operational systems, our technology, software, and services improve how our customers manage and automate their operations. Help us deliver solutions that ensure Life Is On everywhere, for everyone, and at every moment. http://www.youtube.com/watch?v=YtExntUe89c Key Responsibilities Include Great people make Schneider Electric a great company. Collaborate with team members to conceptualize, design, and deliver enterprise and departmental data solutions to support business intelligence, data warehousing, reporting, and machine learning requirements. Implement reliable and scalable solutions to meet the service levels associated with mission-critical solutions. Participate in and enhance our DevOps practice to ensure highly available solutions and quick issue resolution. Translate business requirements into data pipelines and data stores to support business requirements. Perform assessments (Proof of Concepts) of the latest tools and technologies. Work with Data and Solution Architects to define and implement migration strategies from legacy systems to cloud architecture and technologies. Provide team feedback to optimize the delivery of our solutions. Education Bachelor's degree related to Computer Science or Information Technology or equivalent Benefits Competitive salary Comprehensive health benefits Retirement savings plan Professional development opportunities We know skills and competencies show up in many ways and can be based on your life experience. If you do not necessarily meet all the requirements that are listed, we still encourage you to apply for the position. Qualifications Required qualifications: 5+ years of experience with modern programming languages such as Python, Scala, or Java. 3+ years of experience developing data-related solutions on cloud platforms such as Amazon Web Services (AWS). Demonstrated experience with primary AWS services such as EC2, Lambda, EMR, S3, IAM policies, CloudWatch, Cloud Formation, SES Demonstrated experience with Cloud Services for data handling and database technologies (DMS, Kafka, Spark, Redshift, Athena, Hadoop, Airflow, etc.). Knowledge of Data Management, Integration, and Data Quality tools, such as Alteryx, Trifecta, Informatica Power Center, Informatica Cloud, and Oracle Data Integrator. Command of advanced SQL queries and programming. Experience contributing to and following best practices for architecture, design, and implementation. Have an eye for operational transparency and resiliency at every application layer. Proven analytical and problem-solving abilities. Ability to assimilate information, quickly discern the most relevant facts, and recommend creative, practical design solutions. Ability to think outside the box is a real asset. Experience with DevOps tools and processes and CI/CD are an asset. Excellent communication, presentation, influencing, and reasoning capabilities. Solid understanding of data modeling, ETL processes, and data warehousing concepts. We know skills and competencies show up in many ways and can be based on your life experience. If you do not necessarily meet all the requirements that are listed, we still encourage you to apply for the position. Schedule: Full-time Req: 00922Q",https://mx.linkedin.com/jobs/view/senior-data-engineer-at-oil-and-gas-job-search-ltd-4017867467,4017867467,"The Data Engineer will develop, maintain, and improve data delivery through the North America Data Excellence platform, supporting improvements in data architecture, metric definition, and processes necessary for business data and analytical initiatives. Responsibilities include collaborating to conceptualize and deliver data solutions, implementing reliable solutions for mission-critical systems, participating in DevOps practices, translating business requirements into data pipelines, and assessing tools and technologies.","Python, Scala, Java, Amazon Web Services (AWS), EC2, Lambda, EMR, S3, IAM, CloudWatch, CloudFormation, SES, DMS, Kafka, Spark, Redshift, Athena, Hadoop, Airflow, SQL, Alteryx, Trifecta, Informatica Power Center, Informatica Cloud, Oracle Data Integrator",5+ years,Bachelor,True,5.0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0
Procurement Data Engineer II,Johnson Controls,Monterrey Metropolitan Area,ON-SITE,Entry level,Full-time,Industrial Machinery Manufacturing,2024-09-01 11:27:40.933821,25,Information Technology,,,"Johnson Controls is a global diversified technology and multi industrial leader serving a wide range of customers in more than 150 countries. Our 130,000 employees create intelligent buildings, efficient energy solutions, integrated infrastructure and next generation transportation systems that work seamlessly together to deliver on the promise of smart cities and communities. Our commitment to sustainability dates back to our roots in 1885, with the invention of the first electric room thermostat. We are committed to helping our customers win and creating greater value for all of our stakeholders through strategic focus on our buildings and energy growth platforms. For additional information, please visit www.johnsoncontrols.com or follow us @johnsoncontrols on Twitter. What you will do? Join us in the Procurement Execution Center (PEC) as a Data Engineer as part of a is a diverse team of data and procurement individuals. In this role, you will be responsible for deploying supporting the E2E management of our data, including: ETL/ELT, DW/DL, data staging, data governance, and manage the different layers of data required to ensure a successful BI & Reporting for the PEC. This role will work with multiple types of data, spreading across multiple functional areas of expertise, including Logistics, MRO & Energy, Travel, Professional Services, among others. How you will do it? Deploy data ingestion processes through Azure Data Factory to load data models as required into Azure Synapse. Build and design ETL/ELT processes with Azure Data Factory (ADF) and/or Python, which once deployed, will require to be executed daily and weekly. Assemble large, complex data sets that meet functional / non-functional business requirements. Build the infrastructure required for optimal ETL/ELT of data from a wide variety of data sources using Azure SQL and ADF. Develop data models that enable DataViz, Reporting and Advanced Data Analytics, striving for optimal performance across all data models. Maintain conceptual, logical, and physical data models along with corresponding metadata. Manages the DevOps pipeline deployment model, including automated testing procedures Deploys data stewardship and data governance across our data warehouse, to cleanse and enhance our data, using knowledge bases and business rules. Performs the necessary data ingestion, cleansing, transformation, and coding of business rules to support annual Procurement bidding activities. Support the deployment of a global data standard for Logistics. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Support Rate Repository management as required (including Rate Card uploads to our DW). Other Procurement duties as assigned. What are we looking for? Bachelor’s degree in related field (Engineering, Computer Science, Data Science or similar) 3+ years of relevant experience in BI Engineering, data modeling, data engineering, software engineering or other relevant roles. Strong SQL knowledge and experience working with relational databases. Knowledge in DW/DL concepts, data marts, data modeling, ETL/ELT, data quality/stewardship, distributed systems and metadata management. Experience building and optimizing data pipelines, architectures, and data sets. Azure Data Engineering certification preferred (DP-203) ETL/ELT development experience (3+ years). SSIS or ADF are preferred. Ability to resolve ETL/ELT problems by proposing and implementing tactical/Strategic solutions. Strong project management and Organizational skills. Experience with object-oriented function scripting languages: Python, Scala, C#, etc. Experience with NoSQL databases is a plus to support the transition from On-Prem to Cloud. Excellent problem solving, critical thinking, and communication skills Relevant experience with Azure DevOps (CI/CD, git/repo management) is a plus Due to the global nature of the role, proficiency in English language is a must Johnson Controls does not request pregnancy or HIV testing as a requirement for admission, permanence or promotion.",https://mx.linkedin.com/jobs/view/procurement-data-engineer-ii-at-johnson-controls-4008470721,4008470721,"Join us in the Procurement Execution Center as a Data Engineer responsible for end-to-end management of our data, including ETL/ELT, data warehousing, data governance, and business intelligence. You will deploy data ingestion processes through Azure Data Factory, design and build ETL/ELT processes, manage complex data sets, and develop data models for reporting and analytics. A Bachelor’s degree in a related field and 3+ years of experience in BI Engineering or related roles are required.","Azure Data Factory, Azure Synapse, SQL, Python, ETL, ELT, Data Warehousing, Data Modeling, DevOps, SSIS, NoSQL",3+ years,Bachelor,True,3.0,0,0,0,1,0,1,1,1,0,1,0,0,0,0,1,0,0
Sr. Data Engineer,Uber Freight,Monterrey Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,"Transportation, Logistics, Supply Chain and Storage",2024-08-16 11:27:40.933821,25,Information Technology,,,"About The Team The Uber Freight team is building a better future for logistics. We believe that when shippers and carriers have the freedom to move together, the entire industry moves ahead. Our teams design and build innovative applications, infrastructure, and models to power Uber Freight. Utilizing Uber Freight's foundational elements, these include the mobile app for Carriers, the portals and integrations that give Shippers access to the platform, tools for our Operations teams, and all the underlying pricing, matching, and forecasting algorithms that evolve the freight industry forward. About The Role We are seeking a talented and experienced Data Engineer to contribute to our technical efforts in modernizing and replacing legacy reporting solutions. This role involves collaborating closely with Data Analysts and Business SMEs to perform detailed requirement analysis for enhancing and creating new reporting and analytics solutions. The ideal candidate will have a knack for imagining and implementing creative, innovative reporting solution designs while adhering to architectural requirements of maintainability and scalability. What You'll Do Build scalable highly performant dashboards for delivering clear business insights from a variety of raw data sources Understanding of Web concepts (HTML, CSS, URLS, frames) to the level appropriate to develop Tableau reports in HTML according to UX designs EXPERIENCE in working with Tableau Reporting system an Power BI Develop batch and real-time analytical solutions, prototypes and proof of concept for selected solutions. Collaborate with cross functional team to resolve data quality and operational issues. Basic Qualifications EXPERIENCE with Tableau EXPERIENCE with Power BI Advanced Microsoft Office EXPERIENCE with SQL server reporting services (SSRS); SQL; queries EXPERIENCE with Oracle",https://mx.linkedin.com/jobs/view/sr-data-engineer-at-uber-freight-3976383188,3976383188,"We are seeking a talented and experienced Data Engineer to contribute to modernizing and replacing legacy reporting solutions. This role involves collaborating closely with Data Analysts and Business SMEs to perform detailed requirement analysis for enhancing and creating new reporting and analytics solutions. The ideal candidate will develop scalable dashboards for delivering business insights, understand web concepts to develop Tableau reports, and collaborate with cross-functional teams to resolve data quality issues.","Tableau, Power BI, SQL, Microsoft Office, SQL Server Reporting Services (SSRS), Oracle, HTML, CSS",,,True,,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
Data Insights & Visualization Specialist,Accenture México,Monterrey Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Business Consulting and Services,2024-09-16 15:10:44.080834,158,Information Technology,,,"DARE TO BE A PART OF THE CHALLENGE! COME AND JOIN OUR TEAM TOGETHER WE CAN MAKE THE DIFFERENCE! Did you know that Accenture is leading the digital transformation in the World? Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Our main purpose is to collaborate with our clients, so they can become high-performance businesses. Accenture is present in more than 200 cities, 49 countries and approximately 732,000 employees worldwide. We Offer Career development according to your profile and interests. Work in one of the best companies and feel proud. Access to an innovative methodology and tools. Direct contact with experts worldwide. Use of work schemes and cutting-edge technologies. Constant training. Work environment based on teamwork and collaboration. Participation in International Projects Skills: +7 years of experience Microsoft Power BI Responsibilities: As a Mid Level Data Insights Visualization Practitioner, you use your Microsoft Power BI PBI expertise to develop and implement effective data visualization solutions. You should have expert proficiency in PBI and advanced proficiency in BI Reporting Tools, Data Analysis Interpretation, and Data Visualization. Develop and implement effective data visualization solutions using PBI. Create interactive dashboards and custom reports to provide insights to business stakeholders. Analyze data to identify trends and patterns, and provide recommendations for business improvement. Collaborate with cross functional teams to ensure seamless integration of data visualization solutions. Provide technical guidance and support to project teams throughout the implementation lifecycle.",https://mx.linkedin.com/jobs/view/data-insights-visualization-specialist-at-accenture-m%C3%A9xico-4004418995,4004418995,"As a Mid Level Data Insights Visualization Practitioner, you will use your Microsoft Power BI expertise to develop and implement effective data visualization solutions, create interactive dashboards, analyze data for trends and patterns, and collaborate with cross-functional teams to ensure seamless integration of solutions.","Microsoft Power BI, BI Reporting Tools, Data Analysis, Data Visualization",7+ years,,True,7.0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0
Data Engineer,Chubb,Monterrey Metropolitan Area,HYBRID,Entry level,Full-time,Insurance,2024-09-16 15:10:53.434211,34,Information Technology,,,"Job Description With you, Chubb is better! Are passionate with data infrastructure, metrics and coding? Do you love creating pipelines to support business? Would you like to be a member of a fun working environment where your innovative projects make a real impact? Then, check this outstanding opportunity in our new Technology Hub in Mexico – CBSM ( Chubb Business Services Monterrey ) as a Data Engineer. If you are a tech lover and are raring to develop your career join our growing, pioneer, diverse team within one of the largest companies in the world, we would love to hear from you! The Opportunity Your Responsibilities for this role may include, but are not limited to: Conceptualize, support, and drive the data architecture for multiple large-scale projects as well as recommend solutions to improve processes. Integrate data from various sources and build robust, multi-functional data assets to support analytics. Responsible for data asset design, development, integration, and optimization. Must love coding – prepare to spend more than 80% of the time on hands-on development with groundbreaking technologies. Gatekeeper of end-to-end applications and frameworks ranging from system programming to micro-services to simple front-end applications Build pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts. Moreover, clean, unify and organize messy and complex data sets for easy access and analysis. Collaborate with others to understand data needs, representing key data insights in a meaningful way. Ability to own complete project or a subject area delivery while leading team members in a scrum setting. Design, build, and launch collections of sophisticated data models and visualizations that support multiple use cases across different products or domains. Solve our most exciting data integration problems, applying optimal ETL patterns, frameworks, query techniques, sourcing from structured and unstructured data sources. Be the point of reference for solving a challenging technical problem Knowledge, Skills, And Abilities At least 4 years of data/software engineering experience including data analysis, design and integration/ETL. Good knowledge of Informatica Intelligent Cloud Services (IICS) Strong knowledge of Python Experience with SQL Bonus points for PySpark Databricks Snowflake NoSQL Data Modelling Our team makes a difference, every time. For this reason, we offer in return! We offer hybrid working model, explicit, structured career development, a competitive salary package, annual bonus, private medical cover, monthly allowance for lunch, continuous learning experiences, work in a fun, lively environment with mentoring from our groundbreaking senior mentors. Integrity. Client Focus. Respect. Excellence. Teamwork Our core values instruct how we live and work. We’re an ethical and honest company that’s wholly committed to its clients. A business that’s engaged in mutual trust and respect for its employees and partners. A place where colleagues perform at the highest levels. And a working environment that’s collaborative and encouraging. Diversity & Inclusion. At Chubb, we consider our people our chief competitive advantage and as such we treat colleagues, candidates, clients, and business partners with equality, fairness, and respect, regardless of their age, disability, race, religion or belief, gender, sexual orientation, marital status or family circumstances. We strive to achieve an environment where all colleagues feel comfortable performing to their full potential and are recognized for their contributions. Many voices, One Chubb!",https://mx.linkedin.com/jobs/view/data-engineer-at-chubb-3870861602,3870861602,"In the Data Engineer role, the responsibilities include conceptualizing, supporting, and driving data architecture for large-scale projects, integrating data from various sources, and building multi-functional data assets to support analytics. The role involves hands-on development with technologies, ensuring the design, development, integration, and optimization of data assets. The engineer will be responsible for developing pipelines, dashboards, and systems, as well as cleaning and organizing complex data sets. Collaboration with others to understand data needs and delivering impactful data models and visualizations across different products is key. The role also requires solving data integration problems with optimal ETL patterns and serving as a technical reference.","Python, SQL, Informatica Intelligent Cloud Services (IICS), PySpark, Databricks, Snowflake, NoSQL",4,,True,4.0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,1,0,0
Power BI Consultant,Accenture México,Monterrey Metropolitan Area,HYBRID,Mid-Senior level,Full-time,Business Consulting and Services,2024-09-16 15:10:53.434211,200,Information Technology,,,"DARE TO BE A PART OF THE CHALLENGE! COME AND JOIN OUR TEAM TOGETHER WE CAN MAKE THE DIFFERENCE! Did you know that Accenture is leading the digital transformation in the World? Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Our main purpose is to collaborate with our clients, so they can become high-performance businesses. Accenture is present in more than 200 cities, 49 countries and approximately 732,000 employees worldwide. We Offer Career development according to your profile and interests. Work in one of the best companies and feel proud. Access to an innovative methodology and tools. Direct contact with experts worldwide. Use of work schemes and cutting-edge technologies. Constant training. Work environment based on teamwork and collaboration. Participation in International Projects Requirements: 1-3 years of experience working with reporting and data visualization tools, particularly Power BI. Professional background in data analysis. Practical experience using SQL and DAX. Ability to rapidly transform data into robust reporting and analytical solutions. Understanding of the principles and methodologies of database modeling. Familiarity with Power BI Service. Strong written and verbal communication skills in English. Knowledge of Azure Modern Data Platform (Azure Data Lake, Synapse, Data Factory, Databricks) is a plus. Knowledge or training in Microsoft Fabric is a plus.",https://mx.linkedin.com/jobs/view/power-bi-consultant-at-accenture-m%C3%A9xico-3931982607,3931982607,"The position requires 1-3 years of experience working with reporting and data visualization tools, particularly Power BI. A professional background in data analysis is necessary, along with practical experience using SQL and DAX. The candidate should be able to rapidly transform data into robust reporting and analytical solutions, understand database modeling principles, and be familiar with Power BI Service. Strong written and verbal communication skills in English are required, and knowledge of Azure Modern Data Platform and Microsoft Fabric is a plus.","Power BI, SQL, DAX, Azure Data Lake, Azure Synapse, Azure Data Factory, Databricks, Microsoft Fabric",1-3,,True,1.0,0,0,1,1,0,0,0,0,1,1,0,0,0,0,0,0,0
Workday Data Sr. Analyst,Accenture México,Monterrey Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,Business Consulting and Services,2024-09-16 15:11:11.469289,25,Information Technology,Engineering,,"DARE TO BE A PART OF THE CHALLENGE! COME AND JOIN OUR TEAM TOGETHER WE CAN MAKE THE DIFFERENCE! Did you know that Accenture is leading the digital transformation in the World? Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Our main purpose is to collaborate with our clients, so they can become high-performance businesses. Accenture is present in more than 200 cities, 49 countries and approximately 743,000 employees worldwide. Offer Career development according to your profile and interests. Work in one of the best companies and feel proud. Access to an innovative methodology and tools. Direct contact with experts worldwide. Use of work schemes and cutting-edge technologies. Constant training. Work environment based on teamwork and collaboration. Participation in International Projects Basic Qualifications: 1+ years’ previous consulting experience or congruent professional experience either as an internal consultant or with a consulting/software company 1+ years of experience in HRIS field with Workday related experience in data migration from SAP, Oracle, PeopleSoft, or similar applications Experience with XML, XSD, XSLT or XPath Formula and macro experience in Microsoft Excel Experience with at least 1 full life cycle ERP implementations in a Data Conversion role 1+ years project workstream experience Ability and willingness to travel up to 80% Preferred Skills: Four-year college degree in a computer related or engineering field or equivalent work experience Developed understanding and demonstration of the Software Development Lifecycle (SDLC) Developed experience in Reporting/Analytics Self-starter with proven ability to work within a team-oriented environment Ability to work in a fast-paced environment and to adapt to frequent change Demonstrated ability to work creatively and analytically in a problem-solving environment Demonstrated experience with Excel, Visio, MS Project (or equivalent) and PowerPoint Solid communication (both written and oral) effectiveness with project leadership Accenture does not discriminate based on race, religion, color, sex, age, disability, nationality, sexual orientation, gender identity or expression, or for any other reason covered by local law.",https://mx.linkedin.com/jobs/view/workday-data-sr-analyst-at-accenture-m%C3%A9xico-4004420828,4004420828,"Join our team to make a difference! The position requires 1+ years of previous consulting experience and 1+ years in the HRIS field with Workday. Responsibilities include data migration from SAP, Oracle, PeopleSoft, or similar applications, and experience with XML, XSD, XSLT, or XPath. Experience in Microsoft Excel with formulas and macros, as well as at least 1 full life cycle ERP implementation in a Data Conversion role is necessary. Ability and willingness to travel up to 80% is required.","Workday, SAP, Oracle, PeopleSoft, XML, XSD, XSLT, XPath, Microsoft Excel, Visio, MS Project, PowerPoint",1+,,True,1.0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0
Sr. Data Engineering,Accenture México,Monterrey Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Business Consulting and Services,2024-09-18 07:36:23.414069,25,Information Technology,,,"DARE TO BE A PART OF THE CHALLENGE! COME AND JOIN OUR TEAM TOGETHER WE CAN MAKE THE DIFFERENCE! Did you know that Accenture is leading the digital transformation in the World? Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Our main purpose is to collaborate with our clients, so they can become high-performance businesses. Accenture is present in more than 200 cities, 49 countries and approximately 732,000 employees worldwide. We Offer Career development according to your profile and interests. Work in one of the best companies and feel proud. Access to an innovative methodology and tools. Direct contact with experts worldwide. Use of work schemes and cutting-edge technologies. Constant training. Work environment based on teamwork and collaboration. Participation in International Projects Skills: +5 years of experience Microsoft Azure Microsoft SQL Microsoft Azure Databricks Microsoft Data Factory SSIS ETL Responsibilities As a Data Engineer: You will be responsible for designing, developing, and maintaining data solutions for data generation, collection, and processing. Your main tasks will include creating data pipelines, ensuring data quality, and implementing ETL extract, transform, and load processes to migrate and deploy data across systems. You will be expected to perform independently and become a subject matter expert, actively participating and contributing in team discussions, as well as providing solutions to work related problems. Intermediate proficiency in Microsoft Azure Data Factory is required. Additionally, intermediate proficiency in Microsoft Azure Synapse Analytics, Microsoft Azure Databricks, and beginner proficiency in Microsoft SQL Server Integration Services SSIS are recommended. Develop innovative data solutions to optimize data generation, collection, and processing. Collaborate with cross functional teams to ensure data quality and integrity. Implement efficient ETL processes to migrate and deploy data across systems. Stay updated with the latest industry trends and technologies in data engineering. Identify and resolve data related issues to ensure smooth data operations.",https://mx.linkedin.com/jobs/view/sr-data-engineering-at-accenture-m%C3%A9xico-4026774506,4026774506,"As a Data Engineer, you will be responsible for designing, developing, and maintaining data solutions for data generation, collection, and processing. Your main tasks will include creating data pipelines, ensuring data quality, and implementing ETL processes to migrate and deploy data across systems. You will perform independently, become a subject matter expert, and actively contribute in team discussions.","Microsoft Azure, Microsoft SQL, Microsoft Azure Databricks, Microsoft Data Factory, SSIS, ETL",5+ years,,True,5.0,0,0,1,1,0,0,1,0,0,1,0,0,0,0,0,0,0
AI Data Engineer,Recruiters Worldwide,Monterrey Metropolitan Area,HYBRID,Entry level,Full-time,IT Services and IT Consulting,2024-09-18 07:36:40.941057,25,Information Technology,,,"Buscamos un AI Data Engineer Senior Resource Description • Ingeniero de datos, especialista en Inteligencia Artificial Generativa (Específicamente en modelos CHATGPT de Azure u otros, que pueda configurarlos, configurar contexto, prompting engineering) Requirements • Ingeniero de datos, especialista en Inteligencia Artificial Generativa LLMs (Open AI,  Llama, Mistral, etc.). • Específicamente en modelos CHATGPT de Azure u otros, vector DataBase, configurar contexto, prompting engineering • Azure functions • Containers. Consideraciones Importantes: • La persona requiere dominar muy bien el inglés. • La persona seleccionada debe residir en Nuevo León., porque el puesto es un  80% presencial. ¿Qué ofrecemos? • Contrato por tiempo determinado de 9 meses (posibilidad de extensión). • Vacaciones conforme a la ley. (Al cumplir un año tienes derecho a 12 días, el siguiente 14 días, después 16 y así sucesivamente). • Aguinaldo conforme a la ley. (15 días por año trabajado). • Prima vacacional del 25%. • Seguro de gastos médicos mayores para el colaborador. • Tarjeta de beneficios MedicallHom o Doctor en línea 24/7 o Ambulancia (1 envío gratis, subsecuentes con precio preferencial) o Médico a domicilio desde $450 pesos. o Chequera de la salud digital (promociones y descuentos a través de la  app) o Consultas con médicos especialistas desde $350 o Descuentos en laboratorios, clínicas, hospitales. o Descuentos comerciales en restaurantes, tiendas departamentales, spas,  tiendas para mascotas, etc. o Servicios oftalmológicos y odontológicos con costos preferenciales o seguro de protección ante accidentes (seguro por muerte accidental,  reembolso de gastos funerarios por accidente, entre otros) o Servicio funerario o Farmacia en línea (Envío de medicamentos a domicilio) o asesoría médica, nutricional y emocional. o Check up médico gratis.",https://mx.linkedin.com/jobs/view/ai-data-engineer-at-recruiters-worldwide-4026715137,4026715137,"We are looking for a Senior AI Data Engineer, a data engineer specializing in Generative Artificial Intelligence (specifically in Azure CHATGPT models or others, capable of configuring them, configuring context, prompting engineering).","Generative AI, OpenAI, Llama, Mistral, Azure, Vector Database, Azure Functions, Containers",,,True,,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0
Data Engineer,Chubb,Monterrey Metropolitan Area,HYBRID,Entry level,Full-time,Insurance,2024-09-18 07:36:40.941057,25,Information Technology,,,"Job Description Data Engineer Job Description: We are seeking an experienced Data Engineer with expertise in ETLs (Extract, Transform, Load), Data Modeling, and Databricks to join our dynamic team. The ideal candidate must possess excellent knowledge and skills in SQL and Python, as they will play a crucial role in managing, optimizing, and enhancing our data infrastructure. Responsibilities: Develop and maintain robust, efficient, and scalable ETL processes for data extraction, transformation, and loading tasks. Design, implement, and optimize data models to meet business requirements and ensure data integrity and accuracy. Collaborate with cross-functional teams, including Data Scientists, Software Engineers, and Business Analysts, to understand data needs and provide data-related solutions. Perform data analysis to identify and resolve data quality issues, inconsistencies, and performance bottlenecks. Build and maintain the data pipeline architecture to enable data ingestion from various sources into the data warehouse or data lake. Work closely with stakeholders to understand business objectives, identify data-related opportunities, and provide actionable insights. Develop and maintain documentation related to data processes, data models, and system architecture. Collaborate with the Data Governance team to ensure compliance with data privacy regulations and implement appropriate security measures. Skills and Qualifications: Bachelor’s or Master’s degree in Computer Science, Information Systems, or a related field. Proven work experience as a Data Engineer or in a similar role. English Fluent Strong knowledge and experience with ETL processes, data modeling, and data warehousing concepts. Proficient in SQL, with the ability to write complex queries and optimize their performance. Expertise in Python programming language and its associated data libraries (e.g., Pandas, NumPy) for data manipulation and analysis. In-depth understanding of relational database systems (e.g., PostgreSQL, MySQL) and experience in query optimization techniques. Hands-on experience with Databricks for data engineering, including building and managing data pipelines, and optimizing data processing workflows. Strong problem-solving and analytical skills, with the ability to troubleshoot and resolve data-related issues. Excellent communication skills and the ability to effectively collaborate with cross-functional teams. Knowledge of data governance and data security principles. Attention to detail and ability to adhere to project timelines and deadlines. Nice to Have Skills: Experience with Informatica Intelligent Cloud Services (IICS) or similar cloud-based integration platforms. Experience designing and developing data integration workflows using IICS or similar tools. Experience with data integration performance tuning and optimization. Familiarity with cloud platform Azure and experience with its data services (e.g., Azure Data Factory). Experience with big data technologies (e.g., Hadoop, Spark) and distributed computing frameworks.",https://mx.linkedin.com/jobs/view/data-engineer-at-chubb-4028793012,4028793012,"We are seeking an experienced Data Engineer with expertise in ETLs, Data Modeling, and Databricks to manage, optimize, and enhance our data infrastructure. Responsibilities include developing and maintaining ETL processes, designing data models, collaborating with cross-functional teams, performing data analysis, building data pipeline architecture, and ensuring compliance with data privacy regulations. The ideal candidate must have a Bachelor’s or Master’s degree in Computer Science or related field and proven work experience in a similar role.","SQL, Python, ETL, Databricks, PostgreSQL, MySQL, Pandas, NumPy, Azure Data Factory, Hadoop, Spark",,Bachelor,True,,0,0,1,1,0,0,1,0,0,1,0,0,0,0,1,0,0
Master Data Analyst,Steelcase,Monterrey Metropolitan Area,HYBRID,Associate,Full-time,Furniture and Home Furnishings Manufacturing,2024-09-18 07:36:40.941057,27,Manufacturing,,,"We are hiring a Master Data Analyst - Associate who will be responsible for the creation and maintenance of Master Data for: customers (Sold-to and Ship-tos), Business partner (site IDs) and other type of data that are fundamental to business processes that influence the customer experience. About the role: The role involves ensuring the integrity, quality, and reliability of master data to support business processes and decision-making. This includes overseeing the creation, modification, and deletion of master data elements to ensure accuracy, completeness, and consistency. The role also involves collaboration with various departments such as IT, Credit, Sales-Channel and other stakeholders to understand data requirements, implement data governance policies, and support business processes. Responsibilities will include: Execute and monitor customer, business partners and product data management and maintenance activities while following global master data policies and practices. Responsibility to manage and communicate directly with Dealers, Customers and Business Partners. Create, update, and maintain master data records in SAP, ensuring data accuracy and consistency. Possible evolution to other systems CRM´s. Implement and enforce data governance policies and standards to guarantee high-quality master data. Conduct regular audits of master data to identify and resolve discrepancies or inconsistencies. Implement data quality checks and validations to prevent errors in master data creation or modification. Identify opportunities for process optimization and automation to enhance efficiency in master data management. Contribute to the development and implementation of best practices for master data processes. Provide training to end-users on SAP master data processes and best practices. Create and maintain documentation related to master data processes, procedures, and standards. Works with relevant partners and appropriate team members to resolve Master Data issues in an efficient and timely manner. Manage customer data and customer data integrity across systems Ensure Replication of data is conducted in a timely manner. Investigate and resolve master data-related issues or errors, working with cross-functional teams to implement corrective actions. Be an active member of assigned integration projects that involve Customer Master Data changes. Who you are Required Skills and Competencies Bachelor’s degree in Business or related. At least 1 year of experience in Master Data or System Administration. Advanced written and spoken English. Intermediate to advanced level of MS Excel. Preferred Skills and Competencies SAP knowledge is a plus. Strong organization skills and able to prioritizes tasks and complete it efficiently. Strong attention to detail with ability to research and resolve complex problems. Demonstrated customer service passion and a willingness to go extra mile. Ability to communicate effectively through a variety of channels with customers and working across matrix organizations (cross functional teams). Continuous improvement mindset. Excellent analytical and problem-solving skills. Why people choose to work with us: At Steelcase, we put people at the center of everything we do. We understand the role of work and believe that it can bring meaning and purpose to the lives of our customers and our employees. We prioritize supporting our employees both in and out of work, in all aspects of their lives. When we bring our talents together, we make a positive lasting impact through our work and communities. Who we are: Organizations around the world trust Steelcase to help them create places that help people work better, be inspired, and accomplish more. We design, manufacture, and partner with other leading organizations to provide architecture, furniture, and technology solutions- accessible through a network of channels, including over 800 Steelcase dealer locations. Steelcase is a global, industry-leading, publicly traded company with fiscal year 2021 revenue of $2.6 billion. What Matters to Us: More than qualifications, we’re looking for talent and potential. We are proud to have a diverse and inclusive workforce, and we're always looking to improve our global community. We value applicants who are comfortable interacting with people different from themselves, building mutual respect and positive relationships. We invite people from all backgrounds and genders to apply. Steelcase provides employment opportunities to all qualified employees and applicants without regard to race, color, creed, genetic information, religion, national origin, gender, sexual orientation, gender identity and expression, age, disability, or veteran status and bases all employment decisions only on valid job requirements. We are proud to be recognized for our inclusive workforce by the Corporate Equality Index for the past nine years.",https://mx.linkedin.com/jobs/view/master-data-analyst-at-steelcase-4028860670,4028860670,"We are hiring a Master Data Analyst - Associate who will be responsible for the creation and maintenance of Master Data for customers, business partners, and other types of data that are fundamental to business processes that influence the customer experience. The role involves ensuring the integrity, quality, and reliability of master data to support business processes and decision-making. Responsibilities include managing data governance policies, conducting audits, implementing quality checks, and optimizing processes. The candidate will create and maintain master data records in SAP, with an emphasis on data accuracy and consistency. Collaboration with various departments is required, along with providing training to end-users.","SAP, MS Excel",1+,Bachelor,True,1.0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
Senior Data Analyst,Chubb,Monterrey Metropolitan Area,HYBRID,Mid-Senior level,Full-time,Insurance,2024-09-18 07:36:40.941057,25,Information Technology,,,"Job Description Senior Data Analyst By joining Chubb as a Senior Data Analyst, you will analyze and certify data, troubleshoot data issues, promote data quality, work directly with the business and developers to document requirements and technical specifications and lead the delivery of key projects in support of North America Statutory Reporting from the enterprise data warehouse. Our data warehouse platform is a strategic application within the business, feeding into multiple systems and applications both up and downstream with data that directly supports business decisions being made each and every day. With us, you’ll leverage your knowledge of SQL and database tables to analyze data, identify gaps or discrepancies, and partner with applications teams, IT teams across the business, our stakeholders, and our Data Architect to drive solutions that directly impacts how data is used throughout the business. You will lead reporting initiatives, delivering solutions from inception to reporting submission while working within budget and timelines. Through it all, we’ll also look to you to share your ideas and manage data related projects end to end that influence how we incorporate, validate, and distribute data enterprise-wide. In this role, you will: Lead all phases of the development, testing, and implementation life cycle, defining, documenting and reviewing all requirements, creating test scenarios, developing test plans, analyzing results and testing/validating data Work with business partners, project management, architecture, development and leadership to deliver reporting solutions on-time, within budget and with data accuracy. Document requirements, technical specifications and implementation documentation on all reporting solutions. Reconcile multiple data sources and identify the root cause of discrepancies in expected output; distinguish between multiple root causes and/or multiple trends in a given data set and articulate results to various stakeholders, management, and technical resources Analyze and test relational databases and investigate any data load failures or data retrieval issues Monitor data warehousing systems based on assigned tasks to ensure reliability and accuracy of information loaded into the databases Generate reports, dashboards, and ad hoc extracts for business and/or leadership Ensure data integrity by implementing quality assurance practices, gathering, and entering missing data, and resolving any anomalies Qualifications 7+ years of experience in a Data Analysis, Business Analysis, Data Quality Assurance (or similar) role as part of a data warehouse team and supporting data-driven projects Experience working with DBMS platforms, including a demonstrated understanding of table structures, hierarchies, joins, etc. Advanced knowledge of SQL, with the ability to write and troubleshoot medium to advanced SQL queries Knowledge of data warehousing methodologies and tools including their connection to systems both up and down stream Bachelor’s degree in Mathematics, Engineering, Computer Science, or a related discipline preferred Prior experience within the insurance industry or related to regulatory reporting is preferred Previous experience with Azure Synapse, Informatica Intelligent Cloud Services (IICS), a plus Our team makes a difference, every time. For this reason, we offer in return! We offer hybrid working model, explicit, structured career development, a competitive salary package, annual bonus, private medical cover, monthly allowance for lunch, continuous learning experiences, work in a fun, lively environment with mentoring from our groundbreaking senior mentors. Integrity. Client Focus. Respect. Excellence. Teamwork Our core values instruct how we live and work. We’re an ethical and honest company that’s wholly committed to its clients. A business that’s engaged in mutual trust and respect for its employees and partners. A place where colleagues perform at the highest levels. And a working environment that’s collaborative and encouraging. Diversity & Inclusion. At Chubb, we consider our people our chief competitive advantage and as such we treat colleagues, candidates, clients, and business partners with equality, fairness, and respect, regardless of their age, disability, race, religion or belief, gender, sexual orientation, marital status or family circumstances. We strive to achieve an environment where all colleagues feel comfortable performing to their full potential and are recognized for their contributions. Many voices, One Chubb!",https://mx.linkedin.com/jobs/view/senior-data-analyst-at-chubb-3992774351,3992774351,"As a Senior Data Analyst, you will analyze and certify data, troubleshoot data issues, promote data quality, and lead the delivery of key projects in support of North America Statutory Reporting from the enterprise data warehouse. Your role involves using SQL to analyze data, identify discrepancies, document requirements, and collaborate with various teams to drive data solutions. You will manage reporting initiatives, ensure data integrity, reconcile data sources, and generate reports while adhering to budget and timelines.","SQL, Data Warehousing, DBMS, Azure Synapse, Informatica Intelligent Cloud Services",7+,Bachelor,True,7.0,0,0,0,1,0,1,1,0,0,1,0,0,0,0,0,0,0
Business Intelligence Specialist,ABB,Monterrey Metropolitan Area,ON-SITE,,Full-time,"Appliances, Electrical, and Electronics Manufacturing",2024-09-18 07:37:03.680629,25,Sales,,,"At ABB, we are dedicated to addressing global challenges. Our core values: care, courage, curiosity, and collaboration - combined with a focus on diversity, inclusion, and equal opportunities - are key drivers in our aim to empower everyone to create sustainable solutions. Write the next chapter of your ABB story. This position reports to EL Customer Operations Manager Your role and responsibilities In this role, you will have the opportunity to facilitate the development of the marketing strategy for existing and potential products, systems, and/or services. Each day, you will support the definition of the assigned market footprint (market presence, execution standards, and delivery model). You will also showcase your expertise by performing various market analyses. The work model for the role is: #L-Hybrid This role is contributing to the ELECTRIFICATION team and stakeholders. You will be mainly accountable for: Collecting data and providing sound business and competitor intelligence analyses of internal sales, technical and financial data, and external market data and trends. Interpreting resulting data and supports the Business Intelligence Manager in providing recommendations to Marketing and Sales management teams. Supporting the definition of business intelligence strategic plans in collaboration with management and driving relevant implementation. Building comprehensive sales analyses regarding channels, segments, geographic areas, customers, products, systems, and services to provide valuable insights for strategic decision-making. Qualifications For The Role Bachelor’s degree in Electrical, Mechatronics or Automation Engineering. Experience with Electrification Projects and Medium Voltage Products. Previous experience working with Infrastructure projects. 2+ years of experience in similar roles working as leadership. Available to relocation and travel. Advanced English level. Benefits Retirement plan Life insurance Accident insurance Paid Parental leave (gender neutral) Wellbeing program",https://mx.linkedin.com/jobs/view/business-intelligence-specialist-at-abb-4026437275,4026437275,"In this role, you will facilitate the development of the marketing strategy for existing and potential products, perform various market analyses, and support the definition of market presence and execution standards. You will collect data and provide business and competitor intelligence analyses, interpret data for marketing and sales management recommendations, and build comprehensive sales analyses for strategic decision-making.","Data Analysis, Business Intelligence, Market Analysis, Sales Analysis, Electrical Engineering",2+ years,Bachelor,True,2.0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
Data Analyst,Epicor,Monterrey Metropolitan Area,ON-SITE,Entry level,Full-time,"IT Services and IT Consulting, Software Development, and Technology, Information and Internet",2024-09-18 07:37:03.680629,57,Information Technology,,,"Requirements Description & Requirements The Job: The Data Quality Analyst is responsible for ensuring the accuracy, integrity, and reliability of data across the organization. What you will be doing: Performing statistical tests on large datasets to determine data quality and integrity. Evaluating system performance and design, as well as its effect on data quality. Collaborating with database developers to improve data collection and storage processes. Running data queries to identify coding issues and data exceptions, as well as cleaning data. Gathering data from primary or secondary data sources to identify and interpret trends. Reporting data analysis findings to management to inform business decisions and prioritize information system needs. Documenting processes and maintaining data records. Adhering to best practices in data analysis and collection. Keeping abreast of developments and trends in data quality analysis. Working with functional operational teams to institute new processes to mitigate impacts to data integrity Perform corrections within source systems to adhere to overall data integrity guidelines. You bring (most) of this!: Bachelor's degree in statistics, mathematics, computer science, information management, or similar. At least 3-5 years of experience in data quality analysis. Proficiency in programming languages, including Structured Query Language (SQL) and JavaScript is preferred. In-depth knowledge of statistical methods and tests. Extensive experience with statistical packages, such as MS Excel, SAS, and SPSS Exceptional analytical skills. Advanced problem-solving skills. Knowledge of best practices in data analysis. Excellent interpersonal and communication skills. The Finance Team You’ll find a strong sense of community, collaboration, and cross-functional partnering within the Epicor Finance and Accounting organization. With Epicor being an eager company, you will play a key role in supporting mergers and acquisitions and strategic financial activity globally. We are rapidly expanding and looking for exceptional talent to join our team in all of our Epicor offices. About Epicor At Epicor we know that success comes from working together. Everyone has a role to play, and it’s the essential partnerships across our company that are crucial to our customers’ success and our growth as a business. We’re truly a team. Working in close partnership, we bring wide-ranging talents together in powerful collaborations. We think innovatively, share our knowledge generously, and constantly learn from our colleagues. We’re proud of the success we achieve every day, but we never stop challenging ourselves and encouraging each other. Together, we go further and imagine an even brighter future. Whatever your career journey, we’ll help you find the right path. Through our training courses, mentorship, and continuous support, you’ll get everything you need to thrive. At Epicor, your success is our success. And that success really matters, because we’re the essential partners for the world’s most essential businesses—the hardworking companies who make, move, and sell the things the world needs. Equal Opportunities and Accommodations Statement Epicor is committed to creating a workplace and global community where inclusion is valued; where you bring the whole and real you—that’s who we’re interested in. If you have interest in this or any role- but your experience doesn’t match every qualification of the job description, that’s okay- consider applying regardless. We are an equal-opportunity employer.",https://mx.linkedin.com/jobs/view/data-analyst-at-epicor-3994990217,3994990217,"The Data Quality Analyst is responsible for ensuring the accuracy, integrity, and reliability of data across the organization, performing statistical tests on large datasets, collaborating with database developers, running data queries, interpreting trends, and reporting findings to management.","SQL, JavaScript, MS Excel, SAS, SPSS, Statistical Methods",3-5,Bachelor,True,3.0,0,0,0,0,0,1,0,0,1,1,0,0,0,0,0,0,0
Master Data Analyst,Clarios,Monterrey Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,Motor Vehicle Parts Manufacturing,2024-09-18 07:37:03.680629,64,Information Technology,,,"Responsibilities Master Data Management using knowledge of/experience with SAP master data and concepts across Materials Management (MM), Production Planning (PP) modules, with emphasis on plant-specific material masters, BOMs, Work centers, Routings, and production versions. Master Data Management using the SAP Business Workplace and workflow-enabled processes and coordinating with Cost Accounting following Engineering Change Order release to extend materials and BOMs to plants, create/update routings, and production versions, and verify that all master data objects are complete for the business operations. Conduct Material Master Data updates as needed by the business using mass update tools including Winshuttle, LSMW, and MM17/MASS. Develop and maintain mass maintenance scripts using Winshuttle (10.7x or 11.x) including script and Excel template development, file management / version control, and general technical support (utilizing Winshuttle Support, as necessary). Coordinate with domain data stewards and data quality lead to ensure master data integrity and data quality in key systems is aligned to approved data standards and business rules. Active monitoring of material data quality audit reports. Identifying Root cause, documenting and resolving data quality issues. Support day-to-day data related issues for US/CA/MX plants in SAP, BES and QAD. About Clarios: Clarios is the global leader in advanced, low-voltage battery technologies for mobility. We power progress through ever-smarter solutions for virtually every kind of vehicle. With 16,000 employees in over 140 countries, we bring deep expertise to our Aftermarket and OEM partners, and reliability, safety and comfort to everyday lives. We answer to the planet with a rigorous ESG focus – advancing best-in-class sustainability practices and advocating for them across our industry. We recover, recycle and reuse up to 99% of our battery materials. Clarios is a Brookfield portfolio company. To all recruitment agencies: Clarios does not accept unsolicited agency resumes/CVs. Please do not forward resumes/CVs to our careers email addresses, Clarios employees or any other company location. Clarios is not responsible for any fees related to unsolicited resumes/CVs. Clarios, LLC is an equal employment opportunity and affirmative action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, protected veteran status, status as a qualified individual with a disability, or any other characteristic protected by law. For more information, please view EEO is the Law, EEO is the Law (supplement), and Pay Transparency Non-discrimination. If you are an individual with a disability and you require an accommodation during the application process, please email Special.Accommodations@Clarios.com. A Note to Job Applicants : please be aware of scams being perpetrated through the Internet and social media platforms. Clarios will never require a job applicant to pay money as part of the application or hiring process.",https://mx.linkedin.com/jobs/view/master-data-analyst-at-clarios-3992226351,3992226351,"The responsibilities include Master Data Management using SAP master data within Materials Management (MM) and Production Planning (PP) modules. The position emphasizes plant-specific material masters, BOMs, work centers, routings, and production versions. You will conduct updates using mass tools like Winshuttle, LSMW, and MM17/MASS, and develop maintenance scripts with technical support. Coordination with data stewards and auditing for data quality are also crucial components of the role.","SAP, Winshuttle, LSMW, MM17/MASS, Excel",,,True,,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
Data Platform Engineer,Chubb,Monterrey Metropolitan Area,HYBRID,Entry level,Full-time,Insurance,2024-09-19 02:09:41.054441,25,Engineering,Information Technology,,"Job Description Chubb is the world’s largest publicly traded property and casualty insurer. With operations in 54 countries, Chubb provides commercial and personal property and casualty insurance, personal accident and supplemental health insurance, reinsurance and life insurance to a diverse group of clients. The company is distinguished by its extensive product and service offerings, broad distribution capabilities, exceptional financial strength, underwriting excellence, superior claims handling expertise and local operations globally. Chubb is looking for a Azure Database Platform Engineering Professional with a Bachelor’s Degree to join our Global Data Platform team. This is a permanent full-time position and a compelling opportunity to join a global, growing, financially stable and successful company. As the industry leader, Chubb is an employer of choice for skilled IT professionals aspiring to develop a meaningful career in a fast-paced, diverse company with offices in most major US and key International cities. Chubb's Global Data Platform (GDP ) team manages multi cloud Data and Analytics capabilities and is responsible for cutting edge technlogies like Azure, DataBricks, OpenAI, Informatica, Dataiku and Alteryx. Our Technology teams are dedicated to creating competitive advantages in products, customer services and business costs by driving digital transformation in our business with a modernized focus on agile methodology and data analytics. Responsibilities Ideal candidate will be a highly skilled Platform engineer with deep knowledge of Azure SQLServer, SQLServer Always on and Azure. You are a self-starter who is passionate about Data and Platform Engineering and Analytics. You are adept at providing solutions to challenging data problems by utilizing a variety of different strategies, architectures and technlogies. Manage Tier-1 SQLServer Always on Clusters and Applications Monitor and troubleshoot issues related to Database Services, Storage and performance. Application SQL Performance Tuning and Monitoring Automate Project onboarding process using CI/CD and Dev-Ops tools. Collaborate with Data Engineers, Data Scientist and Application developers on complex technical challenges. Deliver on Azure and Data Platform projects. Implement and maintain data security measures in compliance with company policies and industry best practices. Researching and develop modern data services and enhancments Build proof of concepts & prototypes to solve emerging challenges Stay current with new data technologies and programming models Be self-motivated and creative. Qualifications Experience and Qualifications Bachelor’s degree in software engineering, computer science or related engineering field 4+ years of professional experience in managing SQLServer with focus on supporting critical systems, performance tuning and monitoring Experience with Informatica MDM a plus 2+ years of experience in cloud data lake technologies, preferably Azure Skilled in SQL, NoSQL, Scripting, Terraform and other cloud and Automation technologies Experience in mordern data design and best practices Experience in backup, recovery, performance tuning and optimization Familiar with working in linux operating system and scripting Azure certifications such as Azure solutions Architect Expert is a plus. Chubb strives to offer a diverse and inclusive and rewarding work environment. Teamwork and mutual respect are central to how Chubb operates and we believe the best solutions draw upon diverse perspectives, experiences and skills. We operate in such a way where everyone, regardless of their singular background has the opportunity to contribute to our collective success. Chubb offers a competitive compensation package and comprehensive benefits package including life, health and dental, vision, a generous retirement savings plan, disability coverage, stock purchase plan, flexible spending accounts, tuition reimbursement, and business casual dress. At Chubb, we are committed to equal employment opportunity and compliance with all laws and regulations pertaining to it. Our policy is to provide employment, training, compensation, promotion, and other conditions or opportunities of employment, without regard to race, color, religion, age, sex, sexual orientation, transgender, national origin, disability, genetic information, veteran, or marital status, or any other characteristic protected by law.",https://mx.linkedin.com/jobs/view/data-platform-engineer-at-chubb-4029405833,4029405833,"Chubb is looking for an Azure Database Platform Engineering Professional to join the Global Data Platform team. The ideal candidate will have deep knowledge of Azure SQLServer, experience managing SQLServer Always on Clusters, and a strong background in Performance Tuning and Monitoring. Responsibilities include monitoring and troubleshooting database services, automating project onboarding using CI/CD and DevOps tools, and collaborating with data engineers and scientists on technical challenges. Candidates should be passionate about data and platform engineering, with experience in cloud data lake technologies, scripting, and modern data design.","Azure, SQLServer, NoSQL, Scripting, Terraform, DataBricks, OpenAI, Informatica, Dataiku, Alteryx",4+,Bachelor,True,4.0,0,0,1,1,0,0,0,0,0,1,0,1,0,0,0,0,0
Data Analyst,Chubb,Monterrey Metropolitan Area,HYBRID,Entry level,Full-time,Insurance,2024-09-19 02:09:41.054441,25,Information Technology,,,"Job Description Overview: Chubb's North America data delivery team provides business insights, data management, and business and data analysis to North America. As a Data Analyst, you will be responsible for conducting a detailed analysis of various data sources to identify trends, patterns, and insights that will support strategic decision-making. Additionally, you will perform quality assurance tasks to ensure data accuracy and integrity across our systems. The ideal candidate will possess strong analytical skills, advanced knowledge of querying languages, and a keen eye for detail. Role Summary: Partner with business teams to analyze requirements and identify data sources needed for analytics/reporting applications with medium level complexity Establish open data standards, metadata management policies and data classifications. Conduct full data lifecycle analysis to develop new insights for analytics and reporting dashboards Partner with business and tech teams to develop testing requirements, procedures and corrective actions to ensure data products meet quality standards Provide recommendations to address data quality issues with source systems. Communicate approaches with cross functional teams Establish open data standards, metadata management policies and data classifications Responsibilities: Comprehend and adhere to all data security policies and procedures Create data tools for analytics and data scientist team members Build analytical tools to provide actionable insights into key business KPIs, etc Work with data engineers to optimize pipelines for scalability and data delivery Qualifications Functional Competencies Working knowledge with data and analytics framework supporting data lakes, warehouses, marts, reporting, etc Experience with data tools for visualizations, analytics and reporting Knowledge of testing policies, procedures and the role testing performs within the software development lifecycle Strong analytical skills with ability to research, assess and develop observations/findings Ability to communicate findings, approaches to cross functional teams and stakeholders. Technical competencies 3+ years' hands-on experience with a data science background Some programming skills in Java, Python and SQL Clear hands-on experience with database systems - Cloud technologies (e.g. AWS, Azure, Google), in-memory database systems (e.g. HANA, Hazel cast, etc) and other database systems - traditional RDBMS (e.g. Teradata, SQL Server, Oracle), and NoSQL databases (e.g. Cassandra, MongoDB, DynamoDB) Education, Knowledge, Experience: Background in SQL, databases and/or data science OR BS/MS in software engineering, computer science, mathematics Experience working with global teams is a must. English proficiency is a must.",https://mx.linkedin.com/jobs/view/data-analyst-at-chubb-4029409269,4029409269,"As a Data Analyst, you will be responsible for conducting a detailed analysis of various data sources to identify trends, patterns, and insights that will support strategic decision-making. You will perform quality assurance tasks to ensure data accuracy and integrity across our systems, create data tools for analytics, build analytical tools to provide actionable insights, and work with data engineers to optimize pipelines for scalability and data delivery.","Java, Python, SQL, AWS, Azure, Google Cloud, HANA, Hazelcast, Teradata, SQL Server, Oracle, Cassandra, MongoDB, DynamoDB",3+ years,Bachelor,True,3.0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0
Data Engineer,K2 Partnering Solutions,Monterrey Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-19 02:10:22.354884,25,Information Technology,,,"We are looking for a Data Engineer , to join one of our most important clients. Work : Hybrid in Monterrey, NL, or Buenos Aires, Arg Qualifications : Proficiency in large dataset transformation using Python Proficiency in building out scalable and reliable ETL pipelines and processes to ingest data from variety of data sources including but not limited to SharePoint, REST API, Blob Storage. Proficiency in Azure PaaS offerings and data engineering target architecture, including but not limited to Azure SQL database, Azure Data Factory, Azure Synapse, Azure Databricks, Azure Functions, Data lake, Azure Log Analytics. Proficiency in relational databases and SQL, including but not limited to stored procedures, indexes, functions and triggers. Proficiency in Azure DevOps CI/CD and Git Repository. Deep understanding in data model design and relational database normalization Familiarity with Non SQL databases. E.g Cosmos DB Role Description: Understanding the business use of data and the stakeholders requirements to support work processes and strategic business objectives Leverage data and software engineering techniques, data science to create business value through data accessibility (includes data ingestion, data preparation and analytics processing) Identifying, acquiring, cleansing/preparing, storing data and developing reusable data products aligned with defined architecture patterns Enabling data scientists, making data available for advanced analytics models, and contributing to advanced analytics models Working with data analysts and architects to scale and deploy solutions including models, documentation, training, integration",https://mx.linkedin.com/jobs/view/data-engineer-at-k2-partnering-solutions-4027377592,4027377592,"We are looking for a Data Engineer to join one of our clients. The role involves transforming large datasets using Python, building scalable ETL pipelines from various data sources, and working with Azure PaaS offerings and data engineering architectures. The engineer will have to understand business data use and support strategic objectives by enabling data scientists and developing reusable data products.","Python, Azure SQL Database, Azure Data Factory, Azure Synapse, Azure Databricks, Azure Functions, Data Lake, Azure Log Analytics, SQL, Cosmos DB, Azure DevOps, Git",,,True,,0,0,1,1,0,0,0,0,0,1,0,1,0,0,1,0,0
Analyst Equipment Master Data,The Hershey Company,Monterrey Metropolitan Area,ON-SITE,Entry level,Full-time,Manufacturing,2024-09-19 02:10:22.354884,25,Information Technology,,,"Job Title Equipment Master Data Analyst Reports to Master Data Owner, Transformation (HBP) Department TMO, Master Data Specialist Job Location Monterrey Summary The Enterprise Master Data Management (EMDM) Equipment Master Data Specialist is accountable for two primary work streams in relation to new equipment / production line installation and existing equipment asset care strategy. The Equipment Master Data Specialist position is responsible for ensuring plants are equipped to minimize equipment downtime and increase asset life cycle by leading the development of equipment maintenance strategy, development of equipment bill of materials (BOM) and stocking strategy, as well as gathering and archieving equipment manuals and associated documentation. This role coordinates with the Plant Maintenance (Maintenance Planners, Reliability Leads, and Maintenance Managers) and Engineering PMO teams while being a steward of company policies, procedures, timelines and master data governance. For existing equipment, this role assists with the management of equipment data in order to improve and maintain timeliness and quality of the data. The role provides the specialist viewpoint when representing enterprise data and equipment strategy initiatives. This role specifically assists with the management SAP PM master data, technical objects, and equipment related documentation / attachments. The role will guide local and global resources to ensure the continuous improvement of business results through the implementation and management of standard processes, tools, and accountabilities. Responsibilities : Equipment Master Data Standards Governance Ensure adherence to the data governance policy for all equipment master data domains. Leverage existing and propose new technology solutions to improve workflow and master data creation, maintenance and archival. Oversight of maintaining equipment database in SAP to ensure equipment information, documentation, BOMs and PM Plans are standardized, accurate, and updated Supports by acting as “first line of defense” in fielding opportunities to improve data quality as well as resolving data issues. Targets opportunities to improve data quality, policy, and processes, and ownership. Identifies root causes of data quality problems within their assigned area of stewardship and identifies sustainable solutions. Ensures team members are kept informed of changes in data standards and processes. Incorporate industry best practices and tools based on emerging trends and changing business requirements. Benchmark and participate in sharegroups with other organizations in order to advance The Hershey Company’s capability Equipment Data Entry Setup and modify new and existing equipment to meet enterprise standards Work with Engineering and equipment OEM on projects during commissioning and validation to gather equipment specific data (i.e. OEM, Model, Serial #) and entering equipment numbers in SAP PM with linkage to Asset numbers. Assigning equipment numbers and descriptions and maintaining this equipment with the proper description and RAV. Create / process CARD forms, (Capital Asset Relocation & Disposal forms), in the system to remove equipment from plant Equipment Strategy Development Development / documentation of PM plans in SAP and attach the plans to the equipment Work with plants to ensure proper PM task list details (including work center, planner code, task frequency, and object lists) in relation to plant personnel structure, equipment maintainability, equipment production needs, and equipment environment. Obtain OEM recommended maintenance tasks, task steps, and frequency. The role should leverage existing PM plans to replicate and optimize like equipment strategy Propose new technology solutions to improve reliability or manufacturing equipment Coordinate with plants to ensure proper tools and training related to maintenance strategy deployment. Equipment Spare Parts Compile complete spare parts list with maintenance assembly (IBAU) structure. Obtain list of critical spares required for regular operation of equipment as recommended by OEM and plant maintenance personnel. Provide suggested plant stocking levels and subsequent HIBE requests Provide guidance for known obsolete parts Equipment Documentation Obtain OEM equipment manuals and troubleshooting guides Request addition plant specific guides and documentation related to equipment set up and maintenance Maintain equipment information libraries attached to equipment within SAP, enterprise document library, and/or local plant digital storage. Coordinate with Plant Maintenance to ensure documentation completeness. Minimum Knowledge And Skills Technical Skills General knowledge of manufacturing maintenance and reliability practices Strong computer skills with accuracy (Teams, Word, Outlook, Excel, Power BI) Microsoft Office skills (Excel analytics/pivot tables) Working knowledge of ERP (i.e. SAP PM) systems Knowledge of or ability to learn policies and procedures (i.e. Hershey Lean) Strong communication skills Strong attention to detail Analytical thinker Basic math skills Qualifications Intermediate knowledge level of ERP system, preferred SAP PM (ECC and S4/HANA) experience. Strong communication skills and tenacity (written and verbal). Must be willing and capable to support North American businesses real-time. (Eastern Time Zone) Capable of documenting and adhering to process discipline. Communication Skills Ability to work well with others as well as part of a team Sensitivity to other cultures and cultural differences Ability to handle multiple priorities Strong organizational skills Strong drive for results Education Accossiates's degree in a quantative field preferrable or equivalent relevant experience. Experience Minimum of 1-3 years with data maintenance of Customer, Vendor or Planner maintenance master data. Minimum of 1-3 years working in an ERP system.",https://mx.linkedin.com/jobs/view/analyst-equipment-master-data-at-the-hershey-company-4027894669,4027894669,"The Equipment Master Data Specialist is accountable for managing new equipment and production line installation while ensuring equipment downtime minimizes and asset lifecycle increases. The role includes developing maintenance strategies, equipment billing of materials (BOM), and documentation management. It involves governance of equipment master data, improvement of data quality, maintenance in the SAP PM system, and collaboration with engineering and maintenance teams.","SAP PM, Microsoft Office, Power BI, Excel",1-3,,True,1.0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
Sr Data Engineer,The Agency IT,Monterrey Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,Human Resources Services,2024-09-19 02:10:22.354884,25,,,,"Resource Description Ingeniero de Datos Sr para el proyecto de SupplyChain USA Conocimiento en Modelado  de Datos, en Ingesta de Datos, Deseable conocimiento en temas Logistica y SAP. Requirements • Ingeniero de Datos Sr para el proyecto de SupplyChain USA Conocimiento en Modelado  de Datos, en Ingesta de Datos, conocimiento en temas Logistica y SAP • +3 Años SQL DB • +1 Año Experiencia en Snowflake DB • +2 Años Experiencias en Ingesta de Datas vis ETLs, o Replicadores Five Tran o Informatica • +2 años Experiencia en Power BI. Deseable • + SAP deseable • Speaking Proficiency • Writing Proficiency • Reading Proficiency Responsibilities • Encargado de la ingeniería de datos para el proyecto de Supply Chain Acc en USA, con una visión global y responsable de +2 personas Consideraciones Importantes: • La persona requiere dominar muy bien el inglés. • La persona seleccionada debe residir en Nuevo León., porque el puesto es un 80%  presencial. • Las oficinas están ubicadas en San Pedro Garza García, Nuevo Léon. ¿Qué ofrecemos? • El esquema de contratación es 100% nominal en pesos mexicanos • Sería un contrato por tiempo determinado de 4 meses",https://mx.linkedin.com/jobs/view/sr-data-engineer-at-the-agency-it-4029255967,4029255967,"Senior Data Engineer for the Supply Chain project in the USA. Requires knowledge in Data Modeling, Data Ingestion, desirable knowledge in Logistics and SAP. Responsible for data engineering for the project with a global vision and leading a team of over 2 people.","SQL, Snowflake, ETL, FiveTran, Informatica, Power BI, SAP","+3 years SQL, +1 year Snowflake, +2 years ETL experience",,True,1.0,0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,0,0
Machine Learning Engineer,Grid Dynamics,Guadalajara,REMOTE,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-08-16 11:29:34.794464,41,Engineering,Information Technology,,"We are seeking a Senior Machine Learning Engineer with proven expertise in developing Machine Learning models, including tabular data and NLP models. The ideal candidate will have experience with product recommendation systems and the ability to innovate beyond traditional approaches. This role requires strong programming skills in Python, extensive experience with AWS cloud services (particularly SageMaker, EC2, S3, and Redshift), and a solid understanding of the full ML lifecycle and MLOps principles. Responsibilities Collaborate closely with the engineering and product team to design and implement Machine Learning models that support product recommendations and other business needs Develop and manage the Machine Learning lifecycle, from initial prototyping to full-scale production deployment Interpret and integrate complex data sets from various sources, including structured and unstructured data Apply expert knowledge in Machine Learning and Artificial Intelligence to diverse datasets and use cases, ensuring scalability and adaptability of solutions based on volume and requirements Build and maintain a robust MLOps workflow, including model prototyping, deployment, and monitoring. Requirements Proven expertise in developing Machine Learning models, including tabular data and NLP models Experience with product recommendation systems and the ability to innovate beyond traditional approaches. Experience with AWS cloud services, particularly SageMaker, EC2, S3, and Redshift. Strong programming skills in Python Experience in deploying Machine Learning models into production environments, particularly using CI/CD frameworks Solid understanding of the full ML lifecycle and MLOps principles Demonstrated ability to work collaboratively in cross-functional teams and communicate complex technical information to non-expert stakeholders. We offer 100% payroll scheme, benefits by law (IMSS, INFONAVIT, 12+ vacation days) Benefits above the law: Vacation premium 50%, 5 PTOs, 3 sick days, 10 guaranteed public holidays per year Major medical insurance, Dental and Vision plan for an employee and direct family members Minor Medical Insurance (Multiservicios Médicos Santander) for an employee and direct family members Life Insurance and funeral expenses 5% savings fund, uncapped (matched by the company in the end of the year) Grocery cards/vouchers (Vales de Despensa) 30 days End of the Year Bonus (Aguinaldo) Opportunity to work on bleeding-edge projects with a highly motivated and dedicated team all over the world Individual career development plan and support from the best experts Professional development opportunities (Linkedin Learning, Cloud certification programs, access to corporate LMS integrated with other learning platforms) Well-equipped office in a business area of Guadalajara (quiet room, games room, air hockey, PS5, Nintendo Switch and Xbox Series X, pool table, ping pong, snacks, smoothies, and much more) Corporate social events (yoga, massages, sport tournaments, discussion panels, technical talks, lunch & learns) Flexible working hours Opportunity to relocate to another country where the company's offices are present. About Us Grid Dynamics (NASDAQ: GDYN) is a leading provider of technology consulting, platform and product engineering, AI, and advanced analytics services. Fusing technical vision with business acumen, we solve the most pressing technical challenges and enable positive business outcomes for enterprise companies undergoing business transformation. A key differentiator for Grid Dynamics is our 8 years of experience and leadership in enterprise AI, supported by profound expertise and ongoing investment in data, analytics, cloud & DevOps, application modernization, and customer experience. Founded in 2006, Grid Dynamics is headquartered in Silicon Valley with offices across the Americas, Europe, and India.",https://mx.linkedin.com/jobs/view/machine-learning-engineer-at-grid-dynamics-3990273246,3990273246,"We are seeking a Senior Machine Learning Engineer with proven expertise in developing Machine Learning models, including tabular data and NLP models. The ideal candidate will have experience with product recommendation systems and the ability to innovate beyond traditional approaches. This role requires strong programming skills in Python, extensive experience with AWS cloud services, and a solid understanding of the full ML lifecycle and MLOps principles. Responsibilities include collaborating closely with engineering and product teams to design and implement Machine Learning models, managing the Machine Learning lifecycle, interpreting complex data sets, and building and maintaining a robust MLOps workflow.","Python, AWS (SageMaker, EC2, S3, Redshift), Machine Learning, NLP, CI/CD, MLOps",,,True,,0,0,0,1,0,0,0,0,0,0,0,0,1,0,1,0,0
Data Scientist with Azure Machine Learning Engineer - Fulltime,"Cliecon Solutions, Inc.",Guadalajara,REMOTE,Entry level,Full-time,IT Services and IT Consulting,2024-09-12 11:29:34.794464,26,Engineering,Information Technology,,"Hello Professional, Greetings from Cliecon Solutions Inc., I am Musham Goutham, part of Cliecon Recruiting team. Please check/review the below requirements and forward your/Consultant resume, and contact details if you are interested and comfortable with the below job description feel free to call/mail me at goutham@cliecon.com or O: 732-626-9717 Ext 107 *Please make sure consultant should be in Mexico only and Mexican Citizen, because need to visit the Client location based on the Client need. Role - Azure Machine Learning – Technical Support Engineer Location – Guadalajara, MX (Remote) Job description: Skills: Knowledge with Azure Machine Learning and how it works with associated Azure services. Strong Python coding skills preferably SDK Ver2 Knowledge of AML workspace Provisioning and model Deployment Knowledge in AML Studio, Azure Key Vault, Azure Kubernetes Services, Azure cloud Storage, Azure Container Registry Knowledge of scenario-based Inferencing, how to deploy, how to provision on a compute and get the inferencing results Knowledge of Networking, DNS, Troubleshooting will be added advantage Familiarity with machine learning algorithms, model development, and deployment. Experience in troubleshooting and resolving technical issues related to machine learning frameworks and tools. Responsible for providing technical support and expertise to customers utilizing the Azure Machine Learning platform. Respond to inquiries, troubleshoot technical issues and provide solutions. Debugging, and problem-solving skills Investigate and resolve customer-reported problems related to Azure Machine Learning services (Ex:ML job failures). Understand API errors, browser compatibility issues, image processing, face recognition. Azure, AWS cloud development experience Effective communication and interpersonal skills to interact with customers and cross-functional teams. About us: Cliecon Solutions Inc.,( headquartered in central NJ ) is one of the fastest-growing and leading consulting and management firms with 16 years of experience in Staff Augmentation. We handle a complete recruiting cycle for fortune 500 clients, major implementing partners, and tier -1 vendors. We specialized in recruiting for Application development, Bigdata, Databases, Infrastructure, Cloud, Mobile, and ERP-based solutions projects. Thanks & Regards, Musham Goutham, Technical Lead, Cliecon Solutions Inc., (Client + Consultants) O: 732-626-9717 Ext 107 Direct: 609-901-9002 E: goutham@cliecon.com || http://www.cliecon.com Contact me on LinkedIn: https://www.linkedin.com/in/goutham-m-640035a2/",https://mx.linkedin.com/jobs/view/data-scientist-with-azure-machine-learning-engineer-fulltime-at-cliecon-solutions-inc-4022936511,4022936511,"The role of Azure Machine Learning Technical Support Engineer involves providing technical support and expertise to customers utilizing the Azure Machine Learning platform, troubleshooting and resolving technical issues related to machine learning frameworks, and deploying models on Azure services. Responsibilities include responding to inquiries, debugging, and investigating customer-reported problems, with a strong emphasis on Python coding and machine learning algorithms.","Azure Machine Learning, Azure Services, Python, Azure Key Vault, Azure Kubernetes Services, Azure Cloud Storage, Azure Container Registry, Machine Learning Algorithms",,,True,,0,0,0,1,1,0,0,0,0,0,0,0,1,0,1,0,0
AI/ML and MLOps Field Engineer,Canonical,Guadalajara,REMOTE,Entry level,Full-time,"Technology, Information and Internet",2024-09-01 11:29:34.794464,25,Engineering,Information Technology,,"Canonical is a leading provider of open source software and operating systems to the global enterprise and technology markets. Our platform, Ubuntu, is very widely used in breakthrough enterprise initiatives such as public cloud, data science, AI, engineering innovation and IoT. Our customers include the world's leading public cloud and silicon providers, and industry leaders in many sectors. The company is a pioneer of global distributed collaboration, with 1000+ colleagues in 70+ countries and very few roles based in offices. Teams meet two to four times yearly in person, in interesting locations around the world, to align on strategy and execution. The company is founder led, profitable and growing. We are hiring an AI/ML and MLOps Field Engineer to help global companies embrace AI in their business, using the latest open source capabilities on public and private cloud infrastructure, Linux and Kubernetes. Our team applies expert insights to real-world customer problems, enabling the enterprise adoption of Ubuntu, Kubeflow, MLFlow, Feast, DVC and related analytics, machine learning and data technologies. We are working to create the world's best open source data platform, covering traditional SQL databases and today's NoSQL data stores, as well as the machinery which turns data into insights and executable models. The people who love this role are software engineers who enjoy customer conversations and solving customer problems during the presales cycle. They are are developers who like to solve customer problems through architecture, presentations and training. Ubuntu is used by pretty much every enterprise in the world, in every industry. This is a fantastic opportunity to learn about the open source technology landscape and develop your business technology insights. You will see first hand in various industries how Linux - and Ubuntu in particular - is shaping innovation and changing the world for the better. This role is particularly suited to candidates with a technical background who are business minded and driven by commercial success. This role is on our global Field Engineering team and will work closely with enterprise sales leads. We are specifically looking for people interested in solving the most difficult problems in modern data architectures. Training LLMs on multiple K8s clusters deployed on a hybrid cloud infrastructure with GPU sharing across multiple teams? Processing 10M events in real time for financial transactions? Object detection on 10k parallel 4K video streams? These are the problems we solve day to day. Location: Most of our colleagues work from home. We are growing teams in EMEA, Americas and APAC time zones, so can accommodate candidates from almost any country. What your day will look like The global Field Engineering team members are Linux and cloud solutions architects for our customers, designing private and public cloud solutions fitting their workload needs. They are the cloud consultants who work hands-on with the technologies by deploying, testing and handing over the solution to our support or managed services team at the end of a project. They are also software engineers who use Python to develop Kubernetes operators and Linux open source infrastructure-as-code. Work across the entire Linux stack, from kernel, networking, storage, to applications Architect cloud infrastructure solutions like Kubernetes, Kubeflow, OpenStack, and Spark Deliver solutions either on-premise or in public cloud (AWS, Azure, Google Cloud) Collect customer business requirements and advise them on Ubuntu and relevant open source applications Grow a healthy, collaborative engineering culture in line with the company values Deliver presentations and demonstrations of Ubuntu Pro and AI/ML capabilities to prospective and current clients Liaise with product teams to give them feedback on requirements to influence roadmap Work collaboratively with your sales team to reach our common targets Global travel up to 25% of time for internal and external events and 25% to customer meetings What we are looking for in you Exceptional academic track record from both high school and university Undergraduate degree in a technical subject or a compelling narrative about your alternative chosen path Experience in data engineering, MLOps, or big data solutions deployment Experience with a relevant programming language, like Python, R, or Rust. Confidence to respectfully speak up, exchange feedback, and share ideas without hesitation Track record of going above-and-beyond expectations to achieve outstanding results Demonstrated personal interest in continuous learning and development Practical knowledge of Linux, virtualisation, containers and networking Business-minded technology thinker and problem solver Knowledge of cloud computing concepts & leaders, such as Kubernetes, AWS, Azure, GCP Interest in large-scale enterprise open source - private clouds, machine learning and AI, data and analytics Intermediate level Python programming skills Passion for technology evidenced by personal projects and initiatives The work ethic and confidence to shine alongside motivated colleagues Professional written and spoken English with excellent presentation skills Experience with Linux (Debian or Ubuntu preferred) Excellent interpersonal skills, curiosity, flexibility, and accountability A dynamic person who loves to jump in new projects and interact with people Appreciative of diversity, polite and effective in a multi-cultural, multi-national organisation Thoughtfulness and self-motivation Result-oriented, with a personal drive to follow up and meet commitments Ability to travel internationally, for company events up to two weeks long, and customer or industry meetings What you'll learn Architect and deploy AI/ML infrastructures, data processing pipelines and multi-cluster distributed training Wide range of open source applications and skills Work directly with customers in a range of different businesses Real-life and hands-on exposure to a wide range of emerging technologies and tools What we offer colleagues We consider geographical location, experience, and performance in shaping compensation worldwide. We revisit compensation annually (and more often for graduates and associates) to ensure we recognise outstanding performance. In addition to base pay, we offer a performance-driven annual bonus or commission. We provide all team members with additional benefits, which reflect our values and ideals. We balance our programs to meet local needs and ensure fairness globally. Distributed work environment with twice-yearly team sprints in person Personal learning and development budget of USD 2,000 per year Annual compensation review Recognition rewards Annual holiday leave Maternity and paternity leave Employee Assistance Programme Opportunity to travel to new locations to meet colleagues Priority Pass, and travel upgrades for long haul company events About Canonical Canonical is a pioneering tech firm at the forefront of the global move to open source. As the company that publishes Ubuntu, one of the most important open source projects and the platform for AI, IoT and the cloud, we are changing the world of software. We recruit on a global basis and set a very high standard for people joining the company. We expect excellence - in order to succeed, we need to be the best at what we do. Most colleagues at Canonical have worked from home since its inception in 2004. Working here is a step into the future, and will challenge you to think differently, work smarter, learn new skills, and raise your game. Canonical is an equal opportunity employer We are proud to foster a workplace free from discrimination. Diversity of experience, perspectives, and background create a better work environment and better products. Whatever your identity, we will give your application fair consideration.",https://mx.linkedin.com/jobs/view/ai-ml-and-mlops-field-engineer-at-canonical-4013777275,4013777275,"We are hiring an AI/ML and MLOps Field Engineer to help global companies embrace AI in their business, using the latest open source capabilities on public and private cloud infrastructure, Linux, and Kubernetes. The role involves designing cloud infrastructure solutions, developing Kubernetes operators using Python, and working with various open source applications to solve customer problems in modern data architectures.","Python, Kubernetes, Linux, OpenStack, Spark, AWS, Azure, Google Cloud, Kubeflow, MLFlow, Feast, DVC",,Undergraduate Student,True,,0,0,1,1,1,0,0,0,0,0,0,1,1,0,1,0,0
Python Software Engineer for AI,Oowlish,Guadalajara,REMOTE,Entry level,Full-time,IT Services and IT Consulting,2024-09-01 11:29:34.794464,93,Engineering,Information Technology,,"Join Our Team Oowlish, one of Latin America's rapidly expanding software development companies, is seeking experienced technology professionals to enhance our diverse and vibrant team. As a valued member of Oowlish, you will collaborate with premier clients from the United States and Europe, contributing to pioneering digital solutions. Our commitment to creating a nurturing work environment is recognized by our certification as a Great Place to Work, where you will have opportunities for professional development, growth, and a chance to make a significant international impact. We offer the convenience of remote work, allowing you to craft a work-life balance that suits your personal and professional needs. We're looking for candidates who are passionate about technology, proficient in English, and excited to engage in remote collaboration for a worldwide presence. We are seeking a highly skilled Senior Python Developer with experience in Machine Learning and Artificial Intelligence. The ideal candidate will have recent hands-on experience in these areas and a proven track record of delivering high-quality technical projects. Must Have Advanced English skills, both written and verbal. Over 5 years of experience in Python development. Hands-on experience with Generative AI technologies (Langchain, Bedrock, prompt engineering, RAG, etc.). Proven experience in designing and implementing AI-driven solutions. Strong problem-solving skills and attention to detail. Excellent communication and collaboration skills. Ability to work independently and as part of a team. Benefits & Perks Home office; Flexible Hours Competitive compensation based on experience; Career plans to allow for extensive growth in the company; International Projects; Oowlish English Program (Technical and Conversational); Oowlish Fitness with Total Pass; Connecting You (Internet allowance); Anniversary bonus; Wedding gift; Pet adoption incentive; New baby Oowl bonus; Back to School bonus; Streaming Subscription; PTO Bonus; Games and Competitions; Enjoy your national Holidays. You Can Also Apply Here Website: https://www.oowlish.com/work-with-us/ LinkedIn: https://www.linkedin.com/company/oowlish/jobs/ Instagram: https://www.instagram.com/oowlishtechnology/",https://mx.linkedin.com/jobs/view/python-software-engineer-for-ai-at-oowlish-4010711405,4010711405,"We are seeking a highly skilled Senior Python Developer with experience in Machine Learning and Artificial Intelligence. The ideal candidate will have recent hands-on experience in these areas and a proven track record of delivering high-quality technical projects. Must have advanced English skills, both written and verbal. Candidates will engage in delivering AI-driven solutions and have strong problem-solving skills and attention to detail.","Python, Machine Learning, Artificial Intelligence, Langchain, Bedrock, Prompt Engineering, RAG",5+ years,,True,5.0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0
"Python and Kubernetes Software Engineer - Data, AI/ML & Analytics",Canonical,Guadalajara,REMOTE,Entry level,Full-time,"Technology, Information and Internet",2024-09-01 11:29:34.794464,25,Engineering,Information Technology,,"Canonical is a leading provider of open source software and operating systems to the global enterprise and technology markets. Our platform, Ubuntu, is very widely used in breakthrough enterprise initiatives such as public cloud, data science, AI, engineering innovation and IoT. Our customers include the world's leading public cloud and silicon providers, and industry leaders in many sectors. The company is a pioneer of global distributed collaboration, with 1000+ colleagues in 70+ countries and very few roles based in offices. Teams meet two to four times yearly in person, in interesting locations around the world, to align on strategy and execution. The company is founder led, profitable and growing. We are hiring Python and Kubernetes Specialist Engineers focused on Data, AI/ML and Analytics Solutions to join our teams building open source solutions for public cloud and private infrastructure. As a software engineer on the team, you'll collaborate on an end-to-end data analytics and mlops solution composed of popular, open-source, machine learning tools, such as Kubeflow, MLFlow, DVC, and Feast. You may also work on workflow, ETL, data governance and visualization tools like Apache SuperSet, dbt, and Temporal, or data warehouse solutions such as Apache Trino, or ClickHouse. Your team will own a solution from the analytics and machine learning space, and integrate with the solutions from other teams to build the world's best end-to-end data platform. These solutions may be run on servers or on the cloud, on machines or on Kubernetes, on developer desktops, or as web services. We serve the needs of individuals and community members as much as the needs of our Global 2000 and Fortune 500 customers; we make our primary work available free of charge and our Pro subscriptions are also available to individuals for personal use at no cost. Our goal is to enable more people to enjoy the benefits of open source, regardless of their circumstances. Location: This initiative spans many teams that are home-based in EMEA, Americas and APAC time zones, so we can accommodate candidates in almost any location. We believe in distributed collaboration but we also try to ensure that colleagues have company during their work hourse! Successful candidates will join a team where most members and your manager are broadly in the same time zone so that you have the benefits of constant collaboration and discussion. What your day will look like Develop your understanding of the entire Linux stack, from kernel, networking, and storage, to the application layer Design, build and maintain solutions that will be deployed on public and private clouds and local workstations Master distributed systems concepts such as observability, identity, tracing Work with both Kubernetes and machine-oriented open source applications Collaborate proactively with a distributed team of engineers, designers and product managers Debug issues and interact in public with upstream and Ubuntu communities Generate and discuss ideas, and collaborate on finding good solutions What we are looking for in you Professional or academic software delivery using Python or Golang Exceptional academic track record from both high school and university Undergraduate degree in a technical subject or a compelling narrative about your alternative chosen path Confidence to respectfully speak up, exchange feedback, and share ideas without hesitation Track record of going above-and-beyond expectations to achieve outstanding results Passion for technology evidenced by personal projects and initiatives The work ethic and confidence to shine alongside motivated colleagues Professional written and spoken English with excellent presentation skills Experience with Linux (Debian or Ubuntu preferred) Excellent interpersonal skills, curiosity, flexibility, and accountability Appreciative of diversity, polite and effective in a multi-cultural, multi-national organisation Thoughtfulness and self-motivation Result-oriented, with a personal drive to meet commitments Ability to travel twice a year, for company events up to two weeks long Additional Skills That Would Be Nice To Have The following skills may be helpful to you in the role, but we don't expect everyone to bring all of them. Hands-on experience with machine learning libraries, or tools. Proven track record of building highly automated machine learning solutions for the cloud. Experience with container technologies (Docker, LXD, Kubernetes, etc.) Experience with public clouds (AWS, Azure, Google Cloud) Working knowledge of cloud computing Passionate about software quality and testing Experience working on an open source project What we offer colleagues We consider geographical location, experience, and performance in shaping compensation worldwide. We revisit compensation annually (and more often for graduates and associates) to ensure we recognise outstanding performance. In addition to base pay, we offer a performance-driven annual bonus or commission. We provide all team members with additional benefits, which reflect our values and ideals. We balance our programs to meet local needs and ensure fairness globally. Distributed work environment with twice-yearly team sprints in person Personal learning and development budget of USD 2,000 per year Annual compensation review Recognition rewards Annual holiday leave Maternity and paternity leave Employee Assistance Programme Opportunity to travel to new locations to meet colleagues Priority Pass, and travel upgrades for long haul company events About Canonical Canonical is a pioneering tech firm at the forefront of the global move to open source. As the company that publishes Ubuntu, one of the most important open source projects and the platform for AI, IoT and the cloud, we are changing the world of software. We recruit on a global basis and set a very high standard for people joining the company. We expect excellence - in order to succeed, we need to be the best at what we do. Most colleagues at Canonical have worked from home since its inception in 2004. Working here is a step into the future, and will challenge you to think differently, work smarter, learn new skills, and raise your game. Canonical is an equal opportunity employer We are proud to foster a workplace free from discrimination. Diversity of experience, perspectives, and background create a better work environment and better products. Whatever your identity, we will give your application fair consideration.",https://mx.linkedin.com/jobs/view/python-and-kubernetes-software-engineer-data-ai-ml-analytics-at-canonical-4011644944,4011644944,"Canonical is hiring Python and Kubernetes Specialist Engineers focused on Data, AI/ML, and Analytics Solutions to build open source solutions for public cloud and private infrastructure. Responsibilities include developing an understanding of the entire Linux stack, designing, building, and maintaining solutions for public and private clouds, and collaborating with a distributed team. Candidates should have experience in software delivery using Python or Golang, exceptional academic track record, and the ability to communicate effectively in English.","Python, Golang, Kubernetes, Kubeflow, MLFlow, DVC, Feast, Apache SuperSet, dbt, Temporal, Apache Trino, ClickHouse, Linux, Docker, AWS, Azure, Google Cloud",,Undergraduate Student,True,,0,1,1,1,1,0,0,0,0,0,0,0,1,0,1,0,0
Senior Data Scientist,Launch Potato,Guadalajara,REMOTE,Mid-Senior level,Full-time,Advertising Services,2024-09-08 11:29:34.794464,25,Engineering,Information Technology,,"WHO ARE WE? Launch Potato is a digital media company with a portfolio of brands and technologies. As The Discovery and Conversion Company, Launch Potato is a leading connector of advertisers to customers at all parts of the consumer journey, from awareness to consideration to purchase. The company is headquartered in vibrant downtown Delray Beach, Florida, with a unique international team across over a dozen countries. Launch Potato's success comes from a diverse, energetic culture and high-performing, entrepreneurial team. As a result, the company is always looking for like-minded teammates and partners. (This role will heavily focus on building machine learning models. This is NOT an engineering/data engineering position.) MUST HAVE: Experience within the performance marketing/lead gen industries. Professional experience designing, implementing, optimizing, and testing end-to-end Multi-Armed Bandit (MAB) and recommendation systems. EXPERIENCE: A minimum of 4 years experience in a hands-on, in-the-weeds data science position. YOUR ROLE You will be developing deep personalization models for our users and complex optimization algorithms to bridge our customer experiences with new products/services. Your direct contribution will impact how we connect hundreds of thousands of customers to hundreds of advertisers together daily and will drive significant consumer impact while increasing revenue. You will play a pivotal role in the growth of our data science team and will be an instrumental resource as we continue to build a team of data scientists and machine learning engineers that can increase customer engagement and stickiness on our sites while improving the quality of the leads to our partners. This is an extremely hands-on and in-the-weeds Data Science role where you will be heavily immersed in the data and coding part of the solution implementation. You will design and oversee integrating state-of-the-art machine learning solutions across the company’s products. This role will be responsible for strategic planning of Machine Learning initiatives with the Product, Engineering, Performance and Business Intelligence teams, analysis of potential impact and prioritization of those projects. SUCCESS LOOKS LIKE Innovate, create, and design ML solutions to various business problems such as: Design, implement and continuously improve Multi-Armed Bandit solutions to optimize decisions/options in place of multiple AB-tests. Utilizing Large Language Models in content personalization across various verticals. Recommendation systems to serve ads, offers, questions, etc. Collaborate with stakeholders across the company including but not limited to Analytics, Engineering, Product and Business Leads to improve model infrastructure, tracking and monitoring. Provide data science support at different project stages, including the implementation of ML solutions by collaborating with Data Engineers and MLOps. Being hands-on and in-the-weeds in the data, coding part of the solution implementation. What You Need To Succeed 4+ years of related work experience in the field of Data Science & Machine learning. 2+ years of experience in the Marketing/Advertising Industry. Solid background in Machine Learning and Statistics. Professional experience designing and implementing Multi-Armed Bandit (MAB) solutions and recommendation systems. Proficiency in SQL, Python and working with Data Science tools (e.g., git, kubernetes, Docker, etc.). Structure and clarify any ambiguity for the team, i.e., divide complex projects into sprints and coordinate implementation across multiple teams and individuals. Experience creating ML solutions within cloud services (AWS/GCP). Experience with ML model development lifecycle. Experience with data visualization (preferably Looker). Experience managing a team of data scientists and machine learning researchers (including career development). Ability to communicate clearly, think independently, provide direction, and effectively communicate with technical and non-technical stakeholders. NICE TO HAVES Experience with LLMs and Deep learning models to develop business and data science solutions. Want to make your impact in a profitable, high-growth company? Apply now! Since day one, we've been committed to having a diverse, inclusive team and culture. We are proud to be an Equal Employment Opportunity company. We value diversity, equity, and inclusion. We do not discriminate based on race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",https://mx.linkedin.com/jobs/view/senior-data-scientist-at-launch-potato-4019304707,4019304707,"This role heavily focuses on building machine learning models and is not an engineering/data engineering position. You will be developing deep personalization models and complex optimization algorithms. Your contribution will impact how customers connect with advertisers and drive significant consumer impact while increasing revenue. The position requires designing and overseeing integrating state-of-the-art machine learning solutions, strategic planning of initiatives with various teams, and providing data science support at different project stages. You will need to innovate and create ML solutions for various business problems and collaborate with stakeholders across the company.","Python, SQL, Machine Learning, Multi-Armed Bandit Systems, Recommendation Systems, Statistics, Docker, Kubernetes, AWS, GCP",4+ years,,True,4.0,0,0,0,1,1,0,0,0,0,1,0,0,1,0,1,0,0
Big Data Developer,Grid Dynamics,Guadalajara,REMOTE,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-01 11:29:34.794464,25,Engineering,Information Technology,,"We are seeking a highly skilled Data Engineer to join our team and lead the development and management of our data feeds for digital eCommerce. In this role, you will act as a critical liaison between the digital and data teams, ensuring seamless data integration and flow across our platforms. Your expertise will drive the success of our data initiatives and support our mission to provide top-notch digital services to our customers. Responsibilities Develop, manage, and optimize data feeds for digital eCommerce data. Serve as a liaison between the digital and data teams, ensuring effective communication and collaboration. Design and implement scalable data pipelines using the Databricks platform. Work with cloud platforms, primarily GCP, but also adapt to Azure or AWS as needed. Ensure data integrity, quality, and availability across all systems. Collaborate with stakeholders to understand data requirements and deliver solutions that meet business needs. Monitor and troubleshoot data processes to maintain seamless operations. Implement best practices in data management, security, and governance. Requirements 5+ years of experience in data engineering, with a focus on digital eCommerce. Proven expertise with the Databricks platform. Strong knowledge of cloud platforms, particularly GCP. Experience with Azure or AWS is a plus. Strong understanding of data warehousing concepts and big data technologies. Hands-on experience with SQL Ability to work in a fast-paced, dynamic environment. Strong problem-solving skills and attention to detail. Nice to have Familiarity with data visualization tools and techniques. Knowledge of data governance and security best practices. We offer 100% payroll scheme, benefits by law (IMSS, INFONAVIT, 12+ vacation days) Benefits above the law: Vacation premium 50%, 5 PTOs, 3 sick days, 10 guaranteed public holidays per year Major medical insurance, Dental and Vision plan for an employee and direct family members Minor Medical Insurance (Multiservicios Médicos Santander) for an employee and direct family members Life Insurance and funeral expenses 5% savings fund, uncapped (matched by the company in the end of the year) Grocery cards/vouchers (Vales de Despensa) 30 days End of the Year Bonus (Aguinaldo) Opportunity to work on bleeding-edge projects with a highly motivated and dedicated team all over the world Individual career development plan and support from the best experts Professional development opportunities (Linkedin Learning, Cloud certification programs, access to corporate LMS integrated with other learning platforms) Well-equipped office in a business area of Guadalajara (quiet room, games room, air hockey, PS5, Nintendo Switch and Xbox Series X, pool table, ping pong, snacks, smoothies, and much more) Corporate social events (yoga, massages, sport tournaments, discussion panels, technical talks, lunch & learns) Flexible working hours Opportunity to relocate to another country where the company's offices are present. About Us Grid Dynamics (NASDAQ: GDYN) is a leading provider of technology consulting, platform and product engineering, AI, and advanced analytics services. Fusing technical vision with business acumen, we solve the most pressing technical challenges and enable positive business outcomes for enterprise companies undergoing business transformation. A key differentiator for Grid Dynamics is our 8 years of experience and leadership in enterprise AI, supported by profound expertise and ongoing investment in data, analytics, cloud & DevOps, application modernization and customer experience. Founded in 2006, Grid Dynamics is headquartered in Silicon Valley with offices across the Americas, Europe, and India.",https://mx.linkedin.com/jobs/view/big-data-developer-at-grid-dynamics-4013792922,4013792922,"We are seeking a highly skilled Data Engineer to lead the development and management of data feeds for digital eCommerce. In this role, you will ensure seamless data integration and flow across our platforms, driving the success of our data initiatives. Responsibilities include optimizing data feeds, collaborating between digital and data teams, designing scalable data pipelines using the Databricks platform, and ensuring data integrity and availability. Additionally, you will monitor data processes and implement best practices in data management and security.","Databricks, GCP, Azure, AWS, SQL, Data Warehousing, Big Data Technologies",5+ years,,True,5.0,0,0,1,1,0,1,1,0,0,1,0,0,0,0,0,0,0
Senior Applied Scientist,Launch Potato,Guadalajara,REMOTE,Mid-Senior level,Full-time,Advertising Services,2024-09-08 11:29:34.794464,25,Research,"Analyst,",Information Technology,"WHO ARE WE? Launch Potato is a digital media company with a portfolio of brands and technologies. As The Discovery and Conversion Company, Launch Potato is a leading connector of advertisers to customers at all parts of the consumer journey, from awareness to consideration to purchase. The company is headquartered in vibrant downtown Delray Beach, Florida, with a unique international team across over a dozen countries. Launch Potato's success comes from a diverse, energetic culture and high-performing, entrepreneurial team. As a result, the company is always looking for like-minded teammates and partners. (This role will heavily focus on building machine learning models. This is NOT an engineering/data engineering position.) MUST HAVE: Experience within the performance marketing/lead gen industries. Professional experience designing, implementing, optimizing, and testing end-to-end Multi-Armed Bandit (MAB) and recommendation systems. EXPERIENCE: A minimum of 4 years experience in a hands-on, in-the-weeds data science position. YOUR ROLE You will be developing deep personalization models for our users and complex optimization algorithms to bridge our customer experiences with new products/services. Your direct contribution will impact how we connect hundreds of thousands of customers to hundreds of advertisers together daily and will drive significant consumer impact while increasing revenue. You will play a pivotal role in the growth of our data science team and will be an instrumental resource as we continue to build a team of data scientists and machine learning engineers that can increase customer engagement and stickiness on our sites while improving the quality of the leads to our partners. This is an extremely hands-on and in-the-weeds Data Science role where you will be heavily immersed in the data and coding part of the solution implementation. You will design and oversee integrating state-of-the-art machine learning solutions across the company’s products. This role will be responsible for strategic planning of Machine Learning initiatives with the Product, Engineering, Performance and Business Intelligence teams, analysis of potential impact and prioritization of those projects. SUCCESS LOOKS LIKE Innovate, create, and design ML solutions to various business problems such as: Design, implement and continuously improve Multi-Armed Bandit solutions to optimize decisions/options in place of multiple AB-tests. Utilizing Large Language Models in content personalization across various verticals. Recommendation systems to serve ads, offers, questions, etc. Collaborate with stakeholders across the company including but not limited to Analytics, Engineering, Product and Business Leads to improve model infrastructure, tracking and monitoring. Provide data science support at different project stages, including the implementation of ML solutions by collaborating with Data Engineers and MLOps. Being hands-on and in-the-weeds in the data, coding part of the solution implementation. What You Need To Succeed 4+ years of related work experience in the field of Data Science & Machine learning. 2+ years of experience in the Marketing/Advertising Industry. Solid background in Machine Learning and Statistics. Professional experience designing and implementing Multi-Armed Bandit (MAB) solutions and recommendation systems. Proficiency in SQL, Python and working with Data Science tools (e.g., git, kubernetes, Docker, etc.). Structure and clarify any ambiguity for the team, i.e., divide complex projects into sprints and coordinate implementation across multiple teams and individuals. Experience creating ML solutions within cloud services (AWS/GCP). Experience with ML model development lifecycle. Experience with data visualization (preferably Looker). Experience managing a team of data scientists and machine learning researchers (including career development). Ability to communicate clearly, think independently, provide direction, and effectively communicate with technical and non-technical stakeholders. NICE TO HAVES Experience with LLMs and Deep learning models to develop business and data science solutions. Want to make your impact in a profitable, high-growth company? Apply now! Since day one, we've been committed to having a diverse, inclusive team and culture. We are proud to be an Equal Employment Opportunity company. We value diversity, equity, and inclusion. We do not discriminate based on race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",https://mx.linkedin.com/jobs/view/senior-applied-scientist-at-launch-potato-4019305670,4019305670,"The role focuses on building machine learning models with specific emphasis on developing deep personalization models, complex optimization algorithms, and designing Multi-Armed Bandit (MAB) and recommendation systems. The position requires collaboration with various teams to innovate and implement ML solutions that enhance customer experiences and increase revenue.","Python, SQL, Machine Learning, Statistics, Large Language Models, Data Science tools, Git, Kubernetes, Docker, AWS, GCP, Looker",4+ years,,True,4.0,0,0,0,1,1,1,0,0,1,1,0,1,1,0,1,0,0
"Senior Artificial Intelligence/Machine Learning Engineer - Remote, Latin America",Bluelight Consulting | DevOps & Software Development,Guadalajara,REMOTE,,Full-time,IT Services and IT Consulting,2024-09-08 11:29:34.794464,25,Engineering,Information Technology,,"Bluelight Consulting is a leading software consultancy dedicated to designing and developing innovative technology that enhances users' lives. With a steadfast commitment to delivering exceptional service to our clients, Bluelight excels in its focus on quality and customer satisfaction. Our mission is not only to create cutting-edge applications but also to foster a collaborative and enriching work environment where each team member can grow and thrive. With a presence across the United States and Central/South America, Bluelight is in an exciting phase of expansion, continually seeking exceptional talent to join its dynamic and diverse community. We are looking for a skilled individual to join our rapidly growing team at Bluelight Consulting. This position is ideal for someone who thrives in a fast-paced, dynamic environment where everyone's opinions and efforts are valued and appreciated. You will have the opportunity to contribute to challenging and meaningful projects, developing high-quality applications that stand out in the market. We value continuous learning, personal growth, and hard work, offering a collaborative environment that promotes professional development. If you are passionate about software development and eager to be part of a growing software consultancy, we invite you to apply and join us on this exciting journey. What we are looking for Strong background in computer science or engineering with 3+ years of experience Knowledge of machine learning, deep learning, and natural language processing Experience with LLMs like GPT and LLama3 Proficient in Python and familiar with TensorFlow or PyTorch Good problem-solving skills and ability to work independently and in a team Experience with AI voice programs/products Proficient in cloud services (AWS, Azure, Google Cloud) and container technologies (Docker, Kubernetes) Strong communication skills for explaining technical ideas to various audiences Ability to manage product specifications from concept to production Understanding of software design principles, including optimization and performance tuning Company Benefits Competitive salary and bonuses, including performance-based salary increases Generous paid-time-off policy Technology / Office stipend Health Coverage Flexible working hours Work remotely Continuing education, training, conferences Company-sponsored coursework, exams, and certifications Being a consultant in our team is a fun, challenging, and rewarding career choice. Your contributions are highly valued by clients, and the work you do often has a direct and significant impact on their business. You will have the opportunity to work on a variety of projects for our incredible clients, which will accelerate your career growth. You’ll collaborate with modern technologies and work alongside some of the best professionals in the industry! If you’re eager to be part of an exciting, challenging, and rapidly growing consultancy, we encourage you to apply.",https://mx.linkedin.com/jobs/view/senior-artificial-intelligence-machine-learning-engineer-remote-latin-america-at-bluelight-consulting-devops-software-development-4018827405,4018827405,"We are looking for a skilled individual with a strong background in computer science or engineering and 3+ years of experience. You should have knowledge of machine learning, deep learning, and natural language processing, with experience using LLMs like GPT and LLama3. Proficiency in Python and familiarity with TensorFlow or PyTorch are required. Good problem-solving skills and the ability to work both independently and in a team are essential. Experience with AI voice programs/products and proficiency in cloud services (AWS, Azure, Google Cloud) and container technologies (Docker, Kubernetes) is also needed. Strong communication skills for explaining technical ideas to various audiences are important, along with the ability to manage product specifications from concept to production and an understanding of software design principles, including optimization and performance tuning.","Python, TensorFlow, PyTorch, AWS, Azure, Google Cloud, Docker, Kubernetes, Machine Learning, Deep Learning, Natural Language Processing",3+,,True,3.0,0,0,0,1,1,0,0,0,0,0,0,0,1,0,1,0,0
Senior Machine Learning Researcher,Launch Potato,Guadalajara,REMOTE,Mid-Senior level,Full-time,Advertising Services,2024-09-08 11:29:34.794464,25,Other,,,"WHO ARE WE? Launch Potato is a digital media company with a portfolio of brands and technologies. As The Discovery and Conversion Company, Launch Potato is a leading connector of advertisers to customers at all parts of the consumer journey, from awareness to consideration to purchase. The company is headquartered in vibrant downtown Delray Beach, Florida, with a unique international team across over a dozen countries. Launch Potato's success comes from a diverse, energetic culture and high-performing, entrepreneurial team. As a result, the company is always looking for like-minded teammates and partners. (This role will heavily focus on building machine learning models. This is NOT an engineering/data engineering position.) MUST HAVE: Experience within the performance marketing/lead gen industries. Professional experience designing, implementing, optimizing, and testing end-to-end Multi-Armed Bandit (MAB) and recommendation systems. EXPERIENCE: A minimum of 4 years experience in a hands-on, in-the-weeds data science position. YOUR ROLE You will be developing deep personalization models for our users and complex optimization algorithms to bridge our customer experiences with new products/services. Your direct contribution will impact how we connect hundreds of thousands of customers to hundreds of advertisers together daily and will drive significant consumer impact while increasing revenue. You will play a pivotal role in the growth of our data science team and will be an instrumental resource as we continue to build a team of data scientists and machine learning engineers that can increase customer engagement and stickiness on our sites while improving the quality of the leads to our partners. This is an extremely hands-on and in-the-weeds Data Science role where you will be heavily immersed in the data and coding part of the solution implementation. You will design and oversee integrating state-of-the-art machine learning solutions across the company’s products. This role will be responsible for strategic planning of Machine Learning initiatives with the Product, Engineering, Performance and Business Intelligence teams, analysis of potential impact and prioritization of those projects. SUCCESS LOOKS LIKE Innovate, create, and design ML solutions to various business problems such as: Design, implement and continuously improve Multi-Armed Bandit solutions to optimize decisions/options in place of multiple AB-tests. Utilizing Large Language Models in content personalization across various verticals. Recommendation systems to serve ads, offers, questions, etc. Collaborate with stakeholders across the company including but not limited to Analytics, Engineering, Product and Business Leads to improve model infrastructure, tracking and monitoring. Provide data science support at different project stages, including the implementation of ML solutions by collaborating with Data Engineers and MLOps. Being hands-on and in-the-weeds in the data, coding part of the solution implementation. What You Need To Succeed 4+ years of related work experience in the field of Data Science & Machine learning. 2+ years of experience in the Marketing/Advertising Industry. Solid background in Machine Learning and Statistics. Professional experience designing and implementing Multi-Armed Bandit (MAB) solutions and recommendation systems. Proficiency in SQL, Python and working with Data Science tools (e.g., git, kubernetes, Docker, etc.). Structure and clarify any ambiguity for the team, i.e., divide complex projects into sprints and coordinate implementation across multiple teams and individuals. Experience creating ML solutions within cloud services (AWS/GCP). Experience with ML model development lifecycle. Experience with data visualization (preferably Looker). Experience managing a team of data scientists and machine learning researchers (including career development). Ability to communicate clearly, think independently, provide direction, and effectively communicate with technical and non-technical stakeholders. NICE TO HAVES Experience with LLMs and Deep learning models to develop business and data science solutions. Want to make your impact in a profitable, high-growth company? Apply now! Since day one, we've been committed to having a diverse, inclusive team and culture. We are proud to be an Equal Employment Opportunity company. We value diversity, equity, and inclusion. We do not discriminate based on race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",https://mx.linkedin.com/jobs/view/senior-machine-learning-researcher-at-launch-potato-4019305690,4019305690,"The role will heavily focus on building machine learning models, requiring experience in the performance marketing and lead generation industries. You will develop deep personalization models and complex optimization algorithms, significantly impacting consumer connections and driving revenue. The position involves designing and implementing Multi-Armed Bandit solutions, utilizing Large Language Models for content personalization, and collaborating across teams to improve model infrastructure. Success in the role entails innovating ML solutions, analyzing impact, and integrating machine learning across the company’s products.","Python, SQL, Machine Learning, Statistics, Multi-Armed Bandit, Recommendation Systems, Git, Kubernetes, Docker, AWS, GCP, Looker",4+ years,,True,4.0,0,0,0,1,1,0,0,0,1,1,0,1,1,0,1,0,0
Tech Support Data Engineer,Boldr,Guadalajara,REMOTE,Mid-Senior level,Full-time,Non-profit Organizations and Primary and Secondary Education,2024-08-16 11:29:34.794464,44,Engineering,,,"Working hours: US Business hours What Is Your Role This role is part of the team of Customer Engineers in Professional Services, and we're seeking highly talented individuals to join and grow our team. This is the intersection where the product has to meet customer needs and create value. You are a customer-facing data engineer who loves to see technology and data used in ways that ensure our projects' and customers' success. You have great attention to detail and are very proactive in seeking potential roadblocks to success. You have great people skills and know how to manage the trust and expectations of a customer. What Will You Do Customer Engineers are the customer facing technical owners of our existing customer relationships and data driven deliverables on the company's platform You will work hands-on with our technology stack and collaborate with several teams such as Product Engineering and Customer Engagement in order to deliver on all customer technical requests. You will be responsible for regularly interacting with our customers to gather requirements (e.g. weekly meetings, email, etc), and for scoping and prioritizing the incoming work. This can include: Designing Solutions - translate business requirements into technical solutions using SQL, scripting, codebase configurations, etc Setting up ETL pipelines across disparate data sources, and creating a unified Data Model Setting up/enabling new product features & ingest/export integrations Implementing the company's platform and its various components for our new customers Helping answer customer questions, and troubleshooting where necessary Participating in the on-call rotation You will also be: Finding out sustainable ways of addressing repeatable issues, and building tools for automation Contributing with documentation and building our customer specific configuration knowledge base A source of feedback for our product team, full stack and backend engineering teams Requirements BS degree in Computer Science, Engineering, Mathematics, Economics, Statistics, Information Management or similar 2+ years in a technical role that involves managing and manipulating large data sets, such as ETL, Data Warehousing, Analytics, Data Science etc 2+ years in a client-facing role that involves being a point-of-contact for technical and non-technical users Proficient in one programming language and working knowledge of SQL and Unix command line tools Working Knowledge of Github, and AWS infrastructure Excellent problem solving skills Strong Communication skills Improvement mindset, through processes, tools and/ or documentation Strong professionalism & work ethic Nice to have: Working knowledge of Java and/or Scala Marketing technology industry & relevant vendor knowledge Benefits Law Benefits Private Health Insurance Paid Time Off Training Life insurance Mental Health Support Learning and Development Programs",https://mx.linkedin.com/jobs/view/tech-support-data-engineer-at-boldr-3994917960,3994917960,"This role is part of the Customer Engineers team in Professional Services, where you will serve as a customer-facing data engineer, responsible for ensuring project and customer success. You'll interact regularly with customers to gather requirements, design solutions based on business needs using SQL, and set up ETL pipelines. You will also implement product features, troubleshoot issues, and contribute documentation to support customer-specific configurations.","SQL, Unix, ETL, Data Warehousing, Data Analytics, AWS, Java, Scala, Github",2+ years,Bachelor,True,2.0,0,0,0,1,0,1,1,0,0,1,0,1,0,0,0,0,0
AI Machine Learning Engineer,Scale Up Recruiting Partners,Guadalajara,REMOTE,Associate,Full-time,Software Development,2024-09-13 11:29:34.794464,25,Information Technology,,,"Hi there! We are Scale Up and our client is looking for a AI Machine Learning Engineer! The Machine Learning Engineer role is responsible for the design, development and implementation of machine learning solutions to serve our organization. This includes ownership or oversight of projects from conception to deployment with appropriate AWS services, Docker, MLFlow, and others. The role also includes responsibility for following best practices with which to optimize and measure the performance of our models and algorithms against business goals. Responsibilities Design and develop machine learning models and algorithms for various aspects of the localization and business workflow processes, including machine translation, LLM fine tuning, and quality assurance. Take ownership of key projects from definition to deployment, ensuring that they meet technical requirements and maintain momentum and direction until delivery. Evaluate and select appropriate machine learning techniques and algorithms to solve specific problems. Implement and optimize machine learning models and technologies using Python, TensorFlow, and other relevant tools and frameworks. Perform statistical analysis and fine-tuning using test results. Deploy machine learning models and algorithms using appropriate techniques and technologies, such as containerization using Docker and deployment to cloud infrastructure. Use AWS technologies (including but not limited to Sagemaker, EC2, S3) to deploy and monitor production environments. Keep abreast of developments in the field, with a dedication to learning in the role. Document diligently and communicate thoughtfully about ML experimentation, design, and deployment. Project scope: Define and design solutions to machine learning problems. Integration with larger systems done with guidance from more senior colleagues. Requirements Effective model development: success is evident when the models developed are accurate, efficient, and align with project requirements. Positive team collaboration: demonstrated ability to collaborate effectively with various teams and stakeholders, contributing positively to project outcomes. Continuous learning and improvement: a commitment to continuous learning and applying new techniques to improve existing models and processes. Clear communication: ability to articulate findings, challenges, and insights to a range of stakeholders, ensuring understanding and appropriateness. Skills And Knowledge Ability to write robust, production-grade code in Python. Excellent communication and documentation skills. Strong knowledge of machine learning techniques and algorithms, including supervised and unsupervised learning, deep learning, and reinforcement learning. Hands-on, high proficiency experience with machine learning frameworks such as TensorFlow, PyTorch, and Scikit-learn. Experience with natural language processing (NLP) techniques and tools. Strong communication and collaboration skills, with the ability to explain complex technical concepts to non-technical stakeholders. Experience taking ownership of projects from conception to deployment, and mentoring more junior team members. Hands-on experience with AWS technologies including EC2, S3, and other deployment strategies. Experience with SNS, Sagemaker a plus. Experience with ML management technologies and deployment techniques, such as AWS ML offerings, Docker, GPU deployments, etc. Education And Experience BSc in computer science, mathematics or similar field. Master’s Degree is a plus. 3+ years’ experience as a Machine Learning Engineer or similar role. Benefits National public holidays. Vacations: 3 weeks per year. Work laptop provided. If this opportunity sounds good to you, send us your resume!",https://mx.linkedin.com/jobs/view/ai-machine-learning-engineer-at-scale-up-recruiting-partners-4023312409,4023312409,"The Machine Learning Engineer role is responsible for the design, development, and implementation of machine learning solutions to serve the organization, including ownership of projects from conception to deployment with appropriate AWS services, Docker, and MLFlow. Responsibilities include designing and developing machine learning models and algorithms, optimizing performance against business goals, deploying models using cloud infrastructure, and documenting processes.","Python, TensorFlow, PyTorch, Scikit-learn, AWS (EC2, S3, Sagemaker), Docker, MLFlow",3+ years,Bachelor,True,3.0,0,0,0,1,1,0,0,0,0,0,0,0,1,0,1,0,0
Data Scientist ll,O'Reilly Autopartes México,Guadalajara,HYBRID,Mid-Senior level,Full-time,"Motor Vehicle Parts Manufacturing, IT System Data Services, and Data Infrastructure and Analytics",2024-09-08 11:30:57.007212,55,Information Technology,,,"¡Únete a nuestro equipo como Data Scientist ll! ¿Te apasiona resolver problemas empresariales complejos a través del análisis de datos y la aplicación de técnicas avanzadas de modelado estadístico y aprendizaje automático? Si es así, esta es tu oportunidad para ser parte de un equipo innovador y contribuir a la toma de decisiones estratégicas dentro de nuestra organización. Resumen General: Como Data Scientist ll , serás responsable de modelar problemas empresariales complejos, descubrir insights y detectar oportunidades mediante el uso de técnicas estadísticas, algoritmos, minería de datos y visualización. Trabajarás estrechamente con clientes, administradores de datos, gerentes de proyectos/programas y otros equipos de TI para transformar los datos en información crítica y conocimiento que apoye la toma de decisiones organizacionales. Funciones Esenciales del Puesto: Colaboración con Stakeholders: Trabajarás con diversas partes interesadas en la organización para identificar oportunidades de aprovechamiento de datos que impulsen soluciones empresariales efectivas. Análisis Complejo: Sintetizarás hechos, teorías, tendencias e inferencias en situaciones complejas y variables, reconociendo patrones abstractos y relaciones entre entidades o situaciones aparentemente no relacionadas. Desarrollo de Soluciones: Aplicarás conceptos y teorías apropiadas en el desarrollo de principios, prácticas, técnicas, herramientas y soluciones innovadoras. Investigación y Mejora Continua: Recogerás y analizarás información sobre las tendencias actuales y futuras en las mejores prácticas, mejorando el rendimiento organizacional mediante la aplicación de ideas originales a métodos, procesos, productos y servicios existentes y emergentes. Otras Funciones del Puesto: Implementación de Innovaciones: Utilizarás un juicio sólido para determinar cómo se implementarán las innovaciones que produzcan un retorno de la inversión positivo. Mejora del Rendimiento: Traducirás la información más actualizada en actividades de mejora continua que optimicen el rendimiento. Resolución de Problemas: Anticiparás, identificarás y definirás problemas, buscando causas raíces y desarrollando soluciones prácticas y oportunas. Experiencia en Machine Learning: Tendrás un conocimiento profundo de varias técnicas de aprendizaje automático (como clustering, árboles de decisión, redes neuronales artificiales, etc.) y sus ventajas/desventajas en el mundo real. Técnicas Estadísticas Avanzadas: Contarás con conocimientos avanzados en técnicas y conceptos estadísticos (regresión, propiedades de distribuciones, pruebas estadísticas y su uso adecuado, etc.) y experiencia en su aplicación práctica. Requisitos: Licenciatura. 5+ años de experiencia práctica en ETL, procesamiento de datos, programación de bases de datos y análisis de datos. Experiencia extensiva con Python y bibliotecas como Pandas, Numpy, SciKit-Learn, y Jupyter notebooks. Experiencia extensiva en aprendizaje automático y modelado estadístico. Maestría en SQL junto con conocimientos en diseño y optimización de bases de datos. Excelentes habilidades de comunicación y deseo de trabajar en un entorno dinámico y colaborativo. Capacidad demostrable para desarrollar e implementar soluciones matemáticas a problemas de datos. Ingles avanzado conversacional",https://mx.linkedin.com/jobs/view/data-scientist-ll-at-o-reilly-autopartes-m%C3%A9xico-4017387486,4017387486,"Join our team as a Data Scientist II! The role involves solving complex business problems through data analysis and the application of advanced statistical modeling and machine learning techniques. As a Data Scientist II, you will be responsible for modeling complex business problems, discovering insights, and detecting opportunities using statistical techniques, algorithms, data mining, and visualization. You will work closely with clients, data managers, project/program managers, and other IT teams to transform data into critical information and knowledge to support organizational decision-making.","Python, Pandas, Numpy, SciKit-Learn, Jupyter Notebooks, SQL, ETL, Data Analysis, Machine Learning, Statistical Modeling",5+ years,Bachelor,True,5.0,0,0,0,0,0,1,1,0,0,1,0,0,1,0,1,0,0
AI Graduate,Cognizant,Guadalajara,HYBRID,Entry level,Full-time,IT Services and IT Consulting,2024-06-17 11:30:57.007212,60,Research,"Analyst,",Information Technology,"Cognizant is an America IT consultancy with a presence in more than 40 countries. A Great Place to Work where we look for people who contribute new ideas, experiencing a dynamic and growing environment. At Cognizant we promote an inclusive culture, where we value different perspectives providing career growth and development opportunities. This is an opportunity with the aim of training students or nearly graduated in the field of technology so that can develop their careers. All program participants undergo training in specific technologies so that they can later perform their roles in the projects. Why choose this program? Training: Participants will be able to receive behavioral and technical training for a period of time to later put into practice in the project. This makes theoretical + practical knowledge possible in a short time! Career: You will start your career as an analyst in the technology field. From them on, contact with technology will be constant. Collaboration : Here you will know that no ones is alone at the beginning of their career. All associates receive constant support from Cognizant’s leadership and stakeholders, charting the way forward. Position Overview By joining Cognizant as an entry-level in AI, you will be analyzing, designing, programming, and testing software programs and applications across all industries. Kick-start your software engineering career in our new hire training program to learn the latest technical skills! Responsibilities: Develop auxiliar functions on Python language. Testing AI applications developed by the team, looking for and analyzing possible errors. Label new documents to be analyzed by AI models. Generate project documentation. Basic Qualifications: Bachelor’s degree or equivalent in IT related field Basic knowledge with Python Advanced English level Self-motivated individuals with strong analytical, troubleshooting, and problem-solving skills with the passion and appetite to learn newer technologies. Excellent interpersonal & communication skills Ability to work collaboratively with global project teams. Location Guadalajara Start Date May 2024 Why choose us? Cognizant delivers that draw upon the full power and scale of our associates. You will be supported by high-caliber experts and employ some of the most advanced and patented capabilities. Our associate’s diverse backgrounds offer varied perspectives and fuel new ways of thinking. We encourage lively discussions which inspire better results for our clients. If you’re comfortable with ambiguity excited by change, and excel through autonomy, we’d love to hear from you. Benefits : Cognizant offers upper law benefits We are committed to respecting human rights and build a better future by helping your minds and the environment We invest in people and their wellbeing. We create conditions for everyone to thrive. We do not discriminate based on race, religion, color, sex, age, disability, nationality, sexual orientation, gender identity or expression, or for any other reason covered. Employee Status : Full Time Employee Shift : Day Job Travel : No Job Posting : Apr 05 2024 About Cognizant Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @Cognizant. 00058405301",https://mx.linkedin.com/jobs/view/ai-graduate-at-cognizant-3970607635,3970607635,"By joining Cognizant as an entry-level in AI, you will be analyzing, designing, programming, and testing software programs and applications across all industries. You will develop auxiliary functions in Python, test AI applications developed by the team, label new documents for AI models, and generate project documentation.",Python,,Bachelor,True,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
Principal Data Scientist,HP,Guadalajara,HYBRID,,Full-time,"Computer Hardware Manufacturing, Software Development, and IT Services and IT Consulting",2024-09-11 11:30:57.007212,25,Engineering,Information Technology,,"Position Overview We are seeking a talented and visionary Principal Data Scientist to join our Supply Chain Planning Analytics team. As a Principal Data Scientist, you will play a key role in shaping our long-term strategic direction by providing data-driven insights, conducting in-depth analysis, and developing innovative solutions to drive business growth and competitiveness while communicating business value and innovation potential through effective insights and visualizations. You will collaborate closely with senior leadership, business stakeholders, and cross-functional teams to identify strategic opportunities, assess market trends, and drive strategic initiatives across the organization. Key Responsibilities Forecasting Models: Develop predictive models and analytical frameworks to forecast market demand, assess competitive dynamics, predict demand, optimize inventory levels, and inform strategic decision-making. Utilize time series analysis, machine learning, and statistical techniques to improve forecast accuracy. Analyze large datasets to identify trends, patterns, and opportunities for improvement in supply planning. Build and validate predictive models to forecast inventory needs and minimize stockouts and overstock situations. Continuously monitor and refine models to ensure accuracy and reliability. Inventory Optimization Utilize methods such as linear programming, queuing theory, and simulation to optimize inventory and production workflows. Develop optimization models to improve supply planning and logistics. Work with the supply chain team to implement inventory optimization strategies. Conduct scenario analysis to support decision-making processes. Component Classification and Segmentation Conduct in-depth analysis of internal and external data sources to identify market trends, customer behaviors, and strategic opportunities. Collaborate with cross-functional teams to define strategic priorities, establish performance metrics, and track progress against strategic goals. Utilize deep learning models such as Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Transformer models for complex product classification and segmentation tasks. Implement prescriptive analytics techniques to recommend actionable insights for product categorization and segmentation, enabling targeted marketing and inventory management strategies. Supply Planning Optimization Lead strategic data science initiatives to support key business objectives in Inventory Optimization / Planning area. Develop optimization models to improve supply planning and logistics. Work with the supply chain team to implement inventory optimization strategies. Conduct scenario analysis and simulation to support decision-making processes. Mentor and coach junior team members and contribute to the development of a high-performing and collaborative data science team. Qualifications Master's degree or related work experience Data Science, Mathematics, Statistics, Operations Research, Computer Science or a related field. PhD a Plus 10 -15 years of experience in strategic planning within Supply Chain, business analytics, or a similar role, with a strong focus on data-driven decision-making. Proficiency in programming languages such as Python, R, or Scala, and experience with data analysis libraries and frameworks (e.g., pandas, scikit-learn, TensorFlow, PyTorch, PuLP, SciPy, SimPy). Experience in advanced forecasting techniques (e.g., ARIMA, Prophet, LSTM) Strong analytical and problem-solving skills, with the ability to translate complex data into actionable insights and strategic recommendations. In-depth supply chain knowledge. Fluent in structured and unstructured data, its management, and modern data transformation methodologies Excellent communication and presentation skills, with the ability to convey technical concepts to non-technical stakeholders. Proven track record of leading strategic initiatives, driving organizational change, and delivering measurable business results. Ability to thrive in a fast-paced, dynamic environment, and manage multiple priorities effectively. Strong leadership and collaboration skills, with the ability to build consensus and drive alignment across diverse stakeholders. Experience in strategic consulting, management consulting, or corporate strategy is a plus. The base pay range for this role is $137,000 to $211,000 annually with additional opportunities for pay in the form of bonus and/or equity (applies to US candidates only). Pay varies by work location, job-related knowledge, skills, and experience. Benefits HP offers a comprehensive benefits package for this position, including: Health insurance Dental insurance Vision insurance Long term/short term disability insurance Employee assistance program Flexible spending account Life insurance Generous time off policies, including; 4-12 weeks fully paid parental leave based on tenure 11 paid holidays Additional flexible paid vacation and sick leave (US benefits overview) The compensation and benefits information is accurate as of the date of this posting. The Company reserves the right to modify this information at any time, with or without notice, subject to applicable law.",https://mx.linkedin.com/jobs/view/principal-data-scientist-at-hp-4017034443,4017034443,"We are seeking a talented and visionary Principal Data Scientist to join our Supply Chain Planning Analytics team. You will develop predictive models, analyze large datasets, and optimize inventory and production workflows. Responsibilities include forecasting market demand, conducting scenario analysis, and utilizing machine learning models for classification tasks. A Master's degree or related work experience is required, along with 10-15 years of experience in strategic planning within Supply Chain and proficiency in programming languages.","Python, R, Scala, pandas, scikit-learn, TensorFlow, PyTorch, PuLP, SciPy, SimPy, ARIMA, Prophet, LSTM",10-15,Masters,True,10.0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0
AI/ML Engineer - Azure,Synechron,Guadalajara,HYBRID,Entry level,Full-time,Software Development and IT Services and IT Consulting,2024-09-12 11:30:57.007212,25,Engineering,Information Technology,,"We are At Synechron, we believe in the power of digital to transform businesses for the better. Our global consulting firm combines creativity and innovative technology to deliver industry-leading digital solutions. Synechron’s progressive technologies and optimization strategies span end-to-end Artificial Intelligence, Consulting, Digital, Cloud & DevOps, Data, and Software Engineering, servicing an array of noteworthy financial services and technology firms. Through research and development initiatives in our FinLabs we develop solutions for modernization, from Artificial Intelligence and Blockchain to Data Science models, Digital Underwriting, mobile-first applications and more. Over the last 20+ years, our company has been honored with multiple employer awards, recognizing our commitment to our talented teams. With top clients to boast about, Synechron has a global workforce of 14,000+, and has 55 offices in 20 countries within key global markets. Our challenge We are seeking a skilled and motivated AI/ML Engineer with Azure to join our team. Candidate will collaborate, analyze, design, develop, test, maintain and implement premier software while working with cross-functional teams such as product and architecture. The Role Responsibilities : Experience in CMS as major subsystem and FAS or TRAMS as minor sub-Collaboration: Work closely with cross-functional teams, including IT, business, operations, and business stakeholders, to align AI support with objectives. Work with business users to understand their needs and document them using various tools Anticipate user needs and propose solutions and alternatives Understand functional and non-functional requirements Work with development teams in building and testing the solutions Maintain active communication channels with all stakeholders on deliverables and report status Track all outstanding issues and manage them from initiation to production deployment Ability to multitask and work with multiple teams Manage enhancement requests and production issues. Able to prioritize and allocate resources effectively Requirements: You are: Python and AI/ML Develop and deploy GenAI applications on Azure with focuses on: Azure OpenAI Azure Functions Azure Cosmos Azure Blob Storage Azure API Management Infrastructure as Code experience with Terraform with Azure CI/CD experiences with Jenkins Experience with Azure cloud, Python, Angular (applications are built today with azure cloud, using python & angular as backend & front end, and other azure services) Support in Regression Testing & Patch Releases for new & existing applications We can offer you: A highly competitive compensation and benefits package A multinational organization with 55 offices in 20 countries and the possibility to work abroad Laptop/equipment 12 days of paid annual leave (plus sick leave and national holidays) Maternity & Paternity leave plans A comprehensive insurance plan including: medical, dental, vision, and long-/short-term disability (plans vary by region) Retirement savings plans A higher education certification policy Extensive training opportunities, focused on skills, substantive knowledge, and personal development On-demand Udemy for Business for all Synechron employees with free access to more than 5000 curated courses Coaching opportunities with experienced colleagues from our Financial Innovation Labs (FinLabs) and Center of Excellences (CoE) groups Cutting edge projects at the world’s leading tier-one banks, financial institutions and insurance firms A flat and approachable organization A truly diverse, fun-loving and global work culture Saving funds plan for Mexico S YNECHRON’S DIVERSITY & INCLUSION STATEMENT Diversity & Inclusion are fundamental to our culture, and Synechron is proud to be an equal opportunity workplace and is an affirmative action employer. Our Diversity, Equity, and Inclusion (DEI) initiative ‘Same Difference’ is committed to fostering an inclusive culture – promoting equality, diversity and an environment that is respectful to all. We strongly believe that a diverse workforce helps build stronger, successful businesses as a global company. We encourage applicants from across diverse backgrounds, race, ethnicities, religion, age, marital status, gender, sexual orientations, or disabilities to apply. We empower our global workforce by offering flexible workplace arrangements, mentoring, internal mobility, learning and development programs, and more. All employment decisions at Synechron are based on business needs, job requirements and individual qualifications, without regard to the applicant’s gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law. Candidate Application Notice",https://mx.linkedin.com/jobs/view/ai-ml-engineer-azure-at-synechron-4021940326,4021940326,"We are seeking a skilled and motivated AI/ML Engineer with Azure to join our team. The candidate will collaborate, analyze, design, develop, test, maintain, and implement software while working with cross-functional teams. Responsibilities include understanding user needs, working with development teams, managing enhancement requests and production issues, and maintaining communication with stakeholders.","Python, AI/ML, Azure, Azure OpenAI, Azure Functions, Azure Cosmos, Azure Blob Storage, Azure API Management, Terraform, Jenkins, Angular",,,True,,0,0,0,1,0,0,0,0,0,0,1,1,0,0,1,0,0
Python Data Engineer,Deloitte,Guadalajara,HYBRID,Associate,Full-time,Business Consulting and Services,2024-08-25 11:30:57.007212,200,Information Technology,,,"Learn more about our great opportunities and don't miss the opportunity to be part of the evolution with this incredible team. We have this vacancy: Python Data Engineer It is hybrid, showing up twice a week at offices. Required: Strong proficiency in Python for data engineering tasks Experience with Kafka for real-time data streaming and processing Experience with SQL Preferred: Hands-on experience with Azure Cloud services for data solution Proficient with Kubernetes and Docker for container management Knowledge of CI/CD pipelines using Jenkins for automated deployment Experience with monitoring tools and techniques for data pipeline health Experience with MongoDB for NoSQL database management Familiarity with Apache Airflow for workflow orchestration Experience with version control systems, specifically Git",https://mx.linkedin.com/jobs/view/python-data-engineer-at-deloitte-4006452223,4006452223,"We have a vacancy for a Python Data Engineer, which is a hybrid role requiring attendance at the office twice a week. The position requires strong proficiency in Python for data engineering tasks, experience with Kafka for real-time data streaming and processing, and experience with SQL. Preferred qualifications include hands-on experience with Azure Cloud services, proficiency with Kubernetes and Docker, knowledge of CI/CD pipelines using Jenkins, experience with monitoring tools for data pipeline health, experience with MongoDB for NoSQL database management, familiarity with Apache Airflow, and experience with version control systems like Git.","Python, Kafka, SQL, Azure Cloud, Kubernetes, Docker, Jenkins, MongoDB, Apache Airflow, Git",,,True,,0,0,1,1,1,0,0,0,0,1,0,1,0,0,1,0,0
Data Engineer,MezTal,Guadalajara,HYBRID,Associate,Full-time,Non-profit Organizations and Primary and Secondary Education,2024-09-10 11:30:57.007212,25,Information Technology,,,"Meztal is looking for a talented and motivated Data Engineer to join our growing team. As a Data Engineer, you will be working closely with cross-functional teams, including product managers, data scientists, and software engineers, to design, build, and maintain scalable data pipelines and infrastructure. You will play a critical role in ensuring data integrity, availability, and accessibility to help drive business decisions and support our mission of delivering innovative solutions. Key Responsibilities: Design, develop, and maintain scalable ETL (Extract, Transform, Load) pipelines to process large volumes of structured and unstructured data from various sources Collaborate with data scientists and analysts to understand data requirements and ensure optimal data delivery architecture Implement data validation and cleansing processes to ensure data quality and consistency Develop and optimize data storage solutions (such as data lakes, warehouses, and databases) to support analytics and reporting needs Work with cloud-based data platforms and services (e.g., AWS, Azure, GCP) to deploy and manage data infrastructure Participate in code reviews, and maintain comprehensive documentation for data pipelines and processes Monitor and troubleshoot data workflows to ensure reliability, efficiency, and scalability Collaborate with team members to drive the overall data strategy and provide input on data governance and best practices Contribute to the development and deployment of machine learning models and algorithms in collaboration with data scientists Requirements Professional English Proficiency: Strong verbal and written communication skills in English are a must, as you will be collaborating with international teams Location Requirement: Must be based in Guadalajara, Jalisco, Mexico, and be willing to work in a hybrid model (combination of remote and in-office work) Experience: 3+ years of experience in a data engineering role or similar Technical Skills: Strong programming skills in Python, SQL, and familiarity with other languages such as Java or Scala Experience with data pipeline orchestration tools such as Apache Airflow, Prefect, or similar Hands-on experience with cloud-based data storage and processing services (AWS S3, Redshift, Glue, Azure Data Lake, GCP BigQuery, etc.) Familiarity with big data technologies such as Apache Spark, Hadoop, Kafka, or Flink Experience with database management systems (e.g., MySQL, PostgreSQL, NoSQL databases) Data Modeling and Warehousing: Strong understanding of data modeling, schema design, and building data warehouses Data Tools: Experience with data visualization and BI tools (Tableau, Power BI, Looker) is a plus Problem-Solving Mindset: Ability to work independently and collaboratively in a fast-paced environment, with a proactive approach to solving complex problems Attention to Detail: Strong analytical skills and attention to detail to ensure data quality and reliability Adaptability: Comfortable working in a dynamic and unstructured startup environment, with a willingness to learn and adapt to new tools and technologies Benefits Awesome Benefits for Our Team! Christmas Bonus: 30 days, to be paid in December Major Medical Expense Insurance: Coverage up to $20,000,000.00 MXN Minor Medical Insurance: VRIM membership with special discounts on doctor's appointments and accident reimbursements Dental Insurance: Always smile with confidence! Life Insurance: (Death and MXN Disability) Vacation Days: 12 vacation days in accordance with Federal Labor Law, with prior approval from your manager. + Floating Holidays: 3 floating holidays in addition to the 7 official holidays in Mexico Cell Phone Reimbursement & Transportation Subsidy. Hybrid Scheme: Enjoy the best of both worlds, remote and in-office work. Multicultural Exposure: Work with operations within Mexico and United Satates MezTal Internal Events: Strike a healthy balance between your professional and personal goals Exclusive Discounts: Benefits with different companies for being part of MezTal Academic Agreements: Access to national universities and language schools",https://mx.linkedin.com/jobs/view/data-engineer-at-meztal-4021666245,4021666245,"Meztal is looking for a talented and motivated Data Engineer to design, build, and maintain scalable data pipelines and infrastructure while ensuring data integrity, availability, and accessibility. You will collaborate with cross-functional teams to process large volumes of structured and unstructured data, implement data validation and cleansing processes, and develop data storage solutions. You will also work with cloud-based data platforms, monitor data workflows, and contribute to machine learning model development.","Python, SQL, Java, Scala, Apache Airflow, Prefect, AWS S3, Redshift, Glue, Azure Data Lake, GCP BigQuery, Apache Spark, Hadoop, Kafka, Flink, MySQL, PostgreSQL, NoSQL databases, Tableau, Power BI, Looker",3+ years,,True,3.0,0,0,1,1,0,0,0,0,1,1,0,0,0,0,1,0,0
Machine Learning Engineer - USA (TN Visa),Openwave Computing,Guadalajara,ON-SITE,Entry level,Full-time,IT Services and IT Consulting and Software Development,2024-09-08 11:32:47.028901,40,Engineering,Information Technology,,"Company Description Openwave Computing LLC is a global information technology company that provides comprehensive web and mobile app development services, catering to clients from diverse verticals. We have been in the industry for over two decades, gaining vast expertise and winning Company Description Openwave Computing LLC is a global information technology company that provides comprehensive web and mobile app development services, catering to clients from diverse verticals. We have been in the industry for over two decades, gaining vast expertise and winning the trust of our clients. We are a customer-centric company committed to quality, innovation, and security. At Openwave, we celebrate ideas and welcome breakthroughs from anyone. We are looking for someone who is passionate about their craft, committed to excellence, and wants to be part of a dynamic team. We offer TN visas for Mexican engineers. Job overview: We are seeking a highly skilled and motivated Machine Learning/AI Engineer to join our innovative team. The ideal candidate will have a strong background in machine learning and artificial intelligence, with experience developing and deploying ML/AI models. As a Machine Learning/AI Engineer for our clients projects, you will play a key role in designing, developing, and implementing ML/AI models to solve complex business problems for our clients. You will work closely with stakeholders to understand business needs and translate them into technical solutions, and collaborate with cross-functional teams to integrate ML/AI solutions into products. This role requires a strong understanding of machine learning algorithms, proficiency in Python and libraries like TensorFlow, PyTorch, and scikit-learn, and the ability to work independently and collaboratively in a fast-paced environment. Responsibilites: Design, develop, and implement machine learning, deep learning, and artificial intelligence models to solve complex business problems for our clients. Work closely with stakeholders to understand business needs and translate them into technical solutions. Collect, clean, and preprocess data for use in ML/DL/AI models. Train, test, and evaluate models to ensure accuracy and reliability. Deploy models into production environments and monitor their performance. Collaborate with cross-functional teams to integrate ML/DL/AI solutions into products. Stay up-to-date with the latest developments in the fields of machine learning, deep learning, and artificial intelligence. Qualifications Bachelor's degree in Computer Science, Engineering, or related field. Minimum of 5 years of experience in machine learning, deep learning, and artificial intelligence. Proficiency in Python and libraries like TensorFlow, PyTorch, and scikit-learn. Strong understanding of machine learning and deep learning algorithms. Experience with data preprocessing techniques and feature engineering. Familiarity with cloud platforms such as AWS, Google Cloud, or Azure. Excellent communication and problem-solving skills. Ability to work independently and collaboratively in a fast-paced environment. We offer: -TN Visa -Starting salary range $65,000 - 85,000 USD annual -Health insurance -More benefits will be discussed in the interview -Relocation help (Housing, transportation, and food)",https://mx.linkedin.com/jobs/view/machine-learning-engineer-usa-tn-visa-at-openwave-computing-4014109994,4014109994,"We are seeking a highly skilled and motivated Machine Learning/AI Engineer to join our innovative team. The ideal candidate will have a strong background in machine learning and artificial intelligence, with experience in developing and deploying ML/AI models. You will design, develop, and implement machine learning, deep learning, and AI models to solve complex business problems, work closely with stakeholders to translate business needs into technical solutions, collect and preprocess data, train and evaluate models, deploy them into production, and collaborate with cross-functional teams. The role requires a strong understanding of machine learning algorithms and proficiency in Python and libraries such as TensorFlow, PyTorch, and scikit-learn.","Python, TensorFlow, PyTorch, scikit-learn, AWS, Google Cloud, Azure",5,Bachelor,True,5.0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,1,0,0
Data Scientist,Cognizant,Guadalajara,ON-SITE,Entry level,Full-time,IT Services and IT Consulting,2024-08-16 11:32:47.028901,25,Engineering,Information Technology,,"Cognizant is always looking for top talent. We are searching for candidates to fill future needs within the business. This job posting represents potential future employment opportunities with Cognizant. Although the position is not currently available, we want to provide you with the opportunity to express your interest in future employment opportunities with Cognizant. If a job opportunity that you may be qualified for becomes available in the future, we will notify you. At that time you can determine whether you would like to apply for the specific open position. Thank you for your interest in Cognizant career opportunities. We’re hiring! At Cognizant we have an ideal opportunity for you to be part of one of the largest companies in the digital sector worldwide. A Great Place To Work where we look for people who contribute new ideas, experiencing a dynamic and growing environment. At Cognizant we promote an inclusive culture, where we value different perspectives providing career growth and development opportunities. #WelcomeToCognizant! We have an exciting opportunity for an exceptional individual to work supporting one of our clients as a IT Engineer What you’ll be able to do: Big Data Technologies: GCP Azure Data Lake GCP Big Query Databricks Spark Hadoop Kafka SQL and NO-SQL Data Visulaization tools: Qlickview Qlicksense Tableau PowerBI AI/ML technologies Statistical Methods application: ANOVA Principal Component analysis Correspondence Analysis K-means clustering Factor analysis Mutli-variate analysis, Neural Networks, causal inference, Gaussian Regression Others. Open source Data science technologies: Python R Why Cognizant? Improve your career in one of the largest and fastest growing IT services providers worldwide Receive ongoing support and funding with training and development plans Have a highly competitive benefits and salary package Get the opportunity to work for leading global companies We are committed to respecting human rights and build a better future by helping your minds and the environment We invest in people and their wellbeing. We create conditions for everyone to thrive. We do not discriminate based on race, religion, color, sex, age, disability, nationality, sexual orientation, gender identity or expression, or for any other reason covered. At Cognizant we believe than our culture make us stronger! Join us now! #BeCognizant #IntuitionEngineered Igualdad de Empleo y Política de Acción Afirmativa: Cognizant es un empleador que ofrece igualdad de oportunidades. Todos los solicitantes calificados recibirán consideración para el empleo sin distinción de sexo, identidad de género, orientación sexual, raza, color, religión, origen nacional, discapacidad, estado de veterano protegido, edad o cualquier otra característica protegida por la ley. Employee Status : Full Time Employee Shift : Day Job Job Posting : Apr 23 2024 About Cognizant Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @Cognizant. 44080",https://mx.linkedin.com/jobs/view/data-scientist-at-cognizant-4006276504,4006276504,"We have an exciting opportunity for an exceptional individual to work supporting one of our clients as an IT Engineer. The position involves working with Big Data technologies such as GCP, Azure Data Lake, GCP Big Query, Databricks, Spark, Hadoop, Kafka, SQL, and NoSQL. Additionally, candidates will utilize data visualization tools like QlikView, QlikSense, Tableau, and PowerBI. AI/ML technologies and statistical methods such as ANOVA, Principal Component Analysis, Correspondence Analysis, K-means Clustering, Factor Analysis, Multivariate Analysis, Neural Networks, Causal Inference, and Gaussian Regression will also be required. Open source data science technologies like Python and R are essential.","GCP, Azure Data Lake, GCP Big Query, Databricks, Spark, Hadoop, Kafka, SQL, NoSQL, QlikView, QlikSense, Tableau, PowerBI, Python, R",,,True,,0,0,1,1,0,0,0,0,1,1,0,0,0,0,1,0,0
AI Software Engineer,Plexus Corp.,Guadalajara,ON-SITE,,Full-time,"Defense and Space Manufacturing, Appliances, Electrical, and Electronics Manufacturing, and Medical Equipment Manufacturing",2024-09-10 11:32:47.028901,25,Engineering,Information Technology,,"Purpose Statement: The AI Software Engineer II is responsible for designing, developing, and implementing new or modified software products for ongoing AI/decision technology projects. They collaborate closely with various teams and stakeholders, including Data Scientists, Architects, Analysts, Project Managers, and other developers, to ensure software projects meet requirements. A key focus of this role will be supporting the AI/Decision Technology Team and their respective applications. This position will work on integrating different AI algorithms to create user and data friendly solutions. Key Job Accountabilities: Collaboration: Actively collaborate with cross-functional teams to conceptualize and develop or enhance software applications, ensuring adherence to project requirements, best practices, and business objectives. Software Development: Research, design, write, test, and implement high-performing code for software applications, ensuring they meet project requirements, coding standards and best practices. Integrate AI models into production systems and monitor their performance. Documentation: Prepare and maintain project documentation, including design and unit test documents, with a preference for UML proficiency. Testing and Quality Assurance: Participate in testing and quality assurance activities, including code reviews, unit testing, and bug identification. Help ensure software meets quality standards. Innovation and Research: Stay updated on emerging software development technologies and best practices, actively seeking opportunities and contributing ideas to improve development processes and efficiency. Creation of functional and friendly user and data interfaces. Education/Experience Qualifications: Typically requires a Bachelor’s degree and a minimum of 2 years of related experience; or equivalent work experience. Minimum of 1 year of AI/decision technology integration and development experience. Other Qualifications: English Proficiency Experience with cloud platforms such as AWS, Google Cloud, or Azure for AI model deployment. Agile and Lean Six Sigma certifications are desirable JDE / DSI .NET / C# - Design and setup development framework with n-tier environment (C#/.NET). Python, Machine Learning, IoT and Big Data analysis User Interface (UI) / User Design (UX ) Action oriented Ability to escalate issues appropriately Present information for decision making purposes with little to no direction Strong time management skills Ability to multi-task i.e. managing multiple projects A strong passion for software development and willingness to learn and grow. Strong problem-solving and analytical abilities. Ability to work effectively in a team. Excellent communication and teamwork skills. Physical Requirements: Professional office environment with suitable lighting, comfortable temperatures, and low noise level. May require prolonged periods of sitting at a desk, using a computer, and other office equipment. Minimal physical activity is generally involved, emphasizing the importance of good posture and ergonomic workplace arrangements. Travel Requirements: N/A This document does not represent a contract of employment and is not intended to capture every possible assignment the incumbent could be asked to perform.",https://mx.linkedin.com/jobs/view/ai-software-engineer-at-plexus-corp-4021817862,4021817862,"The AI Software Engineer II is responsible for designing, developing, and implementing new or modified software products for AI and decision technology projects. This includes collaborating with various teams to ensure software projects meet requirements, integrating AI algorithms, and creating user-friendly solutions. The role involves researching, writing, testing, and implementing code that meets project requirements and coding standards, as well as preparing project documentation. The engineer will also participate in testing and quality assurance activities, stay updated on software development technologies, and seek opportunities to improve processes.","C#, .NET, Python, Machine Learning, IoT, Big Data, AWS, Google Cloud, Azure, UML, Agile Methodologies, Lean Six Sigma",2,Bachelor,True,2.0,1,1,1,1,0,0,0,0,0,0,0,0,1,0,1,0,0
Senior Data Scientist,AdventInfotech,Guadalajara,ON-SITE,Mid-Senior level,Full-time,"IT Services and IT Consulting, IT System Data Services, and Software Development",2024-09-13 11:32:47.028901,25,Consulting,"Analyst,",Engineering,"Data Scientist: We are seeking a highly motivated and skilled Data Scientist to join our dynamic team. The Data Scientist will play a crucial role in turning complex data into actionable insights that drive business decisions and innovation. This position involves analyzing large datasets, developing models, and delivering strategic recommendations to enhance our products and services. Skills Requirements: Bachelor's or Master's degree in Data Science, Statistics, Computer Science, Mathematics, or a related field. 6plus years experience in data analysis, machine learning, and predictive modeling. Proficiency in programming languages such as Python or R. Strong knowledge of machine learning frameworks and libraries (e.g., TensorFlow, scikit-learn, PyTorch). Experience with data visualization tools (e.g., Tableau, Power BI, Matplotlib, Seaborn). Excellent problem-solving skills and attention to detail. Effective communication and presentation skills. Ability to work in a collaborative team environment and independently. Experience with big data technologies and platforms (e.g., Hadoop, Spark, SQL, NoSQL). Knowledge of natural language processing (NLP) and deep learning. Familiarity with cloud computing platforms (e.g., AWS, Azure, Google Cloud). Previous industry experience in a data scientist or analytics role. What do we expect from you? Masters or Bachelor in CIS/ Engineering / Science / Mathematics / Statistics/ Design …etc Should have Cedula /Titulo Should have hands-on years of experience in any one of the above technology Advance English Speaking Ability to work independently Competitive Salary NOTE: We sponsor TN visas for qualified Mexican citizens. If you are interested in pursuing this opportunity then forward an updated Word copy of your resume in English. Our company runs on referrals and your referrals are always appreciated. If you can forward these emails to any of your friends that would be great. About Advent Infotech: Advent Infotech is a multinational IT services company with offices in 7 countries, including Mexico. Our clients mainly come from the United States. Our head office is located in New Jersey, USA Our delivery centers are located in six countries: India, Indonesia, Australia, Poland, Canada, and Mexico. Advent is led by great leadership with more than twenty years in the business. Our directors are highly ethical and come with a Harvard Business School education, serial entrepreneurs, and angel investors with long-standing business ethics. Advent's motto has always been to provide profitable technology solutions for our clients while creating value for our clients.",https://mx.linkedin.com/jobs/view/senior-data-scientist-at-adventinfotech-4025686300,4025686300,"We are seeking a highly motivated and skilled Data Scientist to join our dynamic team. The Data Scientist will play a crucial role in turning complex data into actionable insights that drive business decisions and innovation. This position involves analyzing large datasets, developing models, and delivering strategic recommendations to enhance our products and services.","Python, R, TensorFlow, scikit-learn, PyTorch, Tableau, Power BI, Matplotlib, Seaborn, Hadoop, Spark, SQL, NoSQL, AWS, Azure, Google Cloud",6+,Bachelor,True,6.0,0,0,1,1,0,0,0,0,1,1,0,0,1,0,1,0,0
QA Machine Learning Engineer,C3 AI,Guadalajara,ON-SITE,Entry level,Full-time,Software Development,2024-09-15 11:32:47.028901,200,Engineering,Information Technology,,"C3.ai, Inc. (NYSE:AI) is a leading Enterprise AI software provider for accelerating digital transformation. The proven C3 AI Platform provides comprehensive services to build enterprise-scale AI applications more efficiently and cost-effectively than alternative approaches. The C3 AI Platform supports the value chain in any industry with prebuilt, configurable, high-value AI applications for reliability, fraud detection, sensor network health, supply network optimization, energy management, anti-money laundering, and customer engagement. Learn more at: C3 AI C3 AI is seeking for a QA Machine Learning Engineer to work with Platform Engineering, Product Development, QA, and Operations, to drive the software quality automation solutions for our existing Machine learning Infrastructure. You will be part of a team of highly skilled dedicated engineers to ensure that we are shipping the highest quality software possible. This is a great opportunity to work with cutting-edge artificial intelligence and machine learning technologies. Responsibilities Improve software tooling and operational procedures for standing-up, monitoring and troubleshooting the Model Inference Service. Take ownership of the operational aspects of such a service for internal use in C3 AI. Help disseminate operations knowledge to customers who wish to stand up the Model Inference Service. Write and maintain playbooks and runbooks for customer Site Reliability Engineers (SREs). Contribute to existing (or develop new) dashboards and tooling to monitor Quality-of-Service (QoS) of the Model Inference Service. Become a C3 AI Suite and C3 AI SaaS application expert to thoroughly understand all use case scenarios. Design and develop automated test suites for new C3 AI products and features. Automate and maintain test execution flow via Continuous Integration in Jenkins. Work with performance engineers to build automation for performance, scalability, and reliability tests. Perform analysis to identify root cause for defects identified during the release validation process. Qualifications Bachelor’s degree in a Science, Technology, Engineering or Math (STEM) field. Good understanding of software development lifecycle, and automation testing solutions. Advanced programming and troubleshooting skills. Clear understanding of Agile software development methodology. Outstanding team player with excellent interpersonal skills. Preferred Qualifications Strong understanding of common machine learning techniques, Python programming, and quality assurance methodologies. Proficiency with Linux command line tools, shell scripting, Node.js, Python, and JavaScript. Proficiency working with web applications and cloud deployments (AWS, Azure, GCP). Experience with container orchestration technologies (Kubernetes). Experience with cloud infrastructure technologies. Experience with logging and monitoring tools such as OpenSearch, Graphana, and Glowroot. Great verbal and written communication skills to collaborate multi-functionally. C3 AI provides a competitive compensation package and excellent benefits. Employee Testimonial - Juan Castaneda from C3 on Vimeo. C3 AI is proud to be an Equal Opportunity and Affirmative Action Employer. We do not discriminate on the basis of any legally protected characteristics, including disabled and veteran status.",https://mx.linkedin.com/jobs/view/qa-machine-learning-engineer-at-c3-ai-3853531535,3853531535,"C3 AI is seeking a QA Machine Learning Engineer to work with Platform Engineering, Product Development, QA, and Operations to drive software quality automation solutions for existing Machine Learning Infrastructure. Responsibilities include improving software tooling, taking ownership of operational aspects, writing and maintaining playbooks, contributing to dashboards and tooling, designing and developing automated test suites, and automating test execution flow via Continuous Integration. The role requires a good understanding of the software development lifecycle, automation testing solutions, and Agile methodologies.","Python, JavaScript, Node.js, Linux, AWS, Azure, GCP, Kubernetes, OpenSearch, Grafana, Glowroot, Jenkins",,Bachelor,True,,0,1,0,1,1,0,0,0,0,0,0,0,0,0,1,0,0
AI ML Engineer- Azure,Synechron,Guadalajara,ON-SITE,Mid-Senior level,Full-time,Financial Services and Investment Banking,2024-09-13 11:32:47.028901,25,Information Technology,,,"Our challenge We are seeking a skilled and motivated AI/ML Engineer with Azure to join our team. Candidate will collaborate, analyze, design, develop, test, maintain and implement premier software while working with cross-functional teams such as product and architecture. The Role Responsibilities: Experience in CMS as major subsystem and FAS or TRAMS as minor sub-Collaboration: Work closely with cross-functional teams, including IT, business, operations, and business stakeholders, to align AI support with objectives. Work with business users to understand their needs and document them using various tools Anticipate user needs and propose solutions and alternatives Understand functional and non-functional requirements Work with development teams in building and testing the solutions Maintain active communication channels with all stakeholders on deliverables and report status Track all outstanding issues and manage them from initiation to production deployment Ability to multitask and work with multiple teams Manage enhancement requests and production issues. Able to prioritize and allocate resources effectively Requirements: You are: Python and AI/ML Develop and deploy GenAI applications on Azure with focuses on: Azure OpenAI Azure Functions Azure Cosmos Azure Blob Storage Azure API Management Infrastructure as Code experience with Terraform with Azure CI/CD experiences with Jenkins Experience with Azure cloud, Python, Angular (applications are built today with azure cloud, using python & angular as backend & front end, and other azure services) Support in Regression Testing & Patch Releases for new & existing applications We can offer you: A highly competitive compensation and benefits package A multinational organization with 55 offices in 20 countries and the possibility to work abroad Laptop/equipment 12 days of paid annual leave (plus sick leave and national holidays) Maternity & Paternity leave plans A comprehensive insurance plan including: medical, dental, vision, and long-/short-term disability (plans vary by region) Retirement savings plans A higher education certification policy Extensive training opportunities, focused on skills, substantive knowledge, and personal development On-demand Udemy for Business for all Synechron employees with free access to more than 5000 curated courses Coaching opportunities with experienced colleagues from our Financial Innovation Labs (FinLabs) and Center of Excellences (CoE) groups Cutting edge projects at the world’s leading tier-one banks, financial institutions and insurance firms A flat and approachable organization A truly diverse, fun-loving and global work culture Saving funds plan for Mexico S​YNECHRON’S DIVERSITY & INCLUSION STATEMENT Diversity & Inclusion are fundamental to our culture, and Synechron is proud to be an equal opportunity workplace and is an affirmative action employer. Our Diversity, Equity, and Inclusion (DEI) initiative ‘Same Difference’ is committed to fostering an inclusive culture – promoting equality, diversity and an environment that is respectful to all. We strongly believe that a diverse workforce helps build stronger, successful businesses as a global company. We encourage applicants from across diverse backgrounds, race, ethnicities, religion, age, marital status, gender, sexual orientations, or disabilities to apply. We empower our global workforce by offering flexible workplace arrangements, mentoring, internal mobility, learning and development programs, and more. All employment decisions at Synechron are based on business needs, job requirements and individual qualifications, without regard to the applicant’s gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law.",https://mx.linkedin.com/jobs/view/ai-ml-engineer-azure-at-synechron-4014991273,4014991273,"We are seeking a skilled and motivated AI/ML Engineer with Azure to develop, test, maintain, and implement software while collaborating with cross-functional teams. The role involves understanding user needs, proposing solutions, and managing enhancement requests. Responsibilities include developing and deploying GenAI applications on Azure with a focus on Azure OpenAI, Azure Functions, Azure Cosmos, Azure Blob Storage, and Azure API Management, and utilizing Infrastructure as Code with Terraform and CI/CD with Jenkins.","Python, Azure, AI, ML, Azure OpenAI, Azure Functions, Azure Cosmos, Azure Blob Storage, Azure API Management, Terraform, Jenkins, Angular",,,True,,0,0,0,1,0,0,0,0,0,0,1,1,0,0,1,0,0
Senior Data Scientist - Support Global Supply Chain,AstraZeneca,Guadalajara,ON-SITE,Associate,Full-time,Pharmaceutical Manufacturing,2024-09-01 11:32:47.028901,165,Engineering,Information Technology,,"Sr. Data Scientist 📌Positions are open to Mexican Citizens and official residents of Mexico. 📍Location: Guadalajara (hybrid) 📌Strong English Communication Skills Required. Join our diverse team , where we ensure our partners have access to the data, insights, and innovations required to deliver against our Supply Chain Digital Strategy. We are seeking Data Scientists who can help advance the field within the Supply Chain Organization and deliver substantial solutions that strive to solve our biggest challenges. This is your chance to thrive with standardised ways of working driven by Lean. Embrace our standardised approach to drive efficiencies through our processes and focus us on the essentials. Accountabilities: As a Sr. Data Scientist, you will lead analytics projects and work with our Supply Chain Customers to take on significant challenges, resulting in breakthroughs in understanding our business and driving results, impacting Customer Service, Efficiency, Cost, and Sustainability. You will advance the development of internal capability for Data Science within supply chain, including Artificial Intelligence (AI), and Machine Learning (ML). You will play a significant role in crafting the future of analytics in the supply chain organization. You will engage with key stakeholders in operations and IT to advance the quality of analysis and data science capabilities. Essential Skills/Experience: - 8+ yr. proven experience in Statistical Modeling, Machine Learning, Data Mining, Unstructured Data Analytics, incorporate and/or Academic Research environments- 8+ yr. experience with Data Science tools, including Dataiku, SAS, AWS Sagemaker, and Machine Learning methods (Clustering, Regression, Optimization, Recommendation, Neural Networks) Desirable experience in Supply Chain Projects (Demand planning & forecasting Inventory Optimization, Logistics, Network Design, Segmentation, and S&OP) Bachelor's degree in Applied Mathematics, Computer Science, Physics, Economics, Engineering, Statistics, Operations Research, Quantitative Social Science, etc.) Desirable Skills/Experience: Master’s degree in a quantitative field, Engineering, Computer Science, Physics, Applied Mathematics, Statistics, Economics or related field. When we put unexpected teams in the same room, we unleash bold thinking with the power to inspire life-changing medicines. In-person working gives us the platform we need to connect, work at pace and challenge perceptions. That’s why we work, on average, a minimum of three days per week from the office. But that doesn't mean we’re not flexible. We balance the expectation of being in the office while respecting individual flexibility. Join us in our outstanding and ambitious world. Why AstraZeneca? With constant new products and launches, there's never been a better time to join Supply Chain and craft our future with a big contribution to life-changing medicines. Our resilience helps us to thrive as we innovate and evolve. Ours is a safe and positive space where ideas are encouraged and rewarded. As part of an agile team it's crucial we speak up to offer innovative approaches for process improvements and faster execution. It's our patient focus that drives us. If you want to make a big impact, this is the place for you. Our contribution to life changing medicines is why people have been here for decades. We do it for the patients. Are you ready to join our team and make a difference? Apply now and let's craft the future together!",https://mx.linkedin.com/jobs/view/senior-data-scientist-support-global-supply-chain-at-astrazeneca-3920041308,3920041308,"Join our diverse team as a Senior Data Scientist to lead analytics projects within the Supply Chain Organization, implementing substantial solutions to improve customer service, efficiency, cost, and sustainability. You will develop internal data science capabilities, applying artificial intelligence (AI) and machine learning (ML) techniques while engaging with key stakeholders to enhance analysis quality.","Statistical Modeling, Machine Learning, Data Mining, Unstructured Data Analytics, Dataiku, SAS, AWS Sagemaker, Clustering, Regression, Optimization, Recommendation, Neural Networks",8+ years,Bachelor,True,8.0,0,0,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0
"Sr. Applied Scientist, Devices, Device Science and Data Technology",myGwork - LGBTQ+ Business Community,Guadalajara,ON-SITE,Entry level,Full-time,"Technology, Information and Internet",2024-09-08 11:32:47.028901,25,Research,"Analyst,",Information Technology,"This job is with Amazon, an inclusive employer and a member of myGwork – the largest global platform for the LGBTQ+ business community. Please do not contact the recruiter directly. Description The Amazon Devices team designs and engineers high-profile consumer electronics, including the best-selling Kindle family of products. We have also produced groundbreaking devices like Fire tablets, Fire TV, Amazon Dash, and Amazon Echo. What will you help us create? The Team: How often have you had an opportunity to be a founding member of a team that is solving a significant problem through innovative technology? Would you like to know more about how we are envisioning the use of machine learning and GenAI to solve these problems? If this sounds intriguing, then we'd like to talk to you about a role on our team that's tackling a set of problems requiring significant innovation and scaling. As a Sr. Applied Scientist, you will design, evangelize, and implement state-of-the-art solutions for never-before-solved problems, helping Amazon Device to provide customer great products. This role will be a key member of a Science and Data technology team based in Guadalajara, Mexico. You will work closely with other scientists, machine learning experts, engineers to design and run experiments, research new algorithms, and find new ways to improve Amazon Device Services & Software products. You will partner with technology and product leaders to solve business and technology problems using scientific approaches to build new services that surprise and delight our customers. Our scientists work closely with software engineers to put algorithms into practice. They also work on cross-disciplinary efforts with other scientists within Amazon. The Key Responsibility For This Role Include Define proper output business Metrics, and build input models to identify patterns and drivers of the output. Drive actions at scale using scientifically-based methods and decision making. Design and develop complex mathematical, statistical, Machine Learning, GenAI models and apply them to define strategic and tactical needs and drive the appropriate business and technical solutions Design experiments, test hypotheses, and build actionable models Prototype these models by using modeling languages such as R or in software languages such as Python. Work with software engineering teams to drive scalable, real-time implementations Utilizing Amazon systems and tools to effectively work with terabytes of data We are open to hiring candidates to work out of one of the following locations: Zapopan, MEX Basic Qualifications 5+ years of building machine learning models for business application experience PhD, or Master's degree and 6+ years of applied research experience Experience programming in Java, C++, Python or related language Experience with neural deep learning methods and machine learning Preferred Qualifications Experience with modeling tools such as R, scikit-learn, Spark MLLib, MxNet, Tensorflow, numpy, scipy etc. Experience with large scale distributed systems such as Hadoop, Spark etc.",https://mx.linkedin.com/jobs/view/sr-applied-scientist-devices-device-science-and-data-technology-at-mygwork-lgbtq%2B-business-community-4018420774,4018420774,"As a Sr. Applied Scientist, you will design, evangelize, and implement state-of-the-art solutions for innovative problems, working closely with other scientists and engineers to run experiments, research new algorithms, and improve Amazon Device Services & Software products. You will define business metrics, build input models, design and develop complex mathematical models, and drive scalable implementations using Amazon systems and tools.","Python, R, Java, C++, scikit-learn, Spark MLLib, MxNet, Tensorflow, numpy, scipy, Hadoop, Machine Learning, GenAI",5+ years,Masters,True,5.0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,1,0,0
"Sr. Applied Scientist, Amazon Devices, Device Science and Data Technology",Amazon,Guadalajara,ON-SITE,Mid-Senior level,Full-time,Software Development,2024-09-01 11:32:47.028901,58,Research,"Science,",Engineering,"Description The Amazon Devices team designs and engineers high-profile consumer electronics, including the best-selling Kindle family of products. We have also produced groundbreaking devices like Fire tablets, Fire TV, Amazon Dash, and Amazon Echo. What will you help us create? The Team: How often have you had an opportunity to be a founding member of a team that is solving a significant problem through innovative technology? Would you like to know more about how we are envisioning the use of machine learning and GenAI to solve these problems? If this sounds intriguing, then we’d like to talk to you about a role on our team that's tackling a set of problems requiring significant innovation and scaling. As a Sr. Applied Scientist, you will design, evangelize, and implement state-of-the-art solutions for never-before-solved problems, helping Amazon Device to provide customer great products. This role will be a key member of a Science and Data technology team based in Guadalajara, Mexico. You will work closely with other scientists, machine learning experts, engineers to design and run experiments, research new algorithms, and find new ways to improve Amazon Device Services & Software products. You will partner with technology and product leaders to solve business and technology problems using scientific approaches to build new services that surprise and delight our customers. Our scientists work closely with software engineers to put algorithms into practice. They also work on cross-disciplinary efforts with other scientists within Amazon. The Key Responsibility For This Role Include Define proper output business Metrics, and build input models to identify patterns and drivers of the output. Drive actions at scale using scientifically-based methods and decision making. Design and develop complex mathematical, statistical, Machine Learning, GenAI models and apply them to define strategic and tactical needs and drive the appropriate business and technical solutions Design experiments, test hypotheses, and build actionable models Prototype these models by using modeling languages such as R or in software languages such as Python. Work with software engineering teams to drive scalable, real-time implementations Utilizing Amazon systems and tools to effectively work with terabytes of data We are open to hiring candidates to work out of one of the following locations: Zapopan, MEX Basic Qualifications 5+ years of building machine learning models for business application experience PhD, or Master's degree and 6+ years of applied research experience Experience programming in Java, C++, Python or related language Experience with neural deep learning methods and machine learning Preferred Qualifications Experience with modeling tools such as R, scikit-learn, Spark MLLib, MxNet, Tensorflow, numpy, scipy etc. Experience with large scale distributed systems such as Hadoop, Spark etc. Company - Servicios Comerciales Amazon Mexico S. de R.L. de C.V. Job ID: A2641396",https://mx.linkedin.com/jobs/view/sr-applied-scientist-amazon-devices-device-science-and-data-technology-at-amazon-3924984506,3924984506,"As a Sr. Applied Scientist, you will design, evangelize, and implement state-of-the-art solutions for complex problems, helping Amazon Devices provide great products. You will work closely with scientists, machine learning experts, and engineers to design and run experiments, research new algorithms, and improve services and software products. Your responsibilities will include defining business metrics, building input models, driving actions using scientific methods, designing experiments, and prototyping models using various programming languages.","Python, Java, C++, R, scikit-learn, Spark MLLib, MxNet, TensorFlow, numpy, scipy, Hadoop, Spark",5+ years,Masters,True,5.0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,1,0,0
"Data Engineer, Science & Data Technology team",Amazon,Guadalajara,ON-SITE,,Full-time,Software Development,2024-09-13 11:32:47.028901,196,Strategy/Planning,"Analyst,",Information Technology,"Description The Amazon Devices team designs and engineers high-profile consumer electronics, including the best-selling Kindle family of products. We have also produced groundbreaking devices like Fire tablets, Fire TV, Amazon Dash, and Amazon Echo. What will you help us create? The Team: How often have you had an opportunity to be a founding member of a team that is solving a significant problem through innovative technology? Would you like to know more about how we are envisioning the use of data analytics, machine learning, AI and linear programming to solve these problems? If this sounds intriguing, then we’d like to talk to you about a role on a new Amazon team that's tackling a set of problems requiring significant innovation and scaling. We are seeking a Data Engineer with strong analytical, communication and project management skills to join our team. This role will be a key member of a Science and Data technology team based in Guadalajara,MX. Working closely with business stakeholders, software development engineers and scientist colleagues, you will design, evangelize, and implement state-of-the-art solutions for never-before-solved problems, helping Amazon Device to provide customer great products and keep the data secure. You will work with the most complicated data environment, employ right architecture to handle big data and support various analytics use cases, including business reporting, production data pipeline, machine learning, optimization models, statistical models, simulation, etc. Your work will have a direct impact on the day-to-day decision making in the Amazon Devices Sales & Operations Technology, and end customers. You are an individual with outstanding analytical abilities, excellent communication skills, good business understanding, and technically savvy. The successful candidate will be an analytical problem solver who enjoys diving into data, is excited about solving ambiguity problems, can multi-task, and can credibly interface between technical teams and business stakeholders. We are open to hiring candidates to work out of one of the following locations: Zapopan, MEX Basic Qualifications 3+ years of data engineering experience Experience with data modeling, warehousing and building ETL pipelines Preferred Qualifications Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases) Company - Servicios Comerciales Amazon Mexico S. de R.L. de C.V. - D44 Job ID: A2564109",https://mx.linkedin.com/jobs/view/data-engineer-science-data-technology-team-at-amazon-3877282509,3877282509,"We are seeking a Data Engineer with strong analytical, communication, and project management skills to join our team. You will design, evangelize, and implement state-of-the-art solutions for complex problems, helping Amazon Device provide great products and keep the data secure. You will work with a complicated data environment, employing the right architecture to handle big data and support various analytics use cases, including business reporting, production data pipelines, machine learning, optimization models, statistical models, and simulation. Your work will impact the decision-making in Amazon Devices Sales & Operations Technology and end customers.","AWS Redshift, AWS S3, AWS Glue, AWS EMR, AWS Kinesis, AWS FireHose, AWS Lambda, Data Modeling, ETL Pipelines, Non-relational Databases",3+ years,,True,3.0,0,0,1,1,0,1,1,1,0,1,0,0,0,0,0,0,0
Big Data Engineer,Infosys,Guadalajara,ON-SITE,Entry level,Full-time,IT Services and IT Consulting,2024-09-01 11:32:47.028901,25,Engineering,Information Technology,,"Job Description Looking for a BigData Eng At least 1 year of experience in Big Data projects, with experience in Hadoop -Spark/Scala Must have experience in AWS Experience with Python Good English communication skills Can be located in MTY, CDMX or GDL About Us Infosys is a global leader in next-generation digital services and consulting. We enable clients in more than 50 countries to navigate their digital transformation. With over four decades of experience in managing the systems and workings of global enterprises, we expertly steer our clients through their digital journey. We do it by enabling the enterprise with an AI-powered core that helps prioritize the execution of change. We also empower the business with agile digital at scale to deliver unprecedented levels of performance and customer delight. Our always-on learning agenda drives their continuous improvement through building and transferring digital skills, expertise, and ideas from our innovation ecosystem.",https://mx.linkedin.com/jobs/view/big-data-engineer-at-infosys-4012245318,4012245318,"Looking for a Big Data Engineer with at least 1 year of experience in Big Data projects, with experience in Hadoop and Spark/Scala. Must have experience in AWS and proficiency in Python. Good English communication skills are required.","Hadoop, Spark, Scala, AWS, Python",1,,True,1.0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,1,0,0
"Data Engineer, Science & Data Technology team",myGwork - LGBTQ+ Business Community,Guadalajara,ON-SITE,Entry level,Full-time,"Technology, Information and Internet",2024-09-08 11:32:47.028901,25,Information Technology,,,"This job is with Amazon, an inclusive employer and a member of myGwork – the largest global platform for the LGBTQ+ business community. Please do not contact the recruiter directly. Description The Amazon Devices team designs and engineers high-profile consumer electronics, including the best-selling Kindle family of products. We have also produced groundbreaking devices like Fire tablets, Fire TV, Amazon Dash, and Amazon Echo. What will you help us create? The Team: How often have you had an opportunity to be a founding member of a team that is solving a significant problem through innovative technology? Would you like to know more about how we are envisioning the use of data analytics, machine learning, AI and linear programming to solve these problems? If this sounds intriguing, then we'd like to talk to you about a role on a new Amazon team that's tackling a set of problems requiring significant innovation and scaling. We are seeking a Data Engineer with strong analytical, communication and project management skills to join our team. This role will be a key member of a Science and Data technology team based in Guadalajara,MX. Working closely with business stakeholders, software development engineers and scientist colleagues, you will design, evangelize, and implement state-of-the-art solutions for never-before-solved problems, helping Amazon Device to provide customer great products and keep the data secure. You will work with the most complicated data environment, employ right architecture to handle big data and support various analytics use cases, including business reporting, production data pipeline, machine learning, optimization models, statistical models, simulation, etc. Your work will have a direct impact on the day-to-day decision making in the Amazon Devices Sales & Operations Technology, and end customers. You are an individual with outstanding analytical abilities, excellent communication skills, good business understanding, and technically savvy. The successful candidate will be an analytical problem solver who enjoys diving into data, is excited about solving ambiguity problems, can multi-task, and can credibly interface between technical teams and business stakeholders. We are open to hiring candidates to work out of one of the following locations: Zapopan, MEX Basic Qualifications 3+ years of data engineering experience Experience with data modeling, warehousing and building ETL pipelines Preferred Qualifications Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases)",https://mx.linkedin.com/jobs/view/data-engineer-science-data-technology-team-at-mygwork-lgbtq%2B-business-community-4018426579,4018426579,"We are seeking a Data Engineer with strong analytical, communication, and project management skills to join a Science and Data technology team. You will design, implement state-of-the-art solutions for complex problems, helping Amazon Devices to provide great products and keep data secure. Your work will involve handling big data and supporting various analytics use cases, including machine learning, optimization models, and business reporting.","AWS Redshift, AWS S3, AWS Glue, AWS EMR, AWS Kinesis, AWS FireHose, AWS Lambda, non-relational databases, data modeling, ETL pipelines",3+ years,,True,3.0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0
Data Cloud Engineer,DB Schenker,Guadalajara,ON-SITE,Entry level,Full-time,"Transportation, Logistics, Supply Chain and Storage",2024-09-12 11:32:47.028901,25,Engineering,Information Technology,,"At DB Schenker, you are part of a global logistics network that connects the world. A network that allows you to shape your career by encouraging you to contribute and truly make a difference. With more than 76,000 colleagues worldwide, we welcome diversity and thrive on individual backgrounds, perspectives, and skills. Together as one team, we are Here to move. Job Overview At Schenker International S.A. de C.V. we are looking for a Data Cloud Engineer to be part of our IT team, for our office in Guadalajara, Mexico. This role contributes to turning DB Schenker into a data-driven company. Our Data Engineering team focuses on designing advanced analytics solutions to solve potential business use cases in logistics using Machine Learning, AI techniques, Data Visualization tools and Big Data technologies in cooperation with our Software Engineering team, internal business units and global IT. We are looking for a talented Data Engineer who can contribute to our projects with solid data intuition, hands-on problem-solving skills, engineering mindset and eagerness to learn about our logistics business data. What will be your challenges? Analyze data and design, code, test, debug, automate, document, and maintain data solutions Support building, improving, and maintaining a cloud native data lake platform Integrate machine learning and operations research solutions into the DB Schenker system landscape Support and interact with data scientist, operations research specialists and business consultants in all their data-related activities What you need to succeed? Experience working with distributed computing tools especially Spark using Databricks and streaming technologies (Kafka, Spark Structured Streaming, etc.) Knowledge of cloud platforms (ideally Azure, alternatively AWS or GCP) and respective Data and Machine Learning related service associated models Fluency in at least one programming language such as Python or Scala Experience with relational databases (Oracle, PostgreSQL) and good knowledge of SQL Fluency in POSIX systems (e.g., Linux, MacOS X) and the command-line terminal Experience with orchestration / data pipelining tools like Argo, Azure Data Factory, Airflow etc. Experience in delivering software and of the software development life cycle: source code repositories (Git) and versioning/branching/peer reviewing, continuous integration (e.g., GitLab CI, Azure DevOps), deployment/release (e.g., artifact building and repositories), maintenance Competences Proficient English skills in reading, writing and speaking for clear communication with global teams Customer and service orientation Ability to work effectively across diverse organizations, groups and functions Flexible thinker able to operate in a changing environment Why you will love DB Schenker Many of our jobs come with great benefits and career path opportunities: Generous and additional vacation and yearly bonus schemes Financial savings and various insurance options Grocery & restaurant vouchers Flexible & hybrid working models Global & multicultural environment: Collaborate with colleagues all around the world. Language courses Mentorship, career program & development opportunities Learning & education programs Mental health & support initiatives How To Get Started You can begin by applying above or visit us at https://dbschenker.com/global/careers Stay Connected With Us Web Page: http://www.dbschenker.com DB Schenker is committed to a diverse and inclusive workplace. DB Schenker is an equal opportunity employer and does not discriminate based on race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.",https://mx.linkedin.com/jobs/view/data-cloud-engineer-at-db-schenker-4022966273,4022966273,"We are looking for a Data Cloud Engineer to contribute to turning DB Schenker into a data-driven company by designing advanced analytics solutions in logistics using Machine Learning, AI, Data Visualization tools, and Big Data technologies. The role involves analyzing data, designing and maintaining data solutions, integrating machine learning into systems, and supporting data-related activities with various specialists.","Python, Scala, SQL, Oracle, PostgreSQL, Spark, Databricks, Kafka, Azure, AWS, GCP, Linux, MacOS X, Argo, Azure Data Factory, Airflow, Git, GitLab CI, Azure DevOps",,,True,,0,0,1,1,0,0,0,0,0,1,0,1,0,0,1,0,0
AWS Data Engineer,Cognizant,Guadalajara,ON-SITE,Entry level,Full-time,IT Services and IT Consulting,2024-08-16 11:32:47.028901,25,Information Technology,,,"Cognizant is always looking for top talent. We are searching for candidates to fill future needs within the business. This job posting represents potential future employment opportunities with Cognizant. Although the position is not currently available, we want to provide you with the opportunity to express your interest in future employment opportunities with Cognizant. If a job opportunity that you may be qualified for becomes available in the future, we will notify you. At that time you can determine whether you would like to apply for the specific open position. Thank you for your interest in Cognizant career opportunities. We’re hiring! At Cognizant we have an ideal opportunity for you to be part of one of the largest companies in the digital sector worldwide. A Great Place To Work where we look for people who contribute new ideas, experiencing a dynamic and growing environment. At Cognizant we promote an inclusive culture, where we value different perspectives providing career growth and development opportunities. #WelcomeToCognizant! We have an exciting opportunity for an exceptional individual to work supporting one of our clients as AWS Data Engineer What you’ll do: Data Extraction from On-Prem Hadoop system and Ingestion to AWS S3. Tech stack -AWS CLI. Data Validation, Compression and Processing. Tech stack – AWS Lambda, Glue. Orchestration of the end-to-end pipeline for Machine Learning Models (Train/Score). Tech stack – Step Function, SageMaker, Lambda, ECR. Creating partitioned tables and maintaining ML model output data in the tables. Tech stack – Athena, Redshift Spectrum, Glue. Creating and Maintaining Data warehouse solutions for Analytical Model Output and Intermediate Files. Tech stack – Redshift. Loading Incremental/Full Data to Quicksight for Visualization. Tech stack - Lambda. Building the Interactive Reporting Dashboards in AWS. Tech stack – Quicksight. Implementation of Error Handling and Logging mechanism. Tech stack – CloudWatch, SNS. Part of various phases such as Requirements Gathering, Software development, unit & integration testing, deployment preparation, Go-Live phase involve in Project handover and post implementation support. Preferred experience: Amazon Web Services: S3, Lambda, Glue, Redshift, Athena, Step Function, SNS. Programming Languages: Python. Collaboration Tools: Jira, Confluence. Why Cognizant? Improve your career in one of the largest and fastest growing IT services providers worldwide Receive ongoing support and funding with training and development plans Have a highly competitive benefits and salary package Get the opportunity to work for leading global companies We are committed to respecting human rights and build a better future by helping your minds and the environment We invest in people and their wellbeing. We create conditions for everyone to thrive. We do not discriminate based on race, religion, color, sex, age, disability, nationality, sexual orientation, gender identity or expression, or for any other reason covered. At Cognizant we believe than our culture make us stronger! Join us now! #BeCognizant #IntuitionEngineered Employee Status : Full Time Employee Shift : Day Job Job Posting : Jan 03 2024 About Cognizant Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @Cognizant. 43483",https://mx.linkedin.com/jobs/view/aws-data-engineer-at-cognizant-4006646151,4006646151,"We have an exciting opportunity for an exceptional individual to work supporting one of our clients as an AWS Data Engineer. Responsibilities include data extraction from an on-prem Hadoop system and ingestion to AWS S3, data validation, compression, processing, and the orchestration of end-to-end pipelines for machine learning models. This role involves creating and maintaining data warehouse solutions for analytical model output and intermediate files, loading data to Quicksight for visualization, building interactive reporting dashboards, and implementing error handling and logging mechanisms.","AWS S3, AWS Lambda, AWS Glue, AWS Redshift, AWS Athena, AWS Step Function, AWS SNS, Python, Jira, Confluence, AWS Quicksight, AWS CloudWatch",,,True,,0,0,1,1,0,0,0,0,0,0,0,0,0,0,1,0,0
Data Engineer,In All Media,Guadalajara,ON-SITE,Entry level,Full-time,Information Technology & Services,2024-05-18 11:32:47.028901,25,Information Technology,,,"Data Analyst Engineer The objective of this project and role is to focus on delivering the solution your business partners need to grow the business, e.g. an application, an API, a rules engine, or a Data Pipeline. You know what it takes to deliver the best possible, within the given deadline Deliverables Tool called conversion, delivering recommendations on this tool , solving technical debt updates and maintaining add net new recommendations, we can directly measure these recommendations by count and impact (example - how many more features were adopted) CS - simplify data on active points and deliver the best recommendations, more net new Requirements Technologies Backend * Python * Flask * SQLAlchemy * PyMySQL * MongoDB * Internal SOA libraries * Healthcheck tools * Tracing tools DevOps * GitLab CI/CD * Docker * Kubernetes * AWS We're seeking a talented Software Engineer Level 2 to join our dynamic team responsible for developing a suite of innovative tools. These tools are essential in automating and streamlining communication processes with our clients. If you are passionate about solving complex problems and improving user experiences, we want you on our team.",https://mx.linkedin.com/jobs/view/data-engineer-at-in-all-media-3933079737,3933079737,"The objective of this role is to deliver solutions needed to grow the business, such as applications, APIs, and data pipelines. This includes simplifying data on active points and delivering measurable recommendations based on their impact.","Python, Flask, SQLAlchemy, PyMySQL, MongoDB, GitLab CI/CD, Docker, Kubernetes, AWS",,,True,,0,1,0,1,1,0,0,0,0,1,0,1,0,0,1,0,0
Data Engineer,Cognizant,Guadalajara,ON-SITE,Entry level,Full-time,IT Services and IT Consulting,2024-08-16 11:32:47.028901,25,Information Technology,,,"Cognizant is always looking for top talent. We are searching for candidates to fill future needs within the business. This job posting represents potential future employment opportunities with Cognizant. Although the position is not currently available, we want to provide you with the opportunity to express your interest in future employment opportunities with Cognizant. If a job opportunity that you may be qualified for becomes available in the future, we will notify you. At that time you can determine whether you would like to apply for the specific open position. Thank you for your interest in Cognizant career opportunities. We’re hiring! At Cognizant we have an ideal opportunity for you to be part of one of the largest companies in the digital sector worldwide. A Great Place To Work where we look for people who contribute new ideas, experiencing a dynamic and growing environment. At Cognizant we promote an inclusive culture, where we value different perspectives providing career growth and development opportunities. #WelcomeToCognizant! We have an exciting opportunity for an exceptional individual to work supporting one of our clients as Data Engineer What you’ll do: Responsibilities: Develop and operate the data processing platform and analytical platforms Develop new functionalities in current pipelines of data Find anomalies in current reports and existing databases Understand requirements to create new ETLs Monitor current processes and troubleshoot any possible failure Build data pipelines to support development, verification/validation and monitoring models Qualifications: Bachelor's degree in Computer Science or related technical field, or equivalent practical experience 5+ years' experience as Data Engineer working with ETL projects with SQL and Scala/PySpark Hands on experience in development & optimization of data pipelines Solid SQL skills and understanding of Data Partitioning SQL Queries and Calculations Transformations and aggregations Understanding of structure and semi-structure data sources Good understanding of control version systems (Git, etc) Unit testing skills Experience working within SCRUM methodology and/or Kanban Self-motivated, proactive, adaptable, with teamwork and learning skills Excellent analytical, written and verbal communication skills (skills) Why Cognizant? Improve your career in one of the largest and fastest growing IT services providers worldwide Receive ongoing support and funding with training and development plans Have a highly competitive benefits and salary package Get the opportunity to work for leading global companies We are committed to respecting human rights and build a better future by helping your minds and the environment We invest in people and their wellbeing. We create conditions for everyone to thrive. We do not discriminate based on race, religion, color, sex, age, disability, nationality, sexual orientation, gender identity or expression, or for any other reason covered. At Cognizant we believe than our culture make us stronger! Join us now! #BeCognizant #IntuitionEngineered Igualdad de Empleo y Política de Acción Afirmativa: Cognizant es un empleador que ofrece igualdad de oportunidades. Todos los solicitantes calificados recibirán consideración para el empleo sin distinción de sexo, identidad de género, orientación sexual, raza, color, religión, origen nacional, discapacidad, estado de veterano protegido, edad o cualquier otra característica protegida por la ley. Employee Status : Full Time Employee Shift : Day Job Job Posting : Jan 03 2024 About Cognizant Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @Cognizant. 43441",https://mx.linkedin.com/jobs/view/data-engineer-at-cognizant-4017704396,4017704396,"We have an exciting opportunity for an exceptional individual to work supporting one of our clients as a Data Engineer. Responsibilities include developing and operating the data processing platform, finding anomalies in current reports and databases, understanding requirements to create new ETLs, monitoring processes, and troubleshooting failures. Qualifications include a Bachelor's degree in Computer Science or related technical field, with 5+ years' experience as a Data Engineer working with ETL projects using SQL and Scala/PySpark, solid SQL skills, and experience with control version systems and SCRUM methodology.","SQL, Scala, PySpark, ETL, Git, SCRUM, Kanban",5+ years,Bachelor,True,5.0,1,0,1,0,0,0,1,0,0,1,0,1,0,0,0,0,0
Data & Advanced Process Analytics Engineer,AstraZeneca,Guadalajara,ON-SITE,Associate,Full-time,Pharmaceutical Manufacturing,2024-09-13 11:32:47.028901,25,Information Technology,,,"AstraZeneca is a global, science-led, patient-focused pharmaceutical company that focuses on the discovery, development, and commercialization of prescription medicines for some of the world’s most serious diseases. But we’re more than one of the world’s leading pharmaceutical companies. As a high-performing team, we are united and motivated by our shared purpose – to push the boundaries of science to deliver life-changing medicines. We come to work each day to make a difference – to patients, society, and our company. Here you will experience a fast paced and agile environment as we continue to support the business on a journey of evolution and growth, driven by new, exciting technology and digital innovations. It’s challenging and sometimes demanding, and that’s why we love it. About The Role Join the Process Mining COE within Global Business Services (GBS) at AstraZeneca, a team that has established itself as a pivotal advanced analytics capability. We unlock processing capacity and value through automated process discovery, analytics, and automated decision-support workflows. We are looking for a Process Mining Consultant to join the Process Mining team as we scale the capability and deliver Process Mining (Celonis) solutions across AstraZeneca. Main duties and responsibilities Working alongside the Senior Managers within the Process Mining team, the role will be responsible for the following activities: Work closely with stakeholders to help answer key business questions about the process Identify required data sources and set up data acquisition pipelines to the process mining platform Develop custom process models using process mining techniques Leverage both regular business intelligence dashboard reporting and more sophisticated programmatic techniques to deliver process insights to stakeholders Build automated workflows to facilitate pro-active process interventions Essential Requirements 3-8 years of hands-on experience in Data Engineering, Analytics, or Process Mining projects. Hands-on experience in a Process Mining Tool: Celonis (or similar: UiPath, QPR, Minit, Signavio etc.) will be a strong advantage Fluency with relational databases using SQL queries Experience in producing data visualisations to communicate process data effectively in a data visualisation tool Analytical skills to be able to discover, analyse and draw insight from complex data sets Knowledge of at least 1 functional area processes (Finance, HR etc.) and related Source System datasets is nice to have Excellent communication skills to work with stakeholders daily Energetic, organised and self-motivated Experience with source code version control and issue tracking (Bitbucket, JIRA, Confluence) Python programming skills appreciated Nice to Know: Experience with Databricks appreciated. If you're interested in delivering real business value through data-driven process optimization, we'd love to hear from you. This role offers the opportunity to directly impact AstraZeneca's operational efficiency and bottom line through innovative process mining solutions. Education Requirements: Degree in Computer Science, Business Informatics or a comparable degree Why AstraZeneca? At AstraZeneca when we see an opportunity for change, we seize it and make it happen, because any opportunity no matter how small, can be the start of something big. Delivering life-changing medicines is about being entrepreneurial - finding those moments and recognising their potential. Join us on our journey of building a new kind of organisation to reset expectations of what a bio-pharmaceutical company can be. This means we’re opening new ways to work, pioneering cutting edge methods and bringing unexpected teams together. So, what’s next! Are you already imagining yourself joining our team? Good, because we can’t wait to hear from you. Where can I find out more? Follow AstraZeneca on LinkedIn https://www.linkedin.com/company/1603/ Follow AstraZeneca on Facebook https://www.facebook.com/astrazenecacareers/ Follow AstraZeneca on Instagram https://www.instagram.com/astrazeneca_careers/?hl=en AstraZeneca is an equal opportunity employer. AstraZeneca will consider all qualified applicants for employment without discrimination on grounds of disability, sex or sexual orientation, pregnancy or maternity leave status, race or national or ethnic origin, age, religion or belief, gender identity or re-assignment, marital or civil partnership status, protected veteran status (if applicable) or any other characteristic protected by law. AstraZeneca only employs individuals with the right to work in the country/ies where the role is advertised. 📌Strong English Communication Skills Required. 📌 Positions are open to Mexican Citizens and official residents of Mexico. 📍 Location: Guadalajara (hybrid - Expectation of working in the office 3 days a week) When we put unexpected teams in the same room, we unleash bold thinking with the power to inspire life-changing medicines. In-person working give us the platform we need to connect, work at pace and challenge perceptions. That’s why we w",https://mx.linkedin.com/jobs/view/data-advanced-process-analytics-engineer-at-astrazeneca-4007362296,4007362296,"Join the Process Mining COE within Global Business Services at AstraZeneca as a Process Mining Consultant. The role involves working with stakeholders to answer key business questions, identifying data sources, setting up data acquisition pipelines for process mining, and developing custom process models. Responsibilities include delivering insights through business intelligence dashboards, building automated workflows for proactive interventions, and producing visualizations of complex data sets.","Celonis, Python, SQL, Bitbucket, JIRA, Confluence, Databricks",3-8 years,,True,3.0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,1,0,0
Data Engineer - AWS/ETL/Python,IBM,Guadalajara,ON-SITE,,Full-time,IT Services and IT Consulting,2024-09-08 11:32:47.028901,35,Other,,,"Introduction At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk. Your Role and Responsibilities Day-to-day troubleshooting of forecasting systems, mainly working through data anomalies that cause inaccurate forecasts or prevent forecasts' generation. Collaborate with the data science team to enhance existing forecasting systems for the trade floors. Create dynamic object-oriented methods, full stack solutions, and integrations to existing code solutions. Develop individual Python classes, methods, functions that support the data flow of existing and new projects. Work on code additions to seamlessly support projects for data flows, including logging and support, with little to no supervision. Experience in modifying packages, testing, and repository instances to support CI/CD. Required Technical and Professional Expertise Design, develop, test, and deploy Python applications on AWS, ensuring high availability, scalability, and security Develop and maintain technical documentation for Python applications and AWS infrastructure Optimize application performance, scalability, and reliability using AWS services such as: Serverless technologies (Lambda, API Gateway, Step Functions) S3 for data storage and retrieval Glue for data integration and ETL SQS and SNS for message queuing and notification Cognito for user authentication and authorization CloudWatch for monitoring and logging Preferred Technical And Professional Expertise Implement automated testing, deployment, and monitoring using tools like Jenkins, Docker, and CloudWatch Troubleshoot and resolve technical issues in Python applications and AWS infrastructure Stay up-to-date with the latest developments in Python and AWS, and apply this knowledge to improve our applications and infrastructure Design and develop Serverless front-end applications using AWS services such as API Gateway, Lambda, and S3 Implement PDS Proxy to handle data processing and analytics workloads Integrate AWS services with external systems and APIs using APIs, SDKs, and other integration tools Implement Row Level Security (RLS) to segregate data and ensure secure access to sensitive information Design and implement data models and database schemas for DynamoDB and PostgreSQL Design and develop data ingestion pipelines using AWS Lambda, Glue, AWS Batch and restful API’s Thorough understanding of AWS cloud concepts and related technologies like AWS VPC, Subnets, AZ’s, SG, IAM policies & Roles, EC2, AWS ALB, API Gateway, ECS, RDS, AWS MSK, Kinesis, SQS, SNS, S3, DynamoDB, Secret Manager, Cloud Watch, Cloud Formation scrips(yaml/json), AWS CDK. Collaborate with cross-functional teams to identify and prioritize project requirements Knowledge of API unit & performance testing tools like postman, JMeter, SOAP UI is a plus. Stay up to date with emerging technologies and trends, evaluating their potential impact on our projects. Mentor and provide technical guidance to junior developers, fostering their growth and helping them overcome challenges. Collaborate with cross-functional teams to integrate web applications with existing systems and third-party services. Ensure compliance with development standards, security guidelines, and best practices. Conduct code reviews to maintain high code quality, consistency, and adherence to coding standards. About Business Unit IBM Consulting is IBM’s consulting and global professional services business, with market leading capabilities in business and technology transformation. With deep expertise in many industries, we offer strategy, experience, technology, and operations services to many of the most innovative and valuable companies in the world. Our people are focused on accelerating our clients’ businesses through the power of collaboration. We believe in the power of technology responsibly used to help people, partners and the planet. Your Life @ IBM In a world where technology never stands still, we understand that, dedication to our clients success, innovation that matters, and trust and personal responsibility in all our relationships, lives in what we do as IBMers as we strive to be the catalyst that makes the world work better. Being an IBMer means you’ll be able to learn and develop yourself and your career, you’ll be encouraged to be courageous and experiment everyday, all whilst having continuous trust and support in an environment where everyone can thrive whatever their personal or professional background. Our IBMers are growth minded, always staying curious, open to feedback and learning new information and skills to constantly transform themselves and our company. They are trusted to provide on-going feedback to help other IBMers grow, as well as collaborate with colleagues keeping in mind a team focused approach to include different perspectives to drive exceptional outcomes for our customers. The courage our IBMers have to make critical decisions everyday is essential to IBM becoming the catalyst for progress, always embracing challenges with resources they have to hand, a can-do attitude and always striving for an outcome focused approach within everything that they do. Are you ready to be an IBMer? About IBM IBM's greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world. Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business. At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world. Location Statement For additional information about location requirements, please discuss with the recruiter following submission of your application. Being You @ IBM IBM is committed to creating a diverse environment and is proud to be an equal-opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender, gender identity or expression, sexual orientation, national origin, caste, genetics, pregnancy, disability, neurodivergence, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",https://mx.linkedin.com/jobs/view/data-engineer-aws-etl-python-at-ibm-3996904465,3996904465,"The role involves troubleshooting forecasting systems, collaborating with the data science team to enhance these systems, and developing dynamic object-oriented methods and full stack solutions. Responsibilities include designing, developing, testing, and deploying Python applications on AWS, optimizing application performance using various AWS services, maintaining technical documentation, and implementing automated testing and deployment tools. Candidates will also work on the integration of AWS services with external systems, design data models for databases, develop data ingestion pipelines, and mentor junior developers.","Python, AWS, Lambda, API Gateway, S3, Glue, DynamoDB, PostgreSQL, Jenkins, Docker, CloudWatch, CI/CD, API, SDK, JMeter, SOAP UI",,,True,,0,0,0,1,1,0,0,0,0,1,0,0,0,0,1,1,0
Data Engineer - AWS,IBM,Guadalajara,ON-SITE,,Full-time,IT Services and IT Consulting,2024-09-08 11:32:47.028901,25,Other,,,"Introduction In this role, you'll work in one of our IBM Consulting Client Innovation Centers (Delivery Centers), where we deliver deep technical and industry expertise to a wide range of public and private sector clients around the world. Our delivery centers offer our clients locally based skills and technical expertise to drive innovation and adoption of new technology. Your Role and Responsibilities Day-to-day troubleshooting of forecasting systems, mainly working through data anomalies that cause inaccurate forecasts or prevent forecasts' generation. Collaborate with the data science team to enhance existing forecasting systems for the trade floors. Create dynamic object-oriented methods, full stack solutions, and integrations to existing code solutions. Develop individual Python classes, methods, functions that support the data flow of existing and new projects. Work on code additions to seamlessly support projects for data flows, including logging and support, with little to no supervision. Experience in modifying packages, testing, and repository instances to support CI/CD. Required Technical and Professional Expertise AWS Cloud Data Engineer, you will be responsible for designing, implementing, and managing our data solutions on the AWS platform. AWS GLUE Primary focus will be on building and optimizing data pipelines, ETL processes, and data models to support our data analytics initiatives Preferred Technical And Professional Expertise Experience in automation and scripting, including programming languages such as Python, JavaScript, or PowerShell Strong knowledge and experience in cloud computing platforms Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform (GCP), or other cloud providers. Proficient in cloud infrastructurn, deployment, and management, as well as cloud security and compliance. About Business Unit IBM Consulting is IBM’s consulting and global professional services business, with market leading capabilities in business and technology transformation. With deep expertise in many industries, we offer strategy, experience, technology, and operations services to many of the most innovative and valuable companies in the world. Our people are focused on accelerating our clients’ businesses through the power of collaboration. We believe in the power of technology responsibly used to help people, partners and the planet. Your Life @ IBM In a world where technology never stands still, we understand that, dedication to our clients success, innovation that matters, and trust and personal responsibility in all our relationships, lives in what we do as IBMers as we strive to be the catalyst that makes the world work better. Being an IBMer means you’ll be able to learn and develop yourself and your career, you’ll be encouraged to be courageous and experiment everyday, all whilst having continuous trust and support in an environment where everyone can thrive whatever their personal or professional background. Our IBMers are growth minded, always staying curious, open to feedback and learning new information and skills to constantly transform themselves and our company. They are trusted to provide on-going feedback to help other IBMers grow, as well as collaborate with colleagues keeping in mind a team focused approach to include different perspectives to drive exceptional outcomes for our customers. The courage our IBMers have to make critical decisions everyday is essential to IBM becoming the catalyst for progress, always embracing challenges with resources they have to hand, a can-do attitude and always striving for an outcome focused approach within everything that they do. Are you ready to be an IBMer? About IBM IBM's greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world. Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business. At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world. Location Statement For additional information about location requirements, please discuss with the recruiter following submission of your application. Being You @ IBM IBM is committed to creating a diverse environment and is proud to be an equal-opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender, gender identity or expression, sexual orientation, national origin, caste, genetics, pregnancy, disability, neurodivergence, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",https://mx.linkedin.com/jobs/view/data-engineer-aws-at-ibm-4000282236,4000282236,"In this role, you will troubleshoot forecasting systems, working through data anomalies that cause inaccurate forecasts. You will collaborate with the data science team to enhance forecasting systems for trade floors, create dynamic object-oriented methods, develop Python classes to support data flow, and modify packages for CI/CD. As an AWS Cloud Data Engineer, you will design, implement, and manage data solutions on the AWS platform, focusing on building and optimizing data pipelines and ETL processes.","Python, JavaScript, PowerShell, AWS, AWS GLUE, ETL, Cloud Computing, CI/CD",,,True,,0,0,0,1,0,0,1,0,0,0,0,0,0,0,1,0,0
Data Engineer,Wizeline,Guadalajara,ON-SITE,Entry level,Full-time,IT Services and IT Consulting,2024-09-11 11:32:47.028901,25,Information Technology,,,"The Company Wizeline is a global digital services company helping mid-size to Fortune 500 companies build, scale, and deliver high-quality digital products and services. We thrive in solving our customer’s challenges through human-centered experiences, digital core modernization, and intelligence everywhere (AI/ML and data). We help them succeed in building digital capabilities that bring technology to the core of their business. Your Day-to-Day This job posting is for Data Engineer on our team. Here's what you'll be doing in your day-to-day work: Design and implement product features in collaboration with product owners, report developers, product analysts, architects, and business partners within an Agile / Scrum methodology. Design and implement data platforms for large-scale, high-performance, and scalable requirements, integrating data from several data sources, and managing structured and unstructured data while melding existing warehouse structures. Analyze, diagnose and identify bottlenecks in data workflows Participate in demos to clients and requirements elicitation and translation to systems requirements (functional and nonfunctional). Constantly monitor, refine and report on the performance of data management systems. Are You a Fit? To Be Successful In This Role, You Must Have Strong General Programming Skills Solid experience with Python. If not proficient in Python, we expect the candidate to be proficient in other languages and prove their ability to learn new ones very quickly. Experience with Spark. Solid engineering foundations (good coding practices, good architectural design skills) Experience working with SQL in advanced scenarios that require heavy optimization 5+ years of experience with large-scale data engineering with an emphasis on analytics and reporting 3+ years of experience developing on Hadoop-like Ecosystem Experience building cloud-scalable, real-time and high-performance Data Lake solutions. Proficiency in designing and implementing ETL (Extract, Transform, load) processes, dealing with big volumes of data (terabytes of data which required distributed processing) Experience developing solutions within Cloud Services (AWS, GCP, or Azure) Experience with NoSQL databases such as Apache HBase, MongoDB, or Cassandra. Experience in data streams processing technologies including Kafka, Spark Streaming, etc Advanced English level. About Us Wizeline prioritizes a culture of diversity and development for its nearly 2,000 person team spread across the globe. We believe great technology comes from a mix of talents and perspectives. Our core values of ownership, innovation, community, and inclusivity are central to our work. Wizeline is invested in its employees' growth, offering opportunities to create personalized career paths and develop in-demand skills. We even have a free education program, Wizeline Academy, to help both employees and the broader community upskill in tech. Please note that by submitting your application, you agree with the terms and conditions of our Privacy Policy. Apply now!",https://mx.linkedin.com/jobs/view/data-engineer-at-wizeline-4022155483,4022155483,"This job posting is for a Data Engineer role where you will design and implement product features in collaboration with product owners and business partners using Agile/Scrum methodology. You will be responsible for designing data platforms for large-scale and scalable requirements, integrating data from multiple sources, analyzing data workflows, and monitoring data management systems.","Python, Spark, SQL, Hadoop, AWS, GCP, Azure, Apache HBase, MongoDB, Cassandra, Kafka, Spark Streaming, ETL",5+ years,,True,5.0,0,0,1,1,0,0,1,0,0,1,0,0,0,0,1,0,0
Data Integration Engineer,EPAM Systems,Guadalajara,ON-SITE,Entry level,Full-time,Software Development and IT Services and IT Consulting,2024-09-13 11:32:47.028901,25,Information Technology,,,"Join EPAM as a Data Integration Engineer. In this role, you'll use your strong SQL knowledge to design and implement Data Integration solutions, model databases, and contribute to building enterprise data platforms. If you're an experienced and highly self-motivated professional with outstanding analytical and problem-solving skills, and have experience with Agile methodologies, we'd love to hear from you. Responsibilities Strong SQL knowledge is required Good knowledge of Databases (SQL optimization, Relations, Stored Procedures, Transactions, Isolation Levels, etc.) is a plus Expected experience working with at least one Relational Database (RDBMS: MS SQL Server, Oracle, MySQL, PostgreSQL) is a plus Designing and implementing Data Integration solutions, modeling databases, and contribute to building enterprise data platforms using classic Data technologies and tools (Databases, ETL/ELT technology & tools) - is a plus Experience in direct customer communications is a plus English proficiency Requirements Experienced and highly self-motivated professional with outstanding analytical and problem-solving skills Able to play a Developer role on a project and ensure that delivered solutions meet product requirements Working with modern Agile developing methodologies and tools We offer Career plan and real growth opportunities Unlimited access to LinkedIn learning solutions International Mobility Plan within 25 countries Constant training, mentoring, online corporate courses, eLearning and more English classes with a certified teacher Support for employee’s initiatives (Algorithms club, toastmasters, agile club and more) Enjoyable working environment (Gaming room, napping area, amenities, events, sport teams and more) Flexible work schedule and dress code Collaborate in a multicultural environment and share best practices from around the globe Hired directly by EPAM & 100% under payroll Law benefits (IMSS, INFONAVIT, 25% vacation bonus) Major medical expenses insurance: Life, Major medical expenses with dental & visual coverage (for the employee and direct family members) 13 % employee savings fund, capped to the law limit Grocery coupons 30 days December bonus Employee Stock Purchase Plan 12 vacations days plus 4 floating days Official Mexican holidays, plus 5 extra holidays (Maundry Thursday and Friday, November 2nd, December 24th & 31st) Relocation bonus: transportation, 2 weeks of accommodation for you and your family and more By applying to our role, you are agreeing that your personal data may be used as in set out in EPAM´s Privacy Notice and Policy. EPAM is a leading global provider of digital platform engineering and development services. We are committed to having a positive impact on our customers, our employees, and our communities. We embrace a dynamic and inclusive culture. Here you will collaborate with multi-national teams, contribute to a myriad of innovative projects that deliver the most creative and cutting-edge solutions, and have an opportunity to continuously learn and grow. No matter where you are located, you will join a dedicated, creative, and diverse community that will help you discover your fullest potential.",https://mx.linkedin.com/jobs/view/data-integration-engineer-at-epam-systems-4024921596,4024921596,"Join EPAM as a Data Integration Engineer, where you'll use your strong SQL knowledge to design and implement Data Integration solutions, model databases, and contribute to building enterprise data platforms. Responsibilities include strong SQL knowledge, good knowledge of databases such as SQL optimization and relations, and experience with at least one Relational Database. You will also design and implement Data Integration solutions and work with classic Data technologies and tools. Effective communication skills in English are required.","SQL, RDBMS: MS SQL Server, Oracle, MySQL, PostgreSQL, ETL/ELT technologies, Agile Methodologies",,,True,,1,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0
Snowflake Data Engineer,Cognizant,Guadalajara,ON-SITE,Entry level,Full-time,IT Services and IT Consulting,2024-08-16 11:32:47.028901,25,Information Technology,,,"Cognizant is always looking for top talent. We are searching for candidates to fill future needs within the business. This job posting represents potential future employment opportunities with Cognizant. Although the position is not currently available, we want to provide you with the opportunity to express your interest in future employment opportunities with Cognizant. If a job opportunity that you may be qualified for becomes available in the future, we will notify you. At that time you can determine whether you would like to apply for the specific open position. Thank you for your interest in Cognizant career opportunities. We’re hiring! At Cognizant we have an ideal opportunity for you to be part of one of the largest companies in the digital sector worldwide. A Great Place To Work where we look for people who contribute new ideas, experiencing a dynamic and growing environment. At Cognizant we promote an inclusive culture, where we value different perspectives providing career growth and development opportunities. #WelcomeToCognizant! We have an exciting opportunity for an exceptional individual to work supporting one of our clients as a Snowflake Data Engineer What you’ll do: Experience on building an ETL pipeline using python, pandas, AWS services. Good knowledge on Oracle database, SQLite. Well known of code deployment activities in QA, stage, and production server. Good knowledge of GITHUB tool for version control of the codes. Well versed of creating pull request, merge the pull request. Well known of release management activities. Experienced in python, multithreading and multiprocessing, socket server module and Bluetooth module since our scanning application’s hardware is implemented using these. Well versed in AWS, with hands on experience on services like EC2, S3, SQS, SNS, Cloud Watch, Lambda, ECS, Code Commit, Code Deploy, Code Pipeline, Code. Worked on Django for a POC project to make internal blog site for our company. Good Knowledge in Shell Scripting, Core Java, Java script and HTML, SQL. Worked on Snowflake and dbt for ETL pipeline. Preferred experience: Operating Systems: Linux/Windows Languages: Python, Shell scripting, JavaScript, HTML Databases: Oracle, DynamoDB, AWS RDS, SQLite Software Tools: Visual Studio Code, PyCharm, Jupyter Notebook, GIT bash and GUI, Putty, WinSCP SAAS Software’s and tools: Snowflake (data warehousing tool based on cloud), dbt(data build tool) Cloud Platforms: AWS Why Cognizant? Improve your career in one of the largest and fastest growing IT services providers worldwide Receive ongoing support and funding with training and development plans Have a highly competitive benefits and salary package Get the opportunity to work for leading global companies We are committed to respecting human rights and build a better future by helping your minds and the environment We invest in people and their wellbeing. We create conditions for everyone to thrive. We do not discriminate based on race, religion, color, sex, age, disability, nationality, sexual orientation, gender identity or expression, or for any other reason covered. At Cognizant we believe than our culture make us stronger! Join us now! #BeCognizant #IntuitionEngineered Employee Status : Full Time Employee Shift : Day Job Job Posting : Jan 03 2024 About Cognizant Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @Cognizant. 43486",https://mx.linkedin.com/jobs/view/snowflake-data-engineer-at-cognizant-4006643680,4006643680,"We have an exciting opportunity for an exceptional individual to work supporting one of our clients as a Snowflake Data Engineer. The role involves building an ETL pipeline using Python, Pandas, and AWS services. Knowledge of Oracle databases, SQLite, GITHUB for version control, and release management activities is required. Experience in Python, multithreading, multiprocessing, socket server module, and Bluetooth module is necessary. Skills in AWS services including EC2, S3, SQS, SNS, Cloud Watch, Lambda, ECS, and Code services are also part of the duties. Familiarity with Django, Shell Scripting, Core Java, JavaScript, HTML, SQL, Snowflake, and dbt for ETL pipelines is preferred.","Python, Pandas, AWS, EC2, S3, SQS, SNS, Cloud Watch, Lambda, ECS, Code Commit, Code Deploy, Code Pipeline, Django, Shell Scripting, Core Java, JavaScript, HTML, SQL, Oracle, DynamoDB, AWS RDS, SQLite, Snowflake, dbt, Visual Studio Code, PyCharm, Jupyter Notebook, GIT bash, Putty, WinSCP",,,True,,0,1,0,1,1,0,0,0,0,1,1,0,0,0,1,0,0
Azure Data Engineer,Infosys,Guadalajara,ON-SITE,Entry level,Full-time,IT Services and IT Consulting,2024-08-16 11:32:47.028901,25,Information Technology,,,"Job Description We are looking for an Azure Data Eng to work on hybrid model on any of Infosys Locations (Mexico City, Gdl and Mty) in a Production Support + Development project with one of the top companies in Silicon Valley . Expertise Required Very good communication skills + English Level. At least 3 years of experience in designing, implementing, and maintaining robust and scalable data pipelines on Azure using services such as Azure Data Factory, Azure SQL Data Warehouse, Azure Analysis Services or any of the Azure Databricks/Synapse/Fabric. At least 2 years of experience in data platforms – with multi layered approach, Design/Architecture setup is needed. At least 2 years of experience in troubleshooting performance issues, identifying root cause and applying fixes. At least 3 years of experience in SQL. Ability to implement and manage CI/CD pipelines for data engineering projects, leveraging tools like Azure DevOps. About Us Infosys is a global leader in next-generation digital services and consulting. We enable clients in more than 50 countries to navigate their digital transformation. With over four decades of experience in managing the systems and workings of global enterprises, we expertly steer our clients through their digital journey. We do it by enabling the enterprise with an AI-powered core that helps prioritize the execution of change. We also empower the business with agile digital at scale to deliver unprecedented levels of performance and customer delight. Our always-on learning agenda drives their continuous improvement through building and transferring digital skills, expertise, and ideas from our innovation ecosystem. Infosys provides equal employment opportunities to applicants and employees without regard to race; color; sex; gender identity; sexual orientation; religious practices and observances; national origin; pregnancy, childbirth, or related medical conditions; status as a protected veteran or spouse/family member of a protected veteran; or disability.",https://mx.linkedin.com/jobs/view/azure-data-engineer-at-infosys-3985874139,3985874139,"We are looking for an Azure Data Engineer to work on a hybrid model in various Infosys locations (Mexico City, Gdl, and Mty) on a Production Support and Development project. The position requires excellent communication skills and at least 3 years of experience in designing, implementing, and maintaining robust and scalable data pipelines on Azure using services such as Azure Data Factory, Azure SQL Data Warehouse, and Azure Analysis Services or Azure Databricks/Synapse/Fabric. Additionally, a minimum of 2 years of experience in multi-layered data platforms and troubleshooting performance issues is needed, along with at least 3 years of experience in SQL and the ability to manage CI/CD pipelines for data engineering projects using Azure DevOps.","Azure Data Factory, Azure SQL Data Warehouse, Azure Analysis Services, Azure Databricks, Azure Synapse, Azure DevOps, SQL",At least 3 years in data pipelines; 2 years in data platforms and performance troubleshooting; 3 years in SQL.,,True,2.0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,0,0,0
Data Integration SQL Engineer,EPAM Systems,Guadalajara,ON-SITE,Entry level,Full-time,Software Development and IT Services and IT Consulting,2024-09-13 11:32:47.028901,25,Engineering,Information Technology,,"Join EPAM as a Data Integration SQL Engineer. In this role, you'll use your SQL expertise to create value for our clients, transform the way they use data, and design robust and scalable scripts and workflows that automate data collection, enrichment, and delivery. If you have strong SQL knowledge, good understanding of databases, and experience in designing and implementing Data Integration solutions, we'd love to hear from you. Responsibilities Play a Developer role on a project and ensure that delivered solutions meet product requirements Work with modern Agile developing methodologies and tools Foster cross-functional collaboration to align database solutions with project goals Contribute to enterprise data platforms and data integration strategies Communicate effectively with stakeholders for requirements gathering and progress updates Design and engineer data solutions using SQL to build robust and scalable scripts and workflows that automate data collection, enrichment, and delivery Work independently to identify and solve problems, and collaborate effectively within a team to develop comprehensive solutions Requirements Strong SQL knowledge is required Good knowledge of Databases (SQL optimization, Relations, Stored Procedures, Transactions, Isolation Levels, etc.) is a plus Expected experience working with at least one Relational Database (RDBMS: MS SQL Server, Oracle, MySQL, PostgreSQL) is a plus Experience in designing and implementing Data Integration solutions, modeling databases, and contributing to building enterprise data platforms using classic Data technologies and tools (Databases, ETL/ELT technology & tools) - is a plus Experience in direct customer communications is a plus English proficiency We offer Career plan and real growth opportunities Unlimited access to LinkedIn learning solutions International Mobility Plan within 25 countries Constant training, mentoring, online corporate courses, eLearning and more English classes with a certified teacher Support for employee’s initiatives (Algorithms club, toastmasters, agile club and more) Enjoyable working environment (Gaming room, napping area, amenities, events, sport teams and more) Flexible work schedule and dress code Collaborate in a multicultural environment and share best practices from around the globe Hired directly by EPAM & 100% under payroll Law benefits (IMSS, INFONAVIT, 25% vacation bonus) Major medical expenses insurance: Life, Major medical expenses with dental & visual coverage (for the employee and direct family members) 13 % employee savings fund, capped to the law limit Grocery coupons 30 days December bonus Employee Stock Purchase Plan 12 vacations days plus 4 floating days Official Mexican holidays, plus 5 extra holidays (Maundry Thursday and Friday, November 2nd, December 24th & 31st) Relocation bonus: transportation, 2 weeks of accommodation for you and your family and more By applying to our role, you are agreeing that your personal data may be used as in set out in EPAM´s Privacy Notice and Policy. EPAM is a leading global provider of digital platform engineering and development services. We are committed to having a positive impact on our customers, our employees, and our communities. We embrace a dynamic and inclusive culture. Here you will collaborate with multi-national teams, contribute to a myriad of innovative projects that deliver the most creative and cutting-edge solutions, and have an opportunity to continuously learn and grow. No matter where you are located, you will join a dedicated, creative, and diverse community that will help you discover your fullest potential.",https://mx.linkedin.com/jobs/view/data-integration-sql-engineer-at-epam-systems-4024919702,4024919702,"Join EPAM as a Data Integration SQL Engineer. In this role, you'll use your SQL expertise to create value for clients, transform data usage, and design robust and scalable scripts and workflows that automate data collection, enrichment, and delivery. Responsibilities include ensuring solutions meet product requirements, working with Agile methodologies, designing data solutions using SQL, and contributing to enterprise data platforms. Strong SQL knowledge and understanding of databases are required.","SQL, Relational Databases (MS SQL Server, Oracle, MySQL, PostgreSQL), ETL/ELT tools, Agile Methodologies",,,True,,1,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0
"Senior Data Engineer, DataBricks Platform",CloudGeometry,Guadalajara,REMOTE,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-16 15:11:23.705162,25,Information Technology,,,"CloudGeometry is a Silicon Valley-based cloud-native system integrator with deep expertise in AWS and the CNCF technology stack. We partner with industry leaders like AWS, Google and Databricks to deliver solutions across all layers of the modern technology stack, from generative UI to Kubernetes-powered MLOps workloads. Our distributed team of top technology experts from the US, Europe, and LATAM collaborates on innovative commercial and open-source projects. Our commitment to innovation and excellence makes us a trusted partner for leading technology companies and VC-funded startups. We are looking for a Senior Data Engineer with extensive hands-on experience in the Databricks ecosystem and exceptional communication skills to join our flagship project: a cutting-edge Data Platform for the life sciences industry. This platform supports industry leaders such as Pfizer, Moderna, and Novartis in developing innovative RNA-based solutions, leveraging data-driven research, cloud computing, and advanced AI capabilities. This role offers a unique opportunity for an experienced data engineer to take the next step in their career, playing a key technical leadership role in the rapidly evolving world of AI-driven solutions Responsibility Design, develop, and optimize data pipelines and workflows within the Databricks platform. Take part in architecture discussion with engineering, product managers and data scientists to implement advanced analytics solutions that drive business insights. Build, optimize, and fine-tune Databricks workflows to improve performance and reliability. Work closely with data scientists and analysts to i Ensure the integrity, accuracy, and security of data across all processing stages. Implement data ingestion from various sources into Databricks, ensuring data quality and reliability. Participate in daily Scrum ceremonies and collaborate with team members in the US and Europe with required online presence from 9 AM to 5 PM EST Qualifications Bachelor’s degree in Computer Science, Engineering, or a related field; Master’s degree preferred. 8+ years of experience in the software development industry, preferably in data engineering, data warehousing or data analytics companies and teams. 1+ year of experience with the DataBricks ecosystem. Expert level of Python and Typescript. Expert level of understanding and hands-on experience with Lake House architecture. Expert level of experience with Spark/Glue and Delta tables/iseberg. Experienced in designing and implementing complex, scalable data pipelines/ETL processes using Databricks. Skilled in cloud-based data storage and processing technologies, particularly AWS services such as S3, Step Functions, Lambda, and Airflow. Familiar with CI/CD practices, version control (Git), automated testing, and Agile environments. Experience with the Agile development process in a distributed engineering team. Ability to articulate ideas clearly, present findings persuasively, and build rapport with clients and team members. Experience working in US-led high-tech companies and startups. Nice to Have DataBricks certifications AWS or Azure DevOps or SA certifications Knowledge of basic DevOps and MLOps principles Experience in working with Data Scientists and ML Developers Experience in management and lead developer roles from technology services companies What we commit to you Comprehensive compensation and benefits package. Opportunity to work with cutting-edge technologies; no legacy systems. Extensive training opportunities including certifications, hackathons, remote conference attendance, and free access to Udemy and other digital learning platforms. Collaborative and supportive environment with top global experts to help you reach new professional heights and advance in your career.",https://mx.linkedin.com/jobs/view/senior-data-engineer-databricks-platform-at-cloudgeometry-4025245553,4025245553,"We are looking for a Senior Data Engineer with extensive hands-on experience in the Databricks ecosystem to design, develop, and optimize data pipelines and workflows. The role includes participating in architecture discussions and building complex analytics solutions. Responsibilities involve ensuring data integrity and quality through ingestion and processing stages, and collaborating in Agile Scrum ceremonies.","Databricks, Python, TypeScript, Apache Spark, AWS, S3, Step Functions, Lambda, Airflow, Git",8+ years,Bachelor,True,8.0,0,0,1,1,0,0,0,0,0,0,0,1,0,0,1,0,0
Machine Learning Engineer,Nortal,Guadalajara,ON-SITE,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-16 15:11:37.092628,25,Engineering,Information Technology,,"Overview About Pwrteams Join our fast-growing and diverse team at Pwrteams, where we provide premium IT and engineering nearshore solutions to our global customers. Since 2007, we pursue to become the market leader in assembling cross-border IT and engineering teams for customers. Our operations are strategically positioned within Eastern Europe’s dynamic tech ecosystems, from where we cater the global business landscape. We’re at the forefront of travel, media and fintech innovation, healthcare efficiency enhancements, and others. Our goal? To connect interesting customer projects and skilled talent alike. Become a part of our team and take the next step on your personal career journey. About Our Client Our client is a global leader in manufacturing digital cutting machines that allow millions of people to get amazing experiences in creating craft artwork. To use the cutters, makers apply the company’s own powerful design software, available both for web and mobile devices. So that they can produce their own personalized masterpiece just with a few clicks. About The Project You'll get a chance to work on a graphical editor that allows millions of people to create custom and hand-made pieces of art. This project is not about plain code, it's about bringing change and making life more colourful, so don't stand by and apply!As a Machine Learning Engineer, you will play a pivotal role in developing and deploying state-of-the-art models and algorithms for tasks such as image generation, recommender engines, prediction models, and more. Your work will directly contribute to advancing our cutting-edge machine learning capabilities. Responsibilities Analyze and preprocess large-scale datasets for training and evaluation purposes Experiment with different architectures, loss functions, and data augmentation techniques to improve model performance Collaborate with cross-functional teams to define project requirements and deliver innovative solutions Stay up-to-date with the latest advancements in machine learning and computer vision, and apply them to solve complex problems Troubleshoot and debug issues related to model training, performance, and scalability. Integrate the training software into our continuous integration cluster to support metrics persistence across experiments, weekly/nightly neural network builds, and other unit / throughput tests Collaborate with software engineers to integrate machine learning models into production systems Document research findings, experiments, and algorithms in technical reports and presentations Qualifications Proven industry experience (2+ years) in developing and deploying deep learning machine learning models Solid understanding of deep learning concepts, convolutional neural networks (CNNs), recurrent neural networks (RNNs), and/or graph neural networks (GNNs) Strong programming skills in Python, including proficiency in one or more deep learning frameworks (TensorFlow, PyTorch, Keras). PyTorch preferred Experience with image processing techniques, computer vision libraries (OpenCV), and related tools Familiarity with AWS infrastructure and toolchain (SageMaker, CloudFormation, CloudWatch, etc.) Ability to preprocess and manipulate large datasets using tools such as NumPy, Pandas, and scikit-learn Knowledge of software engineering principles, including version control (Git) and agile development methodologies Excellent problem-solving skills, with the ability to work on complex machine learning challenges independently Strong written and verbal communication skills, with the ability to effectively collaborate with team members and present findings to stakeholders",https://mx.linkedin.com/jobs/view/machine-learning-engineer-at-nortal-4027616198,4027616198,"As a Machine Learning Engineer, you will develop and deploy state-of-the-art models for tasks such as image generation and prediction. You will analyze and preprocess large datasets, experiment with various architectures, and collaborate with teams to define project requirements. You will also troubleshoot issues related to model training and integrate models into production systems.","Python, TensorFlow, PyTorch, Keras, OpenCV, NumPy, Pandas, scikit-learn, AWS, Git",2+ years,,True,2.0,0,0,0,1,0,0,0,0,0,0,0,1,1,0,1,0,0
"Manager, Machine Learning",Pfizer,Guadalajara,ON-SITE,Mid-Senior level,Full-time,Pharmaceutical Manufacturing,2024-09-16 15:11:37.092628,25,Engineering,Information Technology,,"Role Summary Do you want to make an impact on patient health around the world? Do you thrive in a fast-paced environment that brings together scientific and clinical domains together through data and analytics? Then join Pfizer Digital’s AI & Data Analytics (AIDA) organization where you can leverage cutting-edge technology including AI and ML to inform critical business decisions and improve customer experiences for our patients and physicians. Our collection of global teams drives insights to action for some of the most critical business questions for the company. Our analytics professionals are based in over 30 countries around the world and come from diverse backgrounds including: software engineering, data science, digital analytics, finance, investment banking, corporate development, and consulting. Join one of our teams and be at the forefront of Pfizer’s digital transformation, driving innovation and bringing advance analytics to change patients’ lives. As an AI/ML Engineer, you will be part of a team to develop new capabilities that leverages AI to solve complex problems across the enterprise. In this role, you will be responsible for overseeing the design, implementation, and deployment of AI and machine learning models and algorithms, ensuring their accuracy, scalability, and effectiveness. The ideal candidate will have a strong technical background in machine learning and/or software engineering and a passion for innovation, bridging the gap between data, technology, and people, to deliver the promise of AI/ML to improve patients’ lives. Role Responsibilities Design, develop and deploy machine learning products & approaches to solve business problems across multiple domains, including commercial, medical affairs, and R&D. Engage with stakeholders across the enterprise to understand and solve complex problems through AI/ML (including generative AI methods where appropriate) to inform business strategy and decisions Design and execute advanced analytics and predictive modeling projects using rigorous statistical methods and machine learning techniques Design, develop, deploy and maintain reusable assets and custom pipelines to optimize operational efficiencies in analytics execution Research, identify, and apply new algorithms and technologies to solve complex problems and systematize solutions into reusable assets and capabilities Practice Agile-based project management standards (i.e. daily check-in procedures, workload status, and cost overruns/projections) Identify emerging technologies, evaluate their potential impact, and make informed decisions on adopting new tools, frameworks, and methodologies. Basic Qualifications Proven experience (5+ years) as a software engineer, ML engineer, or data scientist and project lead for a diverse range of projects, with a focus on developing and deploying production-grade solutions. Bachelor’s degree in STEM (Science, Technology, Engineering, Mathematics) majors with quantitative emphasis – Statistics, Computer Science, Economics, Engineering etc. Strong programming skills in languages such as Python, Java, or C++, and proficiency with AI and machine learning frameworks and libraries (e.g., TensorFlow, PyTorch, scikit-learn). Applied knowledge of statistical analysis, experience with R, Excel, etc. Strong background in computer science: algorithms, data structures, machine learning, and distributed systems. Superior analytical skills required; Strong verbal and written communication skills Demonstrated experience interfacing with other internal and external teams to incorporate their innovations and vice versa Preferred Qualifications Advanced understanding of machine learning algorithms, deep learning architectures, and statistical techniques. Experience with foundation models, LLMs, and generative AI. Proficiency in data preprocessing, feature engineering, and dimensionality reduction. Familiarity with software engineering principles (e.g. version control, testing, and deployment) Experience with cloud platforms (e.g., AWS, Azure, GCP) and distributed computing frameworks is a plus. A passion for staying up-to-date with the latest advancements in AI and machine learning technologies and a commitment to continuous learning. Experience working in Agile processes and practices. EEO (Equal Employment Opportunity) & Employment Eligibility Pfizer is committed to equal opportunity in the terms and conditions of employment for all employees and job applicants without regard to race, color, religion, sex, sexual orientation, age, gender identity or gender expression, national origin, or disability. Information & Business Tech",https://mx.linkedin.com/jobs/view/manager-machine-learning-at-pfizer-4027621104,4027621104,"As an AI/ML Engineer, you will design, develop, and deploy machine learning products to solve business problems across multiple domains, utilizing AI and machine learning technologies to inform critical business decisions and improve customer experiences. You will engage with stakeholders to address complex problems through AI/ML, execute advanced analytics and predictive modeling projects, and maintain reusable assets to optimize operational efficiencies.","Python, Java, C++, TensorFlow, PyTorch, scikit-learn, R, Excel, AWS, Azure, GCP",5+ years,Bachelor,True,5.0,0,0,0,1,0,0,0,0,1,0,0,0,1,0,1,0,0
"Machine Learning Engineer, IgniteTech (Remote) - $60,000/year USD",Crossover,Guadalajara,REMOTE,Associate,Full-time,"Software Development, IT Services and IT Consulting, and Technology, Information and Internet",2024-09-18 07:37:24.163709,25,Education,"Engineering,",Information Technology,"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, IgniteTech. Have you got what it takes? Are you a forward-thinking developer eager to harness the power of GenAI to redefine business standards and enhance productivity? Are you bored of solving the same customer support tickets or resolving the same bugs over and over again? The majority of companies struggle with integrating AI into existing workflows, often resulting in underutilization and disappointing outcomes. At IgniteTech, we set ourselves apart by focusing on the practical application advanced AI technologies to transform business operations. Our approach isn't just about making incremental improvements; it's about leveraging AI to develop, support, and optimize tools that enhance both the workflow processes and the quality of service provided to our clients. This role IgniteTech is far from a conventional customer support or software engineer job. It is designed for those who are passionate about deploying GenAI to create robust support solutions, significantly improving productivity and customer satisfaction. Ideal for innovators who thrive in a dynamic environment, this position will place you at the helm of integrating revolutionary AI technologies. In this role, you’ll lead the charge in experimenting with and integrating cutting-edge AI technologies. You will play a pivotal role in shaping the future of AI-driven tools, from their inception to their optimization. If you're ready to be at the forefront of the AI revolution and transform how businesses operate, we invite you to apply today. Join us at IgniteTech, where we're not just changing the game—we’re defining it. Let’s innovate together and make a lasting impact. What You Will Be Doing Create and improve autonomous support platforms using LLMs. This includes not only development but also troubleshooting, maintaining, and updating tools based on user feedback and support tickets. One example would be creating an assistant able to guide customers through an upgrade process. Test and integrate state-of-the-art AI technologies, like GPT-4 Vision and Amazon CodeWhisperer, while providing support and guidance for internal teams on how to best utilize these technologies within their workflows. Evaluate and enhance the performance and integration of AI solutions across different infrastructures, notably AWS, and ensures support is available for end-users experiencing issues, focusing on maintaining high service quality and satisfaction. Machine Learning Engineer Key Responsibilities Improve support for both internal and external clients, significantly boosting the company’s innovation capacity and service quality Basic Requirements Advanced generative AI proficiency (i.e., use of multiple AI tools, ability to automate workflows and custom GPTs); if you've only used LLMs for research, learning, brainstorming, or content generation, that will be deemed insufficient At least 2 years of experience in B2B software customer support Proficiency in Python The ability to use AI to code in additional languages you are not very familiar with About IgniteTech If you want to work hard at a company where you can grow and be a part of a dynamic team, join IgniteTech! Through our portfolio of leading enterprise software solutions, we ignite business performance for thousands of customers globally. We’re doing it in an entirely remote workplace that is focused on building teams of top talent and operating in a model that provides challenging opportunities and personal flexibility. A career with IgniteTech is challenging and fast-paced. We are always looking for energetic and enthusiastic employees to join our world-class team. We offer opportunities for personal contribution and promote career development. IgniteTech is an Affirmative Action, Equal Opportunity Employer that values the strength that diversity brings to the workplace. There is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you! Working with Crossover This is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $30 USD/hour, which equates to $60,000 USD/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com/help-and-faqs for more details on this topic. What to expect next: You will receive an email with a link to start your self-paced, online job application. Our hiring platform will guide you through a series of online “screening” assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments. Important! If you do not receive an email from us: First, emails may take up to 15 minutes to send, refresh and check again. Second, check your spam and junk folders for an email from Crossover.com, mark as “Not Spam” since you will receive other emails as well. Third, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked. If all else fails, just reset your password by visiting https://www.crossover.com/auth/password-recovery if you already applied using LinkedIn EasyApply. Crossover Job Code: LJ-5267-MX-Guadalaj-MachineLearnin.002",https://mx.linkedin.com/jobs/view/machine-learning-engineer-ignitetech-remote-%2460-000-year-usd-at-crossover-4028887843,4028887843,"The position involves creating and improving autonomous support platforms using large language models (LLMs) and integrating cutting-edge AI technologies to enhance productivity and customer satisfaction. Responsibilities include troubleshooting, maintaining, and updating tools based on user feedback, evaluating AI solutions' performance, and improving support for both internal and external clients. Advanced generative AI proficiency is required, along with at least 2 years of experience in software customer support and proficiency in Python.","Python, AI tools, LLMs, GPT-4 Vision, Amazon CodeWhisperer, AWS",2,,True,2.0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0
Data Engineer,Listopro,Guadalajara,HYBRID,Entry level,Full-time,Research Services,2024-09-18 07:37:40.772871,25,Engineering,Analyst,,"About The Position We are seeking a skilled Data Analyst with a strong background in Automation and Mechanical Engineering to join our team. The successful candidate will be responsible for analyzing machine data, developing data pipelines and models, and collaborating with cross-functional teams to ensure optimal machine performance and support. This role involves a hands-on approach to understanding machine operations and applying data-driven insights to improve efficiency and performance. Requirements Candidate Requirements: Data Analysis: Proficiency in analyzing data to extract actionable insights and make informed decisions. Reporting & Data Analytics: Capability to prepare detailed reports and apply data analytics, with machine learning experience being a plus, to solve complex issues. Automation & Mechanical Engineering: Familiarity with data analysis in automation. Ability to monitor and control machine data related to performance, energy usage, maintenance, and process quality across the Americas. Skilled in identifying deviations and understanding root causes. Collaboration: Strong ability to work with Central and Regional Product Support and Service teams to provide optimal support and maintain line conditions. Qualifications: Degree in Engineering, Data Science, or a related field. Familiarity with engineering management and mechanical or automation engineering principles. Proven experience in data analysis and reporting. Excellent problem-solving and communication skills Ability to work collaboratively in a team environment. Knowledge of Python and SQL database are a plus Good English written and spoken is mandatory Previous experience as production lines analyst is a plus. Benefits Vacaciones / Flexibilidad de Trabajo ½ Medio día libre para tu cumpleaños 12 días el primer año 9 días libres extraordinarios Salud / Seguros Seguro de Gastos Médicos Mayores Días pagados para maternidad y paternidad de acuerdo a lo establecido en la LFT Apoyo en defunción familiar En caso de contraer matrimonio se podrá gozar de 5 días con goce de sueldo. Seguro de vida Beneficios salariales Esquema 100% vía nómina Fondo de ahorro 25 días de aguinaldo Vales de despensa Beneficios Extras + Educación Se otorga un servicio de transportación colectiva con rutas y paradas definidas. Comedor Tendrás acceso a cursos virtuales y con valor curricular a través de LinkedIn Learning, Capacitaciones internas que impulsan tu desarrollo profesional y personal 7372-18092024",https://mx.linkedin.com/jobs/view/data-engineer-at-listopro-4027178839,4027178839,"We are seeking a skilled Data Analyst with a strong background in Automation and Mechanical Engineering to join our team. The successful candidate will be responsible for analyzing machine data, developing data pipelines and models, and collaborating with cross-functional teams to ensure optimal machine performance. This role involves applying data-driven insights to improve efficiency and performance.","Data Analysis, Machine Learning, Automation, Mechanical Engineering, Python, SQL",,,True,,0,0,0,0,0,1,0,0,0,1,0,1,1,0,1,0,0
Data Analyst (Marketing background),MezTal,Guadalajara,HYBRID,Mid-Senior level,Full-time,Data Infrastructure and Analytics,2024-09-18 07:37:40.772871,25,Marketing,Analyst,,"Responsibilities: Analyze complex data sets, including marketing data, to identify trends, patterns, and actionable insights. Generate data-driven insights to support marketing strategies and decision-making processes. Develop and maintain dashboards and reports using data visualization tools to track and optimize marketing performance. Collaborate with cross-functional teams, including marketing, sales, and product teams, to understand data requirements and deliver analytical solutions tailored to marketing needs. Conduct statistical analyses to interpret marketing data and inform business strategies. Ensure data accuracy and integrity in all marketing analyses and reports. Communicate findings and recommendations to marketing stakeholders in a clear and concise manner. Continuously improve processes and methodologies for data analysis and reporting, with a focus on marketing data. Requirements Bachelor's degree in Data Science, Statistics, Computer Science, Marketing, or a related field. 5+ years of experience in a data analysis role, with a focus on marketing analytics. Proficiency in SQL for querying and managing data. Strong skills in Python for data analysis and statistical modeling. Experience with data visualization tools such as Tableau or Power BI, particularly in creating marketing dashboards. Excellent analytical and problem-solving skills, with a deep understanding of marketing metrics. Strong attention to detail and accuracy in handling marketing data. Ability to work independently and as part of a team. Effective communication skills, both written and verbal, with an ability to translate complex data insights into marketing strategies. Familiarity with data warehousing concepts and ETL processes is a plus. Knowledge of machine learning techniques and tools is an advantage. Background in digital marketing, SEO/SEM, or marketing automation tools. Preferred Skills: Experience with advanced statistical analysis and predictive modeling in the context of marketing. Familiarity with big data technologies and tools (e.g., Hadoop, Spark), especially as they relate to marketing data. Understanding of business intelligence, data warehousing concepts, and their application in marketing. Knowledge of other programming languages such as R or JavaScript, with experience in marketing analytics. Experience with cloud platforms (e.g., AWS, Azure, Google Cloud) for data analysis and storage, particularly in marketing contexts. Benefits Awesome Benefits for Our Team! Christmas Bonus: 30 days, to be paid in December. Major Medical Expense Insurance: Coverage up to $20,000,000.00 MXN. Minor Medical Insurance: VRIM membership with special discounts on doctor’s appointments and accident reimbursements. Dental Insurance: Always smile with confidence! Life Insurance: (Death and MXN Disability) Vacation Days: 12 vacation days in accordance with Federal Labor Law, with prior approval from your manager. + Floating Holidays: 3 floating holidays in addition to the 7 official holidays in Mexico. Cell Phone Reimbursement & Transportation Subsidy. Hybrid Scheme: Enjoy the best of both worlds, remote and in-office work. Multicultural Exposure: Work with operations within Mexico and United Satates. MezTal Internal Events: Strike a healthy balance between your professional and personal goals. Exclusive Discounts: Benefits with different companies for being part of MezTal. Academic Agreements: Access to national universities and language schools.",https://mx.linkedin.com/jobs/view/data-analyst-marketing-background-at-meztal-4028849871,4028849871,"Responsibilities include analyzing complex marketing data sets to identify trends and actionable insights, generating data-driven insights for marketing strategies, developing dashboards and reports, collaborating with cross-functional teams to meet data requirements, conducting statistical analyses, ensuring data accuracy, and communicating findings to stakeholders. The role requires continuous improvement of data analysis processes focused on marketing data.","SQL, Python, Tableau, Power BI, Hadoop, Spark, R, JavaScript, AWS, Azure, Google Cloud",5+ years,Bachelor,True,5.0,0,0,1,1,0,0,0,0,1,1,0,0,0,0,1,0,0
GCP Data Engineer - R01541146,Brillio,Guadalajara,HYBRID,Entry level,Temporary,Information Technology & Services,2024-09-18 07:37:40.772871,25,Information Technology,,,"About Brillio: Brillio is one of the fastest growing digital technology service providers and a partner of choice for many Fortune 1000 companies seeking to turn disruption into a competitive advantage through innovative digital adoption. Brillio, renowned for its world-class professionals, referred to as ""Brillians"", distinguishes itself through their capacity to seamlessly integrate cutting-edge digital and design thinking skills with an unwavering dedication to client satisfaction. Brillio takes pride in its status as an employer of choice, consistently attracting the most exceptional and talented individuals due to its unwavering emphasis on contemporary, groundbreaking technologies, and exclusive digital projects. Brillio's relentless commitment to providing an exceptional experience to its Brillians and nurturing their full potential consistently garners them the Great Place to Work® certification year after year. Role: GCP Data Engineer - R01541146 Functional Area: Data And AI Employment Type: Full Time / Permanent Location: México Job Summary: With 6 years of experience in software design and development, this role focuses on creating and maintaining large-scale data architectures and analytics platforms. The ideal candidate will have extensive experience in data engineering, particularly within the Google Cloud Platform (GCP) ecosystem and be capable of leading projects from conceptualization to operationalization. Key Responsibilities: Design & Development: Lead the design and development of scalable software solutions, with a strong focus on data engineering and cloud-based technologies. Data Architecture: Architect and implement data warehouses, data lakes, and analytics platforms that can handle very large datasets efficiently. GCP Cloud Implementation: Apply hands-on expertise with GCP’s data tools including BigQuery, Pub/Sub, DataFlow/Apache Beam, Airflow/Composer, and Cloud Storage. Technology Proficiency: Utilize advanced skills in GBQ Query, Python, Apache Airflow, and SQL (with a preference for BigQuery). Agile Methodologies: Contribute to projects in an agile development environment, ensuring timely delivery and high-quality output. Cross-Cloud Expertise: Leverage knowledge of cloud functions and comparable skills in AWS and other cloud-based Big Data Engineering environments. Communication: Clearly present ideas, concepts, and technical solutions to both technical and non-technical stakeholders. Required Qualifications Experience: 6 years in software design and development, with 5 years preferred in data engineering, and 3 years in GCP cloud data implementation. Technical Skills: Strong experience with SQL and Python, particularly in the context of data engineering and cloud platforms. Additional experience with Apache Airflow and GCP tools is essential. Educational Background: Bachelor's Degree in Computer Science, Information Technology, or a closely related discipline. Communication Skills: Excellent verbal and written communication abilities, capable of conveying complex ideas clearly and effectively. Agile Development: Familiarity with agile development methodologies is highly desirable. Know what it’s like to work and grow at Brillio: Click here",https://mx.linkedin.com/jobs/view/gcp-data-engineer-r01541146-at-brillio-4008718799,4008718799,"This role focuses on creating and maintaining large-scale data architectures and analytics platforms. The ideal candidate will have extensive experience in data engineering, particularly within the Google Cloud Platform (GCP) ecosystem and be capable of leading projects from conceptualization to operationalization. Responsibilities include designing scalable software solutions, architecting data warehouses and lakes, applying hands-on GCP’s data tools like BigQuery, Pub/Sub, and DataFlow, and contributing to projects in an agile environment.","GCP, BigQuery, Pub/Sub, DataFlow, Apache Beam, Airflow, Cloud Storage, Python, SQL, Apache Airflow",6,Bachelor,True,6.0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0
"Data Support Analyst, Partner Managed Print Services",HP,Guadalajara,HYBRID,,Full-time,"Computer Hardware Manufacturing, Software Development, and IT Services and IT Consulting",2024-09-18 07:37:40.772871,25,Information Technology,,,"HP’s Partner Managed Print Services sales support team headquartered in Boise, Idaho is searching for a Partner Managed Print Services Datal Analyst. Primarily this role will support our US based Partner Managed Print Services team. No experience is required. Potential candidates must have strong communication skills and advanced Microsoft Excel skills. Applies Specialist level of subject matter knowledge to solve a variety of common business issues. Works on problems of moderately complex scope. Acts as an informed team member providing analysis of information and limited project direction input. Exercises independent judgment within defined practices and procedures to determine appropriate action. Follows established guidelines and interprets policies. Evaluates unique circumstances and makes recommendations. Qualifications Are As Follows Excellent organizational skills Excellent communication skills Attention-to-detail approach Great understanding of Microsoft Office products with a focus on Excel Uncompromising ability to meet deadlines Friendly and professional interpersonal skills In-depth research ability Ability to learn quickly and work hard in a fast-paced environment Willingness to be flexible with the work schedule Ability to focus on and work towards goal Demonstrates good questioning techniques and related communication skills. Developing and updating SharePoint sites will be required Developing and updating Power Automate flows Job Duties Will Include Pricing file maintenance Excel tools support Archiving contracts and amendments in DealSource Creating the financials for renewals Reporting for the business Partner reporting for business insights Partner validation on renewals Business planning preparation for major Partners Roster maintenance Contract reconciliation CBA Change Orders -utilizing MPC & DART to accomplish the CO same day or within 24 hours CBA Renewals - utilizing MPC & DART to accomplish the CO same day or within 24 hours Additional duties as determined Impact & Scope Impacts immediate team and acts as an informed team member providing analysis of information and limited project direction input. Complexity Responds to routine issues within established guidelines. Disclaimer This job description describes the general nature and level of work performed in this role. It is not intended to be an exhaustive list of all duties, skills, responsibilities, knowledge, etc. These may be subject to change and additional functions may be assigned as needed by management.",https://mx.linkedin.com/jobs/view/data-support-analyst-partner-managed-print-services-at-hp-4023788556,4023788556,"HP’s Partner Managed Print Services sales support team is searching for a Partner Managed Print Services Data Analyst. This role will support the US-based Partner Managed Print Services team. No experience is required, but candidates must have strong communication skills and advanced Microsoft Excel skills. The position involves providing analysis of information and limited project direction input, exercising independent judgment to determine appropriate actions, and following established guidelines. Responsibilities include maintaining pricing files, supporting Excel tools, archiving contracts, creating financials for renewals, and assisting with partner reporting and contract reconciliation.","Microsoft Excel, Microsoft Office, SharePoint, Power Automate",,,True,,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
Senior Data Scientist,AdventInfotech,Guadalajara,ON-SITE,Mid-Senior level,Full-time,"IT Services and IT Consulting, IT System Data Services, and Software Development",2024-09-18 07:37:58.348713,25,Consulting,"Analyst,",Engineering,"Data Scientist: We are seeking a highly motivated and skilled Data Scientist to join our dynamic team. The Data Scientist will play a crucial role in turning complex data into actionable insights that drive business decisions and innovation. This position involves analyzing large datasets, developing models, and delivering strategic recommendations to enhance our products and services. Skills Requirements: Bachelor's or Master's degree in Data Science, Statistics, Computer Science, Mathematics, or a related field. 6plus years experience in data analysis, machine learning, and predictive modeling. Proficiency in programming languages such as Python or R. Strong knowledge of machine learning frameworks and libraries (e.g., TensorFlow, scikit-learn, PyTorch). Experience with data visualization tools (e.g., Tableau, Power BI, Matplotlib, Seaborn). Excellent problem-solving skills and attention to detail. Effective communication and presentation skills. Ability to work in a collaborative team environment and independently. Experience with big data technologies and platforms (e.g., Hadoop, Spark, SQL, NoSQL). Knowledge of natural language processing (NLP) and deep learning. Familiarity with cloud computing platforms (e.g., AWS, Azure, Google Cloud). Previous industry experience in a data scientist or analytics role. What do we expect from you? Masters or Bachelor in CIS/ Engineering / Science / Mathematics / Statistics/ Design …etc Should have Cedula /Titulo Should have hands-on years of experience in any one of the above technology Advance English Speaking Ability to work independently Competitive Salary NOTE: We sponsor TN visas for qualified Mexican citizens. If you are interested in pursuing this opportunity then forward an updated Word copy of your resume in English. Our company runs on referrals and your referrals are always appreciated. If you can forward these emails to any of your friends that would be great. About Advent Infotech: Advent Infotech is a multinational IT services company with offices in 7 countries, including Mexico. Our clients mainly come from the United States. Our head office is located in New Jersey, USA Our delivery centers are located in six countries: India, Indonesia, Australia, Poland, Canada, and Mexico. Advent is led by great leadership with more than twenty years in the business. Our directors are highly ethical and come with a Harvard Business School education, serial entrepreneurs, and angel investors with long-standing business ethics. Advent's motto has always been to provide profitable technology solutions for our clients while creating value for our clients.",https://mx.linkedin.com/jobs/view/senior-data-scientist-at-adventinfotech-4028753234,4028753234,"We are seeking a highly motivated and skilled Data Scientist to analyze large datasets, develop models, and deliver strategic recommendations to enhance products and services, turning complex data into actionable insights that drive business decisions and innovation.","Python, R, TensorFlow, scikit-learn, PyTorch, Tableau, Power BI, Matplotlib, Seaborn, Hadoop, Spark, SQL, NoSQL, AWS, Azure, Google Cloud",6+ years,Bachelor,True,6.0,0,0,1,1,0,0,0,0,1,1,0,0,1,0,1,0,0
Principal Cloud Engineer- Oracle Analytics,Oracle,Guadalajara,ON-SITE,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-18 07:37:58.348713,25,Engineering,Information Technology,,"Job Description Applicants are required to read, write, and speak the following languages: English Role : Site Reliability Engineer Location : Guadalajara preferred Who are we looking for? The candidate will work with the skilled, highly motivated Oracle Analytics Service Excellence (OASE) team who embrace an agile work style. You will work alongside a software development team within the greater OAC organization where you will support existing features in the cloud as well as new operational processes, automation and content. You will play a key role in improving the processes supporting the OAC services, so the service functions more and more autonomously over time. Roles And Responsibilities Perform DevOps activities to support customers, engineers, and processes through our release cycles as well as production Participate in a follow-the-sun model for 24x7 support of Oracle Analytics services Respond to incidents, troubleshoot issues and drive to completion, driving and participate in root cause analysis Become expert in Analytic services, to prevent, resolve customer issues effectively and prevent regressions and repeats Document various processes & runbooks; update existing processes Execute, with excellence, delivery of interim patches and hotfixes as required Work with various teams to take ownership of and resolve service failure/outages. Monitor metrics and develop ways to improve the CI and CD tools utilized by the team Follow all best practices and procedures as established by the company Mentor and train other engineers and seek to continually improve processes Other duties as assigned The candidate must have knowledge and experience with: A BS or MS in Computer Science, or equivalent Knowledge of Oracle Analytics server, BI publisher, Oracle Analytics Cloud experience required. Providing cloud networking, infrastructure, and service support, configuration, operations, tools, and processes Understand networking, and TCP/IP fundamentals and services such as DNS, HTTP, etc. Linux/Unix system administration including system level knowledge of Linux on OCI Gen 2, creating and executing scripts Experience developing & operating cloud services or large distributed applications in production. Python, Ansible and other cloud Development skills are a plus Methodical approaches to troubleshooting and solving complex technical problems, reverse engineering existing applications. Producing documentation in support of developed work (KBs, run books, help guides) Utilizing agile methodologies Communicating effectively in a team environment Working with remote, global teams as well as individuals Working independently and in a self-directed manner Able to work extended week day and week-end shifts as required for on-call, after hours upgrades, and other duties as assigned. Responsibilities An ideal candidate will have the follow skillsets: 5+ years of experience of running large scale customer facing W eb Applications . Oracle Cloud Infrastructure (OCI) or AWS, Azure, GCP compute, storage, and network operational experience. Programming and scripting languages (Python, bash, Java Script - additional experience with PHP, Groovy, Java, and/or Go is a plus) Using CI/CD scripting tools such as Ansible, Puppet, or Chef Experience in Cloud Native application development using Containers and orchestration ( Kubernetes) independently scalable microservices Oracle database, Oracle Autonomous DB, MySQL (experience with MS SQL and/or NoSQL is a plus). Experience in REST API design and development using java technologies. Issue tracking and collaboration (Jira and Confluence). About Us As a world leader in cloud solutions, Oracle uses tomorrow’s technology to tackle today’s problems. True innovation starts with diverse perspectives and various abilities and backgrounds. When everyone’s voice is heard, we’re inspired to go beyond what’s been done before. It’s why we’re committed to expanding our inclusive workforce that promotes diverse insights and perspectives. We’ve partnered with industry-leaders in almost every sector—and continue to thrive after 40+ years of change by operating with integrity. Oracle careers open the door to global opportunities where work-life balance flourishes. We offer a highly competitive suite of employee benefits designed on the principles of parity and consistency. We put our people first with flexible medical, life insurance and retirement options. We also encourage employees to give back to their communities through our volunteer programs. We’re committed to including people with disabilities at all stages of the employment process. If you require accessibility assistance or accommodation for a disability at any point, let us know by calling +1 888 404 2494, option one. Disclaimer: Oracle is an Equal Employment Opportunity Employer*. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability and protected veterans’ status, or any other characteristic protected by law. Oracle will consider for employment qualified applicants with arrest and conviction records pursuant to applicable law. Which includes being a United States Affirmative Action Employer",https://mx.linkedin.com/jobs/view/principal-cloud-engineer-oracle-analytics-at-oracle-4027113204,4027113204,"The candidate will work with the Oracle Analytics Service Excellence (OASE) team, supporting existing features in the cloud, as well as new operational processes, automation, and content. Responsibilities include performing DevOps activities, participating in 24x7 support, troubleshooting incidents, documenting processes, monitoring metrics, and mentoring other engineers. A successful candidate will have knowledge of Oracle Analytics server, BI publisher, Oracle Cloud Infrastructure (OCI), programming languages such as Python and Bash, and experience in cloud native application development using containers and orchestration.","Python, Bash, JavaScript, Ansible, Oracle Analytics Server, Oracle Cloud Infrastructure, AWS, Azure, GCP, Kubernetes, Oracle Database, MySQL, REST API",5+ years,Bachelor,True,5.0,0,0,0,1,1,0,0,0,0,1,0,1,0,0,1,0,0
Principal Java Developer (Oracle Analytics),Oracle,Guadalajara,ON-SITE,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-18 07:37:58.348713,25,Engineering,Information Technology,,"Job Description Oracle Analytics is an industry-leading product that empowers entire organizations with a full range of business analytics tools, enterprise ready reporting and engaging, and easy-to-use self-service data visualizations. Our customers are business users that demand a software product that allows easy, fast navigation through the full spectrum of data scale from simple spreadsheets to analyzing enormous volumes of information in enterprise class data warehouses. Oracle Analytics is a comprehensive solution to meet the breadth of all analytics needs. Get the right data, to the right people, at the right time with analytics for everyone in your organization. With built-in security and governance, you can easily share insights and collaborate with your colleagues. By leveraging the cloud, you can scale up or down to suit your needs. The Oracle Analytics Cloud offering is a leading cloud service at Oracle built on Oracle Cloud Infrastructure. It runs with a Generation 2 offering and provides consistent high performance and unmatched governance and security controls. Self-service analytics drive business agility with faster time to insights. You no longer need help from IT to access, prepare, analyze, and collaborate on all your data. Easily create data visualizations with automated chart recommendations and optimize insights by collaborating with colleagues on analyses. Augmented analytics with embedded machine learning throughout the platform drive smarter and better insights. Always on—and always working in the background, machine learning is continuously learning from the data it takes in, making it smarter and more accurate as time goes by. Uncover deeper patterns and predict trends for impactful, unbiased recommendations. On the team we develop, deploy, and support the Oracle Analytics platform helping our customers succeed in their journey to drive business value. You will be working with experts in their field, exploring the latest technologies, you will be challenged while creating features that will be delivered to our customers, asked to be creative, and hopefully have some fun along the way. Members of our team are tasked to take on challenges along all aspect of our product. Key Qualifications : BS/MS in Computer Science or related major Exceptional analytic and problem-solving skills Solid understanding of object-oriented programming and MVVM principles Solid skills in Java and SQL programming. Good knowledge of data structures and operating systems. Prior experience with LLMs and generative AI technologies a plus. Experienced in distributed and scalable server-side software development. Knowledge in developing, implementing, and optimizing software algorithms. Prior experience utilizing JavaScript, HTML, CSS a plus. Basic understanding of Agile/Scrum development methodologies Hands-on experience using source control tools such as GIT Good written and verbal English communication skills. Self-motivated and passionate in developing high quality software. Strong Team Player. Other Qualifications : Knowledge of Business Intelligence or Analytics Experience using Python Familiarity with Cloud services such as OCI, AWS or Azure Career Level - IC4 Responsibilities Specific Responsibilities and Desired Qualifications As a member of the development team, you will design, code, debug, and deliver innovative analytic features that involve backend technologies such as Java/Python/C++ and frontend layers in JavaScript/HTML/CSS/SCSS. You will work closely with your peer developers located across the world, including Mexico, Europe, and the USA. Key responsibilities include: Design, develop, test and deliver new features on a world-class analytics platform suitable for deployment to both the Oracle Cloud and on-premise environments Lead the creation of formal design specifications and coding of complex systems Work closely with the Product Management on product requirements and functionality Build software applications following established coding standards Communicate continually with the project teams, explain progress on the development effort Contribute to continuous improvement by suggesting improvements to user interface, software architecture or recommending new technologies Ensure quality of work through development standards and QA procedures Perform maintenance and enhancements on existing software About Us As a world leader in cloud solutions, Oracle uses tomorrow’s technology to tackle today’s problems. True innovation starts with diverse perspectives and various abilities and backgrounds. When everyone’s voice is heard, we’re inspired to go beyond what’s been done before. It’s why we’re committed to expanding our inclusive workforce that promotes diverse insights and perspectives. We’ve partnered with industry-leaders in almost every sector—and continue to thrive after 40+ years of change by operating with integrity. Oracle careers open the door to global opportunities where work-life balance flourishes. We offer a highly competitive suite of employee benefits designed on the principles of parity and consistency. We put our people first with flexible medical, life insurance and retirement options. We also encourage employees to give back to their communities through our volunteer programs. We’re committed to including people with disabilities at all stages of the employment process. If you require accessibility assistance or accommodation for a disability at any point, let us know by calling +1 888 404 2494, option one. Disclaimer: Oracle is an Equal Employment Opportunity Employer*. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability and protected veterans’ status, or any other characteristic protected by law. Oracle will consider for employment qualified applicants with arrest and conviction records pursuant to applicable law. Which includes being a United States Affirmative Action Employer",https://mx.linkedin.com/jobs/view/principal-java-developer-oracle-analytics-at-oracle-4026506307,4026506307,"As a member of the development team, you will design, code, debug, and deliver innovative analytic features that involve backend technologies such as Java, Python, and C++, and frontend layers in JavaScript, HTML, CSS, and SCSS. Key responsibilities include designing, developing, testing, and delivering new features suitable for deployment to both the Oracle Cloud and on-premise environments. The role requires collaboration with peer developers globally and active engagement with product management on requirements and functionality.","Java, Python, C++, JavaScript, HTML, CSS, SCSS, SQL, GIT, Agile/Scrum, Machine Learning, Cloud services (OCI, AWS, Azure)",,Bachelor,True,,1,0,0,1,0,0,0,0,0,1,1,0,1,0,1,0,0
AI Solutions Developer (Python),Oowlish,Guadalajara,REMOTE,Entry level,Full-time,IT Services and IT Consulting,2024-09-19 02:10:45.124906,25,Engineering,Information Technology,,"Join Our Team Oowlish, one of Latin America's rapidly expanding software development companies, is seeking experienced technology professionals to enhance our diverse and vibrant team. As a valued member of Oowlish, you will collaborate with premier clients from the United States and Europe, contributing to pioneering digital solutions. Our commitment to creating a nurturing work environment is recognized by our certification as a Great Place to Work, where you will have opportunities for professional development, growth, and a chance to make a significant international impact. We offer the convenience of remote work, allowing you to craft a work-life balance that suits your personal and professional needs. We're looking for candidates who are passionate about technology, proficient in English, and excited to engage in remote collaboration for a worldwide presence. We are seeking a highly skilled Senior Python Developer with experience in Machine Learning and Artificial Intelligence. The ideal candidate will have recent hands-on experience in these areas and a proven track record of delivering high-quality technical projects. Must Have Advanced English skills, both written and verbal. Over 5 years of experience in Python development. Hands-on experience with Generative AI technologies (Langchain, Bedrock, prompt engineering, RAG, etc.). Proven experience in designing and implementing AI-driven solutions. Strong problem-solving skills and attention to detail. Excellent communication and collaboration skills. Ability to work independently and as part of a team. Benefits & Perks Home office; Flexible Hours Competitive compensation based on experience; Career plans to allow for extensive growth in the company; International Projects; Oowlish English Program (Technical and Conversational); Oowlish Fitness with Total Pass; Connecting You (Internet allowance); Anniversary bonus; Wedding gift; Pet adoption incentive; New baby Oowl bonus; Back to School bonus; Streaming Subscription; PTO Bonus; Games and Competitions; Enjoy your national Holidays. You Can Also Apply Here Website: https://www.oowlish.com/work-with-us/ LinkedIn: https://www.linkedin.com/company/oowlish/jobs/ Instagram: https://www.instagram.com/oowlishtechnology/",https://mx.linkedin.com/jobs/view/ai-solutions-developer-python-at-oowlish-4029401058,4029401058,"Join Oowlish as a Senior Python Developer with expertise in Machine Learning and Artificial Intelligence. You will collaborate with clients from the United States and Europe to deliver high-quality digital solutions. The ideal candidate should possess over 5 years of experience in Python, hands-on experience with Generative AI technologies, and proven skills in designing and implementing AI-driven solutions. Strong problem-solving skills and excellent communication abilities are essential.","Python, Machine Learning, Artificial Intelligence, Generative AI, Langchain, Bedrock, Prompt Engineering, RAG",5+ years,,True,5.0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0
QA Engineer - Data,InfoVision Inc.,Guadalajara,HYBRID,Mid-Senior level,Full-time,"IT Services and IT Consulting, Information Services, and Technology, Information and Media",2024-09-19 02:11:01.738886,25,Information Technology,,,"We’re looking for detail-oriented testers to use our QA team that validates the Inscape data and alert us of critical bugs and errors before actual users are affected. Required skills: 5+ years of proven experience in software engineering. Bachelor’s degree in computer science, Engineering, or equivalent experience. Proven experience as a QA Engineer with focus data/ETL pipeline testing, regression data testing. Experience in designing, developing, and automating tools for testing ETL pipelines Demonstrated experience in validating data and ETL pipelines to integrate new data into a data warehouse. Proven experience with one of BigData technologies such Pyspark, Pandas, Spark, Hadoop, Hive. Experience in writing Python scripts using PySpark for data processing and manipulation. Experience with creation/maintenance of data validation tools and frameworks Proficient in Python as well as AWS tools. Knowledge of data modeling concepts and ETL processes. Familiarity with data integration and data warehousing technologies such as Databricks/Snowflake. Experience with system integration testing, end-to-end testing, databases, CI/CD pipelines Ability to document and troubleshoot errors. Strong attention to detail and patience to track down difficult issues. Possessing an analytical mind, critical-thinking skills, and problem solving aptitude. Strong organizational skills and ability to meticulously follow detailed steps. Experience in creating robust test plans/strategies and test status for Big Data product deliverables. Excellent verbal and written communication skills. Willing and able to go above and beyond. Ability to work collaboratively across different divisions.",https://mx.linkedin.com/jobs/view/qa-engineer-data-at-infovision-inc-4027395038,4027395038,"We’re looking for detail-oriented testers to validate Inscape data, alerting us of critical bugs and errors before actual users are affected. Required skills include 5+ years of experience in software engineering, and a Bachelor’s degree in computer science, Engineering, or equivalent experience. Proven experience as a QA Engineer with a focus on data/ETL pipeline testing and regression data testing. Candidates should have experience designing, developing, and automating tools for testing ETL pipelines, validating data and ETL pipelines for data warehouse integration, and writing Python scripts using PySpark for data processing. Familiarity with Big Data technologies such as Pyspark, Pandas, Spark, Hadoop, Hive, as well as AWS tools and data modeling concepts is necessary. Knowledge of data integration and data warehousing technologies like Databricks/Snowflake is also required. Experience in system integration testing, end-to-end testing, databases, and CI/CD pipelines is a plus. Excellent communication skills and the ability to work collaboratively are essential.","Python, PySpark, Pandas, Spark, Hadoop, Hive, AWS, Databricks, Snowflake, ETL, CI/CD",5+ years,Bachelor,True,5.0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,1,0,0
Analyst Equipment Master Data,The Hershey Company,Guadalajara,ON-SITE,Entry level,Full-time,Manufacturing,2024-09-19 02:11:27.678646,25,Information Technology,,,"Job Title Equipment Master Data Analyst Reports to Master Data Owner, Transformation (HBP) Department TMO, Master Data Specialist Job Location Guadalajara Summary The Enterprise Master Data Management (EMDM) Equipment Master Data Specialist is accountable for two primary work streams in relation to new equipment / production line installation and existing equipment asset care strategy. The Equipment Master Data Specialist position is responsible for ensuring plants are equipped to minimize equipment downtime and increase asset life cycle by leading the development of equipment maintenance strategy, development of equipment bill of materials (BOM) and stocking strategy, as well as gathering and archieving equipment manuals and associated documentation. This role coordinates with the Plant Maintenance (Maintenance Planners, Reliability Leads, and Maintenance Managers) and Engineering PMO teams while being a steward of company policies, procedures, timelines and master data governance. For existing equipment, this role assists with the management of equipment data in order to improve and maintain timeliness and quality of the data. The role provides the specialist viewpoint when representing enterprise data and equipment strategy initiatives. This role specifically assists with the management SAP PM master data, technical objects, and equipment related documentation / attachments. The role will guide local and global resources to ensure the continuous improvement of business results through the implementation and management of standard processes, tools, and accountabilities. Responsibilities: Equipment Master Data Standards Governance Ensure adherence to the data governance policy for all equipment master data domains. Leverage existing and propose new technology solutions to improve workflow and master data creation, maintenance and archival. Oversight of maintaining equipment database in SAP to ensure equipment information, documentation, BOMs and PM Plans are standardized, accurate, and updated Supports by acting as “first line of defense” in fielding opportunities to improve data quality as well as resolving data issues. Targets opportunities to improve data quality, policy, and processes, and ownership. Identifies root causes of data quality problems within their assigned area of stewardship and identifies sustainable solutions. Ensures team members are kept informed of changes in data standards and processes. Incorporate industry best practices and tools based on emerging trends and changing business requirements. Benchmark and participate in sharegroups with other organizations in order to advance The Hershey Company’s capability Equipment Data Entry Setup and modify new and existing equipment to meet enterprise standards Work with Engineering and equipment OEM on projects during commissioning and validation to gather equipment specific data (i.e. OEM, Model, Serial #) and entering equipment numbers in SAP PM with linkage to Asset numbers. Assigning equipment numbers and descriptions and maintaining this equipment with the proper description and RAV. Create / process CARD forms, (Capital Asset Relocation & Disposal forms), in the system to remove equipment from plant Equipment Strategy Development Development / documentation of PM plans in SAP and attach the plans to the equipment Work with plants to ensure proper PM task list details (including work center, planner code, task frequency, and object lists) in relation to plant personnel structure, equipment maintainability, equipment production needs, and equipment environment. Obtain OEM recommended maintenance tasks, task steps, and frequency. The role should leverage existing PM plans to replicate and optimize like equipment strategy Propose new technology solutions to improve reliability or manufacturing equipment Coordinate with plants to ensure proper tools and training related to maintenance strategy deployment. Equipment Spare Parts Compile complete spare parts list with maintenance assembly (IBAU) structure. Obtain list of critical spares required for regular operation of equipment as recommended by OEM and plant maintenance personnel. Provide suggested plant stocking levels and subsequent HIBE requests Provide guidance for known obsolete parts Equipment Documentation Obtain OEM equipment manuals and troubleshooting guides Request addition plant specific guides and documentation related to equipment set up and maintenance Maintain equipment information libraries attached to equipment within SAP, enterprise document library, and/or local plant digital storage. Coordinate with Plant Maintenance to ensure documentation completeness. Minimum Knowledge And Skills Technical Skills General knowledge of manufacturing maintenance and reliability practices Strong computer skills with accuracy (Teams, Word, Outlook, Excel, Power BI) Microsoft Office skills (Excel analytics/pivot tables) Working knowledge of ERP (i.e. SAP PM) systems Knowledge of or ability to learn policies and procedures (i.e. Hershey Lean) Strong communication skills Strong attention to detail Analytical thinker Basic math skills Qualifications Intermediate knowledge level of ERP system, preferred SAP PM (ECC and S4/HANA) experience. Strong communication skills and tenacity (written and verbal). Must be willing and capable to support North American businesses real-time. (Eastern Time Zone) Capable of documenting and adhering to process discipline. Communication Skills Ability to work well with others as well as part of a team Sensitivity to other cultures and cultural differences Ability to handle multiple priorities Strong organizational skills Strong drive for results Education Accossiates's degree in a quantative field preferrable or equivalent relevant experience. Experience Minimum of 1-3 years with data maintenance of Customer, Vendor or Planner maintenance master data. Minimum of 1-3 years working in an ERP system.",https://mx.linkedin.com/jobs/view/analyst-equipment-master-data-at-the-hershey-company-4027894671,4027894671,"The Equipment Master Data Analyst is responsible for managing equipment master data and ensuring the accuracy and timeliness of data in relation to new equipment installations and existing equipment asset care strategies. This role involves developing maintenance strategies, managing equipment data within SAP PM, and coordinating with various teams to improve data quality and processes. The position requires strong analytical skills, attention to detail, and the ability to work collaboratively across different functions to support data governance and continuous improvement.","SAP PM, Microsoft Office, Excel, Power BI, ERP Systems",1-3 years,,True,1.0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
Business Intelligence Analyst,F5,Guadalajara,ON-SITE,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-19 02:11:27.678646,25,Research,"Analyst,",Information Technology,"At F5, we strive to bring a better digital world to life. Our teams empower organizations across the globe to create, secure, and run applications that enhance how we experience our evolving digital world. We are passionate about cybersecurity, from protecting consumers from fraud to enabling companies to focus on innovation. Everything we do centers around people. That means we obsess over how to make the lives of our customers, and their customers, better. And it means we prioritize a diverse F5 community where each individual can thrive. Job Summary: We are seeking a detail-oriented and data-driven Business Intelligence Analyst to join our team. In this role, you will be responsible for analyzing complex data, generating insightful reports, and supporting decision-making processes across the organization. You will work closely with various departments to identify business needs, develop analytical solutions, and drive strategic initiatives that enhance business performance. Key Responsibilities: Develop, implement, and maintain BI solutions using tools such as Tableau, Power BI, and Snowflake, ensuring the delivery of accurate and timely business insights. Design and manage complex SQL queries, stored procedures, and functions to support diverse business needs, ensuring optimal performance and data integrity. Perform data extraction, transformation, and loading (ETL) processes, integrating data from various sources into data warehouses, including Snowflake, for comprehensive reporting. Collaborate with cross-functional teams to gather business requirements, translating them into effective data models, reports, and dashboards that drive decision-making. Ensure the integrity, accuracy, and consistency of data by implementing best practices in relational database design, optimization, and data validation. Utilize APIs and scripting languages to automate data processes, streamline workflows, and enhance data manipulation capabilities. Provide advanced data analysis to identify trends, opportunities, and areas for improvement. Work with Microsoft Power Apps, Dataverse, and Microsoft Power Automate to support and enhance business process automation and data management. Continuously monitor and evaluate BI solutions, making improvements to meet evolving business needs and ensure the highest level of data quality. Support and train team members and stakeholders on the use of BI tools, fostering a data-driven culture within the organization. Qualifications: Bachelor’s degree in Software Engineering, Data Science, Computer Science, or a related field. Demonstrated experience as a Business Intelligence Analyst or in a similar analytical role, with the ability to handle large datasets and conduct complex data analyses. Proficiency in BI tools such as Tableau and Power BI. Strong SQL skills, with experience in data querying, manipulation, and management. Expertise in writing complex queries, stored procedures, and functions tailored to various business requirements. Solid understanding of relational database design and optimization. Familiarity with APIs and scripting for efficient data manipulation and transfer. Hands-on experience with ETL processes and data warehousing. Experience working with cloud-based data platforms such as Snowflake. Experience working with Microsoft Power Apps, Dataverse, and Microsoft Power Automate. Proficiency in programming languages such as Python. Exceptional analytical and problem-solving skills. Experience with advanced statistical analysis and predictive modeling is a plus. The Job Description is intended to be a general representation of the responsibilities and requirements of the job. However, the description may not be all-inclusive, and responsibilities and requirements are subject to change. Please note that F5 only contacts candidates through F5 email address (ending with @f5.com) or auto email notification from Workday (ending with f5.com or @myworkday.com) . Equal Employment Opportunity It is the policy of F5 to provide equal employment opportunities to all employees and employment applicants without regard to unlawful considerations of race, religion, color, national origin, sex, sexual orientation, gender identity or expression, age, sensory, physical, or mental disability, marital status, veteran or military status, genetic information, or any other classification protected by applicable local, state, or federal laws. This policy applies to all aspects of employment, including, but not limited to, hiring, job assignment, compensation, promotion, benefits, training, discipline, and termination. F5 offers a variety of reasonable accommodations for candidates. Requesting an accommodation is completely voluntary. F5 will assess the need for accommodations in the application process separately from those that may be needed to perform the job. Request by contacting accommodations@f5.com.",https://mx.linkedin.com/jobs/view/business-intelligence-analyst-at-f5-4029295900,4029295900,"We are seeking a detail-oriented and data-driven Business Intelligence Analyst to analyze complex data, generate insightful reports, and support decision-making processes. You will develop, implement, and maintain BI solutions using tools like Tableau, Power BI, and Snowflake, design and manage SQL queries, and perform data ETL processes. Collaboration with cross-functional teams to gather business requirements and translating them into data models is essential. The role involves ensuring data integrity, utilizing APIs for automation, and training stakeholders on BI tools.","Tableau, Power BI, Snowflake, SQL, ETL, Python, Microsoft Power Apps, Dataverse, Microsoft Power Automate, APIs",,Bachelor,True,,0,0,0,0,0,0,1,0,1,1,0,0,0,0,1,0,0
Data Scientist Senior - Credit,Digital@FEMSA,Mexico City Metropolitan Area,REMOTE,Mid-Senior level,Full-time,"Technology, Information and Internet",2024-08-25 11:36:38.320163,168,Engineering,Information Technology,,"Objective of the Rol: Plays a crucial role in leveraging advanced data science techniques to enhance credit-related decision-making processes. With 4 to 7 years of experience in data science, statistics, applied mathematics, actuarial science, or similar fields, play a key role in building models that predict credit risk, detect fraud, and find growth opportunities. Their expertise is critical in driving data-driven strategies that align with the organization's financial goals. Responsibilities typically include leading data collection and preprocessing efforts, conducting comprehensive exploratory data analysis, performing sophisticated statistical analyses, advanced feature engineering, model evaluation, and validation, deploying and monitoring models in production environments, and mentoring junior and mid-level data scientists. Expected to have deep expertise in machine learning algorithms, statistical techniques, and domain knowledge relevant to the organization. They lead projects aimed at improving organizational efficiency, identifying growth opportunities, and minimizing risks using machine learning. Overall, the goal is to utilize advanced data science methodologies and tools to solve complex problems, generate valuable insights, improve decision-making processes, and drive innovation, thereby contributing to the organization's success and growth. Required Knowledge and Experience: 4-7 years in data science, statistics, programming, or related fields, with extensive hands-on experience in data analysis, machine learning, and statistical modeling, with at least 2 years in roles specifically related to credit or finance. Bachelor's or Master's degree in Data Science, Statistics, Applied Mathematics, Actuarial Science, Computer Science, or a related discipline. Desirable: Advanced coursework or specialized training in machine learning, statistics, or data science. Experience leading and executing data science projects in diverse domains and working on a wide range of projects, from exploratory analysis to building and deploying advanced machine learning models and predictive analytics solutions. Proficiency in programming languages commonly used in data science, such as Python or R. Familiarity with libraries and frameworks like NumPy, Pandas, scikit-learn (Python), or tidyverse (R) for data manipulation, analysis, and modeling. Experience in advanced statistical techniques, including multivariate analysis, time series analysis, hypothesis testing, and experimental design. Ability to apply statistical methods to analyze complex datasets and derive meaningful insights. Extensive experience in developing, fine-tuning, and deploying machine learning models and predictive analytics solutions. Deep understanding of a wide range of machine learning algorithms, including supervised learning (e.g., linear regression, logistic regression, decision trees, random forests), unsupervised learning (e.g., clustering, dimensionality reduction), and ensemble methods (e.g., gradient boosting, bagging). Ability to select and apply appropriate algorithms to solve specific business problems. Knowledge of deep learning techniques and frameworks, such as neural networks, convolutional neural networks (CNNs), recurrent neural networks (RNNs), and deep reinforcement learning. Experience with deep learning libraries like TensorFlow, Keras, or PyTorch. Proficiency in SQL for querying, manipulating, and analyzing data stored in relational databases. Familiarity with NoSQL databases and other data storage solutions. Familiarity with big data technologies and frameworks, such as Apache Hadoop, Spark, and distributed computing systems. Ability to work with large-scale datasets and optimize algorithms for parallel processing and scalability. Strong analytical and problem-solving skills, with the ability to critically evaluate data and models, identify biases, and make data-driven decisions. Advanced skills in data visualization and storytelling, using tools like Matplotlib, Seaborn, ggplot2, Plotly, or Tableau. Ability to create clear and compelling visualizations to communicate complex findings to non-technical stakeholders. Substancial understanding of the industry in which the organization operates. Knowledge of industry-specific trends, regulations, and business processes. Ability to apply domain knowledge to contextualize data analysis findings and drive strategic decision-making. Understand and apply ethical considerations and best practices in data science, including data privacy, confidentiality, and bias mitigation. Ability to ensure ethical and responsible use of data in all data science activities. Digital FEMSA está comprometida con un lugar de trabajo diverso e inclusivo. Somos un empleador que ofrece igualdad de oportunidades y no discrimina por motivos de raza, origen nacional, género, identidad de género, orientación sexual, discapacidad, edad u otra condición legalmente protegida. Si desea solicitar una adaptación, notifique a su Reclutador.",https://mx.linkedin.com/jobs/view/data-scientist-senior-credit-at-digital%40femsa-4007310710,4007310710,"The role plays a crucial part in leveraging advanced data science techniques to enhance credit-related decision-making processes. Responsibilities include leading data collection, conducting exploratory data analysis, performing statistical analyses, advanced feature engineering, model evaluation, deployment in production environments, and mentoring other data scientists. The goal is to utilize advanced data science methodologies and tools to solve complex problems, generate insights, improve decision-making processes, and drive innovation.","Python, R, SQL, NumPy, Pandas, scikit-learn, TensorFlow, Keras, PyTorch, Apache Hadoop, Spark, Matplotlib, Seaborn, ggplot2, Plotly, Tableau",4-7,Bachelor,True,4.0,0,0,1,0,0,0,0,0,1,1,0,0,1,0,1,0,0
"Machine Learning Data Engineer, Associate",Cultivo,Mexico City Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Non-profit Organizations and Primary and Secondary Education,2024-09-08 11:36:38.320163,28,Engineering,Information Technology,,"Cultivo Land is seeking a talented Machine Learning Data Engineer to join our team. As a Machine Learning Data Engineer at Cultivo, you will play a crucial role in developing and maintaining our data pipeline and infrastructure to support our machine learning projects. You will work closely with environmental scientists and software engineers to ensure efficient data collection, storage, and processing. This role offers a unique opportunity to contribute to impactful projects that are focused on regenerating ecosystems and addressing environmental challenges. About Cultivo Land Cultivo Land is a nature-focused fintech company with a mission to drive investment in regenerative land projects. Our work encompasses climate change, biodiversity, and land degradation. At Cultivo, we believe that by investing in nature, we can create a sustainable and resilient future. We have a diverse, collaborative, and inclusive work culture, and we offer flexible working arrangements to our team members. Responsibilities Designing, building, and maintaining scalable and efficient data pipelines and infrastructure for machine learning models Implement data collection and feature engineering processes in Google Cloud Platform (GCP) Collaborating with data scientists and engineers to implement and deploy machine learning models Managing and optimizing data storage and retrieval systems (BigQuery, Dataflow, Vertex AI) Performing data preprocessing, feature engineering, and analysis Monitoring and optimizing data pipelines for performance and reliability Ensuring data quality and implementing data governance best practices Stay updated with the latest trends and technologies in machine learning and data engineering Requirements Candidates should have ... 2+ years of experience as a data engineer, machine learning engineer, or related role Strong programming skills in Python Experience with SQL and Big Data technologies such as GCP Bigquery, Streaming services, etc Knowledge of machine learning concepts and algorithms Experience with data preprocessing, feature engineering, and analysis Strong problem-solving and analytical skills Experience with data visualization tools Comfort working in a fully remote, distributed, global team Nice to have ... Bachelor's degree or above in Computer Science, Data Science, or a related field Experience with cloud platforms such as GCP Experience with geospatial data Knowledge of deep learning frameworks such as TensorFlow or PyTorch Interest in environmental science and sustainability Benefits The opportunity to grow as an Engineer and make a real impact around the world Competitive compensation package, including equity options and annual bonus Access to health insurance and retirement plan Remote-first setup, with flexible, cadenced in-person co-working days alongside hub-based teammates Flexible work hours with emphasis on results International office locations 6 months paid parental leave Flexible paid vacation Opportunities for personal and professional growth in an innovative and supportive environment Salary range $30,000 - $130,000 per year The specific salary offered will be determined based on factors such as a candidate's individual experience, qualifications, and skills. Cultivo is an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, cognitive diversity, national origin, family or parental status, veteran or disability status. Please contact careers@cultivo.land if you need special assistance during the recruiting process.",https://mx.linkedin.com/jobs/view/machine-learning-data-engineer-associate-at-cultivo-4019382147,4019382147,"Cultivo Land is seeking a talented Machine Learning Data Engineer to develop and maintain data pipelines and infrastructure to support machine learning projects. This role involves collaborating with environmental scientists and software engineers to ensure efficient data collection, storage, and processing. Responsibilities include designing and maintaining scalable data pipelines, implementing data collection and feature engineering in Google Cloud Platform, managing data storage systems, and monitoring data pipeline performance. Candidates should have 2+ years of experience in a related role, strong programming skills in Python, and experience with SQL and Big Data technologies.","Python, SQL, Google Cloud Platform, BigQuery, Dataflow, Vertex AI, TensorFlow, PyTorch",2+ years,Bachelor,True,2.0,0,0,1,1,0,0,0,0,0,1,0,0,1,0,1,0,0
Data Scientist,Virtualent,Mexico City Metropolitan Area,REMOTE,,Full-time,"Technology, Information and Internet",2024-06-17 11:36:38.320163,132,Engineering,Information Technology,,"Virtualent About Us: We’re a leading IT Staffing company, passionate about connecting top talent with exciting opportunities. We are looking for a Data Scientist with advanced skills in predictive modeling and machine learning to join our team. Responsibilities: Predictive Modeling and Machine Learning: Design, develop, and implement advanced models to predict outcomes and optimize processes. Exploratory Data Analysis: Conduct in-depth analysis to uncover hidden patterns and trends in large datasets. Experimentation: Design and conduct experiments to validate hypotheses and improve existing models. Innovation: Research and apply new machine learning and artificial intelligence techniques and algorithms. Multidisciplinary Collaboration: Work closely with data engineers, analysts, and other stakeholders to integrate data-driven solutions into business processes. Requirements: Education: Studies in Computer Science, Statistics, Mathematics, Physics, or a related field. Experience: In Data Science positions. Technical Skills: Experience with Python or R. Practical knowledge of machine learning frameworks (TensorFlow, PyTorch, Scikit-Learn). Experience with big data technologies like Apache Hadoop and Apache Spark. Familiarity with database management systems (NoSQL like MongoDB, advanced SQL like PostgreSQL). Experience with cloud platforms (AWS, Google Cloud Platform, Microsoft Azure). Proficiency in version control systems like Git. Proficiency with data visualization tools (D3.js, Plotly in addition to Tableau and Power BI). Advanced Knowledge: Proficiency in machine learning techniques, predictive analytics, and statistical modeling. Competencies: Advanced analytical thinking, ability to solve complex problems, and effective communication skills. English: Good written and oral english language skills. Benefits: A dynamic and collaborative work environment. Opportunities for professional growth and development. Flexible work arrangements and remote work possibilities. Competitive salary. Interested? Ready to take the next step in your IT career? Apply now and join our team of dedicated professionals who are making a difference in the IT world every day! Requirements: Requirements: Education: Studies in Computer Science, Statistics, Mathematics, Physics, or a related field. Experience: In Data Science positions. Technical Skills: Experience with Python or R. Practical knowledge of machine learning frameworks (TensorFlow, PyTorch, Scikit-Learn). Experience with big data technologies like Apache Hadoop and Apache Spark. Familiarity with database management systems (NoSQL like MongoDB, advanced SQL like PostgreSQL). Experience with cloud platforms (AWS, Google Cloud Platform, Microsoft Azure). Proficiency in version control systems like Git. Proficiency with data visualization tools (D3.js, Plotly in addition to Tableau and Power BI). Advanced Knowledge: Proficiency in machine learning techniques, predictive analytics, and statistical modeling. Competencies: Advanced analytical thinking, ability to solve complex problems, and effective communication skills. English: Good written and oral english language skills.",https://mx.linkedin.com/jobs/view/data-scientist-at-virtualent-3948027659,3948027659,"We are looking for a Data Scientist with advanced skills in predictive modeling and machine learning. Responsibilities include designing and implementing advanced models to predict outcomes, conducting in-depth exploratory data analysis, conducting experiments to validate hypotheses, applying new machine learning techniques, and collaborating with data engineers and analysts to integrate data-driven solutions into business processes.","Python, R, TensorFlow, PyTorch, Scikit-Learn, Apache Hadoop, Apache Spark, NoSQL, MongoDB, PostgreSQL, AWS, Google Cloud Platform, Microsoft Azure, Git, D3.js, Plotly, Tableau, Power BI",,,True,,0,0,1,1,0,0,0,0,1,1,0,1,1,0,1,0,0
AI Machine Learning Engineer,Welocalize,Mexico City Metropolitan Area,REMOTE,,Full-time,Translation and Localization,2024-09-12 11:36:38.320163,27,Engineering,Information Technology,,"As a trusted global transformation partner, Welocalize accelerates the global business journey by enabling brands and companies to reach, engage, and grow international audiences. Welocalize delivers multilingual content transformation services in translation, localization, and adaptation for over 250 languages with a growing network of over 400,000 in-country linguistic resources. Driving innovation in language services, Welocalize delivers high-quality training data transformation solutions for NLP-enabled machine learning by blending technology and human intelligence to collect, annotate, and evaluate all content types. Our team works across locations in North America, Europe, and Asia serving our global clients in the markets that matter to them. www.welocalize.com To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. The Machine Learning Engineer role is responsible for the design, development and implementation of machine learning solutions to serve our organization. This includes ownership or oversight of projects from conception to deployment with appropriate AWS services, Docker, MLFlow, and other. The role also includes responsibility for following best practices with which to optimize and measure the performance of our models and algorithms against business goals. Tasks and Responsibilities Design and develop machine learning models and algorithms for various aspects of the localization and business workflow processes, including machine translation, LLM fine tuning, and quality assurance Take ownership of key projects from definition to deployment, ensuring that they meet technical requirements and maintain momentum and direction until delivery Evaluate and select appropriate machine-learning techniques and algorithms to solve specific problems Implement and optimize machine learning models and technologies using Python, TensorFlow, and other relevant tools and frameworks Perform statistical analysis and fine-tuning using test results Deploy machine learning models and algorithms using appropriate techniques and technologies, such as containerization using Docker and deployment to cloud infrastructure Use AWS technologies (including but not limited to Sagemaker, EC2, S3) to deploy and monitor production environments Keep abreast of developments in the field, with a dedication to learning in the role Document diligently and communicate thoughtfully about ML experimentation, design, and deployment Project scope: Define and design solutions to machine learning problems. Integration with larger systems done with guidance of more-senior Success Indicators of a Machine Learning Engineer Effective Model Development: success is evident when the models developed are accurate, efficient, and align with project requirements Positive Team Collaboration: demonstrated ability to collaborate effectively with various teams and stakeholders, contributing positively to project outcomes Continuous Learning and Improvement: a commitment to continuous learning and applying new techniques to improve existing models and processes Clear Communication: ability to articulate findings, challenges, and insights to a range of stakeholders, ensuring understanding and appropriate Skills and Knowledge Ability to write robust, production-grade code in Python Excellent communication and documentation skills Strong knowledge of machine learning techniques and algorithms, including supervised and unsupervised learning, deep learning, and reinforcement learning Hands-on, high proficiency experience with machine learning frameworks such as TensorFlow, PyTorch, and Scikit-learn Experience with natural language processing (NLP) techniques and tools Strong communication and collaboration skills, with the ability to explain complex technical concepts to non-technical stakeholders Experience taking ownership of projects from conception to deployment, and mentoring more junior team members Hands-on experience with AWS technologies including EC2, S3, and other deployment strategies. Experience with SNS, Sagemaker a plus Experience with ML management technologies and deployment techniques, such as AWS ML offerings, Docker, GPU deployments, etc Education and Experience BS in Computer Science, Mathematics or similar field Master’s Degree is a plus 3+ years experience as a Machine Learning Engineer or similar role",https://mx.linkedin.com/jobs/view/ai-machine-learning-engineer-at-welocalize-4022226591,4022226591,"The Machine Learning Engineer role is responsible for the design, development, and implementation of machine learning solutions. Tasks include designing and developing machine learning models and algorithms, taking ownership of key projects from definition to deployment, and implementing and optimizing models using Python and TensorFlow. The engineer will use AWS technologies for deployment and monitor production environments while ensuring effective collaboration and communication with stakeholders.","Python, TensorFlow, Docker, AWS (Sagemaker, EC2, S3), MLFlow, PyTorch, Scikit-learn",3+ years,Bachelor,True,3.0,0,0,0,1,1,0,0,0,0,0,0,0,1,0,1,0,0
Senior Data Scientist,Fusemachines,Mexico City Metropolitan Area,REMOTE,Mid-Senior level,Contract,Internet Publishing,2024-08-16 11:36:38.320163,41,Engineering,Information Technology,,"About Fusemachines: Fusemachines is a leading AI strategy, talent, and education services provider. Founded by Sameer Maskey Ph.D., Adjunct Associate Professor at Columbia University, Fusemachines has a core mission of democratizing AI. With a presence in 4 countries (Nepal, United States, Canada, and Dominican Republic and more than 400 full-time employees). Fusemachines seeks to bring its global expertise in AI to transform companies around the world. About the Role: The position is a remote, 3 months contract-based engagement (with a possibility of extension), About you: 7+ years of experience in AI and machine learning, model building and strong coding skills in python Master's or Ph.D. degree in Computer Science, Statistics, Mathematics, or a related field Deep understanding of NLP including text classifier, re-ranker, topic modeling Experience working directly with large language models and Transformer based architectures including BERT, RoBERTa, T5 etc Working knowledge of applying recent LLMs including ChatGPT, GPT 3.5, OPT, BLOOM, etc Experience with reinforcement learning, prompt engineering, hallucination mitigation DevOps repos Debugging, building APIs and managing the algorithm flow across multiple work streams in one repo Experience working with large datasets and distributed computing systems (e.g., Hadoop, Spark) Excellent communicator, with the ability to translate complex technical concepts to non-technical stakeholders Strong work ethics and dedication to the project's success Strong problem-solving skills and the ability to think outside the box Collaborative behavior, ability to efficiently share code and knowledge and good teammates Responsibilities: Research, development, and implementation of algorithms and models to solve business challenges Design and execute experiments to evaluate the performance of models and iterate on them to achieve state-of-the-art results Utilize Large Language Models (LLM) or similar architectures to build scalable and efficient solutions Collaborate with software engineers to integrate solutions into production systems and ensure scalability and reliability Fusemachines is an Equal Opportunities Employer, committed to diversity and inclusion. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or any other characteristic protected by law. Powered by JazzHR jlYJ0PGwGV",https://mx.linkedin.com/jobs/view/senior-data-scientist-at-fusemachines-3996266806,3996266806,"The position is a remote, 3 months contract-based engagement requiring 7+ years of experience in AI and machine learning, model building, and strong coding skills in Python. A Master's or Ph.D. degree in Computer Science, Statistics, Mathematics, or a related field is required. The role includes deep understanding of NLP, experience with large language models and Transformer architectures, and knowledge of distributed computing systems. Responsibilities include research, development, and implementation of algorithms and models, designing and executing experiments, and collaborating with software engineers.","Python, NLP, BERT, RoBERTa, T5, ChatGPT, GPT 3.5, OPT, BLOOM, Hadoop, Spark, DevOps",7+,Masters,True,7.0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0
Machine Learning Engineer,Project Growth,Mexico City Metropolitan Area,REMOTE,Entry level,Contract,Marketing Services,2024-09-01 11:36:38.320163,25,Engineering,Information Technology,,"Our client is currently seeking an experienced Machine Learning Engineer to join their growing team and contribute to the development and optimization of the technical infrastructure and support enterprise-scale ML data pipelines and model hosting solutions. Location: Fully-Remote (Work from Home), 9 AM - 5 PM EST Key Responsibilities: ML Data Pipeline Support: Design, develop, and maintain enterprise-scale machine learning data pipelines and data licensing marketplace, ensuring efficient data flow and integration. Model Training Integration & Hosting: Integrate training pipelines for machine learning models and host ML models for low-latency interference. Full Stack Development: Contribute to full stack development with a focus on backend systems, ensuring seamless integration and functionality. Cross-Functional Collaboration: Work closely with cross-functional teams to gather requirements, provide technical insights, and ensure successful project execution. Communication and Analysis: Utilize excellent communication and analytical skills to effectively convey technical concepts and analyze complex problems. What Success Looks Like: Robust Pipelines: Successfully develop and maintain ML data pipelines that support enterprise-scale operations and enhance data processing efficiency. Efficient Model Hosting: Implement low-latency model hosting solutions that meet performance benchmarks and support business goals. Collaborative Impact: Contribute to successful cross-functional projects, enhancing team collaboration and achieving project milestones. Qualifications: Experience: 4+ years of experience in full-stack development with a focus on backend systems. Technical Skills: Proficiency in programming languages such as Python, JavaScript, and Java. ML Expertise: Experience with supporting enterprise-scale ML data pipelines and model hosting for low-latency inference. AWS Familiarity: Familiarity with AWS systems is a plus. Startup Experience: Prior experience in a startup environment is advantageous. Communication: Excellent verbal and written communication skills. Analytical Ability: Strong analytical skills for problem-solving and data analysis. Independence: Ability to work independently and demonstrate self-motivation. This role offers an exciting opportunity for a Machine Learning Engineer to contribute to cutting-edge projects in the field of AI and ML. If you are passionate about technology and eager to drive innovation, we invite you to apply and join our client’s forward-thinking team. Application Process: To be considered for this role these steps need to be followed: Fill in the application form Record a video showcasing your skill sets",https://mx.linkedin.com/jobs/view/machine-learning-engineer-at-project-growth-4010725214,4010725214,"Our client is currently seeking an experienced Machine Learning Engineer to contribute to the development and optimization of technical infrastructure and support enterprise-scale ML data pipelines and model hosting solutions. Key responsibilities include designing and maintaining machine learning data pipelines, integrating training pipelines for models, contributing to full stack development with a focus on backend systems, and collaborating with cross-functional teams. The role requires strong communication and analytical skills.","Python, JavaScript, Java, AWS",4+ years,,True,4.0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0
Data Scientist - Business Finance,Virtualent,Mexico City Metropolitan Area,REMOTE,,Contract,"Technology, Information and Internet",2024-06-17 11:36:38.320163,65,Engineering,Information Technology,,"Data Scientist – Business Finance Virtualent About Us: Hey there! We’re Virtualent, and we’re on the lookout for a talented Data Scientist to join our Finance Transformation team. We’re all about innovation and optimization, and we need someone who’s as passionate about data as we are. If you're ready to dive into the world of finance and make a real impact, keep reading! Job Description Highlights: As a Data Scientist focusing on Business Finance, you’ll be the go-to person for building predictive models using historical financial data and other client data. Your work will be central to our financial analysis and optimization efforts. We’re looking for someone who’s not just a numbers whiz but also a leader who can take the initiative and drive projects forward. Your goal? Predictive analytics with straightforward models that get the job done. Main Responsibilities: Data Analysis and Modeling: Develop and refine predictive models to support financial decision-making. Financial Process Optimization: Identify areas for improvement in financial processes and implement solutions. Data Management and Governance: Ensure the integrity and accuracy of financial data. Strategic Insights and Reporting: Translate data into actionable insights and present them to stakeholders. Continuous Learning and Development: Stay up-to-date with the latest trends and technologies in data science and finance. Required Skills: Strong analytical skills with proficiency in Python, R, SQL, and data visualization tools. Solid understanding of finance principles and experience with statistical analysis, machine learning, and predictive modeling. Excellent communication skills to translate complex findings for non-technical stakeholders. Ability to work effectively in cross-functional teams and manage multiple tasks in a fast-paced environment. Good written and oral English language skills. Desired Background: Bachelor’s degree in a quantitative field, master’s preferred. 3+ years of experience in data science or analytics, with a focus on finance. Leadership skills, professional maturity, and experience in finance are important. Why Join Us? We’re not just offering a job; we’re offering a chance to be part of something bigger. At Virtualent, you’ll work with a team of smart, dedicated professionals who are always pushing the envelope. Plus, you’ll get the chance to grow your skills and your career in a supportive environment. Ready to Apply? If you’re excited about the opportunity to make a real difference in the world of finance with your data science skills, we’d love to hear from you! Apply now and join our team of dedicated professionals who are making a difference in the IT world every day! Requirements: Required Skills: Strong analytical skills with proficiency in Python, R, SQL, and data visualization tools. Solid understanding of finance principles and experience with statistical analysis, machine learning, and predictive modeling. Excellent communication skills to translate complex findings for non-technical stakeholders. Ability to work effectively in cross-functional teams and manage multiple tasks in a fast-paced environment. Good written and oral English language skills.",https://mx.linkedin.com/jobs/view/data-scientist-business-finance-at-virtualent-3940210377,3940210377,"As a Data Scientist focusing on Business Finance, you will develop and refine predictive models to support financial decision-making, identify areas for improvement in financial processes, ensure the integrity and accuracy of financial data, and translate data into actionable insights for stakeholders.","Python, R, SQL, Data Visualization, Statistical Analysis, Machine Learning, Predictive Modeling",3+,Bachelor,True,3.0,0,0,0,0,0,1,0,0,0,1,0,0,1,0,1,0,0
"Principal Data Scientist, Predictive Modeling",Nielsen,Mexico City Metropolitan Area,REMOTE,,Full-time,Market Research and Business Consulting and Services,2024-09-01 11:36:38.320163,109,Engineering,Information Technology,,"At Nielsen, we believe that career growth is a partnership. You ultimately own, fuel and set the journey. By joining our team of nearly 14,000 associates, you will become part of a community that will help you to succeed. We champion you because when you succeed, we do too. Embark on a new initiative, explore a fresh approach, and take license to think big, so we can all continuously improve. We enable your best to power our future. Principal Data Scientist, Predictive Modeling What would make me a great candidate? You enjoy applying your skills to developing new models and processes for predictive modeling.  You are able to be both hands on in creating models and equally capable of overseeing the work of others as they apply the tools you have built to additional datasets.  You are familiar with survey research and recommendation engine models.  You are highly analytical and are able to defend the validity of your models by conducting hold-out analyses, and presenting the results in plain language to people outside of the Data Science industry.  You have a passion for continuous improvement, driving operational efficiency in the speed of modeling, the volume of compute power used, etc.  You’re excited to build new capabilities and help drive advancement of the business. Responsibilities: Design, test and implement recommendation engine models to turn sparse datasets into synthetic datasets.  This includes writing code from scratch.  Must be proficient with reading, manipulating and analyzing big data and writing new code to build models Prove model validity through analytic research (e.g. holdouts) and speak to predictive power internally and externally to clients as needed Use iterative modeling to determine the ideal parameters for the sparse data - e.g. minimum level of completeness, key required datapoints that drive higher predictive accuracy, minimum number of datapoints required for a given predicted variable, etc Using the analytic findings from ideal parameter exploration, consult with internal and external partners on the best way to source the ideal sparse data Support screening and hiring of other data scientists in the mid to long term future.  Support onboarding and development of more junior data scientist staff.  Serve as a subject matter expert for others internally and externally.  Provide technical assistance in predictive modeling methodologies, data manipulation, fusion, and modeling Define and implement a vision for scaling new models across increasingly larger datasets - driving for efficient speed, computer usage, etc Support automation for scaling routinized processes Support pilot programs for R&D purposes. Conduct tactical or strategic analyses to address business and customer opportunities Utilize tools such as Python, R, SPSS, etc. to perform complex data analysis, develop tools for automating procedures Develop, test, and implement high quality, modular python code that can be seamlessly integrated into an existing production system Develop and implement machine learning solutions to leverage big data from internal and external sources Assist with ad hoc analyses and projects Qualifications: Undergraduate or graduate degree in Mathematics, Statistics, Social Science, Engineering, Computer Science, Economics, Business or fields that employ rigorous data analysis and strong statistical skills 10+ years of relevant data science experience in implementing various types of modeling.  Prior experience with predictive modeling and specifically with recommendation engines is highly preferred Strong skills in Python and relevant packages, including but not limited to pytorch and familiarity with other scripting languages Knowledge of statistical tests and procedures such as Correlation, Regression, Hypothesis Testing, Segmentation Techniques, ANOVA, Chi-squared, Student t-test, and Time Series Familiarity with machine learning and data modeling techniques such as Decision Trees, Random Forests, Incremental Response Modeling, Scoring, SVM, Neural Networks, and Credit Scoring Strong critical thinking and creative problem solving skills Strong planning and organizational skills Strong verbal, presentation, and written skills and English fluency Demonstrated success and effectiveness working in a time-critical production environment Familiarity with SQL, Oracle or other relational database software including manipulation of large data sets Familiarity with BI, Spotfire, Tableau or other data visualization software and techniques Proficiency in MS Office suite (Excel, PowerPoint and Word) and/or Google Office Apps (Sheets, Docs, Slides, Gmail) Knowledge of Atlassian suite of software including Bitbucket, Confluence, Jira, Hipchat, Crucible and Fisheye Knowledge of Apache Spark ecosystem, Databricks, and AWS",https://mx.linkedin.com/jobs/view/principal-data-scientist-predictive-modeling-at-nielsen-4002960745,4002960745,"The Principal Data Scientist, Predictive Modeling will design, test, and implement recommendation engine models, applying skills to develop new models and processes for predictive modeling. The role includes writing code, analyzing big data, supporting hiring and onboarding of data scientists, and providing technical assistance in predictive modeling methodologies. Responsibilities also include consultations for sourcing ideal data, conducting strategic analyses, and scaling models for larger datasets.","Python, R, SPSS, SQL, Oracle, Apache Spark, Databricks, AWS, BI, Spotfire, Tableau, MS Office, Google Office Apps",10+ years,Undergraduate Student,True,10.0,0,0,1,1,0,0,0,0,1,1,0,0,0,0,1,0,0
Evergreen - Data Science Code Reviewer,TripleTen,Mexico City Metropolitan Area,REMOTE,Mid-Senior level,Part-time,E-Learning Providers,2024-09-01 11:36:38.320163,25,Engineering,Information Technology,,"About TripleTen TripleTen is a service that empowers individuals, regardless of their prior experience, to embark on the exciting and challenging journey of mastering tech professions. Our bootcamps focus on training students in software engineering, data science, business intelligence analytics, and QA engineering in a feasible and accessible way, ultimately leading them to thrive in a new career. Our mission is to ensure that every student has the opportunity to successfully master a new profession, find their purpose, and become a valuable member of the tech industry. TripleTen is a remote first organization mirroring our students who complete our bootcamps in a remote environment. Please submit Resumes / CV's in English** Please note that after applying for this position, you will be required to complete a test assignment. Successfully completing this assignment will be the first step in the interview process. ﻿ What We're Looking For For the Data Science program, we are looking for an experienced data scientist to review our students and help them successfully become professionals. What you will do: You will check students’ projects and provide them with feedback. You will be responsible for deciding whether the project gets accepted or if it needs to be improved through additional iterations. You will provide advice to students on how to improve the project according to industry standards and our program’s requirements, will point out errors and highlight what must be corrected. Requirements: Proficient English; Experience working as a DS specialist for 1+ years (experience with Python, basics of Machine Learning, advanced SQL knowledge); Ability to explain topics in Data Science in a way that is understandable for students (how to work with data, data visualisation, appropriate syntax); Readiness to dedicate at least 10 hours a week to review student code; Additional experience in deeper DS concepts (such as Computer Vision and Sentiment Analysis) would be an advantage. What we can offer you: Training in review and communication techniques; The ability to work alongside your primary job; Opportunities for networking with the DS professionals in our community; Cross-cultural, international work experience; Competitive payment which depends on the number of reviewed projects. Disclosures At this time we are unable to offer H1B sponsorship opportunities in the USA. This job description is not designed to contain a comprehensive listing of activities, duties, or responsibilities that are required. Nothing in this job description restricts management's right to assign or reassign duties and responsibilities at any time. TripleTen is an equal employment opportunity/affirmative action employer and considers qualified applicants for employment without regard to race, color, religion, sex, national original, age, religion, disability, marital status, sexual orientation, gender identity/expression, protected military/veteran status, or any other legally protected factor.",https://mx.linkedin.com/jobs/view/evergreen-data-science-code-reviewer-at-tripleten-4012939957,4012939957,"For the Data Science program, we are looking for an experienced data scientist to review our students and help them successfully become professionals. You will check students’ projects and provide them with feedback, decide whether the project gets accepted or needs improvement, and provide advice on improving projects according to industry standards. Additionally, you will guide students on data handling, data visualization, and necessary syntax and will be ready to dedicate at least 10 hours a week to review student code.","Python, Machine Learning, SQL, Data Visualization, Computer Vision, Sentiment Analysis",1+ years,,True,1.0,0,0,0,0,0,1,0,0,0,1,0,0,1,0,1,0,0
AI/ML and MLOps Field Engineer,Canonical,Mexico City Metropolitan Area,REMOTE,Entry level,Full-time,"Technology, Information and Internet",2024-09-01 11:36:38.320163,25,Engineering,Information Technology,,"Canonical is a leading provider of open source software and operating systems to the global enterprise and technology markets. Our platform, Ubuntu, is very widely used in breakthrough enterprise initiatives such as public cloud, data science, AI, engineering innovation and IoT. Our customers include the world's leading public cloud and silicon providers, and industry leaders in many sectors. The company is a pioneer of global distributed collaboration, with 1000+ colleagues in 70+ countries and very few roles based in offices. Teams meet two to four times yearly in person, in interesting locations around the world, to align on strategy and execution. The company is founder led, profitable and growing. We are hiring an AI/ML and MLOps Field Engineer to help global companies embrace AI in their business, using the latest open source capabilities on public and private cloud infrastructure, Linux and Kubernetes. Our team applies expert insights to real-world customer problems, enabling the enterprise adoption of Ubuntu, Kubeflow, MLFlow, Feast, DVC and related analytics, machine learning and data technologies. We are working to create the world's best open source data platform, covering traditional SQL databases and today's NoSQL data stores, as well as the machinery which turns data into insights and executable models. The people who love this role are software engineers who enjoy customer conversations and solving customer problems during the presales cycle. They are are developers who like to solve customer problems through architecture, presentations and training. Ubuntu is used by pretty much every enterprise in the world, in every industry. This is a fantastic opportunity to learn about the open source technology landscape and develop your business technology insights. You will see first hand in various industries how Linux - and Ubuntu in particular - is shaping innovation and changing the world for the better. This role is particularly suited to candidates with a technical background who are business minded and driven by commercial success. This role is on our global Field Engineering team and will work closely with enterprise sales leads. We are specifically looking for people interested in solving the most difficult problems in modern data architectures. Training LLMs on multiple K8s clusters deployed on a hybrid cloud infrastructure with GPU sharing across multiple teams? Processing 10M events in real time for financial transactions? Object detection on 10k parallel 4K video streams? These are the problems we solve day to day. Location: Most of our colleagues work from home. We are growing teams in EMEA, Americas and APAC time zones, so can accommodate candidates from almost any country. What your day will look like The global Field Engineering team members are Linux and cloud solutions architects for our customers, designing private and public cloud solutions fitting their workload needs. They are the cloud consultants who work hands-on with the technologies by deploying, testing and handing over the solution to our support or managed services team at the end of a project. They are also software engineers who use Python to develop Kubernetes operators and Linux open source infrastructure-as-code. Work across the entire Linux stack, from kernel, networking, storage, to applications Architect cloud infrastructure solutions like Kubernetes, Kubeflow, OpenStack, and Spark Deliver solutions either on-premise or in public cloud (AWS, Azure, Google Cloud) Collect customer business requirements and advise them on Ubuntu and relevant open source applications Grow a healthy, collaborative engineering culture in line with the company values Deliver presentations and demonstrations of Ubuntu Pro and AI/ML capabilities to prospective and current clients Liaise with product teams to give them feedback on requirements to influence roadmap Work collaboratively with your sales team to reach our common targets Global travel up to 25% of time for internal and external events and 25% to customer meetings What we are looking for in you Exceptional academic track record from both high school and university Undergraduate degree in a technical subject or a compelling narrative about your alternative chosen path Experience in data engineering, MLOps, or big data solutions deployment Experience with a relevant programming language, like Python, R, or Rust. Confidence to respectfully speak up, exchange feedback, and share ideas without hesitation Track record of going above-and-beyond expectations to achieve outstanding results Demonstrated personal interest in continuous learning and development Practical knowledge of Linux, virtualisation, containers and networking Business-minded technology thinker and problem solver Knowledge of cloud computing concepts & leaders, such as Kubernetes, AWS, Azure, GCP Interest in large-scale enterprise open source - private clouds, machine learning and AI, data and analytics Intermediate level Python programming skills Passion for technology evidenced by personal projects and initiatives The work ethic and confidence to shine alongside motivated colleagues Professional written and spoken English with excellent presentation skills Experience with Linux (Debian or Ubuntu preferred) Excellent interpersonal skills, curiosity, flexibility, and accountability A dynamic person who loves to jump in new projects and interact with people Appreciative of diversity, polite and effective in a multi-cultural, multi-national organisation Thoughtfulness and self-motivation Result-oriented, with a personal drive to follow up and meet commitments Ability to travel internationally, for company events up to two weeks long, and customer or industry meetings What you'll learn Architect and deploy AI/ML infrastructures, data processing pipelines and multi-cluster distributed training Wide range of open source applications and skills Work directly with customers in a range of different businesses Real-life and hands-on exposure to a wide range of emerging technologies and tools What we offer colleagues We consider geographical location, experience, and performance in shaping compensation worldwide. We revisit compensation annually (and more often for graduates and associates) to ensure we recognise outstanding performance. In addition to base pay, we offer a performance-driven annual bonus or commission. We provide all team members with additional benefits, which reflect our values and ideals. We balance our programs to meet local needs and ensure fairness globally. Distributed work environment with twice-yearly team sprints in person Personal learning and development budget of USD 2,000 per year Annual compensation review Recognition rewards Annual holiday leave Maternity and paternity leave Employee Assistance Programme Opportunity to travel to new locations to meet colleagues Priority Pass, and travel upgrades for long haul company events About Canonical Canonical is a pioneering tech firm at the forefront of the global move to open source. As the company that publishes Ubuntu, one of the most important open source projects and the platform for AI, IoT and the cloud, we are changing the world of software. We recruit on a global basis and set a very high standard for people joining the company. We expect excellence - in order to succeed, we need to be the best at what we do. Most colleagues at Canonical have worked from home since its inception in 2004. Working here is a step into the future, and will challenge you to think differently, work smarter, learn new skills, and raise your game. Canonical is an equal opportunity employer We are proud to foster a workplace free from discrimination. Diversity of experience, perspectives, and background create a better work environment and better products. Whatever your identity, we will give your application fair consideration.",https://mx.linkedin.com/jobs/view/ai-ml-and-mlops-field-engineer-at-canonical-4013779145,4013779145,"We are hiring an AI/ML and MLOps Field Engineer to help global companies embrace AI using the latest open source capabilities on public and private cloud infrastructure. The role involves applying expert insights to real-world customer problems, enabling enterprise adoption of Ubuntu, Kubeflow, MLFlow, Feast, and related analytics technologies.","Python, R, Rust, Kubernetes, AWS, Azure, Google Cloud, Linux, OpenStack, Spark, Kubeflow, MLFlow, Feast, DVC",,Undergraduate Student,True,,0,0,1,1,1,0,0,0,0,0,0,1,1,0,1,0,0
Machine Learning Engineer,EPAM Systems,Mexico City Metropolitan Area,REMOTE,Entry level,Full-time,Software Development and IT Services and IT Consulting,2024-09-13 11:36:38.320163,25,Engineering,Information Technology,,"Join EPAM as a Machine Learning Engineer. In this role, you'll design and optimize GenAI prompts, automate complex workflows, and process large volumes of data. If you have an understanding of GenAI prompts, proficiency in coding with SQL and Python, and experience in API integration and development, we'd love to hear from you. Responsibilities Design and optimize GenAI prompts using prompt engineering techniques for productivity tools Leverage GenAI to automate complex workflows and process large volumes of data quickly and accurately Develop and integrate APIs to build robust interfaces between the GenAI platform and productivity tools Collaborate with BCG and client leaders to implement AI solutions Use analytics to measure the impact of AI on productivity and drive continuous improvement (optional) Requirements Understanding of design and optimization of GenAI prompts using prompt engineering techniques Skills in leveraging GenAI to automate complex workflows and process large volumes of data Proficiency in coding with SQL and Python Experience in API integration and development for building robust interfaces Ability to work in collaboration with BCG and client leaders Nice to have JavaScript or any UI experience Experience with Marketing Media Technologies GenAI platforms (e.g., Enterprise ChatGPT) Retool (preferred) SQL, Python Databricks We offer Career plan and real growth opportunities Unlimited access to LinkedIn learning solutions International Mobility Plan within 25 countries Constant training, mentoring, online corporate courses, eLearning and more English classes with a certified teacher Support for employee’s initiatives (Algorithms club, toastmasters, agile club and more) Enjoyable working environment (Gaming room, napping area, amenities, events, sport teams and more) Flexible work schedule and dress code Collaborate in a multicultural environment and share best practices from around the globe Hired directly by EPAM & 100% under payroll Law benefits (IMSS, INFONAVIT, 25% vacation bonus) Major medical expenses insurance: Life, Major medical expenses with dental & visual coverage (for the employee and direct family members) 13 % employee savings fund, capped to the law limit Grocery coupons 30 days December bonus Employee Stock Purchase Plan 12 vacations days plus 4 floating days Official Mexican holidays, plus 5 extra holidays (Maundry Thursday and Friday, November 2nd, December 24th & 31st) Monthly non-taxable amount for the electricity and internet bills By applying to our role, you are agreeing that your personal data may be used as in set out in EPAM´s Privacy Notice and Policy. EPAM is a leading global provider of digital platform engineering and development services. We are committed to having a positive impact on our customers, our employees, and our communities. We embrace a dynamic and inclusive culture. Here you will collaborate with multi-national teams, contribute to a myriad of innovative projects that deliver the most creative and cutting-edge solutions, and have an opportunity to continuously learn and grow. No matter where you are located, you will join a dedicated, creative, and diverse community that will help you discover your fullest potential.",https://mx.linkedin.com/jobs/view/machine-learning-engineer-at-epam-systems-4024719849,4024719849,"Join EPAM as a Machine Learning Engineer. In this role, you'll design and optimize GenAI prompts, automate complex workflows, and process large volumes of data. Responsibilities include designing prompts using prompt engineering techniques for productivity tools, leveraging GenAI for automation, developing and integrating APIs, collaborating with leaders to implement AI solutions, and using analytics to measure AI impact on productivity.","Python, SQL, API Development, Prompt Engineering, GenAI, JavaScript, Retool, Databricks",,,True,,0,0,1,0,0,0,0,0,0,1,0,0,0,0,1,0,0
Senior Data Scientist,LLYC,Mexico City Metropolitan Area,REMOTE,,Other,Public Relations and Communications Services,2024-09-01 11:36:38.320163,25,Engineering,Information Technology,,"LLYC es una firma global de Corporate Affairs y Marketing, que trabaja como partner de sus clientes en materia de creatividad, influencia e innovación, con el objetivo de hacer crecer y proteger el valor de sus negocios, convirtiendo cada día en una oportunidad para nutrir sus marcas. Para nuestras oficinas de México, Colombia o Perú, buscamos incorporar a un Senior Data Scientist. ¿QUÉ OFRECEMOS? Un entorno de trabajo dinámico y colaborativo con clientes globales. Participación en proyectos innovadores en el campo de la inteligencia artificial y análisis de datos. Oportunidades de crecimiento profesional en una empresa líder en su sector. PRINCIPALES FUNCIONES Desarrollo de Modelos con Python: Utiliza bibliotecas avanzadas como Pandas, Scikit-learn, Tensorflow, Pytorch y Spacy para crear modelos que impulsen la toma de decisiones estratégicas. Visualización de Datos: Transforma datos complejos en visualizaciones claras y persuasivas utilizando herramientas como Power BI, Looker Studio y Tableau. Experiencia en la Nube - Google Cloud: Implementa, gestiona y optimiza soluciones de análisis de datos en Google Cloud para garantizar la escalabilidad y eficiencia. Entendimiento y Traducción de Requerimientos del Cliente: Colabora con clientes internos y externos, comprendiendo sus necesidades y proponiendo soluciones efectivas. Habilidad de Documentación e Investigación: Desarrolla y documenta procesos, asegurando que las soluciones propuestas estén alineadas con los objetivos del cliente. Atención al Cliente y Propuesta de Soluciones: Atiende a clientes globales proponiendo soluciones de IA y análisis de datos que se ajusten a sus necesidades. Análisis de Big Data: Lidera proyectos de análisis de grandes volúmenes de datos, proporcionando insights valiosos para la estrategia empresarial. Desarrollo de Soluciones de IA: Diseña e implementa soluciones de inteligencia artificial que optimicen procesos y mejoren la eficiencia operativa. Gestión de Proyectos: Coordina y ejecuta proyectos de análisis de datos, asegurando su entrega en tiempo y forma. ¿QUÉ NECESITAMOS? 4 a 5 años de experiencia en Data Science o roles similares. Dominio avanzado de Python y bibliotecas de machine learning. Experiencia sólida en herramientas de visualización de datos (Power BI, Looker Studio, Tableau). Conocimientos avanzados en Google Cloud y gestión de datos en la nube. Inglés avanzado, capaz de trabajar en un entorno global. QUÉ VALORAMOS: Solución de Problemas Complejos: Capacidad para abordar y resolver problemas técnicos y de negocio de alta complejidad. Personalidad Analítica: Enfoque riguroso y detallado para el análisis de datos y la interpretación de resultados. Excelente Comunicación: Habilidad para comunicar eficazmente con clientes internos y externos, facilitando la comprensión y aplicación de soluciones. Si tienes gran capacidad de trabajo en equipo, orientación a resultados e ilusión por los nuevos retos, ¡te estamos esperando! En LLYC creemos en la diversidad e inclusión. Estamos comprometidos en promover un lugar y ambiente de trabajo diverso e incluyente, en el cual todo nuestro personal, sin importar su género, edad, origen étnico, condición social o económica, orientación sexual, expresión o identidad de género, condición física o de salud, religión, afiliación política, o cualquiera otra diferencia o condición, tenga la oportunidad real de desarrollarse y alcanzar su potencial.",https://mx.linkedin.com/jobs/view/senior-data-scientist-at-llyc-4010107323,4010107323,"LLYC is looking for a Senior Data Scientist for its offices in Mexico, Colombia, or Peru. The main responsibilities include developing models with Python using advanced libraries like Pandas, Scikit-learn, Tensorflow, Pytorch, and Spacy to support strategic decision-making. The role involves data visualization, transforming complex data into clear and persuasive visuals using tools like Power BI, Looker Studio, and Tableau. Additional tasks include cloud experience with Google Cloud to implement and optimize data analysis solutions, understanding and translating client requirements, and leading big data analysis projects. The candidate will also design and implement AI solutions to optimize processes and enhance operational efficiency, ensuring project coordination and delivery.","Python, Pandas, Scikit-learn, Tensorflow, Pytorch, Spacy, Power BI, Looker Studio, Tableau, Google Cloud, Big Data",4 to 5 years,,True,4.0,0,0,1,1,0,0,0,0,1,0,0,0,0,0,1,0,0
Data Science Tutor LATAM,TripleTen,Mexico City Metropolitan Area,REMOTE,Mid-Senior level,Part-time,E-Learning Providers,2024-09-08 11:36:38.320163,25,Education,Training,,"📚 TripleTen is a service that empowers individuals, regardless of their prior experience, to embark on the exciting and challenging journey of mastering tech professions. Our bootcamps focus on training students in software engineering, data science, business intelligence analytics, and QA engineering in a feasible and accessible way, ultimately leading them to thrive in a new career. 🧠 Our mission is to ensure that every student has the opportunity to successfully master a new profession, find their purpose, and become a valuable member of the tech industry. Please submit all resumes or CV's in English. Please note that after applying for this position, you will be required to complete a test assignment after your Online Introductory Call. 🚀 Who we're looking for: For the Data Science and Data Analytics program, we are looking for a data scientist to support our students' educational process and help them successfully become professionals. What you will do: You will lead a cohort of students through our Data Science and Data Analytics programs while sharing your experience and inspiring them with your industry knowledge. You will help students by answering questions and by giving them practical advice in the following forms: Video webinars (once-twice a week); Chats with students; Live-coding sessions (1 live session every 2 weeks); Moderating and consulting colleagues in the student experience team (reviewers, tutors) And most importantly, you'll be someone that your students will look up to!? Requirements: Experience working as an analyst using Python 🐍 Experience working with machine learning projects for more than a year; Familiar with the Pandas, NumPy, Matplotlib, Sklearn libraries; Readiness to dedicate at least 10 hours a week to mentor students; Intermediate English(B2), Native Spanish speaker. What we can offer you: Training in mentoring and communication techniques; The ability to teach students while performing your primary job; Sharing experience with developers in our community; Tangible results measured by the percentage of students who find a job after completing one of our courses. Cross-cultural collaboration experience in mentoring and conducting webinars; Payment of 20 USD per hour; Remote cooperation with a schedule that’s convenient for you and the team. There isn’t a focus on micromanaging; A comfortable digital office. We use modern digital tools — Miro, Notion, Zoom, etc. — to make working together process seamless; Diverse and tight-knit team which is spread out across the US, Israel, and LatAm! Disclosures: TripleTen is an equal employment opportunity/affirmative action employer and considers qualified applicants for employment without regard to race, color, religion, sex, national original, age, religion, disability, marital status, sexual orientation, gender identity/expression, protected military/veteran status, or any other legally protected factor.",https://mx.linkedin.com/jobs/view/data-science-tutor-latam-at-tripleten-4017680320,4017680320,"We are looking for a data scientist to support our students' educational process in the Data Science and Data Analytics programs. You will lead a cohort of students by sharing your experience, conducting video webinars, and providing practical advice through live-coding sessions and chats.","Python, Pandas, NumPy, Matplotlib, Sklearn, Machine Learning",1+,,True,1.0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,1,0,0
"Principal Engineer, Deep Learning",Outrider,Mexico City Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Software Development,2024-09-01 11:36:38.320163,75,Engineering,Information Technology,,"The Company Outrider is a software company that is automating distribution yards with electric, self-driving trucks. Our system eliminates manual tasks that are hazardous and repetitive while it improves safety and efficiency. Outrider’s mission is to drive the rapid adoption of sustainable freight transportation. We are a private company founded in 2018 and backed by NEA, 8VC, Koch Disruptive Technologies, and other top-tier investors. Our customers are Fortune 200 companies and our autonomous trucks are already running in distribution yards. For more information, visit www.outrider.ai The Role Outrider is an ambitious company that aims to solve autonomous vehicles for yard/warehouse operation. We are building a special electric truck that can achieve complex maneuvers in huge warehouses, among traffic, people and other complicated settings. This is not your generic autonomous vehicle product: we have a specific setting, specific hardware and specific customers. We have great financial backing, a clear product in mind and a highly competent engineering team. Now, we want to expand on critical hires. We are looking for a Principal ML/Deep Learning Engineer that is able to steer and execute the technical strategy for our deep learning stack in our autonomous vehicle. You will work with a great engineering team that is highly motivated to make this a reality and a leadership that is laser focused on a product. Duties & Responsibilities Devise solutions and design neural networks for perception that run online on our autonomous vehicle Provide technical and theoretical guidance to the deep learning team Communicate and distill evaluations and results to the leadership Help to design/improve our key deep learning tools: data, evaluation, compute Lead cross functional efforts with respect to interfacing with the other autonomy consumers and upstream/downstream components Required Qualifications Bachelor/Master in CS or equivalent Three years of engineering experience in deep learning oriented teams Mastering modern DL and python-related frameworks: Pytorch/Tensor Flow, Numpy, Scikit. Familiar with respect to DL state of the art, practices and recent research Able to design ML models from scratch: problem definition, data, model bring-up, debugging, evaluation and deployment Excellent communication skills for leadership and stakeholders Compensation & Benefits Competitive Salary Package Ownership of projects from day one, highly collaborative teams and a dynamic work environment 100% Remote work set up, flexible work schedule (Flex time - off policy) Annual career development stipend to support and encourage your career growth Allowance for home office set up Business traveling in our headquarters in Denver, Colorado (3-4 times/year) to stay connected with the team At Outrider, we believe in cultivating an environment where there is diversity of perspectives, experiences, and knowledge with the expectation that we thrive in an inclusive environment. Outrider is committed to a workforce where everyone's opportunities are limitless regardless of race, national origin, gender, age, religion, disability, veteran status, or any others that are protected by law. To protect yourself against the increasing number of recruiting scams, please make sure that you are communicating with Outrider Technologies, Inc. or one of its employees. The only way to communicate with us is through our corporate website at www.outrider.ai , through corporate emails utilizing our domain name of @ outrider.ai , and through our job board at jobs.lever.co/outrider . Be vigilant when checking domains because imitators often make very small changes to trick the eye. Additionally, please know that Outrider does not use text messaging or public messaging platforms, such as Telegram or Whatsapp, to communicate with candidates and Outrider will never ask an employment candidate for financial information or for payment of any kind.",https://mx.linkedin.com/jobs/view/principal-engineer-deep-learning-at-outrider-3866468425,3866468425,"Outrider is looking for a Principal ML/Deep Learning Engineer to steer and execute the technical strategy for the deep learning stack in autonomous vehicles. Responsibilities include designing neural networks for perception, providing technical guidance to the deep learning team, and improving key deep learning tools.","Python, Pytorch, TensorFlow, NumPy, Scikit-learn",3 years,Bachelor,True,3.0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0
Senior ML/AI Engineer,EPAM Systems,Mexico City Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Software Development and IT Services and IT Consulting,2024-09-13 11:36:38.320163,25,Engineering,Information Technology,,"We are seeking a Senior ML/AI Engineer to join our Data Center Solutions (DCS) department. The ideal candidate will leverage their expertise in Machine Learning and Artificial Intelligence to automatically detect known failure patterns and enhance the productivity of our testing team. This role involves collaborating with our team to develop a robust cloud strategy and scalable cloud operations, ensuring efficient processing and analysis of on-prem datasets using cloud technologies. Responsibilities Review and evaluate the client’s on-premise server setup and datasets Facilitate the packaging of on-premise datasets and their migration to the Azure cloud environment Develop a working Azure environment from scratch, aimed at POC/MVP development Provision on-premise infrastructure for the EPAM development team if Azure provisioning faces delays Collaborate with the team to formulate and execute a long-term cloud strategy connecting on-premise data generating environments to the cloud Scale up cloud-based operations and optimize data processing and AI model training Identify opportunities for automating test failure detection using advanced ML/AI techniques Continuously update and maintain AI models based on new failure patterns and data insights Document AI solutions and provide support to the deployment team during AI integration Conduct research on the latest ML/AI technologies and methods to enhance system capabilities Requirements Background in deploying and managing applications on cloud platforms, with a focus on Azure Containers, Azure File Storage, and Azure Firewall Expertise in Azure Identity, Azure Migrate and Azure Networking Proficiency in building and maintaining AI models, and in utilizing ML techniques for predictive analysis Knowledge of programming languages including Python, R, and SQL Understanding of data engineering concepts and experience in handling large datasets Capability to develop AI solutions from concept through production in a cross-functional team Qualifications in Computer Science, Engineering, Mathematics, or related field Strong problem-solving skills and ability to work independently as well as collaboratively Nice to have Familiarity with Azure Batch, Azure Databricks, and Azure Endpoint Protection We offer Career plan and real growth opportunities Unlimited access to LinkedIn learning solutions International Mobility Plan within 25 countries Constant training, mentoring, online corporate courses, eLearning and more English classes with a certified teacher Support for employee’s initiatives (Algorithms club, toastmasters, agile club and more) Enjoyable working environment (Gaming room, napping area, amenities, events, sport teams and more) Flexible work schedule and dress code Collaborate in a multicultural environment and share best practices from around the globe Hired directly by EPAM & 100% under payroll Law benefits (IMSS, INFONAVIT, 25% vacation bonus) Major medical expenses insurance: Life, Major medical expenses with dental & visual coverage (for the employee and direct family members) 13 % employee savings fund, capped to the law limit Grocery coupons 30 days December bonus Employee Stock Purchase Plan 12 vacations days plus 4 floating days Official Mexican holidays, plus 5 extra holidays (Maundry Thursday and Friday, November 2nd, December 24th & 31st) Monthly non-taxable amount for the electricity and internet bills By applying to our role, you are agreeing that your personal data may be used as in set out in EPAM´s Privacy Notice and Policy. EPAM is a leading global provider of digital platform engineering and development services. We are committed to having a positive impact on our customers, our employees, and our communities. We embrace a dynamic and inclusive culture. Here you will collaborate with multi-national teams, contribute to a myriad of innovative projects that deliver the most creative and cutting-edge solutions, and have an opportunity to continuously learn and grow. No matter where you are located, you will join a dedicated, creative, and diverse community that will help you discover your fullest potential.",https://mx.linkedin.com/jobs/view/senior-ml-ai-engineer-at-epam-systems-4024722079,4024722079,"We are seeking a Senior ML/AI Engineer to leverage expertise in Machine Learning and Artificial Intelligence to detect known failure patterns and enhance testing team productivity. The role involves developing a robust cloud strategy, facilitating dataset migration to Azure, and optimizing cloud operations. Key responsibilities include evaluating on-premise server setups, developing AI solutions, maintaining AI models, and conducting research on the latest ML/AI technologies.","Azure, Python, R, SQL, ML Techniques, Data Engineering, Azure Containers, Azure File Storage, Azure Firewall, Azure Identity, Azure Migrate, Azure Networking",,,True,,0,0,0,1,0,1,1,0,0,1,0,0,0,1,1,0,0
Fullstack Developer to an AI Consulting Company,rocket code,Mexico City Metropolitan Area,REMOTE,Entry level,Full-time,Non-profit Organizations and Primary and Secondary Education,2024-09-12 11:36:38.320163,29,Engineering,Information Technology,,"Join the AI Revolution with rocket code! At rocket code, we're not just developers — we're dreamers, doers, and disruptors. We are at the forefront of making AI work for you, turning market buzz into groundbreaking realities. Our AI-first approach is revolutionizing the tech landscape, and we need passionate individuals to join us on this exciting journey. Why rocket code? Imagine being part of a team that is not only leading the digital frontier but also redefining it. With our global presence in Mexico, the United States, Spain, and soon Brazil, we offer a dynamic environment where innovation and creativity thrive. We've developed over 100 platforms across various industries, including fintech, insurtech, energy, manufacturing, telecommunications, and e-commerce. At Rocket Code, every day is an opportunity to push boundaries and create impactful solutions. Our mission is to transform existing technology into digital experiences that generate a profoundly positive impact. We aim to be the constellation that guides the digital universe, illuminating paths to authentic progress and prosperity for our clients and their communities. Every solution we create is a shining star of innovation and excellence. Our Commitment: At rocket code, we believe in the power of technology to create a positive societal impact. We are dedicated to social responsibility and sustainability, implementing sustainable practices in all our projects and operations. Your Future at rocket code: We're seeking brilliant, innovative, and passionate tech enthusiasts to join our team. If you're ready to be part of a company that not only solves problems but also inspires and leaves a lasting mark on the digital world, Rocket Code is the place for you. Join us and be part of the change! Requirements Conocimiento de frameworks/librerías frontend, como React, Angular, Vue.js. Conocimiento de frameworks backend como Express.js, Django, Flask, Spring. Experiencia con bases de datos relacionales (MySQL, PostgreSQL) y no relacionales (MongoDB, Firebase). Benefits At rocket code, we value our team members and offer a comprehensive benefits package to support their personal and professional growth: Vacations: Enjoy time off to recharge and rejuvenate. December Bonus: Receive an annual bonus to celebrate your contributions and hard work. Referral Bonus: Get rewarded for bringing talented individuals to our team. Training Opportunities: Access to ongoing training programs to enhance your skills. Courses and Certifications: Stay ahead in your career with company-sponsored courses and certifications.",https://mx.linkedin.com/jobs/view/fullstack-developer-to-an-ai-consulting-company-at-rocket-code-4023635697,4023635697,"Join the AI Revolution with Rocket Code, where we are not just developers but dreamers and disruptors at the forefront of AI technology. We are looking for passionate individuals to help us create innovative solutions across various industries, including fintech, insurtech, energy, manufacturing, telecommunications, and e-commerce. As part of our mission, we aim to transform existing technology into digital experiences that positively impact society.","React, Angular, Vue.js, Express.js, Django, Flask, Spring, MySQL, PostgreSQL, MongoDB, Firebase",,,True,,0,1,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0
Senior Research Data Scientist,Medallia,Mexico City Metropolitan Area,REMOTE,,Full-time,Software Development,2024-09-08 11:36:38.320163,44,Engineering,,,"Overview Medallia is the pioneer and market leader in Experience Management. Our award-winning SaaS platform, Medallia Experience Cloud, leads the market in the understanding and management of experience for candidates, customers, employees, patients, citizens and residents. We are more than a software company. We want to be known as a company that does the right thing, no matter the challenge or controversy. We are committed to creating a culture that values every person and every experience. Individual life experiences shape the way we interact with the world, which is why we encourage people to bring their whole selves to work each day. The strength of our global workforce is the most significant contributor to our success. We believe: Every Experience Matters. Talent is Everywhere. All Belong Here. At Medallia, we hire the whole person. The Team Data Science at Medallia brings together researchers, engineers and designers, to build adaptive, collaborative technologies that are focused on enabling action at all levels of an organization. We drive both platform and product development, so that our customers can interact with their customers in satisfying and emotionally connected ways, regardless of scale. Responsibilities As a Senior Research Data Scientist on the Data Science team, you will lead cutting edge research in artificial intelligence and machine learning applications in the areas of natural language understanding/generation, action recommendation and representation learning. Run data science projects independently. Partner with engineering, design and product teams to deliver solutions to orchestrating, understanding and improving customer experiences in real time. Collaborate with a team of brilliant engineers and scientists responsible for bringing intelligent features to all corners of Medallia’s product offerings. Qualifications Minimum Qualifications Bachelor’s degree in Computer Science or related technical discipline or equivalent practical experience 3 years of relevant work experience, including software development experience or 1 year of relevant work experience with a PhD in Computer Science or related technical discipline 3 years of work or educational experience in Machine Learning or Artificial Intelligence Demonstrated proficieny Python, and detailed working knowledge of the packages and frameworks associated with data wrangling, analysis, and machine learning, e.g. Tensorflow, Pytorch, Sklearn, Spacy, Pandas, PySpark Preferred Qualifications MS or PhD degree in Computer Science, Artificial Intelligence, Machine Learning, or related technical discipline Strong communication skills, especially in describing technical methods and results to both technical and non-technical audiences Experience with utilizing, training,or fine-tuning large language models Extensive experience in one or more of the following areas: Natural Language Processing for text understanding, classification, summarization, pattern recognition, and/or recommendation/ranking systems; Representation learning for unstructured data types (images, text), multiple data sources (e.g. EMR/EHR), or event sequences (e.g. customer journeys) Experience utilizing machine learning platforms e.g. Kubeflow, SageMaker, VertexAI, Databricks At Medallia, we celebrate diversity and recognize the value it brings to our customers and employees. Medallia is proud to be an equal opportunity workplace and is an affirmative action employer. All qualified applicants will receive consideration for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, genetic information, disability, veteran status, or any other applicable status protected by state or local law. Individuals with a disability who need an accommodation to apply please contact us at ApplicantAccessibility@medallia.com. For information regarding how Medallia collects and uses personal information, please review our Privacy Policies. Applications will be accepted for 30 days from the date this role was posted or until the role has been filled.",https://mx.linkedin.com/jobs/view/senior-research-data-scientist-at-medallia-4011282191,4011282191,"As a Senior Research Data Scientist on the Data Science team, you will lead research in artificial intelligence and machine learning applications in natural language understanding, action recommendation, and representation learning. You will run data science projects independently and collaborate with engineering, design, and product teams to enhance customer experiences in real time.","Python, TensorFlow, PyTorch, Sklearn, Spacy, Pandas, PySpark, Kubeflow, SageMaker, VertexAI, Databricks",3,Bachelor,True,3.0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,1,0,0
"AI Software Engineer, IgniteTech (Remote) - $60,000/year USD",Crossover,Mexico City Metropolitan Area,REMOTE,Associate,Full-time,"Software Development, IT Services and IT Consulting, and Technology, Information and Internet",2024-09-11 11:36:38.320163,25,Business Development,"Engineering,",Information Technology,"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, IgniteTech. Have you got what it takes? Are you a forward-thinking developer eager to harness the power of GenAI to redefine business standards and enhance productivity? Are you bored of solving the same customer support tickets or resolving the same bugs over and over again? The majority of companies struggle with integrating AI into existing workflows, often resulting in underutilization and disappointing outcomes. At IgniteTech, we set ourselves apart by focusing on the practical application advanced AI technologies to transform business operations. Our approach isn't just about making incremental improvements; it's about leveraging AI to develop, support, and optimize tools that enhance both the workflow processes and the quality of service provided to our clients. This role IgniteTech is far from a conventional customer support or software engineer job. It is designed for those who are passionate about deploying GenAI to create robust support solutions, significantly improving productivity and customer satisfaction. Ideal for innovators who thrive in a dynamic environment, this position will place you at the helm of integrating revolutionary AI technologies. In this role, you’ll lead the charge in experimenting with and integrating cutting-edge AI technologies. You will play a pivotal role in shaping the future of AI-driven tools, from their inception to their optimization. If you're ready to be at the forefront of the AI revolution and transform how businesses operate, we invite you to apply today. Join us at IgniteTech, where we're not just changing the game—we’re defining it. Let’s innovate together and make a lasting impact. What You Will Be Doing Create and improve autonomous support platforms using LLMs. This includes not only development but also troubleshooting, maintaining, and updating tools based on user feedback and support tickets. One example would be creating an assistant able to guide customers through an upgrade process. Test and integrate state-of-the-art AI technologies, like GPT-4 Vision and Amazon CodeWhisperer, while providing support and guidance for internal teams on how to best utilize these technologies within their workflows. Evaluate and enhance the performance and integration of AI solutions across different infrastructures, notably AWS, and ensures support is available for end-users experiencing issues, focusing on maintaining high service quality and satisfaction. AI Software Engineer Key Responsibilities Improve support for both internal and external clients, significantly boosting the company’s innovation capacity and service quality Basic Requirements Advanced generative AI proficiency (i.e., use of multiple AI tools, ability to automate workflows and custom GPTs); if you've only used LLMs for research, learning, brainstorming, or content generation, that will be deemed insufficient At least 2 years of experience in B2B software customer support Proficiency in Python The ability to use AI to code in additional languages you are not very familiar with About IgniteTech If you want to work hard at a company where you can grow and be a part of a dynamic team, join IgniteTech! Through our portfolio of leading enterprise software solutions, we ignite business performance for thousands of customers globally. We’re doing it in an entirely remote workplace that is focused on building teams of top talent and operating in a model that provides challenging opportunities and personal flexibility. A career with IgniteTech is challenging and fast-paced. We are always looking for energetic and enthusiastic employees to join our world-class team. We offer opportunities for personal contribution and promote career development. IgniteTech is an Affirmative Action, Equal Opportunity Employer that values the strength that diversity brings to the workplace. There is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you! Working with Crossover This is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $30 USD/hour, which equates to $60,000 USD/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com/help-and-faqs for more details on this topic. What to expect next: You will receive an email with a link to start your self-paced, online job application. Our hiring platform will guide you through a series of online “screening” assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments. Important! If you do not receive an email from us: First, emails may take up to 15 minutes to send, refresh and check again. Second, check your spam and junk folders for an email from Crossover.com, mark as “Not Spam” since you will receive other emails as well. Third, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked. If all else fails, just reset your password by visiting https://www.crossover.com/auth/password-recovery if you already applied using LinkedIn EasyApply. Crossover Job Code: LJ-5267-MX-Mexico-AISoftwareEngi.002",https://mx.linkedin.com/jobs/view/ai-software-engineer-ignitetech-remote-%2460-000-year-usd-at-crossover-4022480377,4022480377,"The primary responsibility is to create and improve autonomous support platforms using generative AI, specifically LLMs. This role involves troubleshooting, maintaining, and updating tools based on user feedback, testing and integrating state-of-the-art AI technologies like GPT-4 Vision, and enhancing the performance of AI solutions across different infrastructures, notably AWS.","Python, AWS, GPT-4 Vision, Amazon CodeWhisperer",2,,True,2.0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0
"Python and Kubernetes Software Engineer - Data, AI/ML & Analytics",Canonical,Mexico City Metropolitan Area,REMOTE,Entry level,Full-time,"Technology, Information and Internet",2024-09-01 11:36:38.320163,25,Engineering,Information Technology,,"Canonical is a leading provider of open source software and operating systems to the global enterprise and technology markets. Our platform, Ubuntu, is very widely used in breakthrough enterprise initiatives such as public cloud, data science, AI, engineering innovation and IoT. Our customers include the world's leading public cloud and silicon providers, and industry leaders in many sectors. The company is a pioneer of global distributed collaboration, with 1000+ colleagues in 70+ countries and very few roles based in offices. Teams meet two to four times yearly in person, in interesting locations around the world, to align on strategy and execution. The company is founder led, profitable and growing. We are hiring Python and Kubernetes Specialist Engineers focused on Data, AI/ML and Analytics Solutions to join our teams building open source solutions for public cloud and private infrastructure. As a software engineer on the team, you'll collaborate on an end-to-end data analytics and mlops solution composed of popular, open-source, machine learning tools, such as Kubeflow, MLFlow, DVC, and Feast. You may also work on workflow, ETL, data governance and visualization tools like Apache SuperSet, dbt, and Temporal, or data warehouse solutions such as Apache Trino, or ClickHouse. Your team will own a solution from the analytics and machine learning space, and integrate with the solutions from other teams to build the world's best end-to-end data platform. These solutions may be run on servers or on the cloud, on machines or on Kubernetes, on developer desktops, or as web services. We serve the needs of individuals and community members as much as the needs of our Global 2000 and Fortune 500 customers; we make our primary work available free of charge and our Pro subscriptions are also available to individuals for personal use at no cost. Our goal is to enable more people to enjoy the benefits of open source, regardless of their circumstances. Location: This initiative spans many teams that are home-based in EMEA, Americas and APAC time zones, so we can accommodate candidates in almost any location. We believe in distributed collaboration but we also try to ensure that colleagues have company during their work hourse! Successful candidates will join a team where most members and your manager are broadly in the same time zone so that you have the benefits of constant collaboration and discussion. What your day will look like Develop your understanding of the entire Linux stack, from kernel, networking, and storage, to the application layer Design, build and maintain solutions that will be deployed on public and private clouds and local workstations Master distributed systems concepts such as observability, identity, tracing Work with both Kubernetes and machine-oriented open source applications Collaborate proactively with a distributed team of engineers, designers and product managers Debug issues and interact in public with upstream and Ubuntu communities Generate and discuss ideas, and collaborate on finding good solutions What we are looking for in you Professional or academic software delivery using Python or Golang Exceptional academic track record from both high school and university Undergraduate degree in a technical subject or a compelling narrative about your alternative chosen path Confidence to respectfully speak up, exchange feedback, and share ideas without hesitation Track record of going above-and-beyond expectations to achieve outstanding results Passion for technology evidenced by personal projects and initiatives The work ethic and confidence to shine alongside motivated colleagues Professional written and spoken English with excellent presentation skills Experience with Linux (Debian or Ubuntu preferred) Excellent interpersonal skills, curiosity, flexibility, and accountability Appreciative of diversity, polite and effective in a multi-cultural, multi-national organisation Thoughtfulness and self-motivation Result-oriented, with a personal drive to meet commitments Ability to travel twice a year, for company events up to two weeks long Additional Skills That Would Be Nice To Have The following skills may be helpful to you in the role, but we don't expect everyone to bring all of them. Hands-on experience with machine learning libraries, or tools. Proven track record of building highly automated machine learning solutions for the cloud. Experience with container technologies (Docker, LXD, Kubernetes, etc.) Experience with public clouds (AWS, Azure, Google Cloud) Working knowledge of cloud computing Passionate about software quality and testing Experience working on an open source project What we offer colleagues We consider geographical location, experience, and performance in shaping compensation worldwide. We revisit compensation annually (and more often for graduates and associates) to ensure we recognise outstanding performance. In addition to base pay, we offer a performance-driven annual bonus or commission. We provide all team members with additional benefits, which reflect our values and ideals. We balance our programs to meet local needs and ensure fairness globally. Distributed work environment with twice-yearly team sprints in person Personal learning and development budget of USD 2,000 per year Annual compensation review Recognition rewards Annual holiday leave Maternity and paternity leave Employee Assistance Programme Opportunity to travel to new locations to meet colleagues Priority Pass, and travel upgrades for long haul company events About Canonical Canonical is a pioneering tech firm at the forefront of the global move to open source. As the company that publishes Ubuntu, one of the most important open source projects and the platform for AI, IoT and the cloud, we are changing the world of software. We recruit on a global basis and set a very high standard for people joining the company. We expect excellence - in order to succeed, we need to be the best at what we do. Most colleagues at Canonical have worked from home since its inception in 2004. Working here is a step into the future, and will challenge you to think differently, work smarter, learn new skills, and raise your game. Canonical is an equal opportunity employer We are proud to foster a workplace free from discrimination. Diversity of experience, perspectives, and background create a better work environment and better products. Whatever your identity, we will give your application fair consideration.",https://mx.linkedin.com/jobs/view/python-and-kubernetes-software-engineer-data-ai-ml-analytics-at-canonical-4011650227,4011650227,"We are hiring Python and Kubernetes Specialist Engineers focused on Data, AI/ML and Analytics Solutions to join our teams building open source solutions for public cloud and private infrastructure. As a software engineer, you'll collaborate on an end-to-end data analytics and MLOps solution composed of popular, open-source machine learning tools. You may also work on workflow, ETL, data governance, and visualization tools, or data warehouse solutions. Your team will own a solution from the analytics and machine learning space and integrate with solutions from other teams to build the best end-to-end data platform.","Python, Golang, Kubernetes, Kubeflow, MLFlow, DVC, Feast, Apache SuperSet, dbt, Temporal, Apache Trino, ClickHouse, Linux",,Undergraduate Student,True,,0,1,1,0,1,0,0,0,0,0,0,0,1,0,1,0,0
"Senior Software Development Engineer, Big Data",Zillow,Mexico City Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Real Estate,2024-09-01 11:36:38.320163,25,Engineering,Information Technology,,"About the team Zillow’s Data Management team supports the most critical datasets in Zillow powering Zillow’s critical initiatives. The Data Management team works with near real-time and batch data products to surface high-quality datasets for analytics consumption. Acerca del equipo El equipo de Gestión de Datos de Zillow da soporte a los conjuntos de datos más importantes de Zillow, impulsando las iniciativas críticas de Zillow. El equipo de gestión de datos trabaja con productos de datos en tiempo casi real y por lotes para sacar a la superficie conjuntos de datos de alta calidad para el consumo analítico. About the role As a Senior Software Development Engineer in the Zillow Group Data Management team, you will play a central role for powering analytical and ML teams by providing validated high-quality property datasets that are a single source of truth across the organization. In addition, you will: Design, implement, and take ownership of mission-critical ETL pipelines Contribute to the architecture and development of near real-time/batch data products Work closely with business stakeholders, data analysts, data scientists, and machine learning engineers to productionalize analytic solutions Enable product engineering teams to onboard their data using data mesh principles and architecture. Acerca del rol Como Ingeniero Senior de Desarrollo de Software en el equipo de Gestión de Datos del Grupo Zillow, desempeñarás un papel central para potenciar los equipos analíticos y de ML proporcionando conjuntos de datos de propiedades validados de alta calidad que son una única fuente de verdad en toda la organización. Además, deberás: Diseñar, implementar y asumir la propiedad de las tuberías ETL de misión crítica. Contribuir a la arquitectura y el desarrollo de productos de datos en tiempo casi real/por lotes Trabajar en estrecha colaboración con las partes interesadas del negocio, analistas de datos, científicos de datos e ingenieros de aprendizaje automático para producir soluciones analíticas. Permitir que los equipos de ingeniería de productos incorporen sus datos utilizando principios y arquitectura de malla de datos. This role has been categorized as a teleworker position. Teleworkers do not have a permanent corporate office workplace and, instead, work from a physical location of their choice which must be identified to the Company. Employees may live in any part of Mexico, but preferably in Mexico City, as we would encourage attendance for occasional in-office events. In addition to a competitive base salary and benefits, this position is also eligible for equity awards based on factors such as experience, performance and location. Who you are Have previously designed and built complex, highly scalable/reliable data pipelines, using the Big Data ecosystem (Hadoop/Hive/Spark/Presto/Airflow/Kinesis or equivalents) 5+ years of Software development experience with high proficiency in Python, Java, Scala or another language Must have SQL knowledge Must have a thorough knowledge of data structures and algorithms Must have prior experience working with customers to understand and capture requirements. Understands the concepts behind distributed databases, and both streaming and batch-processing systems Quién es usted Haber diseñado y construido previamente pipelines de datos complejos, altamente escalables/fiables, utilizando el ecosistema Big Data (Hadoop/Hive/Spark/Presto/Airflow/Kinesis o equivalentes). Más de 5 años de experiencia en desarrollo de software con un alto dominio de Python, Java, Scala u otro lenguaje. Debe tener conocimientos de SQL Debe tener un profundo conocimiento de las estructuras de datos y algoritmos Debe tener experiencia previa trabajando con clientes para entender y capturar requerimientos Comprende los conceptos de las bases de datos distribuidas y los sistemas de procesamiento en flujo y por lotes. Get to know us Zillow is reimagining real estate to make it easier to unlock life’s next chapter. As the most-visited real estate website in the United States, Zillow® and its affiliates help movers find and win their home through digital solutions, first class partners, and easier buying, selling, financing and renting experiences. Millions of people visit Zillow Group sites every month to start their home search, and now they can rely on Zillow to help make it easier to move. The work we do is helping people move from dreaming to transacting — and no matter what job you're in, you will play a critical role in making this vision a reality. Our efforts to streamline the real estate transaction are supported by a deep-rooted culture of innovation, our passion to redefine the employee experience, and a fundamental commitment to Equity and Belonging. We’re also setting the standard for work experiences of the future, where our employees are supported in doing their best work and living a flexible, well-balanced life. But don’t just take our word for it. Read recent reviews on Glassdoor and recent recognition from multiple organizations, including: the 100 Best Companies to Work For in 2022 list, Glassdoor Employees’ Choice Award, honoring the Best Places to Work in 2022, Bloomberg Gender-Equality Index 2022, Human Rights Campaign (HRC) Corporate Equity Index and Best Place to Work for LGBTQ Equality 2022, and TIME 100 Most Influential Companies list. Zillow Group is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, and gender identity. If you have a disability or special need that requires accommodation, please contact us at RecruitingAccessibility@zillowgroup.com .",https://mx.linkedin.com/jobs/view/senior-software-development-engineer-big-data-at-zillow-3992839722,3992839722,"As a Senior Software Development Engineer in the Zillow Group Data Management team, you will play a central role in providing validated, high-quality property datasets that serve as a single source of truth across the organization. The role involves designing, implementing, and taking ownership of mission-critical ETL pipelines, contributing to the architecture and development of near real-time/batch data products, and working closely with business stakeholders, data analysts, data scientists, and machine learning engineers to productionalize analytic solutions.","Python, Java, Scala, SQL, Hadoop, Hive, Spark, Presto, Airflow, Kinesis, Big Data ecosystem",5+ years,,True,5.0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,1,0,0
Senior Data Scientist,Launch Potato,Mexico City Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Advertising Services,2024-09-08 11:36:38.320163,25,Engineering,Information Technology,,"WHO ARE WE? Launch Potato is a digital media company with a portfolio of brands and technologies. As The Discovery and Conversion Company, Launch Potato is a leading connector of advertisers to customers at all parts of the consumer journey, from awareness to consideration to purchase. The company is headquartered in vibrant downtown Delray Beach, Florida, with a unique international team across over a dozen countries. Launch Potato's success comes from a diverse, energetic culture and high-performing, entrepreneurial team. As a result, the company is always looking for like-minded teammates and partners. (This role will heavily focus on building machine learning models. This is NOT an engineering/data engineering position.) MUST HAVE: Experience within the performance marketing/lead gen industries. Professional experience designing, implementing, optimizing, and testing end-to-end Multi-Armed Bandit (MAB) and recommendation systems. EXPERIENCE: A minimum of 4 years experience in a hands-on, in-the-weeds data science position. YOUR ROLE You will be developing deep personalization models for our users and complex optimization algorithms to bridge our customer experiences with new products/services. Your direct contribution will impact how we connect hundreds of thousands of customers to hundreds of advertisers together daily and will drive significant consumer impact while increasing revenue. You will play a pivotal role in the growth of our data science team and will be an instrumental resource as we continue to build a team of data scientists and machine learning engineers that can increase customer engagement and stickiness on our sites while improving the quality of the leads to our partners. This is an extremely hands-on and in-the-weeds Data Science role where you will be heavily immersed in the data and coding part of the solution implementation. You will design and oversee integrating state-of-the-art machine learning solutions across the company’s products. This role will be responsible for strategic planning of Machine Learning initiatives with the Product, Engineering, Performance and Business Intelligence teams, analysis of potential impact and prioritization of those projects. SUCCESS LOOKS LIKE Innovate, create, and design ML solutions to various business problems such as: Design, implement and continuously improve Multi-Armed Bandit solutions to optimize decisions/options in place of multiple AB-tests. Utilizing Large Language Models in content personalization across various verticals. Recommendation systems to serve ads, offers, questions, etc. Collaborate with stakeholders across the company including but not limited to Analytics, Engineering, Product and Business Leads to improve model infrastructure, tracking and monitoring. Provide data science support at different project stages, including the implementation of ML solutions by collaborating with Data Engineers and MLOps. Being hands-on and in-the-weeds in the data, coding part of the solution implementation. What You Need To Succeed 4+ years of related work experience in the field of Data Science & Machine learning. 2+ years of experience in the Marketing/Advertising Industry. Solid background in Machine Learning and Statistics. Professional experience designing and implementing Multi-Armed Bandit (MAB) solutions and recommendation systems. Proficiency in SQL, Python and working with Data Science tools (e.g., git, kubernetes, Docker, etc.). Structure and clarify any ambiguity for the team, i.e., divide complex projects into sprints and coordinate implementation across multiple teams and individuals. Experience creating ML solutions within cloud services (AWS/GCP). Experience with ML model development lifecycle. Experience with data visualization (preferably Looker). Experience managing a team of data scientists and machine learning researchers (including career development). Ability to communicate clearly, think independently, provide direction, and effectively communicate with technical and non-technical stakeholders. NICE TO HAVES Experience with LLMs and Deep learning models to develop business and data science solutions. Want to make your impact in a profitable, high-growth company? Apply now! Since day one, we've been committed to having a diverse, inclusive team and culture. We are proud to be an Equal Employment Opportunity company. We value diversity, equity, and inclusion. We do not discriminate based on race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",https://mx.linkedin.com/jobs/view/senior-data-scientist-at-launch-potato-4019305660,4019305660,"The role heavily focuses on building machine learning models and requires experience in performance marketing and lead generation. You will develop deep personalization models, complex optimization algorithms, and design state-of-the-art machine learning solutions across various products. This data science position demands hands-on skills in coding, machine learning initiatives, and collaboration with various teams to improve model infrastructure and monitor performance.","Python, SQL, Machine Learning, Statistics, Multi-Armed Bandit, Recommendation Systems, Git, Kubernetes, Docker, AWS, GCP, Looker",4+ years,,True,4.0,0,0,0,1,1,0,0,0,1,1,0,1,1,0,1,0,0
"Software Engineer II, Machine Learning",Medallia,Mexico City Metropolitan Area,REMOTE,,Full-time,Software Development,2024-09-01 11:36:38.320163,25,Engineering,,,"Overview Medallia is the pioneer and market leader in Experience Management. Our award-winning SaaS platform, Medallia Experience Cloud, leads the market in the understanding and management of experience for candidates, customers, employees, patients, citizens and residents. We are more than a software company. We want to be known as a company that does the right thing, no matter the challenge or controversy. We are committed to creating a culture that values every person and every experience. Individual life experiences shape the way we interact with the world, which is why we encourage people to bring their whole selves to work each day. The strength of our global workforce is the most significant contributor to our success. We believe: Every Experience Matters. Talent is Everywhere. All Belong Here. At Medallia, we hire the whole person. We are looking for a motivated Software Engineer II, Machine Learning to join our Medallia Athena Platform team. Responsibilities Participate in the development of the building blocks of the next generation of products at Medallia. Build analytics tools that utilize the data pipeline to provide actionable insights into customer feedback applying sentiment analytics, NLP, clustering methodologies and generative AI Includes design and implementation of APIs to power front-end applications Implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability. Improve and maintain optimal data pipeline architecture. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product. Implement scalable solutions for dealing with large data prepared by the data science team, and making it available to clients with high performance Qualifications Minimum Qualifications BA/BS degree in Computer Science or a related technical discipline, or equivalent practical experience. Strong experience in a technical role working on distributed systems and web services. 2+ years performing software development in a production environment using a mainstream object-oriented programming language (Python, Java or Scala) Engineering experience including distributed systems like Spark, Hadoop, Kafka etc. Relational SQL including Postgres Experience with services deployment and customization using K8s Strong experience with code quality best practices and implementing testing architectures and modularization on large codebases. Preferred Qualifications. Experience with data pipeline and workflow management tools such Airflow or Kubeflow. Experience with big data tools: Hive, Presto/Trino, Redash. Familiarity with model serving platforms: TensorFlow, TensorRT, Triton, KServe Micro services development using Django or Spring framework Relational SQL and NoSQL databases experience, including Postgres and ElasticSearch At Medallia, we celebrate diversity and recognize the value it brings to our customers and employees. Medallia is proud to be an equal opportunity workplace and is an affirmative action employer. All qualified applicants will receive consideration for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, genetic information, disability, veteran status, or any other applicable status protected by state or local law. Individuals with a disability who need an accommodation to apply please contact us at ApplicantAccessibility@medallia.com. For information regarding how Medallia collects and uses personal information, please review our Privacy Policies. Applications will be accepted for 30 days from the date this role was posted or until the role has been filled.",https://mx.linkedin.com/jobs/view/software-engineer-ii-machine-learning-at-medallia-4011010296,4011010296,"We are looking for a motivated Software Engineer II, Machine Learning to join our Medallia Athena Platform team. Responsibilities include developing building blocks of product, building analytics tools using data pipeline to provide insights through sentiment analytics, NLP, and generative AI, designing APIs, automating processes, optimizing data delivery, re-designing infrastructure for scalability, improving data pipeline architecture, and creating data tools for analytics and data science teams.","Python, Java, Scala, Spark, Hadoop, Kafka, SQL, Postgres, Kubernetes, Airflow, Kubeflow, Hive, Presto/Trino, Redash, TensorFlow, TensorRT, Triton, KServe, Django, Spring, ElasticSearch",2+ years,Bachelor,True,2.0,0,1,1,0,1,0,0,0,0,1,0,0,1,0,1,0,0
Senior Applied Scientist,Microsoft,Mexico City Metropolitan Area,REMOTE,,Full-time,Software Development,2024-09-08 11:36:38.320163,53,Research,"Analyst,",Information Technology,"MSAI organization plays a key role in Microsoft to build products that help boost Enterprise users’ productivity. We help users find relevant artifacts and get their daily jobs done in timely and efficient manner. MSAI is now responsible to deliver M365 Chat which is designed to help users find, summarize, act upon their work data in an interactive pattern. As a Senior Applied Scientist specializing in ranking recommendation ML models, you will play a pivotal role in shaping the future of our ranking systems ( across different enterprise data like Emails, Documents, Calendar, Graph connectors etc). You will collaborate closely with cross-functional teams to design, implement, and evaluate state-of-the-art algorithms that power our cross entity ranking engine. Leveraging your expertise in machine learning, you will drive innovation and continuously improve the performance and relevance of our retrieval stack. Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond. Responsibilities Research and develop novel ML algorithms and techniques to enhance the ranking accuracy and effectiveness of retrieval systems – which in turn gets fed into LLMs for response generation. Design and implement scalable and efficient algorithms for large-scale ranking tasks, considering factors such as user engagement, diversity, and fairness. Conduct rigorous experiments and analysis to evaluate the performance of ranking models, identify areas for improvement, and iterate on existing solutions. Collaborate with software engineers and data engineers to integrate ML models into production systems and optimize their performance. Stay abreast of the latest advancements in machine learning, information retrieval, and recommendation systems, and contribute to the company's intellectual property through patents and publications. Provide technical leadership and mentorship to junior team members, fostering a culture of innovation, collaboration, and continuous learning. Qualifications Required Qualifications: Ph.D. or Master's degree in Computer Science, Electrical Engineering, Statistics, or a related field with a focus on machine learning, information retrieval, or recommender systems. Experience in developing and deploying ranking recommendation ML models and LLMs in real-world applications. #M365CORE #MSAI Microsoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.",https://mx.linkedin.com/jobs/view/senior-applied-scientist-at-microsoft-3943072375,3943072375,"As a Senior Applied Scientist specializing in ranking recommendation ML models, you will develop and implement novel ML algorithms to enhance the accuracy and effectiveness of retrieval systems. You will design scalable algorithms for large-scale ranking tasks, conduct experiments to evaluate model performance, and collaborate with software and data engineers to integrate ML models into production systems. Stay updated on advancements in machine learning and contribute to intellectual property through patents and publications. Provide mentorship to junior team members.","Machine Learning, Large Language Models (LLMs), Algorithms, Data Engineering, Python, Statistics",,Masters,True,,0,0,0,0,0,1,1,0,0,0,0,0,1,0,1,0,0
Senior Clinical Data Science Lead,ICON plc,Mexico City Metropolitan Area,REMOTE,Entry level,Full-time,Biotechnology Research,2024-09-08 11:36:38.320163,25,Research,"Analyst,",Information Technology,"Senior Clinical Data Science Lead - Colombia & Mexico City - Remote or Hybrid ICON plc is a world-leading healthcare intelligence and clinical research organization. We’re proud to foster an inclusive environment driving innovation and excellence, and we welcome you to join us on our mission to shape the future of clinical development. We have an incredible opportunity for a Senior Clinical Data Science Lead to join ICON's Full-Service IOD Clinical Data Science team. The Senior Clinical Data Science Lead (Senior CDSL) serves as the primary contact for internal and external team members regarding clinical data science data review activities and leads these review activities to ensure delivery of data fit for analysis. They are accountable for achieving clinical data science deliverables on-time, with high-quality, and to agreed financial metrics. What you will be doing: Develop and oversee timeliness of clinical data science activities during the life cycle of studies as it relates to data review and data delivery milestones. Provide input into clinical system development activities and clinical risk management activities. Track and keep functional management and those responsible for project management informed of any issues that might affect project target dates, scope or budget and escalates potential problems effectively and in a timely manner. Forecast budget, hours, and resourcing for clinical data review activities. Perform analytic review as defined in the scope of work and functional plans focusing on errors that matter or have a meaningful impact on the safety of the subject or interpretation of the final analysis. Accountable for the development of planning documents related to data review, data analytics, and data deliverables. Participate in Sponsor and/or third-party audits. Negotiate timelines and key deliverables with clients and/or external customers, vendors, and departments as needed. Travel (approximately 15%) domestic and/or international. Your Profile: 5+ years of clinical data management experience in a clinical research organization or pharmaceutical company. 2+ years of experience working in a clinical research organization (CRO) Experience as a functional lead of multiple low and moderately complex studies, whilst acting as a resource for less experienced colleagues. Experience with all steps within the data science lifecycle and most major data science study tasks, with proficiency in at least one Clinical Data Management system required (e.g., Medidata Rave, Inform, Oracle Clinical, Veeva) Excellent communication skills. Budget and timeline management experience. Data Analytic and Data Validation experience. Bachelor’s degree or local equivalent. Equivalent combination of education, training, and relevant experience may be considered in place of the education and experience stated above. Fluent English and host country language is required. What ICON can offer you: Our success depends on the quality of our people. That’s why we’ve made it a priority to build a diverse culture that rewards high performance and nurtures talent. In addition to your competitive salary, ICON offers a range of additional benefits. Our benefits are designed to be competitive within each country and are focused on well-being and work life balance opportunities for you and your family. Our benefits examples include: Various annual leave entitlements A range of health insurance offerings to suit you and your family’s needs. Competitive retirement planning offerings to maximize savings and plan with confidence for the years ahead. Global Employee Assistance Programme, LifeWorks, offering 24-hour access to a global network of over 80,000 independent specialized professionals who are there to support you and your family’s well-being. Life assurance Flexible country-specific optional benefits, including childcare vouchers, bike purchase schemes, discounted gym memberships, subsidized travel passes, health assessments, among others. Visit our careers site to read more about the benefits ICON offers. ICON, including subsidiaries, is an equal opportunity and inclusive employer and is committed to providing a workplace free of discrimination and harassment. All qualified applicants will receive equal consideration for employment without regard to race, colour, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. If, because of a medical condition or disability, you need a reasonable accommodation for any part of the application process, or in order to perform the essential functions of a position, please let us know or submit a request here Interested in the role, but unsure if you meet all of the requirements? We would encourage you to apply regardless – there’s every chance you’re exactly what we’re looking for here at ICON whether it is for this or other roles. Are you a current ICON Employee? Please click here to apply",https://mx.linkedin.com/jobs/view/senior-clinical-data-science-lead-at-icon-plc-4016590479,4016590479,"The Senior Clinical Data Science Lead serves as the primary contact for internal and external team members regarding clinical data science review activities and leads these review activities to ensure delivery of data fit for analysis. They are accountable for achieving clinical data science deliverables on-time, with high-quality, and to agreed financial metrics. Responsibilities include developing and overseeing timelines of clinical data science activities, providing input into clinical system development, tracking project management issues, forecasting budget and resources, performing analytic reviews, and negotiating timelines with clients. The role requires experience in clinical data management, proficiency in at least one Clinical Data Management system, and excellent communication skills.","Medidata Rave, Inform, Oracle Clinical, Veeva, Data Analytics, Data Validation",5+ years,Bachelor,True,5.0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0
Senior Applied Scientist,Launch Potato,Mexico City Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Advertising Services,2024-09-08 11:36:38.320163,25,Research,"Analyst,",Information Technology,"WHO ARE WE? Launch Potato is a digital media company with a portfolio of brands and technologies. As The Discovery and Conversion Company, Launch Potato is a leading connector of advertisers to customers at all parts of the consumer journey, from awareness to consideration to purchase. The company is headquartered in vibrant downtown Delray Beach, Florida, with a unique international team across over a dozen countries. Launch Potato's success comes from a diverse, energetic culture and high-performing, entrepreneurial team. As a result, the company is always looking for like-minded teammates and partners. (This role will heavily focus on building machine learning models. This is NOT an engineering/data engineering position.) MUST HAVE: Experience within the performance marketing/lead gen industries. Professional experience designing, implementing, optimizing, and testing end-to-end Multi-Armed Bandit (MAB) and recommendation systems. EXPERIENCE: A minimum of 4 years experience in a hands-on, in-the-weeds data science position. YOUR ROLE You will be developing deep personalization models for our users and complex optimization algorithms to bridge our customer experiences with new products/services. Your direct contribution will impact how we connect hundreds of thousands of customers to hundreds of advertisers together daily and will drive significant consumer impact while increasing revenue. You will play a pivotal role in the growth of our data science team and will be an instrumental resource as we continue to build a team of data scientists and machine learning engineers that can increase customer engagement and stickiness on our sites while improving the quality of the leads to our partners. This is an extremely hands-on and in-the-weeds Data Science role where you will be heavily immersed in the data and coding part of the solution implementation. You will design and oversee integrating state-of-the-art machine learning solutions across the company’s products. This role will be responsible for strategic planning of Machine Learning initiatives with the Product, Engineering, Performance and Business Intelligence teams, analysis of potential impact and prioritization of those projects. SUCCESS LOOKS LIKE Innovate, create, and design ML solutions to various business problems such as: Design, implement and continuously improve Multi-Armed Bandit solutions to optimize decisions/options in place of multiple AB-tests. Utilizing Large Language Models in content personalization across various verticals. Recommendation systems to serve ads, offers, questions, etc. Collaborate with stakeholders across the company including but not limited to Analytics, Engineering, Product and Business Leads to improve model infrastructure, tracking and monitoring. Provide data science support at different project stages, including the implementation of ML solutions by collaborating with Data Engineers and MLOps. Being hands-on and in-the-weeds in the data, coding part of the solution implementation. What You Need To Succeed 4+ years of related work experience in the field of Data Science & Machine learning. 2+ years of experience in the Marketing/Advertising Industry. Solid background in Machine Learning and Statistics. Professional experience designing and implementing Multi-Armed Bandit (MAB) solutions and recommendation systems. Proficiency in SQL, Python and working with Data Science tools (e.g., git, kubernetes, Docker, etc.). Structure and clarify any ambiguity for the team, i.e., divide complex projects into sprints and coordinate implementation across multiple teams and individuals. Experience creating ML solutions within cloud services (AWS/GCP). Experience with ML model development lifecycle. Experience with data visualization (preferably Looker). Experience managing a team of data scientists and machine learning researchers (including career development). Ability to communicate clearly, think independently, provide direction, and effectively communicate with technical and non-technical stakeholders. NICE TO HAVES Experience with LLMs and Deep learning models to develop business and data science solutions. Want to make your impact in a profitable, high-growth company? Apply now! Since day one, we've been committed to having a diverse, inclusive team and culture. We are proud to be an Equal Employment Opportunity company. We value diversity, equity, and inclusion. We do not discriminate based on race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",https://mx.linkedin.com/jobs/view/senior-applied-scientist-at-launch-potato-4019308215,4019308215,"This role will heavily focus on building machine learning models and is not an engineering/data engineering position. You will be developing deep personalization models and complex optimization algorithms to improve customer experiences. The role involves designing and implementing Multi-Armed Bandit solutions and recommendation systems, collaborating with various teams, and overseeing machine learning solutions across the company’s products.","Python, SQL, Machine Learning, Statistics, Multi-Armed Bandit (MAB), Recommendation Systems, Cloud Services (AWS/GCP), Data Visualization (Looker), Git, Kubernetes, Docker",4+ years,,True,4.0,0,0,0,1,1,1,0,0,1,1,0,1,1,0,1,0,0
"Senior Artificial Intelligence/Machine Learning Engineer - Remote, Latin America",Bluelight Consulting | DevOps & Software Development,Mexico City Metropolitan Area,REMOTE,,Full-time,IT Services and IT Consulting,2024-09-08 11:36:38.320163,25,Engineering,Information Technology,,"Bluelight Consulting is a leading software consultancy dedicated to designing and developing innovative technology that enhances users' lives. With a steadfast commitment to delivering exceptional service to our clients, Bluelight excels in its focus on quality and customer satisfaction. Our mission is not only to create cutting-edge applications but also to foster a collaborative and enriching work environment where each team member can grow and thrive. With a presence across the United States and Central/South America, Bluelight is in an exciting phase of expansion, continually seeking exceptional talent to join its dynamic and diverse community. We are looking for a skilled individual to join our rapidly growing team at Bluelight Consulting. This position is ideal for someone who thrives in a fast-paced, dynamic environment where everyone's opinions and efforts are valued and appreciated. You will have the opportunity to contribute to challenging and meaningful projects, developing high-quality applications that stand out in the market. We value continuous learning, personal growth, and hard work, offering a collaborative environment that promotes professional development. If you are passionate about software development and eager to be part of a growing software consultancy, we invite you to apply and join us on this exciting journey. What we are looking for Strong background in computer science or engineering with 3+ years of experience Knowledge of machine learning, deep learning, and natural language processing Experience with LLMs like GPT and LLama3 Proficient in Python and familiar with TensorFlow or PyTorch Good problem-solving skills and ability to work independently and in a team Experience with AI voice programs/products Proficient in cloud services (AWS, Azure, Google Cloud) and container technologies (Docker, Kubernetes) Strong communication skills for explaining technical ideas to various audiences Ability to manage product specifications from concept to production Understanding of software design principles, including optimization and performance tuning Company Benefits Competitive salary and bonuses, including performance-based salary increases Generous paid-time-off policy Technology / Office stipend Health Coverage Flexible working hours Work remotely Continuing education, training, conferences Company-sponsored coursework, exams, and certifications Being a consultant in our team is a fun, challenging, and rewarding career choice. Your contributions are highly valued by clients, and the work you do often has a direct and significant impact on their business. You will have the opportunity to work on a variety of projects for our incredible clients, which will accelerate your career growth. You’ll collaborate with modern technologies and work alongside some of the best professionals in the industry! If you’re eager to be part of an exciting, challenging, and rapidly growing consultancy, we encourage you to apply.",https://mx.linkedin.com/jobs/view/senior-artificial-intelligence-machine-learning-engineer-remote-latin-america-at-bluelight-consulting-devops-software-development-4018827407,4018827407,"We are looking for a skilled individual to join our rapidly growing team. This position is ideal for someone who thrives in a fast-paced environment. You will contribute to challenging projects, developing high-quality applications. We value continuous learning and personal growth, offering a collaborative environment that promotes professional development. Strong background in computer science or engineering with 3+ years of experience is required. Knowledge of machine learning, deep learning, and natural language processing is essential. Experience with LLMs like GPT and LLama3 is necessary. Proficiency in Python and familiarity with TensorFlow or PyTorch is required. Good problem-solving skills and the ability to work both independently and in a team are important. Experience with AI voice programs/products is needed. Proficiency in cloud services (AWS, Azure, Google Cloud) and container technologies (Docker, Kubernetes) is also required. Strong communication skills for explaining technical ideas to various audiences and the ability to manage product specifications from concept to production is essential. Understanding of software design principles, including optimization and performance tuning, is necessary.","Python, TensorFlow, PyTorch, AWS, Azure, Google Cloud, Docker, Kubernetes, Machine Learning, Deep Learning, Natural Language Processing",3+ years,Bachelor,True,3.0,0,0,0,1,1,0,0,0,0,0,0,0,1,0,1,0,0
Big Data Engineer (Remoto),Azkait,Mexico City Metropolitan Area,REMOTE,,Full-time,"Technology, Information and Internet",2024-08-16 11:36:38.320163,29,Engineering,Information Technology,,"AZKAIT es una empresa Mexicana que busca y conecta el mejor talento IT con empresas Latinoamericanas y de Estados Unidos. Estamos en la búsqueda de tu talento como Big Data Engineer / Tech Lead. Requisitos: Ingeniero en computación/sistemas o Licenciado en carrera afín. Dominio de inglés nivel intermedio alto o avanzado (B2, C1 o superior) +5 años de experiencia en ETL, ELT para tratamiento de datos (ingestión, transformaciones, modelado, consumo). Experiencia de al menos 1 año como lider tecnico o lider de equipos. Experiencia comprobada en Ingeniería de Datos. Skills: ETL Tecnologías Big Data para el tratamiento de datos. SQL. Python. Desarrollo de pipelines de datos en nubes públicas (Azure o GCP). API. Agile/Scrum Framework. Capacidad para guiar a los equipos de ingeniería de datos. Beneficios: Superiores(12 días de vacaciones, prima vacacional 30%, 20 días aguinaldo). Seguro de Vida. Seguro de gastos médicos mayores Familiar. Seguro dental. Localidad y esquema de Trabajo: 100% remoto",https://mx.linkedin.com/jobs/view/big-data-engineer-remoto-at-azkait-3977648630,3977648630,"We are looking for your talent as a Big Data Engineer / Tech Lead. The position requires a degree in computer engineering/systems or a related field. You should have intermediate to advanced English proficiency (B2, C1 or higher) and over 5 years of experience in ETL and ELT for data processing (ingestion, transformations, modeling, consumption). You must have at least 1 year of experience as a technical lead or team leader, and proven experience in Data Engineering.","ETL, Big Data Technologies, SQL, Python, Data Pipelines, Azure, GCP, API, Agile, Scrum",5+ years,Bachelor,True,5.0,1,0,1,1,0,0,1,0,0,1,0,0,0,0,1,0,0
Machine Learning Engineer,PureLogics,Mexico City Metropolitan Area,REMOTE,,Full-time,Software Development,2024-09-14 11:36:38.320163,25,Engineering,Information Technology,,"Job Description: A machine learning engineer is responsible for joining a product team and contributing to the software design, algorithm design, and overall product lifecycle of a product that our users love. ML Engineers are expected to pair daily as they work through user stories and support products as they evolve. ML Engineers may be involved in designing and implementing AI/ML algorithms to embed directly into software products. The role may also involve performance tuning, testing, and product monitoring. Other responsibilities may include performing customer outreach, designing ML educational material, and data engineering. You will also be able to drive multiple ML initiatives by directing algorithm and technology product design Key Skills : Python, GCP, Vertex AI or Tensor Flow, DS, Building & Scale Models, leverage GenAI models Qualifications: 4 + years of relevant work experience. Experience with modern scripting languages (Python). Experience in effective data engineering practices and big data platforms such as BigQuery, Data Store, etc. Experience in modern web application frameworks such as Node.js. Experience in writing SQL queries against a relational database. Experience in version control systems (preferably Git). Experience in Google Cloud Platform and AI/ML-related components such as Vertex AI, BigQueryML, and AutoML. Experience with Data Analysis and Machine Learning Tools and Libraries like Jupyter Notebooks, Pandas, SciPy, Scikit-learn, Gensim, tensorflow, pytorch, etc. Experience in advanced machine learning techniques such as NLP, convolutional neural networks, autoencoders, and embedding generation and utilization. Experience in training machine learning models with extremely large datasets. Experience in front-end technology and frameworks like HTML, CCS, JavaScript, ReactJS, and D3. Experience in REST and effective web service design. Experience in production systems design including High Availability. Disaster Recovery, Performance, Efficiency, and Security. Experience in cloud computing platforms and associated automation patterns and machine learning services they provide. Experience in defensive coding practices and patterns for high-availability",https://mx.linkedin.com/jobs/view/machine-learning-engineer-at-purelogics-4023909858,4023909858,"A machine learning engineer is responsible for contributing to the software design, algorithm design, and overall product lifecycle. ML Engineers will design and implement AI/ML algorithms, perform customer outreach, create educational material, and engage in data engineering activities. Key responsibilities include performance tuning, testing, and product monitoring, as well as driving multiple ML initiatives through algorithm and technology product design.","Python, GCP, Vertex AI, TensorFlow, BigQuery, Node.js, SQL, Jupyter Notebooks, Pandas, SciPy, Scikit-learn, Gensim, PyTorch, HTML, CSS, JavaScript, ReactJS, D3",4+ years,,True,4.0,0,1,1,1,0,0,0,0,0,1,1,0,1,0,1,0,0
AI Machine Learning Engineer,tbo,Mexico City Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Translation and Localization,2024-09-12 11:36:38.320163,25,Engineering,Information Technology,,"The Machine Learning Engineer role is responsible for the design, development and implementation of machine learning solutions to serve our organization. This includes ownership or oversight of projects from conception to deployment with appropriate AWS services, Docker, MLFlow, and others. The role also includes responsibility for following best practices with which to optimize and measure the performance of our models and algorithms against business goals. Responsibilities Design and develop machine learning models and algorithms for various aspects of the localization and business workflow processes, including machine translation, LLM fine tuning, and quality assurance. Take ownership of key projects from definition to deployment, ensuring that they meet technical requirements and maintain momentum and direction until delivery. Evaluate and select appropriate machine learning techniques and algorithms to solve specific problems. Implement and optimize machine learning models and technologies using Python, TensorFlow, and other relevant tools and frameworks. Perform statistical analysis and fine-tuning using test results. Deploy machine learning models and algorithms using appropriate techniques and technologies, such as containerization using Docker and deployment to cloud infrastructure. Use AWS technologies (including but not limited to Sagemaker, EC2, S3) to deploy and monitor production environments. Keep abreast of developments in the field, with a dedication to learning in the role. Document diligently and communicate thoughtfully about ML experimentation, design, and deployment. Project scope Define and design solutions to machine learning problems. Integration with larger systems done with guidance from more senior colleagues. Requisitos Requirements Effective model development success is evident when the models developed are accurate, efficient, and align with project requirements. Positive team collaboration demonstrated ability to collaborate effectively with various teams and stakeholders, contributing positively to project outcomes. Continuous learning and improvement a commitment to continuous learning and applying new techniques to improve existing models and processes. Clear communication ability to articulate findings, challenges, and insights to a range of stakeholders, ensuring understanding and appropriateness. Skills And Knowledge Ability to write robust, production-grade code in Python. Excellent communication and documentation skills. Strong knowledge of machine learning techniques and algorithms, including supervised and unsupervised learning, deep learning, and reinforcement learning. Hands-on, high proficiency experience with machine learning frameworks such as TensorFlow, PyTorch, and Scikit-learn. Experience with natural language processing (NLP) techniques and tools. Strong communication and collaboration skills, with the ability to explain complex technical concepts to non-technical stakeholders. Experience taking ownership of projects from conception to deployment, and mentoring more junior team members. Hands-on experience with AWS technologies including EC2, S3, and other deployment strategies. Experience with SNS, Sagemaker a plus. Experience with ML management technologies and deployment techniques, such as AWS ML offerings, Docker, GPU deployments, etc. Education and Experience BSc in computer science, mathematics or similar field. Master’s Degree is a plus. 3+ years’ experience as a Machine Learning Engineer or similar role. Beneficios Benefits National public holidays. Vacations 3 weeks per year. Work laptop provided. Founded in 2005, tbo . is a global organization that provides translation, talent, training, teams and testing services to a full range of clients in over 40 countries worldwide, from startups to enterprise-level companies. tbo . aims to facilitate global communication by bridging the gap between peoples and cultures, providing simple solutions to complex problems, and outstanding service in 100+ languages. tbo. fosters a culture of continuous improvement, creativity, sustainability and community, with a longstanding commitment to providing high-touch human service. tbo. It is ranked as one of the fifteen fastest organically growing localization companies in the world and operates 24/7, 363 days a year on a “follow the sun” format via offices in Cordoba, Ho Chi Minh City, Kyiv and Lima. Certified under five separate international quality norms. Join our growing staff and boost your career in a global organization! At tbo. , we believe that fostering an inclusive culture and a diverse environment makes us stronger. We are an equal opportunity employer, dedicated to creating a space where everyone can thrive and grow. We are committed to ensuring our hiring processes are fair, transparent, and in compliance with all legal and policy requirements, promoting a workplace free from discrimination.",https://mx.linkedin.com/jobs/view/ai-machine-learning-engineer-at-tbo-4023201507,4023201507,"The Machine Learning Engineer role is responsible for the design, development, and implementation of machine learning solutions to serve the organization. This includes ownership or oversight of projects from conception to deployment using AWS services, Docker, and MLFlow. Responsibilities include designing machine learning models for business workflow processes, evaluating appropriate techniques, implementing models using Python and TensorFlow, deploying models using Docker and cloud infrastructure, and documenting ML experimentation. The role requires effective model development, positive team collaboration, continuous learning, and clear communication.","Python, TensorFlow, PyTorch, Scikit-learn, AWS, Docker, MLFlow, NLP",3+ years,Bachelor,True,3.0,0,0,0,1,1,0,0,0,0,0,0,0,1,0,1,0,0
Senior Machine Learning Researcher,Launch Potato,Mexico City Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Advertising Services,2024-09-08 11:36:38.320163,25,Other,,,"WHO ARE WE? Launch Potato is a digital media company with a portfolio of brands and technologies. As The Discovery and Conversion Company, Launch Potato is a leading connector of advertisers to customers at all parts of the consumer journey, from awareness to consideration to purchase. The company is headquartered in vibrant downtown Delray Beach, Florida, with a unique international team across over a dozen countries. Launch Potato's success comes from a diverse, energetic culture and high-performing, entrepreneurial team. As a result, the company is always looking for like-minded teammates and partners. (This role will heavily focus on building machine learning models. This is NOT an engineering/data engineering position.) MUST HAVE: Experience within the performance marketing/lead gen industries. Professional experience designing, implementing, optimizing, and testing end-to-end Multi-Armed Bandit (MAB) and recommendation systems. EXPERIENCE: A minimum of 4 years experience in a hands-on, in-the-weeds data science position. YOUR ROLE You will be developing deep personalization models for our users and complex optimization algorithms to bridge our customer experiences with new products/services. Your direct contribution will impact how we connect hundreds of thousands of customers to hundreds of advertisers together daily and will drive significant consumer impact while increasing revenue. You will play a pivotal role in the growth of our data science team and will be an instrumental resource as we continue to build a team of data scientists and machine learning engineers that can increase customer engagement and stickiness on our sites while improving the quality of the leads to our partners. This is an extremely hands-on and in-the-weeds Data Science role where you will be heavily immersed in the data and coding part of the solution implementation. You will design and oversee integrating state-of-the-art machine learning solutions across the company’s products. This role will be responsible for strategic planning of Machine Learning initiatives with the Product, Engineering, Performance and Business Intelligence teams, analysis of potential impact and prioritization of those projects. SUCCESS LOOKS LIKE Innovate, create, and design ML solutions to various business problems such as: Design, implement and continuously improve Multi-Armed Bandit solutions to optimize decisions/options in place of multiple AB-tests. Utilizing Large Language Models in content personalization across various verticals. Recommendation systems to serve ads, offers, questions, etc. Collaborate with stakeholders across the company including but not limited to Analytics, Engineering, Product and Business Leads to improve model infrastructure, tracking and monitoring. Provide data science support at different project stages, including the implementation of ML solutions by collaborating with Data Engineers and MLOps. Being hands-on and in-the-weeds in the data, coding part of the solution implementation. What You Need To Succeed 4+ years of related work experience in the field of Data Science & Machine learning. 2+ years of experience in the Marketing/Advertising Industry. Solid background in Machine Learning and Statistics. Professional experience designing and implementing Multi-Armed Bandit (MAB) solutions and recommendation systems. Proficiency in SQL, Python and working with Data Science tools (e.g., git, kubernetes, Docker, etc.). Structure and clarify any ambiguity for the team, i.e., divide complex projects into sprints and coordinate implementation across multiple teams and individuals. Experience creating ML solutions within cloud services (AWS/GCP). Experience with ML model development lifecycle. Experience with data visualization (preferably Looker). Experience managing a team of data scientists and machine learning researchers (including career development). Ability to communicate clearly, think independently, provide direction, and effectively communicate with technical and non-technical stakeholders. NICE TO HAVES Experience with LLMs and Deep learning models to develop business and data science solutions. Want to make your impact in a profitable, high-growth company? Apply now! Since day one, we've been committed to having a diverse, inclusive team and culture. We are proud to be an Equal Employment Opportunity company. We value diversity, equity, and inclusion. We do not discriminate based on race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",https://mx.linkedin.com/jobs/view/senior-machine-learning-researcher-at-launch-potato-4019305689,4019305689,"This role focuses on building machine learning models, specifically designing, implementing, optimizing, and testing end-to-end Multi-Armed Bandit and recommendation systems. The position requires developing deep personalization models and complex optimization algorithms to enhance customer experiences with new products/services. Responsibilities include integrating machine learning solutions across company products, collaborating with various departments, and providing data science support throughout the project stages.","Python, SQL, Machine Learning, Multi-Armed Bandit, Recommendation Systems, Data Science Tools, Git, Kubernetes, Docker, AWS, GCP, Looker",4+ years,,True,4.0,0,0,0,1,1,1,0,0,1,1,0,1,1,0,1,0,0
Big Data Engineer With GCP,LAAgencia,Mexico City Metropolitan Area,REMOTE,,Full-time,IT Services and IT Consulting,2024-02-18 11:36:38.320163,25,Engineering,Information Technology,,"Lingaro Group is the end-to-end data services partner to global brands and enterprises. We lead our clients through their data journey, from strategy through development to operations and adoption, helping them to realize the full value of their data. Responsabilities Ensure that all code, scripts, and configurations conform to established engagement standards Confirm the availability of essential documentation and gain a comprehensive understanding of the new product introduced by the client Proactively collect updates from the support team regarding incidents, service requests, and change requests during daily cadence meetings Conduct meticulous technical investigations to determine root causes and deliver effective resolutions for all raised issues Participate in technical consultations, providing valuable insights and expertise for ongoing and upcoming projects Thoroughly assess estimations provided by Enhancement teams Demonstrate the ability to autonomously lead delivery teams without offshore/onshore peers Possess strong analytical and problem-solving skills, along with the capability to identify the most suitable solutions to technical challenges Engineer IT solutions based on appropriate models Requirements Proficient understanding of Data Lake architecture principles and their implementation within the GCP ecosystem Hands-on experience with SQL and Talend Demonstrated strength in analytical thinking Outstanding communication and presentation abilities Ability to collaborate effectively with the support team to resolve intricate issues Propose improvement ideas and develop proof of concepts (POCs) for initiatives such as automatic data validation Possess a keen awareness of processes to serve as a stand-in for BI Leads, effectively acting as Service Level Managers (SLMs) for specific applications Proven experience in stakeholder management and collaboration with other leaders to drive key initiatives and data strategies 100% remote. Flexibility regarding working hours. Full-time position with a work contract.",https://mx.linkedin.com/jobs/view/big-data-engineer-with-gcp-at-laagencia-3826243515,3826243515,"The position involves ensuring code and configurations meet standards, understanding new products, collecting updates from support teams, conducting technical investigations to resolve issues, participating in consultations, and leading delivery teams. The role requires proficiency in Data Lake architecture within the GCP ecosystem, hands-on SQL and Talend experience, strong analytical skills, and effective communication and collaboration with teams.","GCP, SQL, Talend, Data Lake architecture",,,True,,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0
Data Engineer,Digital@FEMSA,Mexico City Metropolitan Area,REMOTE,Entry level,Full-time,"Technology, Information and Internet",2024-08-16 11:36:38.320163,200,Information Technology,,,"Data Engineer Jr- Mid Responsabilities: Actively participates in requirements gathering, understanding sessions, and research to estimate coding and/or pipeline automation times considering the data engineering lifecycle and ""go to production"" requests for data solutions. Contributes to all phases of the data engineering lifecycle using Agile methodology and adhering to rituals to track and meet the committed delivery dates on time and in a structured manner. Understands and applies Data Governance concepts throughout the data solution development process, ensuring their quality. Performs data ingestion and/or processing of structured data files, using relational databases (SQL); for data processing: batch, micro-batch. Ensures the continuity of digital data solutions, insights, dashboards, etc., to build and consolidate a Data-Driven culture. Documents processes or diagrams related to the processes involved in the development of the data solution under their responsibility, including everything necessary for ""go to production,"" to guarantee continuity and efficient execution in a productive environment. Ensures the application of data privacy design concepts and/or strategy. Alerts their leader of anomalies and/or risks found in data solution developments or under their responsibility, so they can be addressed without affecting the business. Communicates the status of their solution development activities to meet committed deadlines in a timely and structured manner. Required Knowledge: 1 year of experience as a Data Engineer Understanding of data engineering concepts and principles, including ETL (Extract, Transform, Load) processes, data pipelines, and data warehousing. Strong knowledge of Python fundamentals, including data structures, functions, error handling, and modules. Familiarity with Python libraries and frameworks commonly used in data engineering, such as Pandas, NumPy, and PySpark. Intermediate knowledge of different types of databases (SQL and NoSQL), including relational databases (e.g., PostgreSQL, MySQL) and NoSQL databases (e.g., MongoDB, Cassandra). Strong understanding of data modeling concepts and techniques, including normalization, denormalization, and schema design. Familiarity with various data processing methods, such as batch processing and stream processing. Understanding of file processing concepts, including reading and writing files in different formats (e.g., CSV, JSON, Parquet). Basic understanding of data governance principles, including data quality, data lineage, and data privacy. Familiarity with the end-to-end data engineering lifecycle, from data ingestion and processing to storage and retrieval. Basic understanding of various types of data architectures, including data lakes, data warehouses, and data marts. Knowledge of version control systems (e.g., Git) and experience using platforms like GitHub or GitLab. Basic understanding of data visualization tools (e.g., Tableau, Power BI) and reporting techniques. Basic familiarity with cloud computing (GCP and AWS) stack. Participation in projects with Objectives and Key Results (OKRs), ability to identify risks, and contribute to delivering business value. Intermediate ability to transparently communicate project status Digital FEMSA está comprometida con un lugar de trabajo diverso e inclusivo. Somos un empleador que ofrece igualdad de oportunidades y no discrimina por motivos de raza, origen nacional, género, identidad de género, orientación sexual, discapacidad, edad u otra condición legalmente protegida. Si desea solicitar una adaptación, notifique a su Reclutador.",https://mx.linkedin.com/jobs/view/data-engineer-at-digital%40femsa-3988808757,3988808757,"The Data Engineer Jr-Mid participates in requirements gathering and research to estimate coding and pipeline automation times, contributing to all phases of the data engineering lifecycle using Agile methodology. This role ensures data governance and quality, performs data ingestion and processing of structured data files using SQL, and documents processes for data solutions. Required knowledge includes understanding ETL processes, strong Python fundamentals, familiarity with databases (SQL and NoSQL), data modeling concepts, and basic data governance principles.","Python, SQL, NoSQL, PostgreSQL, MySQL, MongoDB, Cassandra, Pandas, NumPy, PySpark, Git, Tableau, Power BI, GCP, AWS",1,,True,1.0,0,0,1,1,0,0,0,0,1,1,0,1,0,0,1,0,0
Senior Data Science Engineer,EPAM Systems,Mexico City Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Software Development and IT Services and IT Consulting,2024-09-13 11:36:38.320163,25,Information Technology,,,"We are actively seeking an experienced Senior Data Science Engineer to join our team. In this role, you will contribute to the development of cutting-edge data science solutions, focusing on natural language processing (NLP) preprocessing and prompt engineering. If you thrive in a dynamic environment and possess a wealth of experience in data science, we welcome you to be a key player in shaping the future of our AI-driven initiatives. Responsibilities Lead prompt engineering initiatives, ensuring the development of effective prompt structures for AI-driven projects Conduct NLP preprocessing to enhance data understanding and improve AI model performance Implement and optimize vector DB similarity search to enhance data retrieval and analysis capabilities Collaborate with cross-functional teams to ensure the success of data science projects Provide expertise and guidance in Gen AI projects, including POCs/pilots and staff training Requirements At least 3+ years of relevant work experience in Data Science, with a focus on NLP preprocessing and prompt engineering Strong proficiency in Python, utilizing its capabilities for data analysis and engineering Proven experience in Gen AI projects, including POCs/pilots and teaching staff Solid understanding of data science principles, demonstrated through successful project implementations Experience in vector DB similarity search, enhancing data retrieval and analysis capabilities Strong problem-solving skills, showcasing the ability to identify and resolve complex data-related issues Fluent English language skills at an Upper-Intermediate level We offer Career plan and real growth opportunities Unlimited access to LinkedIn learning solutions International Mobility Plan within 25 countries Constant training, mentoring, online corporate courses, eLearning and more English classes with a certified teacher Support for employee’s initiatives (Algorithms club, toastmasters, agile club and more) Enjoyable working environment (Gaming room, napping area, amenities, events, sport teams and more) Flexible work schedule and dress code Collaborate in a multicultural environment and share best practices from around the globe Hired directly by EPAM & 100% under payroll Law benefits (IMSS, INFONAVIT, 25% vacation bonus) Major medical expenses insurance: Life, Major medical expenses with dental & visual coverage (for the employee and direct family members) 13 % employee savings fund, capped to the law limit Grocery coupons 30 days December bonus Employee Stock Purchase Plan 12 vacations days plus 4 floating days Official Mexican holidays, plus 5 extra holidays (Maundry Thursday and Friday, November 2nd, December 24th & 31st) Monthly non-taxable amount for the electricity and internet bills By applying to our role, you are agreeing that your personal data may be used as in set out in EPAM´s Privacy Notice and Policy. EPAM is a leading global provider of digital platform engineering and development services. We are committed to having a positive impact on our customers, our employees, and our communities. We embrace a dynamic and inclusive culture. Here you will collaborate with multi-national teams, contribute to a myriad of innovative projects that deliver the most creative and cutting-edge solutions, and have an opportunity to continuously learn and grow. No matter where you are located, you will join a dedicated, creative, and diverse community that will help you discover your fullest potential.",https://mx.linkedin.com/jobs/view/senior-data-science-engineer-at-epam-systems-4024720578,4024720578,"We are actively seeking an experienced Senior Data Science Engineer to contribute to the development of cutting-edge data science solutions, focusing on natural language processing (NLP) preprocessing and prompt engineering. Responsibilities include leading prompt engineering initiatives, conducting NLP preprocessing, implementing vector DB similarity search, and providing expertise in Gen AI projects. The role requires strong problem-solving skills and a solid understanding of data science principles.","Python, NLP, Vector DB, Gen AI",3+ years,,True,3.0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
"(Remote, Latin America) Sr. Site Reliability Engineer, Big Data",PulsePoint,Mexico City Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Advertising Services,2024-08-16 11:36:38.320163,25,Engineering,Information Technology,,"Description Description About PulsePoint: PulsePoint is a fast-growing healthcare technology company (with adtech roots) using real-time data to transform healthcare. We help brands and agencies interpret the hard-to-read signals across the health journey and unify these digital determinants of health with real-world data to produce the most dimensional view of the customer. Our award-winning advertising platforms use machine learning and programmatic automation to seamlessly activate this data, making marketing, predictive analytics, and decision support easy and instantaneous. Watch this video here to learn more about our culture and get a sense of what it’s like to work at PulsePoint! Note that this is a long-term contractor role. What you’ll be doing: Deploying, configuring, monitoring and maintaining multiple big data stores, across multiple datacenters. Perform planning, configuration, deployment and maintenance work relevant to the environment. Managing the large-scale Linux infrastructure to ensure maximum uptime. Developing and documenting system configuration standards and procedures. Performance and reliability testing. This may include reviewing configuration, software choices/versions, hardware specs, etc. Advancing our technology stack with innovative ideas and new creative solutions. Who are you: Collaboration is in your DNA. You enjoy contributing to a mutual cause, that is why you know when the team succeeds, you succeed. You are always looking for ways to grow your skills. You are hungry to learn new technologies and share your insights with your team. You like a big picture perspective and also digging into the fine details. You can think strategically but also dive into complex systems and break them down and build them back better. You are a proactive problem solver. You are irked by an unreliable infrastructure and your first instinct is to find ways to fix it. What you'll need: Multi-faceted Alluxio and Apache Hadoop (GitOps) understanding, including the Kerberos, for data storage and Trino, Hive for data retrieval. Experience managing Kafka clusters on Linux. Experience administering Percona XtraDB Cluster. Thorough understanding of Linux (we use Rocky Linux in production). Any scripting language (Python/Ruby/Shell etc). Understanding of basic networking concepts (TCP/IP stack, DNS, CDN, load balancing). Willing and able to work East Coast U.S. hours 9am-6pm EST. Bonus, but not required: Experience with Security-related best practices. Puppet configuration management tool. Experience with scalable infrastructure monitoring solutions such as Icinga, Prometheus, Graphite, Grafana and ELK. Experience with container technologies such as Docker and Kubernetes. Ability to work with Cassandra cluster from installation through troubleshooting and maintenance. Train/mentor junior-level staff. Experience in AdTech or High-Frequency Trading. Selection Process: Initial Screening Call (30 mins) Team Lead Screening (30 mins) Technical Interview with SREs (1 hour) General Discussion with VP of Data Engineering (30 mins) Technical Interview with Principal Architect (1 hour) Meet & Greet w/ SVP of Engineering (15 mins) Final Video Call with Sr. Director of Data Management at WebMD (30 mins) WebMD and its affiliates is an Equal Opportunity/Affirmative Action employer and does not discriminate on the basis of race, ancestry, color, religion, sex, gender, age, marital status, sexual orientation, gender identity, national origin, medical condition, disability, veterans status, or any other basis protected by law.",https://mx.linkedin.com/jobs/view/remote-latin-america-sr-site-reliability-engineer-big-data-at-pulsepoint-3978109344,3978109344,"The role involves deploying, configuring, monitoring, and maintaining multiple big data stores across datacenters, managing a large-scale Linux infrastructure, developing system configuration standards, and performing performance and reliability testing. The ideal candidate will have an understanding of Alluxio, Apache Hadoop, Kafka clusters, and Linux, along with experience in various scripting languages, networking concepts, and a willingness to work East Coast U.S. hours.","Alluxio, Apache Hadoop, Trino, Hive, Kafka, Linux, Percona XtraDB Cluster, Python, Ruby, Shell, TCP/IP, DNS, CDN, Docker, Kubernetes, Cassandra, Puppet, Icinga, Prometheus, Graphite, Grafana, ELK",,,True,,0,0,1,0,1,0,0,0,0,1,0,0,0,0,1,0,0
Analytics Team Data Engineer,Accenture México,Mexico City Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Business Consulting and Services,2024-09-13 11:36:38.320163,69,Information Technology,,,"Design, develop and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL extract, transform and load processes to migrate and deploy data across systems. Deal Project Description Create retail media strategy and blueprint Data Engineering Data Processing",https://mx.linkedin.com/jobs/view/analytics-team-data-engineer-at-accenture-m%C3%A9xico-4004276131,4004276131,"Design, develop, and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL processes to migrate and deploy data across systems.","Data Engineering, ETL, Data Pipelines, Data Processing",,,True,,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0
Data Engineer - Mexico -100% Remote,"The Dignify Solutions, LLC",Mexico City Metropolitan Area,REMOTE,Mid-Senior level,Contract,IT Services and IT Consulting,2024-06-17 11:36:38.320163,25,Information Technology,,,"Proven experience as a Data Engineer with a focus on Ataccama DQ development. Strong proficiency in backend development with Ataccama, including developing remote executors for EMR. Experience with Ataccama IDE and Ataccama MMM. Skilled in developing data pipelines using BODS, SAP IDH, and DLT. Proficiency in Linux and SQL. Experience with GraphQL for API integration and development. Familiarity with cloud platforms (AWS, Azure, GCP) and their services. Experience with CI/CD pipelines and DevOps practices. Familiarity with agile development methodologies.",https://mx.linkedin.com/jobs/view/data-engineer-mexico-100%25-remote-at-the-dignify-solutions-llc-3944429493,3944429493,"Proven experience as a Data Engineer with a focus on Ataccama DQ development. Strong proficiency in backend development with Ataccama, including developing remote executors for EMR. Experience with Ataccama IDE and Ataccama MMM. Skilled in developing data pipelines using BODS, SAP IDH, and DLT. Proficiency in Linux and SQL. Experience with GraphQL for API integration and development. Familiarity with cloud platforms (AWS, Azure, GCP) and their services. Experience with CI/CD pipelines and DevOps practices. Familiarity with agile development methodologies.","Ataccama DQ, Ataccama IDE, Ataccama MMM, BODS, SAP IDH, DLT, Linux, SQL, GraphQL, AWS, Azure, GCP, CI/CD, DevOps, Agile",,,True,,1,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0
Data Software Engineer - Python AWS Databricks,EPAM Systems,Mexico City Metropolitan Area,REMOTE,Entry level,Full-time,Software Development and IT Services and IT Consulting,2024-09-13 11:36:38.320163,25,Engineering,Information Technology,,"Join our dynamic IT company as a Data Software Engineer specializing in Python, AWS, and Databricks. We are looking for a dedicated Data Analyst to become a key member of our DevOps team. Your role will involve building insightful Databricks dashboards, crafting complex SQL queries, and ensuring the integrity of data across various systems. If you are passionate about data visualization, meticulous in data validation, and thrive in collaborative environments, this opportunity is for you. Responsibilities Build and maintain Databricks dashboards for data visualization and analysis Compose and execute complex SQL queries to extract and manipulate data Validate data streams from Kinesis to Firehose and AWS S3 bucket Work closely with the DevOps team to ensure data integrity and accuracy Collaborate with cross-functional teams to support project objectives Requirements At least 3+ years of hands-on experience with Python and SQL Experience in building and maintaining Databricks dashboards Knowledge and experience with Kinesis streams and Firehose Strong skills in data validation and ensuring data accuracy Strong agile, communication, and proactive skills Nice to have Knowledge of Sumologic for log management and analytics Technologies Databricks Python SQL AWS (Kinesis, Firehose, S3) We offer Career plan and real growth opportunities Unlimited access to LinkedIn learning solutions International Mobility Plan within 25 countries Constant training, mentoring, online corporate courses, eLearning and more English classes with a certified teacher Support for employee’s initiatives (Algorithms club, toastmasters, agile club and more) Enjoyable working environment (Gaming room, napping area, amenities, events, sport teams and more) Flexible work schedule and dress code Collaborate in a multicultural environment and share best practices from around the globe Hired directly by EPAM & 100% under payroll Law benefits (IMSS, INFONAVIT, 25% vacation bonus) Major medical expenses insurance: Life, Major medical expenses with dental & visual coverage (for the employee and direct family members) 13 % employee savings fund, capped to the law limit Grocery coupons 30 days December bonus Employee Stock Purchase Plan 12 vacations days plus 4 floating days Official Mexican holidays, plus 5 extra holidays (Maundry Thursday and Friday, November 2nd, December 24th & 31st) Monthly non-taxable amount for the electricity and internet bills By applying to our role, you are agreeing that your personal data may be used as in set out in EPAM´s Privacy Notice and Policy. EPAM is a leading global provider of digital platform engineering and development services. We are committed to having a positive impact on our customers, our employees, and our communities. We embrace a dynamic and inclusive culture. Here you will collaborate with multi-national teams, contribute to a myriad of innovative projects that deliver the most creative and cutting-edge solutions, and have an opportunity to continuously learn and grow. No matter where you are located, you will join a dedicated, creative, and diverse community that will help you discover your fullest potential.",https://mx.linkedin.com/jobs/view/data-software-engineer-python-aws-databricks-at-epam-systems-4024724482,4024724482,"Join our dynamic IT company as a Data Software Engineer specializing in Python, AWS, and Databricks. Your role will involve building insightful Databricks dashboards, crafting complex SQL queries, and ensuring the integrity of data across various systems. Responsibilities include building and maintaining Databricks dashboards, composing and executing complex SQL queries, validating data streams, and collaborating with cross-functional teams to support project objectives.","Python, SQL, Databricks, AWS (Kinesis, Firehose, S3)",3+ years,,True,3.0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0
Software Engineer - Data Infrastructure,Canonical,Mexico City Metropolitan Area,REMOTE,Entry level,Full-time,"Technology, Information and Internet",2024-09-01 11:36:38.320163,25,Engineering,Information Technology,,"Canonical is building a comprehensive automation suite to provide multi-cloud and on-premise data solutions for the enterprise. The data platform team is a collaborative team that develops a full range of data stores and data technologies, spanning from big data, through NoSQL, cache-layer capabilities, and analytics; all the way to structured SQL engines. We are facing the interesting problem of fault-tolerant mission-critical distributed systems and intend to deliver the world's best automation solution for delivering data platforms. We have a number of openings ranging anywhere from junior to senior level. We will help you identify a suitable position depending on your experience and interests. Engineers who thrive at Canonical are mindful of open-source community dynamics and equally aware of the needs of large, innovative organisations. Location: This is a Globally remote role What your day will look like The data platform team is responsible for the automation of data platform operations. This includes ensuring fault-tolerant replication, TLS, installation, and much more; but also provides domain-specific expertise on the actual data system to other teams within Canonical. This role is focused on the creation and automation of features of data platforms, not analysing the data in them. Collaborate proactively with a distributed team Write high-quality, idiomatic Python code to create new features Debug issues and interact with upstream communities publicly Work with helpful and talented engineers including experts in many fields Discuss ideas and collaborate on finding good solutions Work from home with global travel for 2 to 4 weeks per year for internal and external events What we are looking for in you Proven hands-on experience in software development using Python Proven hands-on experience in distributed systems Have a Bachelor's or equivalent in Computer Science, STEM, or a similar degree Willingness to travel up to 4 times a year for internal events Additional Skills That You Might Also Bring You might also bring a subset of experience from the following, which will determine the exact role and level we consider you for: Experience operating and managing data platform technologies like PostgreSQL, MySQL, MongoDB, OpenSearch, Kafka, Yugabyte, Trino, Superset, Atlas, Ranger, and Redis Experience with Linux systems administration, package management, and operations Experience with the public cloud or a private cloud solution like OpenStack Experience with operating Kubernetes clusters and a belief that it can be used for serious persistent data services What we offer you Your base pay will depend on various factors including your geographical location, level of experience, knowledge and skills. In addition to the benefits above, certain roles are also eligible for additional benefits and rewards including annual bonuses and sales incentives based on revenue or utilisation. Our compensation philosophy is to ensure equity right across our global workforce. In addition to a competitive base pay, we provide all team members with additional benefits, which reflect our values and ideals. Please note that additional benefits may apply depending on the work location and, for more information on these, please ask your Talent Partner. Fully remote working environment - we've been working remotely since 2004! Personal learning and development budget of 2,000USD per annum Annual compensation review Recognition rewards Annual holiday leave Parental Leave Employee Assistance Programme Opportunity to travel to new locations to meet colleagues at 'sprints' Priority Pass for travel and travel upgrades for long haul company events About Canonical Canonical is a pioneering tech firm that is at the forefront of the global move to open source. As the company that publishes Ubuntu, one of the most important open source projects and the platform for AI, IoT and the cloud, we are changing the world on a daily basis. We recruit on a global basis and set a very high standard for people joining the company. We expect excellence - in order to succeed, we need to be the best at what we do. Canonical has been a remote-first company since its inception in 2004. Work at Canonical is a step into the future, and will challenge you to think differently, work smarter, learn new skills, and raise your game. Canonical provides a unique window into the world of 21st-century digital business. Canonical is an equal-opportunity employer We are proud to foster a workplace free from discrimination. Diversity of experience, perspectives, and background create a better work environment and better products. Whatever your identity, we will give your application fair consideration.",https://mx.linkedin.com/jobs/view/software-engineer-data-infrastructure-at-canonical-4013776401,4013776401,"Canonical is building a comprehensive automation suite to provide multi-cloud and on-premise data solutions for the enterprise. The data platform team is responsible for automation of data platform operations, including fault-tolerant replication, installation, and collaboration with distributed teams. The role is focused on creating and automating features of data platforms, requiring collaboration and high-quality Python coding for new features. Proven hands-on experience in software development using Python, distributed systems, and a degree in Computer Science or a similar field is essential.","Python, PostgreSQL, MySQL, MongoDB, OpenSearch, Kafka, Yugabyte, Trino, Superset, Atlas, Ranger, Redis, Linux, Kubernetes",,Bachelor,True,,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0
Tech Support Data Engineer,Boldr,Mexico City Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Non-profit Organizations and Primary and Secondary Education,2024-08-16 11:36:38.320163,43,Engineering,,,"Working hours: US Business hours What Is Your Role This role is part of the team of Customer Engineers in Professional Services, and we're seeking highly talented individuals to join and grow our team. This is the intersection where the product has to meet customer needs and create value. You are a customer-facing data engineer who loves to see technology and data used in ways that ensure our projects' and customers' success. You have great attention to detail and are very proactive in seeking potential roadblocks to success. You have great people skills and know how to manage the trust and expectations of a customer. What Will You Do Customer Engineers are the customer facing technical owners of our existing customer relationships and data driven deliverables on the company's platform You will work hands-on with our technology stack and collaborate with several teams such as Product Engineering and Customer Engagement in order to deliver on all customer technical requests. You will be responsible for regularly interacting with our customers to gather requirements (e.g. weekly meetings, email, etc), and for scoping and prioritizing the incoming work. This can include: Designing Solutions - translate business requirements into technical solutions using SQL, scripting, codebase configurations, etc Setting up ETL pipelines across disparate data sources, and creating a unified Data Model Setting up/enabling new product features & ingest/export integrations Implementing the company's platform and its various components for our new customers Helping answer customer questions, and troubleshooting where necessary Participating in the on-call rotation You will also be: Finding out sustainable ways of addressing repeatable issues, and building tools for automation Contributing with documentation and building our customer specific configuration knowledge base A source of feedback for our product team, full stack and backend engineering teams Requirements BS degree in Computer Science, Engineering, Mathematics, Economics, Statistics, Information Management or similar 2+ years in a technical role that involves managing and manipulating large data sets, such as ETL, Data Warehousing, Analytics, Data Science etc 2+ years in a client-facing role that involves being a point-of-contact for technical and non-technical users Proficient in one programming language and working knowledge of SQL and Unix command line tools Working Knowledge of Github, and AWS infrastructure Excellent problem solving skills Strong Communication skills Improvement mindset, through processes, tools and/ or documentation Strong professionalism & work ethic Nice to have: Working knowledge of Java and/or Scala Marketing technology industry & relevant vendor knowledge Benefits Law Benefits Private Health Insurance Paid Time Off Training Life insurance Mental Health Support Learning and Development Programs",https://mx.linkedin.com/jobs/view/tech-support-data-engineer-at-boldr-3994917836,3994917836,"This role is part of the Customer Engineers team in Professional Services, seeking talented individuals for customer-facing data engineering. You will design solutions by translating business requirements into technical solutions using SQL and scripting, set up ETL pipelines, and implement the company's platform for new customers. Responsibilities include interacting with customers, scoping work, troubleshooting, contributing to documentation, and providing feedback to the product team.","SQL, ETL, Unix, AWS, Github, Java, Scala",2+,Bachelor,True,2.0,0,0,0,1,0,0,1,0,0,1,0,1,0,0,0,0,0
Tech Lead/ Big Data Engineer Sr.,Azkait,Mexico City Metropolitan Area,REMOTE,,Full-time,"Technology, Information and Internet",2024-05-18 11:36:38.320163,25,Engineering,Information Technology,,"AZKAIT es una empresa Mexicana que busca y conecta el mejor talento IT con empresas Latinoamericanas y de Estados Unidos. Estamos en la búsqueda de tu talento como Tech Lead/ Big Data Engineer. ﻿ Requisitos: Tech Lead/ Big Data Engineer Sr Requisitos: Experiencia en el rol de Líder Técnico Experiencia de 7 años con ETLs Licenciatura o Ingeniería, Titulado (Indispensable) Inglés conversacional, avanzado Conocimientos: SQL Python Azure o GCP APIs Agile / Scrum Beneficios: Prestaciones de Ley Sueldo de hasta $ 90,,000 mensuales brutos Esquema de contratación 100% en nómina Aguinaldo Vacaciones de ley Prima Vacacional SGMM Familiar Lugar de trabajo: Modalidad de trabajo Remoto CDMX",https://mx.linkedin.com/jobs/view/tech-lead-big-data-engineer-sr-at-azkait-3926117125,3926117125,"AZKAIT is searching for talent as a Tech Lead/Big Data Engineer. Requirements include 7 years of experience with ETLs and technical leadership, a degree in Engineering or a related field, and advanced conversational English. Knowledge in SQL, Python, Azure or GCP, APIs, and Agile/Scrum methodologies is also required.","SQL, Python, Azure, GCP, APIs, Agile, Scrum",7,Bachelor,True,7.0,1,0,0,1,0,0,0,0,0,1,0,0,0,0,1,0,0
Data Analytics Engineer,Pinterest,Mexico City Metropolitan Area,REMOTE,Mid-Senior level,Full-time,"Technology, Information and Internet, Software Development, and IT Services and IT Consulting",2024-09-01 11:36:38.320163,200,Information Technology,,,"About Pinterest Millions of people across the world come to Pinterest to find new ideas every day. It’s where they get inspiration, dream about new possibilities and plan for what matters most. Our mission is to help those people find their inspiration and create a life they love. In your role, you’ll be challenged to take on work that upholds this mission and pushes Pinterest forward. You’ll grow as a person and leader in your field, all the while helping Pinners make their lives better in the positive corner of the internet. Creating a life you love also means finding a career that celebrates the unique perspectives and experiences that you bring. As you read through the expectations of the position, consider how your skills and experiences may complement the responsibilities of the role. We encourage you to think through your relevant and transferable skills from prior experiences. Our new progressive work model is called PinFlex, a term that’s uniquely Pinterest to describe our flexible approach to living and working. Visit our PinFlex landing page to learn more. We are looking for a Software Engineer II, Analytics Engineering to help improve the quality and velocity of data science at Pinterest. You will shape the future of people-facing and business-facing products we build at Pinterest, by building rock solid data foundations and tooling. Your expertise will be utilized to solve some of the most complex engineering challenges at the company. You will collaborate on a wide array of product and business problems with a diverse set of cross-functional partners across Product, Engineering, Data Science, Product Analytics, Data Engineering, Business Intelligence and others. The results of your work will influence and uplevel our data science and product development teams serving hundreds of millions of pinners, creators, advertisers and merchants around the world. What You’ll Do Develop best practices for instrumentation and experimentation and communicate those to product engineering teams to help us fulfill our mission - to bring everyone the inspiration to create a life they love Build and prototype analysis pipelines iteratively to provide insights at scale while developing comprehensive knowledge of data structures and metrics, advocating for changes where needed for product development Work closely with Data Scientists and Engineers to build and prototype tools and processes that enable the self service of key data sets, insights, and metric investigations Contribute to comprehensive documentation of tools and datasets Think big and drive the strategy for better data quality and discoverability within Pinterest Work cross-functionally to build and communicate key insights, and collaborate closely with product managers, engineers, designers, and researchers to help build the next experiences on Pinterest What We’re Looking For 3+ years of experience working with data in a fast-paced, data-driven environment Ability to manipulate large data sets with high dimensionality and complexity; fluency in SQL (or other database languages) and a scripting language (Python or R); including SQL-based experience in nested data structure manipulation, windowing functions, query optimization, data partitioning techniques Experience in conducting workflow orchestration; ETL / ELT with huge and complicated datasets and handling DAG data dependencies Consistent track record of supplying analytics solutions to existing teams, with ability to take open ended goals and scope them into defined and impactful objectives. A team player who’s able to partner with cross-functional leadership to quickly turn insights into actions An accountable operator who can proactively identify project opportunities even when many things seem urgent or important This position is not eligible for relocation assistance. We let the type of work you do guide the collaboration style. That means we're not always working in an office, but we continue to gather for key moments of collaboration and connection. Our Commitment To Diversity Pinterest is an equal opportunity employer and makes employment decisions on the basis of merit. We want to have the best qualified people in every job. All qualified applicants will receive consideration for employment without regard to race, color, ancestry, national origin, religion or religious creed, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, age, marital status, status as a protected veteran, physical or mental disability, medical condition, genetic information or characteristics (or those of a family member) or any other consideration made unlawful by applicable federal, state or local laws. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you require an accommodation during the job application process, please notify accessibility@pinterest.com for support.",https://mx.linkedin.com/jobs/view/data-analytics-engineer-at-pinterest-3994021470,3994021470,"We are looking for a Software Engineer II, Analytics Engineering to help improve the quality and velocity of data science at Pinterest. You will develop best practices for instrumentation and experimentation, build and prototype analysis pipelines, work closely with Data Scientists and Engineers, and drive the strategy for better data quality and discoverability within Pinterest.","SQL, Python, R, ETL, ELT, Data Analysis",3+ years,,True,3.0,0,0,0,0,0,1,1,0,0,1,0,0,0,0,1,0,0
Principal Data Engineer (Azure) - Mexico,Tiger Analytics,Mexico City Metropolitan Area,REMOTE,Associate,Full-time,Non-profit Organizations and Primary and Secondary Education,2024-03-19 11:36:38.320163,25,Information Technology,,,"Tiger Analytics is a global AI and analytics consulting firm. With data and technology at the core of our solutions, we are solving problems that eventually impact the lives of millions globally. Our culture is modeled around expertise and respect with a team-first mindset. Headquartered in Silicon Valley, you'll find our delivery centers across the globe and offices in multiple cities across India, the US, UK, Canada, and Singapore, including a substantial remote global workforce. We're Great Place to Work-Certified™. Working at Tiger Analytics, you'll be at the heart of an AI revolution. You'll work with teams that push the boundaries of what is possible and build solutions that energize and inspire. Requirements As a Principal Data Engineer (Azure), you would have hands on experience working on Azure as cloud, Databricks and some exposure/experience on Data Modelling. You will build and learn about a variety of analytics solutions & platforms, data lakes, modern data platforms, data fabric solutions, etc. using different Open Source, Big Data, and Cloud technologies on Microsoft Azure. Design and build scalable & metadata-driven data ingestion pipelines (For Batch and Streaming Datasets) Conceptualize and execute high-performance data processing for structured and unstructured data, and data harmonization Schedule, orchestrate, and validate pipelines Design exception handling and log monitoring for debugging Ideate with your peers to make tech stack and tools-related decisions Interact and collaborate with multiple teams (Consulting/Data Science & App Dev) and various stakeholders to meet deadlines, to bring Analytical Solutions to life What do we expect? Experience in implementing Data Lake with technologies like Azure Data Factory (ADF), PySpark, Databricks, ADLS, Azure SQL Database A comprehensive foundation with working knowledge of Azure Synapse Analytics, Event Hub & Streaming Analytics, Cosmos DB, and Purview A passion for writing high-quality code and the code should be modular, scalable, and free of bugs (debugging skills in SQL, Python, or Scala/Java). Enthuse to collaborate with various stakeholders across the organization and take complete ownership of deliverables. Experience in using big data technologies like Hadoop, Spark, Airflow, NiFi, Kafka, Hive, Neo4J, Elastic Search Adept understanding of different file formats like Delta Lake, Avro, Parquet, JSON, and CSV Good knowledge of building and designing REST APIs with real-time experience working on Data Lake or Lakehouse projects. Experience in supporting BI and Data Science teams in consuming the data in a secure and governed manner Certifications like Data Engineering on Microsoft Azure (DP-203) or Databricks Certified Developer (DE) are valuable addition. Note: The designation will be commensurate with expertise and experience. Compensation packages are among the best in the industry. Job Requirement Mandatory: Azure Data Factory (ADF), PySpark, Databricks, ADLS, Azure SQL Database Optional: Azure Synapse Analytics, Event Hub & Streaming Analytics, Cosmos DB and Purview Strong programming, unit testing & debugging skills in SQL, Python or Scala/Java Some experience of using big data technologies like Hadoop, Spark, Airflow, NiFi, Kafka, Hive, Neo4J, Elastic Search Good Understanding of different file formats like Delta Lake, Avro, Parquet, JSON and CSV Experience of working in Agile projects and following DevOps processes with technologies like Git, Jenkins & Azure DevOps Good to have: Experience of working on Data Lake & Lakehouse projects Experience of building REST services and implementing service-oriented architectures Experience of supporting BI and Data Science teams in consuming the data in a secure and governed manner Certifications like Data Engineering on Microsoft Azure (DP-203) or Databricks Certified Developer (DE) Benefits This position offers an excellent opportunity for significant career development in a fast-growing and challenging entrepreneurial environment with a high degree of individual responsibility.",https://mx.linkedin.com/jobs/view/principal-data-engineer-azure-mexico-at-tiger-analytics-3853353110,3853353110,"As a Principal Data Engineer (Azure), you will have hands-on experience working with Azure as a cloud platform, Databricks, and exposure to data modeling. You will build various analytics solutions and platforms, data lakes, and modern data platforms using different Open Source, Big Data, and Cloud technologies on Microsoft Azure. Responsibilities include designing and building scalable data ingestion pipelines for batch and streaming datasets, processing structured and unstructured data, and collaborating with multiple teams to deliver analytical solutions.","Azure, Databricks, Azure Data Factory (ADF), PySpark, ADLS, Azure SQL Database, Azure Synapse Analytics, Event Hub, Streaming Analytics, Cosmos DB, Purview, Hadoop, Spark, Airflow, NiFi, Kafka, Hive, Neo4J, Elastic Search, SQL, Python, Scala, Java, Delta Lake, Avro, Parquet, JSON, CSV, Git, Jenkins, Azure DevOps",,,True,,0,0,1,1,0,0,0,0,0,1,0,1,0,0,1,0,0
Data Engineer / ETL,Azkait,Mexico City Metropolitan Area,REMOTE,,Full-time,"Technology, Information and Internet",2024-03-19 11:36:38.320163,100,Information Technology,,,"AZKAIT es una empresa Mexicana que busca y conecta el mejor talento IT con empresas Latinoamericanas y de Estados Unidos. Estamos en la búsqueda de tu talento como Data Engineer / ETL Developer Requisitos: Ingles conversacional Estudios Superiores concluidos ETL -DataStage Consulta SQL Gitlab Conocimientos de Tableau Control-M - Creación\Monitorización\Modificación Ofrecemos: 100% nómina + SGMM para el recurso y su familia directa, Seguro de Vida por 1 millón de pesos, vales de despensa, PTU de ley, aguinaldo de 30 días, vacaciones a partir del primer año, 25% prima vacacional. Beneficios adicionales como seguro dental, descuentos departamentales y en redes médicas, Certificaciones gratuitas,, apoyo para telecomunicaciones.",https://mx.linkedin.com/jobs/view/data-engineer-etl-at-azkait-3850210231,3850210231,"AZKAIT is looking for your talent as a Data Engineer / ETL Developer. Requirements: Conversational English, completed higher education, ETL - DataStage, SQL query, GitLab, knowledge of Tableau, Control-M - Creation/Monitoring/Modification.","ETL, DataStage, SQL, GitLab, Tableau, Control-M",,,True,,0,0,0,0,0,0,1,0,1,1,0,1,0,0,0,0,0
Data Engineer,Virtualent,Mexico City Metropolitan Area,REMOTE,,Full-time,"Technology, Information and Internet",2024-06-17 11:36:38.320163,47,Information Technology,,,"Virtualent About Us: We’re a leading IT Staffing company dedicated to connecting top talent with the most innovative companies. If you're excited about working with large volumes of data and turning information into knowledge, we'd love to meet you! Responsibilities: Design, develop, and maintain robust and scalable data pipelines. Work with data scientists and analysts to understand their needs and provide the necessary data. Optimize database performance and ensure data integrity and quality. Implement and manage data storage solutions both on-premises and in the cloud. Collaborate in defining data architectures and best practices. Implement and maintain CI/CD pipelines for data applications. Use containerization tools (Docker) to deploy and manage applications. Utilize orchestration tools (Kubernetes) to manage containerized applications. Employ infrastructure as code (IaC) tools (Terraform) to automate infrastructure deployment. Monitor and ensure the availability and performance of data solutions. Requirements: Experience as a Data Engineer or in similar roles. Strong knowledge of programming languages such as Python, Java, R, and/or C++. Experience with database management systems (SQL and NoSQL). Familiarity with Big Data tools like Hadoop, Spark, Kafka, etc. Knowledge of cloud platforms such as AWS, Google Cloud, or Azure. Experience with CI/CD tools and practices (e.g., Jenkins, GitLab CI, CircleCI). Experience with containerization tools like Docker. Familiarity with orchestration tools like Kubernetes. Knowledge of infrastructure as code (IaC) tools like Terraform. Analytical skills and ability to solve complex problems. Good communication skills and ability to work in a team. Good written and oral English language skills. Nice to Haves (but not mandatory): Experience with ETL and data integration tools. Knowledge of machine learning and predictive analytics models. Certifications in data technologies and/or cloud platforms. Benefits: A dynamic and collaborative work environment. Opportunities for professional growth and development. Flexible work arrangements and remote work possibilities. Competitive salary. Interested? Ready to take the next step in your IT career? Apply now and join our team of dedicated professionals who are making a difference in the IT world every day! Requirements: Requirements: Experience as a Data Engineer or in similar roles. Strong knowledge of programming languages such as Python, Java, R, and/or C++. Experience with database management systems (SQL and NoSQL). Familiarity with Big Data tools like Hadoop, Spark, Kafka, etc. Knowledge of cloud platforms such as AWS, Google Cloud, or Azure. Experience with CI/CD tools and practices (Jenkins, GitLab CI, CircleCI). Experience with containerization tools like Docker. Familiarity with orchestration tools like Kubernetes. Knowledge of infrastructure as code (IaC) tools like Terraform. Analytical skills and ability to solve complex problems. Good communication skills and ability to work in a team. Good written and oral English language skills.",https://mx.linkedin.com/jobs/view/data-engineer-at-virtualent-3948026752,3948026752,"The role involves designing, developing, and maintaining robust and scalable data pipelines. The position requires collaboration with data scientists and analysts to meet their data needs, optimizing database performance, ensuring data integrity, and implementing data storage solutions both on-premises and in the cloud. Responsibilities also include defining data architectures and best practices, managing CI/CD pipelines for data applications, deploying applications using containerization tools, and utilizing orchestration tools for container management. Familiarity with infrastructure as code tools is necessary for automating deployment. Analytical skills and teamwork are essential.","Python, Java, R, C++, SQL, NoSQL, Hadoop, Spark, Kafka, AWS, Google Cloud, Azure, Jenkins, GitLab CI, CircleCI, Docker, Kubernetes, Terraform",,,True,,0,0,1,1,1,0,0,0,0,1,0,1,0,0,1,0,0
Data Researcher MX (Remote),Simera,Mexico City Metropolitan Area,REMOTE,Entry level,Full-time,Staffing and Recruiting,2024-09-08 11:36:38.320163,25,Other,,,"Unlock your remote work journey: you shine, we match you! Once you apply, you will be receiving your profile link in the next 24hrs. After applying you will need to complete your profile, receive follow-ups from our talent advisors, and our AI platform will do the rest. Summary: We are seeking a highly skilled and experienced Data Researcher, you'll be an integral part of our team, responsible for gathering, analyzing, and interpreting data to support our internal operations. You'll play a crucial role in ensuring smooth communication, efficient processes, and successful outcomes. Key Responsibilities Transcribe drive-thru interactions accurately and efficiently. Memorize menus for all accounts to facilitate smooth order taking. Utilize an internal dashboard to place telephone food orders promptly and accurately. Implement real-time corrective actions to resolve issues as they arise. Receive customer orders and input them into the POS (point of sale) system swiftly. Test the functionality of AI systems as directed by developers. Collaborate with the Linguistics team on order flows, language variations, and menu updates. Familiarize oneself with local terms, regional accents, and common menu variations. Communicate technical issues with management and submit tickets as needed. Troubleshoot issues on individual consoles as required. Analyze performance data and metrics to identify trends and insights. Collect specific data as requested by Linguistics and Engineering teams. Collaborate with the Data Research Team on performance enhancements and process optimizations. Assist in the creation and documentation of processes, policies, and procedures. Qualifications Proficiency in English language skills at either B2 or C1 level is required English Resume is required Flexibility to work shifts as required. Typing speed of 65+ words per minute. Ability to multitask effectively in a fast-paced environment. Previous experience in customer service, restaurant, and/or POS operations. Reliable high-speed internet connection with direct ethernet plug-in to modem/router. Strong attention to detail and accuracy in work execution.",https://mx.linkedin.com/jobs/view/data-researcher-mx-remote-at-simera-4017771782,4017771782,"We are seeking a highly skilled and experienced Data Researcher, responsible for gathering, analyzing, and interpreting data to support our internal operations. The role includes transcribing interactions accurately, utilizing internal dashboards for order processing, testing AI system functionalities, collaborating with various teams, and analyzing performance data for insights.","Data Analysis, POS Systems, AI Systems, Real-time Data Processing, Database Management",,,True,,0,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0
Data Engineer,Sequoia Connect,Mexico City Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Software Development,2024-09-10 11:36:38.320163,25,Information Technology,Engineering,,"Esta vacante viene de la bolsa de empleo Talenteca.com Vacante para la empresa Sequoia Connect en Benito Juárez, Ciudad de México Our client represents the connected world, offering innovative and customer-centric information technology experiences, enabling Enterprises, Associates, and Society to Rise. They are a USD 6 billion company with 163,000+ professionals across 90 countries, helping 1279 global customers, including Fortune 500 companies. They focus on leveraging next-generation technologies, including 5G, Blockchain, Metaverse, Quantum Computing, Cybersecurity, Artificial Intelligence, and more, on enabling end-to-end digital transformation for global customers. Our client is one of the fastest-growing brands and among the top 7 IT service providers globally. Our client has consistently emerged as a leader in sustainability and is recognized amongst the ‘2021 Global 100 Most sustainable corporations in the World by Corporate Knights. Responsibilities We are currently searching for a Data Engineer : Responsible for the ETL (Extract-Transform-Load) procedures of current and historical data from multiple internal/external data sources, in particular: E: Extract data from multiple data sources through various available data vendors. Most of the data is structured or semi-structured, while a small portion is unstructured. T: Transform data to reconcile changes in file formats and schemas over time or across multiple data sources for the same type of information. Align data at various temporal resolutions (e.g., aggregation or disaggregation at various levels in time). L: Store files in a structured way for future reference and develop a data schema; deposit data to a database for convenient querying and analysis. Pipeline for current data: maintain automatic pipelines to ingest data continuously. Ingestion and curation of historical data is a one-time effort. Once the ingestion pipelines for most of the data are established and stabilized, the support switches to the maintenance mode for the existing ingestion pipelines and additions of new data sources from time to time. Data cleaning is used to provide quick research turnaround, together with a data retrieval API, supported in Excel Add-in and Python packages. Requirements Fluent in Python and packages related to data processing, such as pandas. Fluent in object-oriented programming with Python. Familiar with database technologies/SQL, data warehouses, and related concepts. Deploying cloud resources that support data engineering and ML Ops pipelines. Setting up CICD pipelines for data engineering and ML Ops projects. GitHub experience. Fluent in working with large data sets and distributed computing architectures (i.e. Apache Spark). Experience with various cloud-based data technologies, including Databricks, Azure Data lake, Azure Data Explorer (ADX) Experience with the development of APIs in front of various data technologies. Desired Fluent in front-end development and deployment of single-page applications in one or more Javascript frameworks. Relational database – Azure SQL & Oracle. No SQL databases- MongoDB and/or Cosmos DB Exam AZ-900: Microsoft Azure Fundamentals certification Languages Advanced Oral English. Native Spanish. If you meet these qualifications and are pursuing new challenges, Start your application to join an award-winning employer.Explore all our job openings | Sequoia Career’s Page: * Nivel De Educación Deseada Superior - titulado Nivel De Experiencia Deseada Nivel Experto Función Departamental Tecnología / Internet Industria Desarrollo de Software / Programación Habilidades ETL SQL Cloud based data technologies Python Esta Vacante Viene De La Bolsa De Empleo Talenteca.com https://www.talenteca.com/anuncio?j_id=66e087d42300005400a46092&source=linkedin",https://mx.linkedin.com/jobs/view/data-engineer-at-sequoia-connect-4022492196,4022492196,"We are currently searching for a Data Engineer responsible for the ETL (Extract-Transform-Load) procedures of current and historical data from various data sources. The role involves extracting data from multiple sources, transforming it for reconciliation, and storing it in a structured way for future reference. The engineer will maintain automatic data ingestion pipelines, curate historical data, and ensure effective data cleaning and retrieval using Python and APIs.","Python, pandas, SQL, Apache Spark, Databricks, Azure Data Lake, Azure Data Explorer, Oracle, MongoDB, Cosmos DB, CI/CD",Expert Level,Bachelor,True,,0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0
Data DevOps Engineer,EPAM Systems,Mexico City Metropolitan Area,REMOTE,Entry level,Full-time,Software Development and IT Services and IT Consulting,2024-09-13 11:36:38.320163,25,Engineering,Information Technology,,"Join EPAM as a Data DevOps Engineer. In this role, you'll provide expert guidance on data ingestion, refine and deploy Terraform plans, and develop Azure DevOps Pipelines for simplifying the CI/CD process. If you have experience with Infrastructure as Code (IaC), specifically Terraform for Azure Databricks, and strong problem-solving skills, we'd love to hear from you. Responsibilities Provide answers to the questions the data engineering team may ask about data ingestion Help with the refinement and deployment of the Terraform plans: syntax, best practices, what you should know Develop Terraform modules where appropriate to simplify Customer's IaC plans In conjunction with the rest of the team, develop Azure DevOps Pipelines for simplifying the CI/CD process Provide material, guides, and resources as needed to help the team skill up Requirements Experience with Infrastructure as Code (IaC), specifically Terraform for Azure Databricks Ability to help the customer iron out data connectivity between Azure subscriptions Strong problem-solving skills and ability to provide actionable answers to the data engineering team Experience in developing Terraform modules and refining Terraform plans Nice to have Experience with CI/CD processes Previous experience in creating guides and resources for team training Technologies Azure Databricks Terraform Azure DevOps Pipelines We offer Career plan and real growth opportunities Unlimited access to LinkedIn learning solutions International Mobility Plan within 25 countries Constant training, mentoring, online corporate courses, eLearning and more English classes with a certified teacher Support for employee’s initiatives (Algorithms club, toastmasters, agile club and more) Enjoyable working environment (Gaming room, napping area, amenities, events, sport teams and more) Flexible work schedule and dress code Collaborate in a multicultural environment and share best practices from around the globe Hired directly by EPAM & 100% under payroll Law benefits (IMSS, INFONAVIT, 25% vacation bonus) Major medical expenses insurance: Life, Major medical expenses with dental & visual coverage (for the employee and direct family members) 13 % employee savings fund, capped to the law limit Grocery coupons 30 days December bonus Employee Stock Purchase Plan 12 vacations days plus 4 floating days Official Mexican holidays, plus 5 extra holidays (Maundry Thursday and Friday, November 2nd, December 24th & 31st) Monthly non-taxable amount for the electricity and internet bills By applying to our role, you are agreeing that your personal data may be used as in set out in EPAM´s Privacy Notice and Policy. EPAM is a leading global provider of digital platform engineering and development services. We are committed to having a positive impact on our customers, our employees, and our communities. We embrace a dynamic and inclusive culture. Here you will collaborate with multi-national teams, contribute to a myriad of innovative projects that deliver the most creative and cutting-edge solutions, and have an opportunity to continuously learn and grow. No matter where you are located, you will join a dedicated, creative, and diverse community that will help you discover your fullest potential.",https://mx.linkedin.com/jobs/view/data-devops-engineer-at-epam-systems-4024719705,4024719705,"Join EPAM as a Data DevOps Engineer, providing expert guidance on data ingestion, refining and deploying Terraform plans, and developing Azure DevOps Pipelines to simplify the CI/CD process. Responsibilities include answering questions from the data engineering team, developing Terraform modules, and creating Azure DevOps Pipelines. Ideal candidates will have experience with Infrastructure as Code (IaC), especially Terraform for Azure Databricks, and strong problem-solving skills.","Terraform, Azure DevOps, Azure Databricks, CI/CD",,,True,,0,0,1,1,0,0,0,0,0,0,0,1,0,0,0,0,0
Data Engineer ETL Pentaho Spark,Reclutamiento It,Mexico City Metropolitan Area,REMOTE,Associate,Full-time,"Transportation, Logistics, Supply Chain and Storage",2024-09-12 11:36:38.320163,25,Information Technology,Engineering,,"Esta vacante viene de la bolsa de empleo Talenteca.com Vacante para la empresa Reclutamiento IT en Benito Juárez, Ciudad de México ¿Quiénes somos? Somos una empresa Mexicana especialista en logística y mensajería, tenemos presencia a nivel nacional, latam y EEUU; hemos tenido un crecimiento exponencial y sabemos que la tecnología es parte esencia para ser líderes, por ello, buscamos para nuestras oficinas en CDMX un Ingeniero de Datos Desarrollador ETL con experiencia en diversas plataformas como ETL Pentaho, Cloudera, Spark y apego a buenas prácticas. Con nosotros tendrás la oportunidad de: Proponer, desarrollar y administrar proyectos de análisis y explotación de datos a nivel global. Libertad operativa, innovación y apertura total para ideas disruptivas y únicas, pensar fuera de la caja, para hacer una diferencia. Oportunidad de desarrollo real y estabilidad personal y profesional- Integración con equipos multiculturales en EEUU y Latam. Relacionamiento con proveedores globales. ¿Por qué nosotros? Nos Centramos En Las Personas, La Calidad y Balance De Vida Es Importante Para Nosotros; Contamos Con Programas De Desarrollo, Formación, Dinámicas De Integración, Muy Buen Ambiente De Trabajo y Retos Para Llevar Tu Potencial Al Máximo, Nuestra Propuesta Incluye Ingreso: de 42,000 a 45,000 pesos brutos (nominal directo con nosotros) paquete de beneficios ley, vales, caja y fondo de ahorro, seguro de vida, bonos, 30 días de aguinaldo. Horario: de lunes a viernes de 8:30 a 6:00 p.m. Esquema Híbrido Zona de trabajo: Hipódromo Condesa, Cuauhtémoc (5 minutos del Metro Juan Acatlán Línea 1 Rosa). ¿Qué buscamos? 2 a 3 años de experiencia como: ETL Developer, analista ETL, Programador ETL, Ingeniero ETL, Data engineer ETL, Ingeniero de datos ETL, Ingeniero de datos, especialista de datos. Adecuado conocimiento en análisis de requerimientos, amplio análisis de fuentes de Información, métricas y reglas de negocio. Estimación de esfuerzo y planificación de tareas. 2 a 3 años en desarrollo de ETL con Pentaho, Cloudera o Spark, con apego a buenas prácticas o nociones en gobierno y modelado de datos con framework DAMA. Apego a referencias de DMBOK. Experiencia práctica operativa en proyectos de integración con SAP o SAP HANA en los módulos de BW, BO, BI. Experiencia en gestión de Bases de Datos SQL (MySQL, SQL Server, Oracle) y NoSQL (Mongo, Cassandra, Dynamo) Stored Procedures, Joins, CTEs). Gestión y Modelado de Datos (creación, lectura y conceptos de DWH). Manejo de alguna plataforma de visualización BI como Power BI, Tableau, Qilk View, SAS, etc. Conocimiento básico en al menos un servicio en la nube (GCP, AWS o Azure). Muy deseable experiencia en sector logístico. Nivel De Educación Deseada Superior - trunco Nivel De Experiencia Deseada Nivel Medio Función Departamental Tecnología / Internet Industria Transporte, Logística, Cadena de Suministro y Almacenamiento Habilidades ETL Pentaho DAMA Cloudera Spark Esta Vacante Viene De La Bolsa De Empleo Talenteca.com https://www.talenteca.com/anuncio?j_id=66e354392900005200051bf2&source=linkedin",https://mx.linkedin.com/jobs/view/data-engineer-etl-pentaho-spark-at-reclutamiento-it-4024921952,4024921952,"We are looking for a Data Engineer ETL with experience in various platforms such as ETL Pentaho, Cloudera, Spark, and adherence to best practices. You will have the opportunity to propose, develop, and manage data analysis and exploitation projects on a global level, with operational freedom and innovation. You will also collaborate with multicultural teams in the US and Latin America, and interact with global suppliers.","ETL Pentaho, Cloudera, Spark, SQL, NoSQL, MySQL, SQL Server, Oracle, MongoDB, Cassandra, DynamoDB, Power BI, Tableau, QlikView, SAS, GCP, AWS, Azure",2 to 3 years,,False,2.0,0,0,1,1,0,0,1,0,1,1,0,0,0,0,0,0,0
"Data engineer Java, AWS, Databricks",EPAM Systems,Mexico City Metropolitan Area,REMOTE,Entry level,Full-time,Software Development and IT Services and IT Consulting,2024-09-13 11:36:38.320163,25,Information Technology,,,"We are on the lookout for a skilled Data Engineer with proficiency in Java, AWS, and Databricks to join our dynamic IT team. If you have the knack for using software and data engineering principles to deliver results and hold experience in proactively improving existing systems, this role is for you. Small project leadership and effective team collaboration are key aspects of this role. If you're looking to challenge your skills and dive into the world of data engineering, apply today! Responsibilities Collaborate with team members on problem-solving and development Proactively engage with peers across the company to encourage collaboration Develop expertise in technical areas Develop and test standard software applications and related programs Apply software design principles, data structures, and design patterns Coordinate stakeholder involvement when developing solutions Challenge authority or the status quo when necessary Stay updated on advancements in data engineering technologies Requirements Bachelor's degree with 3+ years of experience or Master's degree with 0-2 years of experience in a relevant field Experience working in a data engineering team environment Proven experience in developing and maintaining data engineering pipelines/products in public/hybrid cloud infrastructure Strong programming skills in relevant languages (Java, Spark, Python) and familiarity with others Experience with data processing patterns (stream vs batch) and knowledge of RDBMS systems vs distributed systems Ability to understand complex systems, test and monitor code, debug applications, and collaborate effectively within a team Familiarity with architecture, testing, monitoring, alerting, business acumen/domain knowledge, data access patterns, streaming technology, and data validation Nice to have Technical degree is preferred Familiarity with modern data access patterns Experience with cloud data platforms, data models, enterprise information management, business intelligence, and data science Technologies Java, Python, Scala Architecture Testing, monitoring, alerting Business acumen/domain knowledge Data access patterns Streaming technology Data validation We offer Career plan and real growth opportunities Unlimited access to LinkedIn learning solutions International Mobility Plan within 25 countries Constant training, mentoring, online corporate courses, eLearning and more English classes with a certified teacher Support for employee’s initiatives (Algorithms club, toastmasters, agile club and more) Enjoyable working environment (Gaming room, napping area, amenities, events, sport teams and more) Flexible work schedule and dress code Collaborate in a multicultural environment and share best practices from around the globe Hired directly by EPAM & 100% under payroll Law benefits (IMSS, INFONAVIT, 25% vacation bonus) Major medical expenses insurance: Life, Major medical expenses with dental & visual coverage (for the employee and direct family members) 13 % employee savings fund, capped to the law limit Grocery coupons 30 days December bonus Employee Stock Purchase Plan 12 vacations days plus 4 floating days Official Mexican holidays, plus 5 extra holidays (Maundry Thursday and Friday, November 2nd, December 24th & 31st) Monthly non-taxable amount for the electricity and internet bills By applying to our role, you are agreeing that your personal data may be used as in set out in EPAM´s Privacy Notice and Policy. EPAM is a leading global provider of digital platform engineering and development services. We are committed to having a positive impact on our customers, our employees, and our communities. We embrace a dynamic and inclusive culture. Here you will collaborate with multi-national teams, contribute to a myriad of innovative projects that deliver the most creative and cutting-edge solutions, and have an opportunity to continuously learn and grow. No matter where you are located, you will join a dedicated, creative, and diverse community that will help you discover your fullest potential.",https://mx.linkedin.com/jobs/view/data-engineer-java-aws-databricks-at-epam-systems-4024717947,4024717947,"We are looking for a skilled Data Engineer with proficiency in Java, AWS, and Databricks to join our IT team. Responsibilities include collaborating on problem-solving and development, developing and testing standard software applications, and proactively improving existing systems. The role requires strong programming skills in relevant languages and the ability to understand complex systems, test and monitor code, and debug applications.","Java, Python, Spark, AWS, Databricks, RDBMS, Distributed Systems",3+ years of experience with Bachelor's degree or 0-2 years of experience with Master's degree,Bachelor,True,0.0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,1,0,0
Azure Data DevOps Engineer (MLOps),EPAM Systems,Mexico City Metropolitan Area,REMOTE,Entry level,Full-time,Software Development and IT Services and IT Consulting,2024-09-13 11:36:38.320163,25,Engineering,Information Technology,,"Are you a skilled Azure Data DevOps Engineer with a passion for creating the next generation of Large Language Models? Do you have experience in designing, developing, and deploying custom software solutions on the Azure platform? If so, we have an exciting opportunity for you! We're currently seeking an Azure Data DevOps Engineer to join our vibrant MLOps team. This role offers the chance to create and maintain the development pipelines of a high-tech Machine Learning solution designed to change the way the world does business. If you're ready to take your career to the next level, we'd love to hear from you! Responsibilities Design, develop and deploy custom software solutions on Azure platform Collaborate with cross-functional teams to identify and implement continuous integration (CI) and continuous deployment (CD) pipeline tools and processes Assist in troubleshooting and providing solutions for software defects and production issues Develop and maintain configuration management tools and processes Create and maintain technical documentation Requirements Solid experience with any public cloud (Azure, GCP, AWS) Wide knowledge of AzureDevOps CI/CD (or a similar tool) Proficiency with Kubernetes & Docker Previous experience with deployment of open source LLMs to the Cloud Competency in tools like Seldon.ui, OpenLLM, bentoml We offer Career plan and real growth opportunities Unlimited access to LinkedIn learning solutions International Mobility Plan within 25 countries Constant training, mentoring, online corporate courses, eLearning and more English classes with a certified teacher Support for employee’s initiatives (Algorithms club, toastmasters, agile club and more) Enjoyable working environment (Gaming room, napping area, amenities, events, sport teams and more) Flexible work schedule and dress code Collaborate in a multicultural environment and share best practices from around the globe Hired directly by EPAM & 100% under payroll Law benefits (IMSS, INFONAVIT, 25% vacation bonus) Major medical expenses insurance: Life, Major medical expenses with dental & visual coverage (for the employee and direct family members) 13 % employee savings fund, capped to the law limit Grocery coupons 30 days December bonus Employee Stock Purchase Plan 12 vacations days plus 4 floating days Official Mexican holidays, plus 5 extra holidays (Maundry Thursday and Friday, November 2nd, December 24th & 31st) Monthly non-taxable amount for the electricity and internet bills By applying to our role, you are agreeing that your personal data may be used as in set out in EPAM´s Privacy Notice and Policy. EPAM is a leading global provider of digital platform engineering and development services. We are committed to having a positive impact on our customers, our employees, and our communities. We embrace a dynamic and inclusive culture. Here you will collaborate with multi-national teams, contribute to a myriad of innovative projects that deliver the most creative and cutting-edge solutions, and have an opportunity to continuously learn and grow. No matter where you are located, you will join a dedicated, creative, and diverse community that will help you discover your fullest potential.",https://mx.linkedin.com/jobs/view/azure-data-devops-engineer-mlops-at-epam-systems-4024721202,4024721202,"We are currently seeking an Azure Data DevOps Engineer to design, develop, and deploy custom software solutions on the Azure platform. This role involves creating and maintaining development pipelines for high-tech Machine Learning solutions, collaborating with teams to implement CI/CD tools and processes, troubleshooting software defects, and maintaining configuration management tools.","Azure, AzureDevOps, Kubernetes, Docker, Seldon.ui, OpenLLM, bentoml",,,True,,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0
Azure Infra Data Engineer,CRH Talento en IT,Mexico City Metropolitan Area,REMOTE,,Full-time,"Technology, Information and Internet",2024-06-17 11:36:38.320163,25,Information Technology,,,"CRH Talento en IT Puesto de trabajo: Ingeniero de Datos de Infraestructura Azure Años de experiencia requeridos: 6 años CRH Talento en IT está en búsqueda de un Ingeniero de Datos de Infraestructura Azure con al menos 6 años de experiencia para unirse a nuestro equipo. Este puesto ofrece la oportunidad de trabajar en proyectos emocionantes y desafiantes, utilizando tecnologías avanzadas y herramientas de vanguardia. Si tienes experiencia en SOA applications y servicios basados en la nube, preferiblemente en Azure, y estás familiarizado con Ansible, Linux/UNIX, Docker y los servicios web de Microsoft Azure, esta podría ser la oportunidad perfecta para ti. Descripción del trabajo: Como Ingeniero de Datos de Infraestructura Azure, serás responsable de diseñar, desarrollar e implementar soluciones de infraestructura de datos basadas en Azure. Deberás tener un sólido conocimiento de los servicios en la nube y una comprensión profunda de los protocolos de red e internet, incluyendo TCP/IP, DNS, SMTP, HTTP y redes distribuidas. Además, se espera que tengas experiencia en bases de datos, incluyendo conocimientos de CosmosDB, SQL y NoSQL, y almacenamientos de datos relacionados como Postgres. Responsabilidades: Diseñar, desarrollar e implementar soluciones de infraestructura de datos en Azure. Colaborar con equipos multidisciplinarios para asegurar la integridad y la escalabilidad de los sistemas. Gestionar y optimizar bases de datos y almacenamiento de datos en la nube. Mantenerse actualizado sobre las últimas tecnologías y tendencias en Azure y servicios en la nube. Participar en la resolución de problemas y ofrecer soporte técnico cuando sea necesario. Requisitos: 6 años de experiencia en la gestión de infraestructura de datos en Azure. Experiencia en el diseño e implementación de SOA applications y servicios basados en la nube. Conocimientos avanzados de Ansible, Linux/UNIX, Docker y servicios web de Azure. Fuerte comprensión de protocolos de red e internet, como TCP/IP, DNS, SMTP, HTTP y redes distribuidas. Experiencia en bases de datos, incluyendo CosmosDB, SQL y NoSQL, y almacenamientos de datos relacionados como Postgres. Si cumples con los requisitos y estás interesado en unirte a nuestro equipo como Ingeniero de Datos de Infraestructura Azure, ¡no dudes en postularte! En CRH Talento en IT valoramos a los profesionales comprometidos, apasionados por la tecnología y con ganas de crecer en un entorno dinámico y estimulante. Para aplicar, envía tu CV actualizado y una carta de presentación a ricardo.morales@.crhit.com",https://mx.linkedin.com/jobs/view/azure-infra-data-engineer-at-crh-talento-en-it-3935237971,3935237971,"CRH Talent in IT is looking for an Azure Data Infrastructure Engineer with at least 6 years of experience to join their team. As an Azure Data Infrastructure Engineer, you will be responsible for designing, developing, and implementing data infrastructure solutions based on Azure. You should have a solid understanding of cloud services and a deep understanding of network and internet protocols, including TCP/IP, DNS, SMTP, HTTP, and distributed networks. Additionally, experience with databases, including knowledge of CosmosDB, SQL, and NoSQL, along with related data storage such as Postgres, is expected.","Azure, Ansible, Linux, UNIX, Docker, Cloud Services, CosmosDB, SQL, NoSQL, Postgres, TCP/IP, DNS, SMTP, HTTP",6,,False,6.0,0,0,0,1,1,0,0,0,0,1,0,1,0,0,0,0,0
Data Engineer Azure,LAAgencia,Mexico City Metropolitan Area,REMOTE,,Full-time,IT Services and IT Consulting,2024-07-17 11:36:38.320163,25,Information Technology,,,"Lingaro Group is the end-to-end data services partner to global brands and enterprises. We lead our clients through their data journey, from strategy through development to operations and adoption, helping them to realize the full value of their data. Responsabilities Responsible for implementing data ingestion pipelines from diverse data sources employing Azure Data Factory, Azure Databricks, and additional ETL tools Tasked with developing scalable and reusable self-service frameworks for data ingestion and processing Will be involved in the design, construction, and administration of SQL Server databases within the Azure cloud environment Engaged in data modeling and the integration of data from various systems Will assess and implement best practices for data manipulation Responsible for creating and maintaining Azure Data Factory pipelines Involved in integrating end-to-end data pipelines to facilitate the seamless transfer of data from source to target data repositories, ensuring data quality and consistency Requirements Over 3 years of Azure development experience Proficiency in cloud-based solutions Comprehensive understanding and practical experience with GIT Sound familiarity with Microsoft ETL tools including Azure Databricks, Azure Data Factory, Data Lake, and SSIS Hands-on experience with both structured and unstructured data Proficiency in utilizing ARM templates Proficient in working with JSON Good grasp of Azure DevOps or Jira Knowledge of SQL Effective communication skills, capable of providing customers with technical insights and interpreting data for them Ability to work independently with a strong sense of ownership for assigned tasks Capability to work effectively in both independent and collaborative team environments, spanning cross-functional and cross-cultural settings Nice to have Proficiency in data analysis programming, particularly in PySpark and SparkSQL, or a willingness to acquire this skill Comprehension of AAS (Azure Analysis Services) Familiarity with Power BI 100% remote. Flexibility regarding working hours. Full-time position with a work contract.",https://mx.linkedin.com/jobs/view/data-engineer-azure-at-laagencia-3959581244,3959581244,"Responsible for implementing data ingestion pipelines from diverse data sources employing Azure Data Factory and Azure Databricks. Tasked with developing scalable and reusable self-service frameworks for data ingestion and processing, designing and administering SQL Server databases within the Azure cloud environment, and integrating data from various systems. Will create and maintain Azure Data Factory pipelines and ensure the seamless transfer of data from source to target repositories, with a focus on data quality and consistency.","Azure Data Factory, Azure Databricks, SQL Server, GIT, Azure DevOps, Jira, ETL tools, ARM templates, JSON, PySpark, SparkSQL, Power BI",3+ years,,True,3.0,0,0,1,1,0,0,1,0,1,1,0,0,0,0,0,0,0
Data Integration Engineer Azure,LAAgencia,Mexico City Metropolitan Area,REMOTE,,Full-time,IT Services and IT Consulting,2024-02-18 11:36:38.320163,25,Information Technology,,,"Lingaro Group is the end-to-end data services partner to global brands and enterprises. We lead our clients through their data journey, from strategy through development to operations and adoption, helping them to realize the full value of their data. Responsabilities Set up data ingestion pipelines from diverse data origins utilizing Azure Data Factory, Azure Databricks, and other ETL tools Develop frameworks that are scalable, reusable, and user-friendly for data ingestion and processing Architect, construct and administer SQL Server databases within the Azure cloud environment Perform data modeling tasks and integrate data from various systems Evaluate and implement best practices for effective data manipulation Construct and maintain Azure Data Factory pipelines Integrate end-to-end data pipelines to seamlessly transfer data from its source to designated repositories, ensuring quality and consistency throughout Engage with customers to provide technical insights and assist with data interpretation Operate both independently and collaboratively in a team-oriented, cross-functional, and culturally diverse setting Requirements Possessing over 3 years of hands-on experience in Azure development Proficient comprehension and practical application of GIT Sound familiarity with Microsoft ETL tools including Azure Databricks, Azure Data Factory, Data Lake, and SSIS Extensive experience handling both structured and unstructured data Proficiency in utilizing ARM templates Familiarity with working with JSON Solid understanding of Azure DevOps or Jira Exceptional command of English language, both spoken and written Capable of collaborating effectively within a team dynamic, while also demonstrating autonomy and strong ownership over assigned responsibilities 100% remote. Flexibility regarding working hours. Full-time position with a work contract.",https://mx.linkedin.com/jobs/view/data-integration-engineer-azure-at-laagencia-3825813812,3825813812,"The responsibilities include setting up data ingestion pipelines from various origins using Azure Data Factory and Azure Databricks, developing scalable frameworks for data ingestion, architecting and administering SQL Server databases in Azure, performing data modeling, integrating data from multiple systems, and collaborating with customers for technical insights. The role requires over 3 years of hands-on Azure development experience and proficiency in GIT, Microsoft ETL tools, handling structured and unstructured data, utilizing ARM templates, and a solid understanding of Azure DevOps or Jira.","Azure Data Factory, Azure Databricks, SQL Server, GIT, ARM templates, Azure DevOps, JSON",3+ years,,True,3.0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,0,0,0
Data Analytics and Visualization Engineer,EPAM Systems,Mexico City Metropolitan Area,REMOTE,Entry level,Full-time,Software Development and IT Services and IT Consulting,2024-09-13 11:36:38.320163,25,Information Technology,,,"Join our innovative IT team as a MicroStrategy Developer and play a crucial role in designing, developing, and implementing cutting-edge business intelligence solutions across our data landscape. If you are experienced in working closely with stakeholders to understand business requirements and are passionate about delivering high-quality reporting and self-service solutions, this opportunity is for you. Dive into a role where your technical expertise and creative problem-solving skills will drive impactful decisions and enhance our business intelligence capabilities. Responsibilities Collaborate as a team member to develop technical and functional requirements through an iterative, Agile development lifecycle Engage in requirements gathering to collect essential information for solving client issues with immediate technical solutions Utilize deep knowledge of MicroStrategy architecture and best practices to develop impactful BI solutions Create dynamic reports and dashboards using all visualization and functionality options available in MicroStrategy Support data analysis, model data, and evaluate new BI technologies to innovate production solutions Develop and manage intelligent cubes, optimize performance, and configure refresh schedules Install, upgrade, and maintain MicroStrategy software components, troubleshooting to optimize performance Requirements 5+ years of experience in MicroStrategy V.2019/2020 reporting solutions design and implementation Profound SQL knowledge Skilled in data profiling, modeling metadata, and integrating complex data sets from various sources using SQL Comprehensive experience with MicroStrategy Suite including Architect, Desktop, Web, Mobile, and more Strong problem-solving, analytical, organizational, and interpersonal skills Self-starter capable of multitasking in fast-paced environments Nice to have Experience with Agile development methodologies Familiarity with additional Business Intelligence tools Experience in performance tuning and optimization of BI solutions Technologies MicroStrategy V.2019/2020/2021 SQL MicroStrategy Suite: Architect, Desktop, Web, Mobile, Object Manager, Enterprise Manager, Command Manager We offer Career plan and real growth opportunities Unlimited access to LinkedIn learning solutions International Mobility Plan within 25 countries Constant training, mentoring, online corporate courses, eLearning and more English classes with a certified teacher Support for employee’s initiatives (Algorithms club, toastmasters, agile club and more) Enjoyable working environment (Gaming room, napping area, amenities, events, sport teams and more) Flexible work schedule and dress code Collaborate in a multicultural environment and share best practices from around the globe Hired directly by EPAM & 100% under payroll Law benefits (IMSS, INFONAVIT, 25% vacation bonus) Major medical expenses insurance: Life, Major medical expenses with dental & visual coverage (for the employee and direct family members) 13 % employee savings fund, capped to the law limit Grocery coupons 30 days December bonus Employee Stock Purchase Plan 12 vacations days plus 4 floating days Official Mexican holidays, plus 5 extra holidays (Maundry Thursday and Friday, November 2nd, December 24th & 31st) Monthly non-taxable amount for the electricity and internet bills By applying to our role, you are agreeing that your personal data may be used as in set out in EPAM´s Privacy Notice and Policy. EPAM is a leading global provider of digital platform engineering and development services. We are committed to having a positive impact on our customers, our employees, and our communities. We embrace a dynamic and inclusive culture. Here you will collaborate with multi-national teams, contribute to a myriad of innovative projects that deliver the most creative and cutting-edge solutions, and have an opportunity to continuously learn and grow. No matter where you are located, you will join a dedicated, creative, and diverse community that will help you discover your fullest potential.",https://mx.linkedin.com/jobs/view/data-analytics-and-visualization-engineer-at-epam-systems-4024717999,4024717999,"Join our innovative IT team as a MicroStrategy Developer and play a crucial role in designing, developing, and implementing cutting-edge business intelligence solutions across our data landscape. This position requires collaborating with stakeholders to understand business requirements, delivering high-quality reporting and self-service solutions. Responsibilities include developing technical and functional requirements through an Agile development lifecycle, engaging in requirements gathering, utilizing knowledge of MicroStrategy architecture, creating dynamic reports and dashboards, supporting data analysis, and managing intelligent cubes. The ideal candidate will have 5+ years of experience in MicroStrategy V.2019/2020 reporting solutions design and implementation, profound SQL knowledge, and experience with MicroStrategy Suite. Strong problem-solving, analytical, organizational, and interpersonal skills are essential.","MicroStrategy V.2019/2020/2021, SQL, MicroStrategy Suite: Architect, Desktop, Web, Mobile, Object Manager, Enterprise Manager, Command Manager",5+,,True,5.0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
Software Engineer - Data Infrastructure - OpenSearch/ElasticSearch,Canonical,Mexico City Metropolitan Area,REMOTE,Entry level,Full-time,"Technology, Information and Internet",2024-09-01 11:36:38.320163,25,Engineering,Information Technology,,"Canonical is building a comprehensive automation suite to provide multi-cloud and on-premise data solutions for the enterprise. The data platform team is a collaborative team that develops a full range of data stores and data technologies, spanning from big data, through NoSQL, cache-layer capabilities, and analytics; all the way to structured SQL engines. The OpenSearch team is, among other things, focused on creating the best enterprise automation solution for search and analytics suites like OpenSearch and Elasticsearch. We have a number of openings we are looking to hire across a range of levels. We will help you identify a suitable position depending on your experience and interests. Engineers who thrive at Canonical are mindful of open-source community dynamics and equally aware of the needs of large, innovative organisations. Location: This is a Globally remote role What your day will look like The OpenSearch team is responsible for the automation of OpenSearch operations. This includes ensuring fault-tolerant replication, TLS, installation, and much more; but also provides domain-specific expertise on the actual data system to other teams within Canonical. This role is focused on the creation and automation of features of data platforms, not analysing the data in them. Collaborate proactively with an internationally distributed team Write high-quality, idiomatic Python code to create new features Debug issues and interact with upstream communities publicly Work with helpful and talented engineers including experts in a diverse set of fields Work from home with global travel for 2 to 4 weeks per year for internal and external events What we are looking for in you Proven hands-on experience in software development using Python Proven hands-on experience in distributed systems development Bachelor's or equivalent in Computer Science, STEM, or a similar degree Willingness to travel up to 4 times a year for internal events Additional Skills That You Might Also Bring You might also bring a subset of experience from the following, which will determine the exact role and level we consider you for: Experience operating and managing search and analytics engines like Elasticsearch, Logstash, KIbana, and OpenSearch Experience with Linux systems administration, package management, and operations Experience with the public cloud or a private cloud solution like OpenStack Experience with operating Kubernetes clusters and a belief that it can be used for serious persistent data services What we offer you Your base pay will depend on various factors including your geographical location, level of experience, knowledge and skills. In addition to the benefits above, certain roles are also eligible for additional benefits and rewards including annual bonuses and sales incentives based on revenue or utilisation. Our compensation philosophy is to ensure equity right across our global workforce. In addition to a competitive base pay, we provide all team members with additional benefits, which reflect our values and ideals. Please note that additional benefits may apply depending on the work location and, for more information on these, please ask your Talent Partner. Fully remote working environment - we've been working remotely since 2004! Personal learning and development budget of 2,000USD per annum Annual compensation review Recognition rewards Annual holiday leave Parental Leave Employee Assistance Programme Opportunity to travel to new locations to meet colleagues at 'sprints' Priority Pass for travel and travel upgrades for long haul company events About Canonical Canonical is a pioneering tech firm that is at the forefront of the global move to open source. As the company that publishes Ubuntu, one of the most important open source projects and the platform for AI, IoT and the cloud, we are changing the world on a daily basis. We recruit on a global basis and set a very high standard for people joining the company. We expect excellence - in order to succeed, we need to be the best at what we do. Canonical has been a remote-first company since its inception in 2004. Work at Canonical is a step into the future, and will challenge you to think differently, work smarter, learn new skills, and raise your game. Canonical provides a unique window into the world of 21st-century digital business. Canonical is an equal-opportunity employer We are proud to foster a workplace free from discrimination. Diversity of experience, perspectives, and background create a better work environment and better products. Whatever your identity, we will give your application fair consideration.",https://mx.linkedin.com/jobs/view/software-engineer-data-infrastructure-opensearch-elasticsearch-at-canonical-4013776394,4013776394,"Canonical is building a comprehensive automation suite to provide multi-cloud and on-premise data solutions for the enterprise. The OpenSearch team is responsible for the automation of OpenSearch operations, including ensuring fault-tolerant replication and installation. This role focuses on the creation and automation of features of data platforms. Collaboration with an internationally distributed team is essential, as well as writing high-quality, idiomatic Python code and debugging issues.","Python, Elasticsearch, Logstash, Kibana, OpenSearch, Linux, Kubernetes",Proven hands-on experience required,Bachelor,True,,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0
Data Integration Engineer,EPAM Systems,Mexico City Metropolitan Area,REMOTE,Entry level,Full-time,Software Development and IT Services and IT Consulting,2024-09-13 11:36:38.320163,25,Information Technology,,,"Join our innovative IT team as a Predictive Analytics Developer and play a pivotal role in shaping the future of data integration. We are looking for a data-oriented, creative individual with strong programming and data analysis skills to take ownership of the Scenario Extractor, contribute to the development of our next-generation Data Import Service, and potentially enhance our Analytics Data Platform. If you are passionate about leveraging data to drive decision-making and optimize performance, this is the perfect opportunity for you. Responsibilities Maintain and enhance the Scenario Extractor Collaborate with the team to build the next-generation Data Import Service Contribute to the development of the Analytics Data Platform Perform data manipulation tasks using Python and Pandas Implement and maintain ETL pipelines to support data processing needs Ensure data integrity and quality throughout the data lifecycle Work closely with the Predictive Analytics team to develop and optimize predictive models Requirements Proficiency in Python programming Hands-on experience with data manipulation using Pandas Understanding of ETL (Extract-Transform-Load) pipeline concepts Strong knowledge of SQL Experience in software engineering Familiarity with Google Protobuf Nice to have Experience with Apache Airflow Knowledge of gRPC communication protocol Technologies Python, Pandas SQL ETL pipelines Google Protobuf We offer Career plan and real growth opportunities Unlimited access to LinkedIn learning solutions International Mobility Plan within 25 countries Constant training, mentoring, online corporate courses, eLearning and more English classes with a certified teacher Support for employee’s initiatives (Algorithms club, toastmasters, agile club and more) Enjoyable working environment (Gaming room, napping area, amenities, events, sport teams and more) Flexible work schedule and dress code Collaborate in a multicultural environment and share best practices from around the globe Hired directly by EPAM & 100% under payroll Law benefits (IMSS, INFONAVIT, 25% vacation bonus) Major medical expenses insurance: Life, Major medical expenses with dental & visual coverage (for the employee and direct family members) 13 % employee savings fund, capped to the law limit Grocery coupons 30 days December bonus Employee Stock Purchase Plan 12 vacations days plus 4 floating days Official Mexican holidays, plus 5 extra holidays (Maundry Thursday and Friday, November 2nd, December 24th & 31st) Monthly non-taxable amount for the electricity and internet bills By applying to our role, you are agreeing that your personal data may be used as in set out in EPAM´s Privacy Notice and Policy. EPAM is a leading global provider of digital platform engineering and development services. We are committed to having a positive impact on our customers, our employees, and our communities. We embrace a dynamic and inclusive culture. Here you will collaborate with multi-national teams, contribute to a myriad of innovative projects that deliver the most creative and cutting-edge solutions, and have an opportunity to continuously learn and grow. No matter where you are located, you will join a dedicated, creative, and diverse community that will help you discover your fullest potential.",https://mx.linkedin.com/jobs/view/data-integration-engineer-at-epam-systems-4024718701,4024718701,"Join our innovative IT team as a Predictive Analytics Developer and play a pivotal role in shaping the future of data integration. We are looking for a data-oriented individual with strong programming and data analysis skills to take ownership of the Scenario Extractor and contribute to the development of our next-generation Data Import Service and Analytics Data Platform. Responsibilities include maintaining and enhancing the Scenario Extractor, collaborating to build the Data Import Service, performing data manipulation using Python and Pandas, implementing and maintaining ETL pipelines, and ensuring data integrity and quality.","Python, Pandas, SQL, ETL, Google Protobuf, Apache Airflow, gRPC",,,True,,0,0,1,0,0,0,1,0,0,1,0,0,0,0,1,0,0
Azure Data Engineer,Encora Inc.,Mexico City Metropolitan Area,REMOTE,Entry level,Full-time,"Technology, Information and Internet",2024-08-25 11:36:38.320163,25,Information Technology,,,"Important Information Experience: + 6 years Job Mode: Full-time Work Mode: Work from home Job Summary We are seeking a highly skilled Azure Data Engineer with a minimum of 6 years of experience in related positions to join our growing team. The ideal candidate will have extensive experience with Azure data services, particularly Azure Cosmos DB, and must hold the Azure Cosmos DB Developer Specialty certification. You will play a crucial role in designing, implementing, and maintaining scalable data solutions on the Azure platform, ensuring optimal performance, security, and reliability. Responsibilities and Duties Design, develop, and implement data solutions using Azure services, with a focus on Azure Cosmos DB. Manage and optimize data pipelines and ETL processes, ensuring data is processed efficiently and accurately. Develop and maintain database schemas, queries, and stored procedures for optimal performance and scalability. Collaborate with cross-functional teams to understand business requirements and translate them into technical solutions. Ensure data security and compliance, implementing best practices for data governance and access control within the Azure environment. Monitor and optimize performance of Azure Cosmos DB, identifying and addressing potential bottlenecks. Implement data migration strategies, including the transfer of on-premises data to Azure cloud services. Automate data workflows and develop solutions for data ingestion, processing, and storage. Work with DevOps teams to integrate data solutions into CI/CD pipelines, ensuring seamless deployment and updates. Troubleshoot and resolve issues related to data integrity, performance, and scalability in the Azure environment. Stay current with Azure advancements and best practices, integrating new tools and services to enhance data solutions. Provide technical guidance and mentorship to junior data engineers and other team members. Qualifications and Skills 6+ years of experience in data engineering, with a strong focus on Azure cloud services. Azure Cosmos DB Developer Specialty certification is required. Extensive experience with Azure Cosmos DB, including database design, partitioning, indexing, and performance tuning. Strong understanding of Azure Data Factory, Azure SQL Database, Azure Data Lake, and other Azure data services. Proficiency in SQL, as well as experience with NoSQL databases and understanding of when to apply different database models. Experience with data warehousing and ETL/ELT processes in cloud environments. Familiarity with programming languages such as Python, C#, or JavaScript for data processing and automation. Knowledge of data governance, security best practices, and regulatory compliance in cloud environments. Experience with DevOps practices and tools, including CI/CD pipelines, version control, and infrastructure as code. Strong analytical and problem-solving skills, with the ability to troubleshoot and resolve complex data issues. Excellent communication and collaboration skills, with the ability to work effectively in a team environment. About Encora Encora is the preferred digital engineering and modernization partner of some of the world's leading enterprises and digital native companies. With over 9,000 experts in 47+ offices and innovation labs worldwide, Encora's technology practices include Product Engineering & Development, Cloud Services, Quality Engineering, DevSecOps, Data & Analytics, Digital Experience, Cybersecurity, and AI & LLM Engineering. At Encora, we hire professionals based solely on their skills and qualifications, and do not discriminate based on age, disability, religion, gender, sexual orientation, socioeconomic status, or nationality.",https://mx.linkedin.com/jobs/view/azure-data-engineer-at-encora-inc-4007315102,4007315102,"We are seeking a highly skilled Azure Data Engineer with a minimum of 6 years of experience to join our team. This role involves designing, implementing, and maintaining scalable data solutions on the Azure platform, particularly Azure Cosmos DB. Responsibilities include managing data pipelines, optimizing performance, ensuring data security, and collaborating with teams to meet business requirements.","Azure Cosmos DB, Azure Data Factory, Azure SQL Database, Azure Data Lake, SQL, NoSQL, Python, C#, JavaScript, ETL/ELT",6+ years,,True,6.0,0,1,0,1,0,0,1,0,0,1,0,0,0,0,1,0,0
Acceleration Center - Adobe Real Time Customer Data Platform (CDP) Engineer (Remote),PwC,Mexico City Metropolitan Area,REMOTE,,Full-time,Professional Services,2024-07-17 11:36:38.320163,25,Other,,,"Line of Service Internal Firm Services Industry/Sector Not Applicable Specialism IFS - Clients & Markets Management Level Manager Job Description & Summary A career in Sales and Marketing will provide you with the opportunity to focus on positioning a distinctive PwC brand in the marketplace and drive long term revenue growth for the Firm. You’ll focus on designing, developing, and implementing communication programmes and media events to promote and sell the PwC’s brand and services as well as contribute to and evaluating our pricing strategies in the marketplace. Our Visual Communications team determines how to visually represent PwC’s key strategic initiatives and business goals. You’ll help the team with corporate visual brand design, creative strategy development and media design ideas. To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. As a Manager, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: Develop new skills outside of comfort zone. Act to resolve issues which prevent the team working effectively. Coach others, recognise their strengths, and encourage them to take ownership of their personal development. Analyse complex ideas or proposals and build a range of meaningful recommendations. Use multiple sources of information including broader stakeholder views to develop solutions and recommendations. Address sub-standard work or work that does not meet firm's/client's expectations. Use data and insights to inform conclusions and support decision-making. Develop a point of view on key global trends, and how they impact clients. Manage a variety of viewpoints to build consensus and create positive outcomes for all parties. Simplify complex messages, highlighting and summarising key points. Uphold the firm's code of ethics and business conduct. Basic Qualifications: Minimum of 4 Years Experience: Minimum Degree Required: High School Diploma or equivalent Preferred Qualifications: Degree Preferred: Bachelor Degree CDP Manager (Adobe RTCDP/AEP) Responsibilities: Demonstrates intimate abilities and/or a proven record of success as a team leader in the following areas: Oversight of Adobe AEP that is directly aligned to the day-to-day delivery of marketing tactics, and closely connected to the other digital marketing teams to develop capabilities and manage technology roadmap Oversight of the CDP technology solution ( e.g. oversee steady state support teams, interact with business owner, plan for break / fix and other enhancements / maintenance) Drive how customer and prospect information is unified across sales, marketing and service channels. Collaborate with Insights, MarTech and Operations teams to refine and optimize measurement process, marketing automation, adjacent Adobe tech Requirements: Demonstrates intimate level abilities with, and/or a proven record of success in a Marketing Technology role, including but not limited to: Previous experience in CDPs (Customer data platforms) such as Adobe Experience Platform (RTCDP) or similar products ; Strong understanding of customer profile segmentation and experience in 360 degree view of customers in CDP for further analytical processing and decision making; Proven track record of managing successful CDP implementation/management and delivering capabilities that drive business growth; Proficient knowledge on data collection, REST/JSON APIs, Experience Data Modeling and Customer Profiling; Experience with one or more back end/server-side technologies including: SOAP/REST, SQL/NoSQL databases and Microservices; Strong knowledge of datasets in Adobe Experience Platform, loading data into Platform through data source connectors, APIs, and streaming ingestion connector; Proven work experience in data architecture and data modeling; preferably with experience working in CDP, CRM, paid media, social, and offline data; Deep understanding of data-driven marketing, analytics and relevance / usage of real-time event data and associated attributes; Ability to set strategic direction and drive execution through collaboration with a cross-functional team; Familiarity with CRM and Marketing Automation platforms ( i.e. Salesforce Sales Cloud, Salesforce Marketing Cloud, etc.); Extensive hands on expertise in implementing/administering Adobe Experience Cloud Products and marketing automation platforms and technologies; Strong understanding of identity resolution components and the enabling technology i.e. profile merge rules, identity graph, identity service provider, etc.; Working with audience-based digital marketing strategy either at an agency or brand; Project managing through a full lifecycle, including the ability to prioritize, sequence, execute and deliver projects on time and on budget; and Translating business requirements and objectives into segmentation strategies and audience building logic Required Skills Optional Skills Desired Languages (If blank, desired languages not specified) Travel Requirements Available for Work Visa Sponsorship? Government Clearance Required? Job Posting End Date",https://mx.linkedin.com/jobs/view/acceleration-center-adobe-real-time-customer-data-platform-cdp-engineer-remote-at-pwc-3959843742,3959843742,"A career in Sales and Marketing will provide you with the opportunity to focus on positioning a distinctive brand in the marketplace and drive long term revenue growth. This role involves designing, developing, and implementing communication programs and media events to promote and sell the brand and services, as well as contributing to and evaluating pricing strategies. Responsibilities include managing the Adobe Experience Platform, overseeing CDP technology solutions, and collaborating with various teams to optimize measurement processes. The position requires deep understanding of data-driven marketing, analytics, and familiarity with CRM and Marketing Automation platforms.","Adobe Experience Platform, CDP, REST, JSON, SQL, NoSQL, Microservices, Salesforce Sales Cloud, Salesforce Marketing Cloud",4,,True,4.0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
Data Engineer (D365),Encora Inc.,Mexico City Metropolitan Area,REMOTE,Entry level,Full-time,"Technology, Information and Internet",2024-08-25 11:36:38.320163,25,Information Technology,,,"Important Information Experience: +5 years Job Mode: Full-time Work Mode: Work from home Job Summary We are seeking a highly skilled Data Engineer with specialized expertise in Microsoft Dynamics 365 Customer Insights to join our data team. The ideal candidate will have a strong background in data engineering, along with the Dynamics 365 Customer Insights (Data) Specialty certification. You will play a crucial role in designing, implementing, and maintaining data pipelines and customer data platforms, enabling our organization to harness the power of data for customer insights, personalized experiences, and data-driven decision-making. Responsibilities and Duties Design and develop data pipelines to ingest, process, and transform customer data from various sources into Dynamics 365 Customer Insights. Implement and manage data integration solutions that unify and enrich customer data, ensuring data accuracy, consistency, and accessibility across the organization. Collaborate with cross-functional teams, including CRM specialists, marketing, and data analysts, to understand business requirements and translate them into scalable data solutions. Optimize and maintain Dynamics 365 Customer Insights environments, including data ingestion, storage, and processing, to support real-time customer insights and analytics. Develop and maintain database schemas, queries, and stored procedures that support the functionality of Dynamics 365 Customer Insights. Ensure data governance and compliance, implementing best practices for data security, privacy, and regulatory requirements within the Dynamics 365 environment. Monitor and troubleshoot data pipelines and systems to ensure reliability and performance, addressing any issues promptly. Automate repetitive tasks and processes, leveraging tools and scripting to improve efficiency and reduce manual intervention. Work closely with IT and DevOps teams to integrate Dynamics 365 Customer Insights with other systems and platforms, ensuring seamless data flow and accessibility. Provide technical guidance and mentorship to junior data engineers and other team members on Dynamics 365 Customer Insights best practices. Stay current with industry trends and advancements in data engineering and Dynamics 365 Customer Insights, recommending new tools and technologies to enhance our data capabilities. Qualifications and Skills Proven experience as a Data Engineer, with a focus on data integration, ETL processes, and data pipeline development. Dynamics 365 Customer Insights (Data) Specialty certification is required. Strong experience with Microsoft Dynamics 365 Customer Insights, including data ingestion, unification, and enrichment processes. Proficiency in SQL and experience with both relational and NoSQL databases. Familiarity with Azure data services such as Azure Data Factory, Azure SQL Database, and Azure Data Lake. Experience with data modeling, schema design, and database optimization. Understanding of data governance, security best practices, and compliance requirements in the context of customer data. Proficiency in data scripting and automation using languages such as Python, PowerShell, or similar. Experience with API integration and working with RESTful services to connect data sources. Strong problem-solving skills, with the ability to troubleshoot and resolve complex data-related issues. Excellent communication and collaboration skills, with the ability to work effectively in a team environment. About Encora Encora is the preferred digital engineering and modernization partner of some of the world's leading enterprises and digital native companies. With over 9,000 experts in 47+ offices and innovation labs worldwide, Encora's technology practices include Product Engineering & Development, Cloud Services, Quality Engineering, DevSecOps, Data & Analytics, Digital Experience, Cybersecurity, and AI & LLM Engineering. At Encora, we hire professionals based solely on their skills and qualifications, and do not discriminate based on age, disability, religion, gender, sexual orientation, socioeconomic status, or nationality.",https://mx.linkedin.com/jobs/view/data-engineer-d365-at-encora-inc-4007314127,4007314127,"We are seeking a highly skilled Data Engineer with specialized expertise in Microsoft Dynamics 365 Customer Insights to join our data team. You will design, implement, and maintain data pipelines and customer data platforms, enabling our organization to harness the power of data for customer insights and data-driven decision-making. Responsibilities include developing data pipelines for customer data, managing data integration solutions, collaborating with cross-functional teams, optimizing Dynamics 365 environments, ensuring data governance, and automating tasks. Qualifications include proven experience as a Data Engineer, Dynamics 365 Customer Insights certification, strong experience with Microsoft Dynamics, proficiency in SQL and NoSQL, familiarity with Azure services, and proficiency in data scripting.","Microsoft Dynamics 365 Customer Insights, SQL, NoSQL, Azure Data Factory, Azure SQL Database, Azure Data Lake, Python, PowerShell, RESTful services",5+ years,,True,5.0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,1,0,0
Lead Data Software Engineer,EPAM Systems,Mexico City Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Software Development and IT Services and IT Consulting,2024-09-13 11:36:38.320163,25,Engineering,Information Technology,,"We are seeking a highly skilled and experienced Lead Data Software Engineer to lead our data engineering team in the design, implementation, and maintenance of our data platform. The successful candidate will play a pivotal role in transforming how we handle data, ensuring its scalability, and maintaining best practices. Responsibilities Collaborate with Solution Architects to design and build a configuration/metadata-driven framework for data transformation and orchestration Develop and implement a Data Ingestion Framework, identifying patterns for initial and incremental data loads Guide the data engineering team in adopting best practices for data processing, ensuring scalability and maintainability of the data platform Oversee the documentation of all data engineering processes and frameworks for knowledge sharing and future reference Collaborate with DevOps Team to deploy & configure required infrastructure components, connect to Data Source, enable CI/CD, and deliver pipelines implementation (framework) Requirements Data Architectural mindset Hands-on coding experience of Databricks Jobs with Python, PySpark Hands-on experience with Data Lake or Data Platform implementation Good understanding of relational and NoSQL data stores, methods, and approaches (star and snowflake, dimensional modeling) Experience in Azure cloud data platform, namely Azure Databricks, Delta Lake, ADSL2, Azure Data Factory, Azure SQL Database, Azure Functions Proven experience in leading data engineering teams Background or Excessive Knowledge in designing and implementing metadata-driven frameworks for data transformation and orchestration Expertise in developing data ingestion strategies for handling both initial and incremental data loads. Various integration patterns (REST, Files, DB Connect) Solid understanding of data engineering best practices and the ability to implement these in a team setting Excellent problem-solving skills and the ability to lead complex data engineering projects Strong communication and collaboration skills to work effectively with both technical and non-technical stakeholders Nice to have Relevant certifications in Azure, Databricks, and data engineering methodologies We offer Career plan and real growth opportunities Unlimited access to LinkedIn learning solutions International Mobility Plan within 25 countries Constant training, mentoring, online corporate courses, eLearning and more English classes with a certified teacher Support for employee’s initiatives (Algorithms club, toastmasters, agile club and more) Enjoyable working environment (Gaming room, napping area, amenities, events, sport teams and more) Flexible work schedule and dress code Collaborate in a multicultural environment and share best practices from around the globe Hired directly by EPAM & 100% under payroll Law benefits (IMSS, INFONAVIT, 25% vacation bonus) Major medical expenses insurance: Life, Major medical expenses with dental & visual coverage (for the employee and direct family members) 13 % employee savings fund, capped to the law limit Grocery coupons 30 days December bonus Employee Stock Purchase Plan 12 vacations days plus 4 floating days Official Mexican holidays, plus 5 extra holidays (Maundry Thursday and Friday, November 2nd, December 24th & 31st) Monthly non-taxable amount for the electricity and internet bills By applying to our role, you are agreeing that your personal data may be used as in set out in EPAM´s Privacy Notice and Policy. EPAM is a leading global provider of digital platform engineering and development services. We are committed to having a positive impact on our customers, our employees, and our communities. We embrace a dynamic and inclusive culture. Here you will collaborate with multi-national teams, contribute to a myriad of innovative projects that deliver the most creative and cutting-edge solutions, and have an opportunity to continuously learn and grow. No matter where you are located, you will join a dedicated, creative, and diverse community that will help you discover your fullest potential.",https://mx.linkedin.com/jobs/view/lead-data-software-engineer-at-epam-systems-4024922404,4024922404,"We are seeking a highly skilled and experienced Lead Data Software Engineer to lead our data engineering team in the design, implementation, and maintenance of our data platform. The successful candidate will play a pivotal role in transforming how we handle data, ensuring its scalability, and maintaining best practices. Responsibilities include collaborating with Solution Architects to design and build a configuration/metadata-driven framework for data transformation and orchestration, developing and implementing a Data Ingestion Framework, overseeing the documentation of all data engineering processes, and working with the DevOps Team to deploy and configure required infrastructure components.","Python, PySpark, Databricks, Delta Lake, Azure Data Factory, Azure SQL Database, Azure Functions, Relational Databases, NoSQL, REST, Files, DB Connect",,,True,,0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0
Data Scientist Jr.,Citibanamex,Mexico City Metropolitan Area,HYBRID,,Full-time,"Banking, Financial Services, and Investment Banking",2024-09-08 11:41:09.361695,132,Engineering,Information Technology,,"Data Scientist Jr Apply specific knowledge in the analysis and evaluation of processes and data. Interprets data and make recommendations. Develop supervised and unsupervised predictive models for use in marketing and risk. Identify inconsistencies in data and results. Defines business problems, and makes recommendations on policies, procedures or practices. Develops a working knowledge of industry practices and standards. as a limited but direct impact on the company, through the quality of the tasks or services provided. Responsibilities: Work with complex and voluminous data sets (internal and external data) to evaluate, recommend and support the implementation of business strategies. Develop of commercial and risk predictive models. Identify and compile data sets using a variety of tools (e.g., SQL, Python) to help predict, improve and measure the success of key outcomes. Be responsible for documenting data requirements, data collection, processing, cleaning and exploratory data analysis; may include the use of statistical models/algorithms and data visualization techniques. Possibility of specialization in the fields of marketing, risk, digital and prevention of money laundering (anti-money laundering, AML). Appropriately assess risk when making business decisions, demonstrating particular consideration for the company's reputation and protecting Citigroup, its clients and assets, by encouraging compliance with applicable laws, rules and regulations, adhering to policy, applying sound ethical judgment regarding personal behavior, conduct and business practices and escalating, managing and reporting control issues with transparency Qualifications: 0-2 years experience using tools for statistical modeling of large data sets Ability to effectively use complex analytical, interpretive and problem solving techniques Analytical, flexible, team-oriented and has good interpersonal/communication skills Demonstrated influencing, facilitation and partnering skills Advanced Excel Experience in Spark,python (pandas, scikit learn) Intermediate-advanced English Education: Bachelor’s/University degree or equivalent experience This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required. Licenciatura en física, matemático, actuario, Ciencias de la Computación, Ingeniería Informática, Análisis de Datos, Sistemas de Información. Deseable: Experiencia laboral Data Scientist Jr. Technical Skills / Knowledge: Experiencia implementando soluciones de alto volumen de datos. Conocimiento en estadística y probabilidad. Conocimiento de modelos de machine Learning. Lenguajes de programación: SQL (1 año), Python, (2 años) java Script (1 año), Ingles intermedio. ------------------------------------------------------ Job Family Group: Technology ------------------------------------------------------ Job Family: Data Science ------------------------------------------------------ Time Type: Full time ------------------------------------------------------ Citi is an equal opportunity and affirmative action employer. Qualified applicants will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran. Citigroup Inc. and its subsidiaries (""Citi”) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi . View the "" EEO is the Law "" poster. View the EEO is the Law Supplement . View the EEO Policy Statement . View the Pay Transparency Posting",https://mx.linkedin.com/jobs/view/data-scientist-jr-at-citibanamex-4000257589,4000257589,"The Data Scientist Jr applies specific knowledge in the analysis and evaluation of processes and data. This role involves interpreting data and making recommendations, developing predictive models for marketing and risk, and identifying inconsistencies in data. Responsibilities include working with complex data sets, developing commercial and risk predictive models, documenting data requirements, and conducting exploratory data analysis. The candidate may specialize in marketing, risk, or anti-money laundering. Qualifications include 0-2 years of experience in statistical modeling and the ability to use analytical techniques effectively. A Bachelor's/University degree or equivalent experience is required.","Python, SQL, JavaScript, Excel, Spark, Machine Learning",0-2 years,Bachelor,True,0.0,0,0,1,0,0,0,0,0,1,1,0,0,1,0,1,0,0
Data Scientist Jr,"Bluetab América, an IBM Company",Mexico City Metropolitan Area,HYBRID,Associate,Full-time,IT Services and IT Consulting,2024-09-01 11:41:09.361695,200,Engineering,,,"En /bluetab seguimos con el desarrollo de negocio. Nuestros equipos están en pleno crecimiento Nos alejamos del concepto de consultoría tradicional, ¿Sabes por qué?: Contratamos para nosotros. Somos fieles a nuestra cultura y queremos compartir contigo nuestra filosofía de trabajo cooperativo, en equipo y de formación continua. Siempre podemos aprender más. Confiamos en la gente y que es posible trabajar bajo pasión, y que sientas en nuestro apoyo tanto en lo profesional como en lo personal. Ningún mar en calma hizo experto a un marinero. ¿Somos exigentes? Sí, porque nuestros retos los son, pero te desarrollarás entre cracks, en entornos innovadores y con las últimas tendencias tecnológicas. Esto es lo que te aporta ser /bluetaber… Queremos invitarte a formar parte del equipo como: Data Scientist Jr ¿Qué buscamos? ¡Que te apasione lo que haces!, ¡Que ames la tecnología, la formación continua y los nuevos retos! Perfil ideal del candidato Experiencia: Conocimientos sólidos de estadística. Experiencia y/o conocimiento de lenguajes de programación. Desarrollo de modelos de machine learning y curiosidad para encontrar soluciones a problemas complejos. Habilidades técnicas: SQL (Intermedio-Avanzado). Python para manejo de datos (Intermedio). PySpark (Deseable). Sólidas bases en estadística, particularmente en modelos predictivos y métricas para evaluar la efectividad del mismo. Experiencia en realizar análisis exploratorios, procesamiento y limpieza de bases de datos. Habilidades blandas: Comunicación de resultados Organizado Proactivo Tu comodidad nos importa. Los bluetabers trabajamos en un entorno confortable, agradable y con proyección de carrera. Eso se traduce en: Contrato indefinido con un salario competitivo. El salario se relaciona en función de los conocimientos técnicos detectados en el proceso y rol asignado, procurando respetar el sentido de equidad y siendo susceptible de mejora tras las evaluaciones continuas de desempeño. Formación continua. Plan de carrera individual definido ya sea técnico, funcional o gestión (¡Decide tu camino, pero sigue formándote!). Beneficios sociales más allá de tu salario: Fondo de Ahorro Seguro de gastos médicos menores y de mayores a nivel familiar, seguro de vida. Vales de despensa. Vacaciones superiores a la ley. Bolsa de capacitación Bono de bienestar Tendrás un Career Coach para que te guíe en tu desarrollo profesional. Capacitación constante Días de descanso adicionales a la ley. ""Bluetab"" es una empresa del grupo IBM. Bluetab será la entidad contratante. Al proceder con esta solicitud, usted entiende que Bluetab compartirá su información personal con otras filiales de IBM involucradas en su proceso de reclutamiento, selección y contratación, donde quiera que éstas se encuentren. Encontrará más información sobre cómo IBM protege su información personal, incluidas las medidas en caso de transferencia transfronteriza de datos, aquí: https://www.ibm.com/careers/us-en/privacy-policy/ Si te gusta la tecnología y la resolución de problemas tanto como a nosotros, ¡Nos encantaría conocerte!",https://mx.linkedin.com/jobs/view/data-scientist-jr-at-bluetab-am%C3%A9rica-an-ibm-company-4013787889,4013787889,"At /bluetab, we invite you to join our team as a Junior Data Scientist. We are looking for someone passionate about technology, continuous learning, and new challenges. The ideal candidate should have solid knowledge of statistics and experience or knowledge of programming languages. You will work on developing machine learning models and have a curiosity to find solutions to complex problems. Key technical skills include intermediate to advanced SQL, intermediate Python for data management, and desirable PySpark. You should have a strong foundation in statistics, particularly in predictive modeling and metrics to evaluate their effectiveness, along with experience in exploratory analysis, data processing, and cleaning.","Python, SQL, PySpark, Statistics, Machine Learning",,,False,,0,0,1,0,0,0,0,0,0,1,0,0,1,0,1,0,0
Data Scientist Jr,Citibanamex,Mexico City Metropolitan Area,HYBRID,,Full-time,"Banking, Financial Services, and Investment Banking",2024-09-01 11:41:09.361695,200,Engineering,Information Technology,,"The Spec Analytics Analyst is a developing professional role. Applies specialty area knowledge in monitoring, assessing, analyzing and/or evaluating processes and data. Identifies policy gaps and formulates policies. Interprets data and makes recommendations. Researches and interprets factual information. Identifies inconsistencies in data or results, defines business issues and formulates recommendations on policies, procedures or practices. Integrates established disciplinary knowledge within own specialty area with basic understanding of related industry practices. Good understanding of how the team interacts with others in accomplishing the objectives of the area. Develops working knowledge of industry practices and standards. Limited but direct impact on the business through the quality of the tasks/services provided. Impact of the job holder is restricted to own team. Responsibilities: Incumbents work with large and complex data sets (both internal and external data) to evaluate, recommend, and support the implementation of business strategies Identifies and compiles data sets using a variety of tools (e.g. SQL, Access) to help predict, improve, and measure the success of key business to business outcomes Responsible for documenting data requirements, data collection / processing / cleaning, and exploratory data analysis; which may include utilizing statistical models / algorithms and data visualization techniques Incumbents in this role may often be referred to as Data Scientists Specialization in marketing, risk, digital and AML fields possible Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency. Qualifications: 0-2 years relevant experience Have the ability to retrieve and manipulation data Possess analytic ability and problem solving skills Working experience in a quantitative field Excellent communication and interpersonal skills, be organized, detail oriented, and adaptive to matrix work environment Ability to build partnerships with cross-functional teams Education: Bachelors/University degree or equivalent experience This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required. ¿Estás buscando aplicar tus conocimientos como Data Scientist? ¿Quisieras trabajar en una empresa que cuente con la tecnología adecuada, grandes volúmenes de datos de diversas fuentes y aplicar técnicas estadísticas avanzadas para proponer oportunidades de negocio? En Citibanamex puedes desarrollar, implementar y ajustar soluciones analíticas que sean automáticas, replicables y escalables en distintos lenguajes de programación. Y si disfrutas de un ambiente laboral que promueva el aprendizaje e innovación continua. Descripción: Decision Science es un área en dónde analizamos grandes volúmenes de datos de diversas fuentes, con técnicas de análisis innovadoras, combinadas con nuevas plataformas tecnológicas y modelos de última generación, dando soluciones o áreas de oportunidad al negocio. Diseñamos e implementamos nuevas estrategias con el fin de dar un mejor servicio a nuestros clientes, desarrollamos estrategias para productos de crédito al consumo y captación, proponemos y comprendemos KPI’s para presentar resultados sintetizados a alta dirección. Responsabilidades: Diseño del monitoreo de los modelos implementados y dar mantenimiento a los mismos. Desarrollar análisis de datos de varias fuentes (demográficos, financieras, de buró de crédito, transaccionales, redes sociales, etc.). Investigación para proponer soluciones de vanguardia referentes al ciclo de vida de los modelos. Trabajar en conjunto con otras áreas del Banco (Producto, Segmento, Riesgo, Finanzas, Cross Sell, etc.) para diseñar e implementar nuevas estrategias. Identificar oportunidades de alto impacto, proponer estrategias que se traducirán en crecimiento de cartera e ingresos a través de modelos estadísticos y minería de datos. Requisitos: Licenciado en Actuaría, Matemáticas, Ingeniería, Economía o afines (carrera por terminar o últimos semestres). Nivel de inglés: Intermedio-avanzado Habilidades: Habilidades e interés en programación y análisis estadístico (experiencia con SQL, R, Python, Spark o SAS). Deseable experiencia en minería de datos, modelos estadísticos, series de tiempo, econometría, etc. Capacidad para traducir números en estrategias accionables. Auto organizado, colaborativo, proactivo, trabajo en equipo, creativo con habilidades de negociación, liderazgo y comunicación. Resiliencia y adaptación al cambio. ------------------------------------------------------ Job Family Group: Decision Management ------------------------------------------------------ Job Family: Specialized Analytics (Data Science/Computational Statistics) ------------------------------------------------------ Time Type: Full time ------------------------------------------------------ Citi is an equal opportunity and affirmative action employer. Qualified applicants will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran. Citigroup Inc. and its subsidiaries (""Citi”) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi . View the "" EEO is the Law "" poster. View the EEO is the Law Supplement . View the EEO Policy Statement . View the Pay Transparency Posting",https://mx.linkedin.com/jobs/view/data-scientist-jr-at-citibanamex-4012319750,4012319750,"The Spec Analytics Analyst is a developing professional role focused on monitoring, assessing, analyzing, and evaluating processes and data. This role involves identifying policy gaps, formulating recommendations, and interpreting data. Responsibilities include working with large and complex datasets to support business strategies and documenting data requirements, processing, and analysis. The position also requires developing strategies to enhance services and measure outcomes through statistical and data mining techniques. Candidates should have a bachelor's degree in fields related to Actuarial Science, Mathematics, Engineering, or Economics and possess programming and statistical analysis skills.","SQL, R, Python, Spark, SAS, Data Visualization, Statistical Models, Data Mining",0-2 years,Bachelor,True,0.0,0,0,1,0,0,1,0,0,0,1,0,0,0,0,1,0,0
Machine Learning Engineer Jr,Minsait,Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-10 11:41:09.361695,154,Customer Service,,,"Un lugar para ti - Talento Minsait Trae tu talento a una compañía global de consultoría y tecnología, con presencia en los 5 continentes y más de 40.000 profesionales. Trabajarás en un entorno de soluciones y servicios innovadores para nuestros clientes en los principales sectores de actividad, aportándoles valor añadido. Participarás de la transformación de los negocios trabajando con profesionales de referencia. Estamos en busca de Machine Learning Jr Descripción de perfil: Actuaría, Física o afín Experiencia minima 1 año en: Perfil matemático, en sistemas, actuaría o similar. Conocimientos en Data Science básicos, SQL y programación con Python. Experiencia utilizando al menos un motor de base de datos (Oracle, SQL Server, RDS). Conocimiento de herramientas cloud AWS y/o GCP como S3, EC2, RDS, Sagemaker y lambdas Zona de trabajo Polanco, esquema hibrido. Beneficios: 100% nómina Beneficios superiores a las de Ley (Vales de despensa, fondo de ahorro, Seguro de Vida, SGMM Familiar, Cursos, etc.) Plan de carrera En Indra tendrás una carrera profesional adaptada a tus objetivos personales, con formación continua y en un entorno flexible. Participarás en proyectos internacionales, con equipos multiculturales o locales, según tus preferencias, en un entorno diverso y con igualdad de oportunidades. Disfrutarás de numerosos beneficios sociales y un interesante paquete retributivo, al tiempo que creces en un entorno innovador.",https://mx.linkedin.com/jobs/view/machine-learning-engineer-jr-at-minsait-4020326803,4020326803,"We are looking for a Junior Machine Learning professional with a background in Actuarial Science, Physics or a related field. The candidate should have a minimum of 1 year of experience in a mathematical profile, systems, actuarial, or similar. Basic knowledge of Data Science, SQL, and programming in Python is required. Experience using at least one database engine (Oracle, SQL Server, RDS) is also needed. Knowledge of cloud tools AWS and/or GCP such as S3, EC2, RDS, SageMaker, and Lambdas is preferred. Work area is Polanco, with a hybrid scheme.","Python, SQL, Data Science, AWS, GCP, Oracle, SQL Server, RDS, S3, EC2, SageMaker, Lambdas",1,Bachelor,False,1.0,0,0,0,1,0,1,0,0,0,1,0,0,0,0,1,0,0
Data Scientist (Hybrid),Stori,Mexico City Metropolitan Area,HYBRID,Entry level,Full-time,"Technology, Information and Internet",2024-07-17 11:41:09.361695,59,Engineering,Information Technology,,"About Stori Stori is a fast-growing, venture-backed financial technology company, on a mission to democratize credit access for 400 million underbanked LatAm consumers. Stori currently operates in Mexico and has a global team with offices in Arlington Virginia, Mexico City, and Asia. We have quickly made our mark as one of the top digital banks in Mexico with more than two million applicants for our credit card product since launching. Stori is one of the top-funded startups in the region with US$250 million raised to date. We are backed by top global venture capital funds, such as GGV Capital, GIC, Lightspeed Venture Partners, General Catalyst, Goodwater Capital, Mexico's Tresalia Capital, Vision Plus Capital, BAI Capital and Source Code Capital; who have successfully invested in startups such as Affirm, Airbnb, Alibaba, Stripe, and TikTok. Stori has a standout founder team among fintechs, leveraging 100+ years of accumulated experience in consumer finance, banking and technology across Mastercard, Intel, Capital One, Morgan Stanley, GE Capital, and HSBC in the U.S., Mexico and Asia. The team has launched and managed many multi-million-customer credit card products globally, providing a wide breadth of experience and knowledge to our team. We welcome diversity of background, experience and thinking. Storians are passionate about our mission and take pride in the products we build. Our culture thrives off of a flat structure and an inclusive environment where all of our employees can be their authentic selves, with boundless opportunities for professional growth. The role As a customer centered company, customer understanding is the top mission of data scientists at Stori. Among all the sources to be used in customer understandings, Stori data scientists use ""Data"" as the most reliable one. On any given day you will be challenged on three types of work – Modeling and Monitoring, Data Analytical Problem Solving and Innovation: Modeling (guided or independently): Communicate with the business intent holders to understand the new business initiatives Design a model as a product Data collection, processing and transformation Explore new data sources Build, Demonstrate, Maintain and Iterate modeling solutions from end to end Analytical Problem Solving Translate vague context and phenomenon into structure analytical problems and leverage statistical knowledge, machine learning models and visualization to derive meaningful insights on business intents and strategies using data and drive action Leverage advanced statistical techniques like incrementality, experiment design, regression analysis, clustering, causal inference, synthetic control selection to measure digital marketing KPIs, ROI on ad spending, marketing effectiveness, lifetime value (LTV) and referral loop factor etc. Build new metrics, dashboards and insights to measure the performance and impact of the growth marketing team activities in order to optimize and scale their actions Innovation We embrace the rapid development in technology and science. You will be encouraged to explore advanced tools or information sources that can help the team in problem understanding, problem solving and product maintenance. An ideal team partner shares: Passion, Curiosity and Problem Solving with cross functional teams As a data scientist at Stori, you will be facing varied problems throughout the life cycle of credit. Though we encourage talents with varied backgrounds to join us, to solve the puzzles with us together, we believe these are the keys: Passion in data: Data is the foundation of everything at the Stori Data Science team. We believe in the power of machine learning but data is always our most trustworthy friend. Curiosity: We believe curiosity is the best mentor to data scientists. We are not only looking for data scientists, but more importantly, we are looking for partners that can inspire us with their wonders. Problem solving: Data scientists at Stori solve puzzles. We use data to understand our customers, we also use data to provide solutions in helping customers. Collaboration: Work effectively in close partnership with marketing and branding leadership, using data and insights to drive strategy including creation and evaluation of marketing programs. Basic Qualifications. Advanced degree in Computer Science, AI, Physics, Statistics, Applied Math or other quantitative fields 3+ years of work experience with Python and SQL programming for data analysis 3+ years of work experience in data science Solid oral and written communication skills, especially around analytical concepts and methods Demonstrated ability to work under pressure and to meet tight deadlines with proactiveness, decisiveness and flexibility Passion in problem solving with data and data analytics Self-motivated with intellectual curiosity Proven ability to quickly learn new technologies, concepts and tools Preferred Qualifications. 2+ years of experience with Credit industry or in growth marketing team 2+ years of experience coaching junior data scientists and analysts 5+ years of work experience with Python programming 5+ years of work experience with Machine learning or Statistical Modeling Experience in A/B testing design and execution Working experience with AWS Experience managing projects independently What we offer Make a positive impact on the lives of our customers via financial inclusion Professional development opportunities International exposure & work experience Company swag Legally required benefits",https://mx.linkedin.com/jobs/view/data-scientist-hybrid-at-stori-3969277316,3969277316,"As a data scientist at Stori, your main responsibilities will include modeling and monitoring data, solving analytical problems, and driving innovation. You will communicate with business stakeholders to design data models, explore data sources, and translate complex phenomena into structured analytical problems using statistical knowledge and machine learning. The role requires collaboration with the marketing team to drive strategic decisions based on data insights. The ideal candidate will have a passion for data, curiosity in problem-solving, and the ability to work in cross-functional teams.","Python, SQL, Machine Learning, Statistical Modeling, AWS, Data Visualization",3+ years,,True,3.0,0,0,0,1,0,1,0,0,0,1,0,0,1,0,1,0,0
Data Scientist,Minsait,Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-08 11:41:09.361695,142,Information Technology,,,"Trae tu talento a una compañía global de consultoría y tecnología, con presencia en los 5 continentes y más de 40.000 profesionales. En Minsait tendrás una carrera profesional adaptada a tus objetivos personales, con formación continua y en un entorno flexible. Participarás en proyectos internacionales, con equipos multiculturales o locales, según tus preferencias, en un entorno diverso y con igualdad de oportunidades. Nos encontramos en búsqueda de: Data Scientist Conocimientos Técnicos: - Lenguaje de programación Python - Dominio práctico de librerías Pyhton orientadas a ciencia de datos (numpy, pandas, scipy, scikit-learn, TensorFlow, etc.) - Machine Learning y Deep Learning. - Extracción, limpieza y procesamiento de datos - Controlador de versiones (git) - Analisis exploratorio de datos - Manejo de bases de datos SQL y NoSQL - Visualización de datos (Matplotlib, vega, Tableau, PowerBI, etc.) Lenguajes: Python, SQL Extras: - Conocimiento de servicios en la nube (AWS, GCP o Azure) - Big data (Spark y/o Hadoop). - Proactivo: capaz de identificar y proponer mejoras de manera creativa y diferente, autocritico y alta capacidad de autogestión. Conocimientos Funcionales: Requisitos: - Autogestión - Trabajo en equipo: que muestre capacidad de gestión y asesoramiento. Que se integre y colabore proactivamente con los miembros del equipo. - Interpretación de datos - Capacidad resolutiva de problemas - Comunicación con el cliente: que muestre entendimiento y empatía con las necesidades del cliente. Empiece a desarrollar la relación con determinados niveles de clientes Empresa que contrata: Indra Minsait Esquema Hibrido – CDMX Beneficios: •Sueldo 100% nominal, acorde a nivel de experiencia. •Contratación directa. •Prestaciones de ley (IMSS, Infonavit, Afore, Aguinaldo). •13% fondo de ahorro. •10% Vales de despensa. •Gastos médicos mayores (familiar) •Seguro de vida •Seguro dental y visual •12 días de vacaciones. •Total pass •Integra Salud: Tendrás acceso a una membresía con múltiples descuentos médicos •Plan de carrera y desarrollo. •Cursos ilimitados y sin costo en Udemy. •Modelo de Aprendizaje Lifelong Learning Interesados, postularse por este medio o al correo de contacto.",https://mx.linkedin.com/jobs/view/data-scientist-at-minsait-4018461605,4018461605,"Join a global consulting and technology company with a presence in all five continents, where you will participate in international projects in a diverse environment as a Data Scientist. The role requires programming skills in Python and practical knowledge of data science libraries (numpy, pandas, scipy, scikit-learn, TensorFlow), as well as expertise in machine learning, data processing, and database management.","Python, SQL, numpy, pandas, scipy, scikit-learn, TensorFlow, git, Matplotlib, Tableau, PowerBI, Spark, Hadoop",,,False,,0,0,1,0,0,0,0,0,1,1,0,0,1,0,1,0,0
Machine Learning Engineer,Match Consulting,Mexico City Metropolitan Area,HYBRID,,Full-time,"Technology, Information and Internet",2024-09-08 11:41:09.361695,25,Engineering,Information Technology,,"Inversora de bienes raíces altamente reconocida dentro de su ramo se encuentra en búsqueda de un Machine Learning Engineer especializado en IA. Licenciatura en Ciencias de la Computación, Ingeniería de Software, Matemáticas o un campo relacionado. Se requieren mínimo 3 años de experiencia en desarrollo de machine learning y proyectos de IA. Para ser responsable de diseñar, implementar y optimizar modelos de machine learning que mejoren la toma de decisiones y la eficiencia en la gestión de proyectos inmobiliarios. Trabajará en la producción de modelos escalables y colaborará estrechamente con los Data Scientists y otros ingenieros. Principales Responsabilidades: Desarrollo de Modelos: Diseñar e implementar modelos de machine learning desde la concepción hasta la producción. Identificación de Necesidades: Trabajar con los equipos de negocio y otros stakeholders para identificar problemas específicos en la gestión de proyectos inmobiliarios, tales como la valoración de propiedades, la predicción de precios, o la optimización de la asignación de recursos. Definición de Objetivos del Proyecto: Establecer objetivos claros y alcanzables para los modelos de machine learning, basados en las necesidades del negocio. Esto incluye la definición de las métricas de éxito y los criterios de rendimiento. Selección de Modelos y Algoritmos: Elegir los algoritmos de machine learning adecuados para el problema específico. Esto podría incluir regresión, clasificación, clustering, o modelos más complejos como redes neuronales profundas. Desarrollo de Código: Escribir y mantener el código para el desarrollo de modelos utilizando Python y/o R, aprovechando frameworks como TensorFlow, Keras y Scikit-learn. Entrenamiento y Validación de Modelos: Entrenar los modelos con datos históricos y validar su rendimiento utilizando técnicas de validación cruzada y métricas apropiadas. Ajustar hiperparámetros y realizar optimizaciones para mejorar el desempeño. Automatización: Desarrollar procesos automatizados para el entrenamiento y despliegue de modelos. Implementación de Pipelines: Crear y gestionar pipelines de procesamiento de datos que automaticen las tareas de preprocesamiento, entrenamiento y evaluación de modelos. Optimización de Modelos: Refinar los modelos para mejorar su precisión y eficiencia. Implementar técnicas avanzadas como el ajuste de hiperparámetros y la optimización de redes neuronales. Escalabilidad: Desarrollar soluciones que sean escalables y eficientes en términos de recursos computacionales. Considerar el uso de tecnologías en la nube y sistemas distribuidos para manejar grandes volúmenes de datos. Integración en Sistemas Existentes: Trabajar con otros ingenieros para integrar los modelos de machine learning en aplicaciones y sistemas existentes. Asegurarse de que los modelos se integren de manera fluida en los flujos de trabajo actuales. Monitoreo de Rendimiento: Supervisar el rendimiento de los modelos en producción para detectar cualquier degradación en su precisión o eficiencia. Establecer alertas y mecanismos para la detección temprana de problemas. Actualización y Reentrenamiento: Actualizar los modelos periódicamente para adaptarse a cambios en los datos o en el entorno de negocio. Reentrenar modelos con nuevos datos para mantener su relevancia y precisión. Colaboración con Data Scientists: Trabajar en conjunto con Data Scientists para interpretar resultados, discutir técnicas avanzadas y optimizar el diseño de modelos. Comunicación con Stakeholders: Presentar hallazgos, resultados y recomendaciones a las partes interesadas del negocio. Traducir resultados técnicos en insights comprensibles para el equipo de negocio. Documentación: Crear documentación detallada sobre el diseño, desarrollo y despliegue de los modelos. Asegurar que el conocimiento se comparta de manera efectiva con el equipo. Requisitos: Educación: Título en Ciencias de la Computación, Ingeniería de Software, Matemáticas o un campo relacionado. Experiencia: Mínimo 3 años de experiencia en desarrollo de machine learning y proyectos de IA. Conocimientos Técnicos en: Dominio de lenguajes de programación como Python y R. Experiencia con frameworks de machine learning (por ejemplo, TensorFlow, Keras, Scikit-learn). Conocimiento en técnicas avanzadas de machine learning y deep learning. Habilidades Blandas: Excelentes habilidades de resolución de problemas y pensamiento analítico. Capacidad para trabajar en equipo y colaborar con múltiples stakeholders. Idiomas nivel avanzado de Inglés y español tanto escrito como hablado. Lomas de Chapultepec, CDMX Horario de Lunes a viernes de 09:00 am a 06:00 pm Salario competitivo más prestaciones adicionales",https://mx.linkedin.com/jobs/view/machine-learning-engineer-at-match-consulting-4015540853,4015540853,"A highly recognized real estate investor is seeking a Machine Learning Engineer specialized in AI. This role requires designing, implementing, and optimizing machine learning models to improve decision-making and project management efficiency. Responsibilities include model development, identifying business needs, defining project objectives, selecting appropriate models and algorithms, developing code using Python and/or R with frameworks like TensorFlow, Keras, and Scikit-learn, training and validating models, creating automated processes, implementing pipelines, and collaborating with Data Scientists and stakeholders.","Python, R, TensorFlow, Keras, Scikit-learn",3,Bachelor,True,3.0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0
Artificial Intelligence Engineer / Python,"Bluetab América, an IBM Company",Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-11 11:41:09.361695,67,Engineering,"Science,",Information Technology,"¡Seguimos creciendo y estamos en búsqueda de apasionados/as del mundo tecnológico! Nos alejamos del concepto de consultoría tradicional ¿sabes por qué?: Contratamos para nosotros. Somos fieles a nuestra cultura y queremos compartir contigo nuestra filosofía de trabajo cooperativo, en equipo y de formación continua. Siempre podemos aprender más. Confiamos en la gente y que es posible trabajar bajo pasión, y que sientas en nuestro apoyo tanto en lo profesional como en lo personal. En nuestra cultura nadie es un número, somos un equipo con un estilo de organización transversal, y así queremos que siga. Ningún mar en calma hizo experto a un marinero. ¿Somos exigentes? Sí, porque nuestros retos los son, pero te desarrollarás entre cracks, en entornos innovadores y con las últimas tendencias tecnológicas. Además, priorizamos el talento y en esta familia nos preocupamos por gente buena que, también, sea buena gente. Si te apasiona el trabajo en equipo, te encanta aprender cosas nuevas y te interesa la innovación, ¡Nos encantaría conocerte! Ingeniero de Datos Al menos 1 año de experiencia en construir e implementar modelos de machine learning en organizaciones grandes o pequeñas. Experiencia y conocimiento en machine learning, especialmente en Procesamiento de Lenguaje Natural (NLP) y (LLM). Marcos de trabajo de ML como TensorFlow, PyTorch, Scikit, Keras o similar. Fuertes habilidades de programación en Python (Indispensable) Desarrollo e implementación de modelos de ML, preferiblemente en NLP. Experiencia en integrar modelos de ML con sistemas de ingeniería de producción para la entrega de predicciones en tiempo real. Resolución de problemas, Ciencia de los datos, Ciencia cognitiva, Matemáticas (estadística, probabilidad y álgebra lineal) Experiencia en herramientas de repositorios. Amplia experiencia en GIT (Línea de comandos y CLI) Conocimiento de Gitflow, Github Flow Conocimiento en herramientas de Continuous Integration/Continuous delivery (Jenkins, Azure devops) Conocimiento en soluciones de Inteligencia Artificial orientada al análisis cognitivo de Datos y Preferencias de los usuarios. Conocimiento de Generative AI Funciones: Desarrollar y mantener los pipelines de machine learning, desplegar los modelos en producción y monitorear su desempeño. Colaborar estrechamente con quants e ingenieros de software, el ingeniero garantizará una integración perfecta de los modelos de machine learning en nuestras aplicaciones. Construir y mejorar nuestro proceso de machine learning (ML) y herramientas relacionadas para respaldar el desarrollo, la experimentación, la integración continua, la entrega continua, la verificación/validación y el monitoreo de modelos de M Perfil ideal de un/una bluetaber… -Apasionado de la tecnología. Completamente al día de las últimas tendencias de la industria. -Habituado a trabajar por objetivos. Acostumbrado a trabajar bajo presión en entornos altamente exigentes. -Buen comunicador, sabrá transmitir ilusión al entorno de trabajo. -Comprometido. Capacidad de análisis y solución de problemas. -Buenas habilidades de negociación. -Capaz de generar empatía tanto con los empleados y clientes. Compatibilizando la capacidad de trabajar con autonomía con un fuerte espíritu de colaboración y, sobre todo, de trabajo en equipo. - Interesado en desarrollar su carrera profesional en entornos altamente competitivos y con alto potencial de crecimiento. Tu comodidad nos importa. Los bluetabers trabajamos en un entorno confortable, agradable y con proyección de carrera. Eso se traduce en: -Contrato indefinido con un salario competitivo. El salario se relaciona en función de los conocimientos técnicos detectados en el proceso y rol asignado, procurando respetar el sentido de equidad y siendo susceptible de mejora tras las evaluaciones continuas de desempeño. -Formación continua. -Plan de carrera individual definido ya sea técnico, funcional o gestión (¡Decide tu camino, pero sigue formándote!). -Beneficios sociales más allá de tu salario: - Fondo de Ahorro -Seguro de gastos médicos menores y de mayores a nivel familiar, seguro de vida. -Vales de despensa. - Vacaciones superiores a la ley. - Bolsa de capacitación -Bono de bienestar -Capacitación constante - Días de descanso adicionales a la ley. ¿Qué esperas para sumarte a Bluetab, an IBM Company? En /b promovemos la diversidad de género, origen étnico, nacionalidad, la inclusión de personas con discapacidad y/o habilidades diferentes mediante la igualdad de oportunidades en todos los procesos, y buscamos ampliar las oportunidades de desarrollo profesional. ""Bluetab"" es una empresa del grupo IBM. Bluetab será la entidad contratante. Al proceder con esta solicitud, usted entiende que Bluetab compartirá su información personal con otras filiales de IBM involucradas en su proceso de reclutamiento, selección y contratación, donde quiera que éstas se encuentren. Encontrará más información sobre cómo IBM protege su información personal, incluidas las medidas en caso de transferencia transfronteriza de datos, aquí: https://www.ibm.com/careers/us-en/privacy-policy/"".",https://mx.linkedin.com/jobs/view/artificial-intelligence-engineer-python-at-bluetab-am%C3%A9rica-an-ibm-company-4022737401,4022737401,"We are looking for passionate individuals in the technology world! We distance ourselves from traditional consulting concepts; we hire for ourselves. We want to share our cooperative work philosophy, teamwork, and continuous learning. This position requires at least 1 year of experience in building and implementing machine learning models in large or small organizations. Experience and knowledge in machine learning, especially in Natural Language Processing (NLP) and Long Language Models (LLM), and strong programming skills in Python (essential). Responsibilities include developing and maintaining machine learning pipelines, deploying models in production, and monitoring performance.","Python, TensorFlow, PyTorch, Scikit-learn, Keras, Git, Jenkins, Azure DevOps, Natural Language Processing, Generative AI",1,,True,1.0,0,0,0,1,0,0,0,0,0,0,0,1,1,0,1,0,0
Artificial Intelligence Engineer,SNGULAR,Mexico City Metropolitan Area,HYBRID,Associate,Full-time,Information Technology & Services,2024-09-08 11:41:09.361695,99,Information Technology,"Engineering,",Consulting,"Desde SNGULAR seguimos desarrollando proyectos a la medida, donde la innovación tecnológica es nuestra palanca y donde buscamos ofrecer un reto profesional a todos los Sngulares.... siempre deforma diferente, porque lo importante eres TÚ! #itcanbedone ¿A quién buscamos? AI Engineer Estarás encargado del diseño, desarrollo e implementación de sistemas y algoritmos de inteligencia artificial. Utilizar tus habilidades en programación, aprendizaje automático y Machine Learning para crear soluciones que pueden realizar tareas inteligentes, como reconocimiento de patrones, toma de decisiones, reconocimiento de caracteres y procesamiento de lenguaje natural. Experiencia: Experiencia de 6 meses en diseño e implementación de soluciones de arquitectura con módulos de inteligencia artificial. Experiencia en lenguajes de programación Python, NodeJS o R Experiencia en Machine Learning (Supervisado y no supervisado) enfocado a la extracción de datos OCR Conocimiento de bibliotecas: Keras, Tensorflow, Pytorch o openCV / CV2; Spacy o NLTK, Conocimientos básicos en DEVOPS. Conocimientos de arquitecturas de integración. Experiencia deseable en arquitecturas de microservicios. Modalidad de trabajo Esta vacante será híbrido, asistencia de 2 a 3 veces por semana ¿Por qué elegir Sngular? ¿Te gusta aprender? Lo primero porque trabajarás con los mejores profesionales del sector y con tecnologías punteras; además te ofrecemos un excelente paquete de beneficios donde cuidamos principalmente el tema de Salud y de educación continua: ● Seguro Gastos Médicos Mayores ● Seguro de Gastos Médico Menores ● Seguro de Vida ● Vales Despensa ● Fondo de Ahorro ● Acceso ilimitado gratuito a plataforma UDEMY ● Bono anual para formación y asistencia a Eventos ● Bono por Obtención de Certificaciones ● Bono por referir amigos/conocidos ● Apoyo para el inglés ● KIT padrísimo de bienvenida ● Bono por compartir conocimiento ● Eventos virtuales muy divertidos Y más...! ¡Únete a Sngular hoy, estamos emocionados de conocerte!",https://mx.linkedin.com/jobs/view/artificial-intelligence-engineer-at-sngular-4016835138,4016835138,"We are looking for an AI Engineer responsible for the design, development, and implementation of artificial intelligence systems and algorithms. You will use your programming skills, machine learning, and deep learning to create solutions capable of performing intelligent tasks such as pattern recognition, decision-making, character recognition, and natural language processing.","Python, NodeJS, R, Machine Learning, Keras, Tensorflow, Pytorch, openCV, Spacy, NLTK, DEVOPS, Microservices Architecture",0.5,,True,0.0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0
Data Scientist,Match Consulting,Mexico City Metropolitan Area,HYBRID,,Full-time,"Technology, Information and Internet",2024-09-08 11:41:09.361695,25,Engineering,Information Technology,,"Inversora de bienes raíces se encuentra en busqueda de un perfil como Data Scientist. Responsabilidades: Análisis de Datos: Recopilar, procesar y analizar datos relevantes del proceso de desarrollo de una construccion y de los proyectos en curso. Desarrollo de Modelos Predictivos: Crear modelos estadísticos y de machine learning para predecir tendencias del proyecto, mercado, medidas de calidad y optimizar procesos. Extracción de Insights: Identificar patrones y tendencias a partir de los datos para proporcionar recomendaciones estratégicas. Colaboración Multidisciplinaria: Trabajar junto a ingenieros de software, project managers y otros stakeholders para integrar soluciones de IA en los procesos de negocio. Visualización de Datos: Diseñar y presentar visualizaciones claras y efectivas de los datos para comunicar hallazgos a equipos no técnicos. Mejora Continua: Evaluar y mejorar continuamente los modelos y procesos de análisis de datos. Cumplimiento y Ética: Asegurar que los análisis y el manejo de datos cumplan con las regulaciones de privacidad y seguridad de datos. Integración de Datos: Trabajar con APIs para la centralización y gestión de datos desde múltiples fuentes. Requisitos: Licencitura en Ciencias de la Computación, Estadística, Matemáticas, Ingeniería o un campo relacionado. (Titulado) Mínimo 4 años de experiencia en análisis de datos y desarrollo de modelos predictivos, preferiblemente en el sector inmobiliario o en proyectos de inteligencia artificial. Conocimientos Técnicos: Dominio de lenguajes de programación como Python, R, SQL. Experiencia con herramientas y bibliotecas de machine learning (por ejemplo, TensorFlow, Scikit-learn, PyTorch). Familiaridad con plataformas de big data (por ejemplo, Hadoop, Spark). Conocimiento en técnicas de análisis estadístico y minería de datos. Habilidad para trabajar con APIs para la centralización de datos desde diversas fuentes. Habilidades de Visualización: Experiencia en herramientas de visualización de datos como Tableau, Power BI o D3.js. Habilidades Analíticas: wCapacidad para abordar problemas complejos y proporcionar soluciones basadas en datos. Habilidades Blandas: Excelentes habilidades de comunicación para explicar conceptos técnicos a audiencias no técnicas. Habilidad para trabajar de manera colaborativa en equipos multidisciplinarios. Mentalidad analítica y atención al detalle. Dominio del inglés y español, tanto escrito como hablado. Sueldo competitivo + prestaciones Lunes a viernes",https://mx.linkedin.com/jobs/view/data-scientist-at-match-consulting-4015543350,4015543350,"Real estate investor is looking for a Data Scientist profile. Responsibilities include data collection, processing, and analysis relevant to construction development and ongoing projects. Develop predictive models using statistical and machine learning techniques to forecast trends, quality measures, and optimize processes. Identify patterns and trends to provide strategic recommendations. Collaborate with software engineers, project managers, and other stakeholders to integrate AI solutions into business processes. Design and present clear data visualizations to communicate findings to non-technical teams. Continuously evaluate and improve data analysis models and processes. Ensure compliance with data privacy and security regulations. Work with APIs for data centralization and management from multiple sources.","Python, R, SQL, TensorFlow, Scikit-learn, PyTorch, Hadoop, Spark, Tableau, Power BI, D3.js",4,Bachelor,True,4.0,0,0,1,0,0,0,0,0,1,1,0,0,1,0,1,0,0
Data and AI Scientist,Klar,Mexico City Metropolitan Area,HYBRID,Associate,Full-time,Financial Services,2024-09-08 11:41:09.361695,124,Business Development,Engineering,,"Data and AI Scientist About KLAR Let’s start with the basics! Klar is a Mexican fintech startup whose mission is to democratize and revolutionize the way in which financial services have been delivered so far in Mexico, especially since half of the population doesn’t have a bank account. We offer a rich set of products across our debit and credit offers and the future is bright for Klar! We have an exciting and ambitious roadmap to bring more features to our products so that we can better serve our users. We have served more than 2 million users since our launch in 2019! We are also proud to have been certified in 2023 as a “Great Place to Work” in Mexico - we’ve worked hard to make that happen and will continue to make bigger strides in the future! Sound like a place you’d like to be? Our people If you join us at Klar, you’ll be welcomed into a team which is rich in many talents and we are very proud! With our head office in Mexico City, and remote tech hubs in Berlin and Argentina, we are always learning something new about another culture or language. With so many people from different backgrounds and walks of life (parents, LGBTQ+, neurodivergence), you’ll definitely find your people here! Our values Ownership - We own our successes & our failures as a team. Excellence - We do everything to the best of our ability & always seek to achieve a new level of excellence in our work. Inclusion - We believe we are stronger together and actively work to promote a safe, diverse, inclusive, and respectful culture. Customer Obsession - We understand the value Klar can bring to its customers & it’s always at the forefront of our decisions. Klarity - We communicate clearly & with authenticity. It’s in our name & it’s what we do. The position and your daily adventures This is a full-time position based in our Mexico City office with a hybrid model, therefore we will expect to see you in the office 2-3 times a week. What you can expect: Help us build the most advanced AI able organization in LATAM Data maintenance: Maintain high data quality and integrity through regular audits, efficient data management, and robust validation processes. Generate Insightful Reports: Produce data analysis reports for monitoring and evaluation of key performance indicators, aiding strategic decision-making. Automate Processes: Focus on process automation and infrastructure development to enhance the efficiency of growth metrics monitoring. You and your assets Bachelor’s degree on: Computer Science, Mechatronics engineer, Computational engineering or related field 2+ years of experience with Python programming language 1+ years of experience with SQL 1+ years of experience as a Data Scientist Advanced English level Experience Machine learning, NLP, LLM, Gen AI is a nice to have Our offer to you Competitive salary based on performance and experience Chance of earning Klar stock options 15 days of paid vacation per year; plus extended maternity and paternity leaves Vacation premium 30 days of Christmas bonus Medical Insurance Computer devices Wellhub subscription to offer mental and physical health Sponsored coaching and therapy sessions via Modern Health A modern centrally located office in Mexico City with free drinks, snacks, and regular social events International work environment with amazing and highly skilled people A world class team that helps you evolve your skills in areas you're interested in Klar is a safe place for everyone! We trust our highly skilled and diverse team and we’re committed to creating a welcoming and inclusive environment for new talents to flourish. We value diversity and welcome all applications regardless of gender, nationality, ethnic and social origin, religion/belief, physical abilities, age, sexual orientation and identity.",https://mx.linkedin.com/jobs/view/data-and-ai-scientist-at-klar-4018563535,4018563535,"This is a full-time position based in Mexico City with a hybrid model. The role involves maintaining high data quality, generating insightful reports for decision-making, and automating processes to enhance efficiency. Candidates should have a bachelor's degree in a related field, 2+ years of experience with Python, 1+ year of experience with SQL, and an advanced level of English. Experience in machine learning, NLP, LLM, and Gen AI is a plus.","Python, SQL, Machine Learning, Natural Language Processing, Generative AI",2+ years,Bachelor,True,2.0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,1,0,0
Data Scientist,Marsh McLennan,Mexico City Metropolitan Area,HYBRID,,Full-time,Insurance and Business Consulting and Services,2024-09-14 11:41:09.361695,78,Engineering,Information Technology,,"MMC is seeking candidates for the following position based in the Mexico City office and be onsite 3 days a week : Data Scientist What is in it for you? Collaborate with international teams to translate complex business problems into impactful data-driven solutions. Lead the development of predictive models and time series analyses that directly influence decision-making. Be part of a forward-thinking team that prioritizes innovation in data science and corporate services. Enjoy unlimited access to a vast range of courses and professional training through Udemy to continually enhance your skills and knowledge We will count on you to: Conduct advanced statistical analysis and build machine learning models using Python, focusing on libraries like Pandas, scikit-learn, and PyTorch. Develop and deploy time series forecasting models to optimize business operations. Design and maintain scalable data pipelines that ensure smooth data flow and high-quality model outputs. Create insightful visualizations using Matplotlib or Seaborn to support decision-making across business units. Work closely with cross-functional teams to ensure model integration aligns with business objectives. Ensure best practices in model validation, performance monitoring, and continuous improvement. Engage in continuous learning and stay up to date with the latest advancements in data science. You will be expected to conduct independent research and apply new techniques to business challenges. What you need to have: A bachelor’s or master’s degree in Computer Science, Mathematics, Statistics, or a related field. 3+ years of hands-on experience in data science, with a strong foundation in statistical methods. Proficiency in Python, particularly in Pandas, scikit-learn, and PyTorch. Experience with data visualization libraries such as Matplotlib and Seaborn. Demonstrated expertise in time series analysis and modeling. Strong understanding of SQL for data extraction and manipulation. Experience with version control tools, particularly Git and GitHub, for collaborative coding and project management. A demonstrated passion for continuous learning and professional development in data science. Effective communication skills in English (C1 level), with the ability to explain complex concepts to both technical and non-technical audiences. What makes you stand out? Experience with cloud platforms like AWS or Azure, especially for model deployment. Familiarity with containerization (Docker) and orchestration (Kubernetes). Experience with PySpark for large-scale data processing. Experience with model tracking and experiment management tools like MLflow. Background in global professional services or similar environments. If you are interested, please send your CV in English. Interviews will be held in English . Marsh McLennan (NYSE: MMC) is the world’s leading professional services firm in the areas of risk, strategy and people. The Company’s 85,000 colleagues advise clients in 130 countries. With annual revenue of over $20 billion, Marsh McLennan helps clients navigate an increasingly dynamic and complex environment through four market-leading businesses. Marsh provides data-driven risk advisory services and insurance solutions to commercial and consumer clients. Guy Carpenter develops advanced risk, reinsurance and capital strategies that help clients grow profitably and pursue emerging opportunities. Mercer delivers advice and technology-driven solutions that help organizations redefine the world of work, reshape retirement and investment outcomes, and unlock health and well being for a changing workforce. Oliver Wyman s serves as a critical strategic, economic and brand advisor to private sector and governmental clients. For more information, visit marshmclennan.com, or follow us on LinkedIn and Twitter. Marsh McLennan is committed to creating a diverse, inclusive and flexible work environment. We aim to attract and retain the best people and embrace diversity of age, background, disability, ethnic origin, family duties, gender orientation or expression, marital status, nationality, parental status, personal or social status, political affiliation, race, religion and beliefs, sex/gender, sexual orientation or expression, skin color, or any other characteristic protected by applicable law. Marsh McLennan is committed to hybrid work, which includes the flexibility of working remotely and the collaboration, connections and professional development benefits of working together in the office. All Marsh McLennan colleagues are expected to be in their local based teams will identify at least one “anchor day” per week on which their full team will be together in person. office or working onsite with clients at least three days per week. R_279220",https://mx.linkedin.com/jobs/view/data-scientist-at-marsh-mclennan-4009011872,4009011872,"MMC is seeking a Data Scientist to collaborate with international teams to translate complex business problems into data-driven solutions. The role involves leading the development of predictive models and time series analyses that influence decision-making. Responsibilities include conducting advanced statistical analysis, building machine learning models in Python using libraries like Pandas, scikit-learn, and PyTorch, developing time series forecasting models, designing data pipelines, creating visualizations with Matplotlib or Seaborn, and ensuring model integration aligns with business objectives. Candidates should have a Bachelor's or Master's degree in a related field and at least 3 years of hands-on data science experience.","Python, Pandas, scikit-learn, PyTorch, Matplotlib, Seaborn, SQL, Git, GitHub, AWS, Azure, Docker, Kubernetes, PySpark, MLflow",3+,Bachelor,True,3.0,0,0,1,1,1,0,0,0,1,1,0,1,1,0,1,0,0
ML Engineer MLOps,"Bluetab América, an IBM Company",Mexico City Metropolitan Area,HYBRID,Associate,Full-time,IT Services and IT Consulting,2024-08-16 11:41:09.361695,36,Information Technology,,,"En Bluetab, seguimos en crecimiento y estamos en busca de personas como tú, que comparten nuestra pasión por la tecnología. Nos destacamos por ser diferentes a la consultoría tradicional. Aquí, creemos en contratarte para formar parte de nuestra familia. Valoramos la colaboración, el trabajo en equipo y el aprendizaje constante. Para nosotros, cada miembro es esencial, no sólo un número en una lista. Somos un equipo unido y horizontal, y queremos que así siga siendo. Recuerda, ningún marinero se convirtió en experto en aguas tranquilas. Sí, somos exigentes, pero nuestros desafíos también lo son. Aquí te desarrollarás junto a auténticos expertos, en entornos innovadores y siempre a la vanguardia de la tecnología. Valoramos el talento y nos preocupamos por las personas que, además de ser talentosas, son buenas personas. Si te apasiona el trabajo en equipo, disfrutas aprendiendo y te interesa la innovación, ¡estamos ansiosos por conocerte! Experiencia: Habilidades avanzadas de programación en Python y conocimiento de bibliotecas de ML, como TensorFlow, PyTorch, Scikit-Learn, etc. SQL ETL (preferentemente DataIku) - Herramientas de flujos analíticos (Alteryx, tableau prep, data fusion, etc) - Administración de bases de datos Conexiones ODBC – JDBC Spark. Adicionales: • Clientes de base de datos (dbeaver, mysql, sqlmanager, etc) • Conocimiento en computación en la nube • Hive • Experiencia sólida en desarrollo de software y operaciones de ML, con énfasis en MLOps. Soft skills: Analítico, proactivo, buena comunicación y adquirir conocimiento de negocio. Responsabilidades: Desarrollar y mantener pipelines de ML altamente automatizados para entrenamiento, validación e implementación de modelos a gran escala. Colaborar estrechamente con los equipos de ingeniería de software para integrar flujos de trabajo de ML en el ciclo de desarrollo de software, aplicando prácticas de DevOps y MLOps. Implementar y gestionar infraestructura de computación distribuida y herramientas de orquestación para soportar flujos de trabajo de ML en entornos de producción. • Desarrollar métricas y herramientas de monitoreo para evaluar el rendimiento y la calidad de los modelos en producción. • Automatizar tareas de mantenimiento y monitoreo para garantizar la estabilidad y confiabilidad continua de los sistemas de ML. Identificar las diferentes necesidades de datos e información (Fuentes, Catálogos, Indicadores, Dimensiones), atendiendo a los procesos y fuentes actuales de negocio así como los disponibles dentro de la arquitectura de Data Analytics, mismos que faciliten el dimensionamiento y propuesta de atención del producto. Proponer estrategias de integración de datos a productos/herramientas considerando a las necesidades de negocio para robustecer el valor de los entregables Identificar y proponer mediante la documentación generada, áreas de mejora dentro de la integración de datos con el objetivo de proponer soluciones más eficientes en la transformación de datos. Conocer el significado e interpretación de los datos, y plasmar dicho entendimiento en los documentos entregados que se recogen de los distintos proyectos de integración de Data Analytics con el objetivo de generar insights valiosos para la toma de decisiones que impulse la consistencia de la información a través de los productos. Perfil del candidato/a ideal: Eres un apasionado/a de la tecnología y estás siempre al día con las últimas tendencias de la industria. Estás acostumbrado/a a trabajar por objetivos y en entornos altamente exigentes. Tienes habilidades excepcionales de comunicación y sabes transmitir entusiasmo en el trabajo. Eres una persona comprometida, con fuertes habilidades de análisis y resolución de problemas, así como habilidades de negociación. Puedes establecer una conexión empática tanto con los compañeros de trabajo como con los clientes. Te adaptas fácilmente a la cultura de trabajo de una empresa donde no hay grandes jerarquías y se valora la autonomía, la colaboración y el trabajo en equipo. Estás interesado/a en desarrollar tu carrera en un entorno altamente competitivo con un gran potencial de crecimiento. En Bluetab, te ofrecemos: Contrato indefinido, posterior al periodo de prueba, con un salario competitivo, basado en tus habilidades técnicas y el rol asignado, con posibilidad de ajustes conforme a tus evaluaciones de desempeño. Formación continua. Plan de carrera individualizado en áreas técnica, funcional o de gestión (¡Tú decides, pero siempre continuamos formándonos!). Beneficios sociales que van más allá del salario, como un fondo de ahorro, seguros médicos para ti y tu familia, vales de despensa, vacaciones superiores a las establecidas por ley y más. ¿Qué estás esperando para unirte a Bluetab, an IBM Company? ¡Queremos saber de ti pronto! En /b promovemos la diversidad de género, origen étnico, nacionalidad, la inclusión de personas con discapacidad y/o habilidades diferentes mediante la igualdad de oportunidades en todos los procesos, y buscamos ampliar las oportunidades de desarrollo profesional. ""Bluetab"" es una empresa del grupo IBM. Bluetab será la entidad contratante. Al proceder con esta solicitud, usted entiende que Bluetab compartirá su información personal con otras filiales de IBM involucradas en su proceso de reclutamiento, selección y contratación, donde quiera que éstas se encuentren. Encontrará más información sobre cómo IBM protege su información personal, incluidas las medidas en caso de transferencia transfronteriza de datos, aquí: https://www.ibm.com/careers/us-en/privacy-policy/"".",https://mx.linkedin.com/jobs/view/ml-engineer-mlops-at-bluetab-am%C3%A9rica-an-ibm-company-4000590424,4000590424,"At Bluetab, we continue to grow and are looking for people who share our passion for technology. We focus on collaborating, teamwork, and continuous learning. The role requires advanced programming skills in Python and knowledge of ML libraries such as TensorFlow, PyTorch, and Scikit-Learn. You will be responsible for developing and maintaining highly automated ML pipelines for training, validation, and large-scale model deployment, collaborating closely with software engineering teams to integrate ML workflows into the software development cycle, applying DevOps and MLOps practices. Additional tasks include managing distributed computing infrastructure and orchestration tools, automating maintenance and monitoring tasks, and providing insights that drive decision-making. The ideal candidate is a technology enthusiast, accustomed to working under high demands, and has excellent communication and negotiation skills.","Python, TensorFlow, PyTorch, Scikit-Learn, SQL, ETL, Alteryx, Tableau Prep, Data Fusion, Spark, ODBC, JDBC, Hive, MLOps, DevOps",,,True,,0,0,1,0,0,0,1,0,1,1,0,0,1,0,1,0,0
Senior Data Scientist,Stori,Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Full-time,"Technology, Information and Internet",2024-09-01 11:41:09.361695,25,Engineering,Information Technology,,"About Stori Stori is a fast-growing, venture-backed financial technology company, on a mission to democratize credit access for 400 million underbanked LatAm consumers. Stori currently operates in Mexico and has a global team with offices in Arlington Virginia, Mexico City, and Asia. We have quickly made our mark as one of the top digital banks in Mexico with more than two million applicants for our credit card product since launching. Stori is one of the top-funded startups in the region with US$250 million raised to date. We are backed by top global venture capital funds, such as GGV Capital, GIC, Lightspeed Venture Partners, General Catalyst, Goodwater Capital, Mexico's Tresalia Capital, Vision Plus Capital, BAI Capital and Source Code Capital; who have successfully invested in startups such as Affirm, Airbnb, Alibaba, Stripe, and TikTok. Stori has a standout founder team among fintechs, leveraging 100+ years of accumulated experience in consumer finance, banking and technology across Mastercard, Intel, Capital One, Morgan Stanley, GE Capital, and HSBC in the U.S., Mexico and Asia. The team has launched and managed many multi-million-customer credit card products globally, providing a wide breadth of experience and knowledge to our team. We welcome diversity of background, experience and thinking. Storians are passionate about our mission and take pride in the products we build. Our culture thrives off of a flat structure and an inclusive environment where all of our employees can be their authentic selves, with boundless opportunities for professional growth. The Role: Main responsibilities: As a customer centered company, customer understanding is the top mission of data scientists at Stori. Among all the sources to be used in customer understandings, Stori data scientists use ""Data"" as the most reliable one. On any given day you will be challenged on three types of work – Modeling and Monitoring, Data Analytical Problem Solving and Innovation: Modeling (guided or independently): Communicate with the business intent holders to understand the new business initiatives Design a model as a product Data collection, processing and transformation Explore new data sources Build, Demonstrate, Maintain and Iterate modeling solutions from end to end Analytical Problem Solving Translate vague context and phenomenon into structure analytical problems and leverage statistical knowledge, machine learning models and visualization to derive meaningful insights on business intents and strategies using data and drive action Leverage advanced statistical techniques like incrementality, experiment design, regression analysis, clustering, causal inference, synthetic control selection to measure digital marketing KPIs, ROI on ad spending, marketing effectiveness, lifetime value (LTV) and referral loop factor etc. Build new metrics, dashboards and insights to measure the performance and impact of the growth marketing team activities in order to optimize and scale their actions Innovation We embrace rapid technological and scientific development. You will be encouraged to explore advanced tools or information sources that can help the team understand problems, solve them, and maintain products. An ideal team partner shares: Passion, Curiosity and Problem Solving with cross-functional teams As a data scientist at Stori, you will be facing varied problems throughout the life cycle of credit. Though we encourage talents with varied backgrounds to join us, to solve the puzzles with us together, we believe these are the keys: Passion in data: Data is the foundation of everything at the Stori Data Science team. We believe in the power of machine learning but data is always our most trustworthy friend. Curiosity: We believe curiosity is the best mentor to data scientists. We are not only looking for data scientists, but more importantly, we are looking for partners that can inspire us with their wonders. Problem solving: Data scientists at Stori solve puzzles. We use data to understand our customers, we also use data to provide solutions in helping customers. Collaboration: Work effectively in close partnership with marketing and branding leadership, using data and insights to drive strategy including creation and evaluation of marketing programs. What we are looking for: Basic Qualifications. Advanced degree in Computer Science, AI, Physics, Statistics, Applied Math, or other quantitative fields 3+ years of work experience with Python and SQL programming for data analysis 3+ years of work experience in data science Solid oral and written communication skills, especially around analytical concepts and methods Demonstrated ability to work under pressure and to meet tight deadlines with proactiveness, decisiveness, and flexibility Passion in problem-solving with data and data analytics Self-motivated with intellectual curiosity Proven ability to quickly learn new technologies, concepts, and tools Preferred Qualifications. 2+ years of experience with the Credit industry or in growth marketing team 2+ years of experience coaching junior data scientists and analysts 5+ years of work experience with Python programming 5+ years of work experience with Machine learning or Statistical Modeling Experience in A/B testing design and execution Working experience with AWS Experience managing projects independently What we offer Make a positive impact on the lives of our customers via financial inclusion Professional development opportunities International exposure & work experience Company swag Legally required benefits",https://mx.linkedin.com/jobs/view/senior-data-scientist-at-stori-4009793033,4009793033,"The role of a data scientist at Stori involves modeling, analytical problem solving, and innovation in order to understand customer behavior and optimize marketing strategies. Responsibilities include designing models, collecting and transforming data, applying statistical techniques, building dashboards, and collaborating with marketing leadership. The ideal candidate will have a passion for data, curiosity, and problem-solving skills.","Python, SQL, Machine Learning, Statistical Modeling, AWS, Data Analytics, A/B Testing",3+,,True,3.0,0,0,0,1,0,1,0,0,0,1,0,0,1,0,1,0,0
IA Data Scientist,Azkait,Mexico City Metropolitan Area,HYBRID,,Full-time,"Technology, Information and Internet",2024-07-17 11:41:09.361695,25,Engineering,Information Technology,,"AZKAIT es una empresa Mexicana que busca y conecta el mejor talento IT con empresas Latinoamericanas y de Estados Unidos. Estamos en la búsqueda de tu talento como IA Data scientist. Requisitos: IA Data Scientist Como especialista en Ciencia de Datos participarás en el desarrollo de implementación de modelos LM/IA, y el uso de los modelos existentes en el mercado, así como el diseño, desarrollo e implementación de prompts Requisitos: Experiencia a partir de 5 años en el diseño, desarrollo e implementación de algoritmos y modelos de LM/IA. Experiencia trabajando con APIs Rest Licenciatura o Ingeniería, Titulado Inglés conversacional Conocimientos: Conocimiento profundo de LM/IA e IA Generativa: Gemini, ChatGPT, OpenSource Conocimiento de desarrollo de software para LM/IA con lenguajes tales como Python y Java Conocimiento de integración de procesos de CI/CD (integración continua y entrega continua). Metodologías ágiles Deseable: Conocimiento de arquitecturas basadas en Docker y/o Kubernetes. Conocimiento de plataformas Big Data. Conocimiento en VertexAI, Gemini, OpenAI, Llama. Conocimiento de DevOps y automatización de pipelines GCP (Big Query) Azure (Databricks, Datalake Storage Responsabilidades: Conocer y manejar diferentes tipos de datos tales como estructurados y semi estructurados en todas sus modalidades a fin de integrar el manejo de ellos en los componentes de IA requeridos. Beneficios: Prestaciones de Ley Sueldo de hasta $ 78,000 mensuales brutos Esquema de contratación 100% en nómina Aguinaldo Vacaciones de ley Prima Vacacional SGMM Seguro de vida Seguro dental Lugar de trabajo: Modalidad de trabajo Híbrido Disponibilidad para acudir a oficinas en la sede más cercana: Azcapotzalco o Toreo, CDMX",https://mx.linkedin.com/jobs/view/ia-data-scientist-at-azkait-3961641637,3961641637,"AZKAIT is looking for an AI Data Scientist. As a data science specialist, you will participate in the development and implementation of AI/ML models and use existing market models, as well as design, develop, and implement prompts. You will work with different types of data such as structured and semi-structured to integrate them into the required AI components.","Python, Java, AI/ML, APIs REST, CI/CD, Agile Methodologies, Docker, Kubernetes, Big Data, VertexAI, Gemini, OpenAI, Llama, GCP, Azure",5+ years,Bachelor,True,5.0,1,0,1,1,1,0,0,0,0,0,0,0,0,0,1,0,0
Gen-AI Engineer,Kavak.com,Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Full-time,"Technology, Information and Media",2024-09-14 11:41:09.361695,25,Information Technology,Engineering,,"Kavak es el Ecommerce #1 de autos en Latinoamérica. Traemos confianza, rapidez y seguridad al mercado automotriz de usados. A través de nuestra plataforma facilitamos a los usuarios encontrar el vehículo de sus sueños o vender el suyo desde la comodidad de una computadora o dispositivo móvil. Además, ofrecemos una experiencia práctica y confiable de compraventa en la que otorgamos la mejor oferta del mercado. Nuestro equipo es la prioridad #1. Crecemos juntos y somos responsables por nuestro desarrollo. Nos encanta aprender de la retroalimentación, tomar riesgos y formarnos constantemente. Trabajamos de forma inteligente y hacemos que las cosas sucedan: ¡Work Smart & Make Kavak Happen! Sobre nuestro equipo de Gen-AI Estamos buscando profesionales talentosos para unirse a nuestro equipo de Gen-AI. Somos un equipo pequeño y ágil, compuesto por perfiles senior enfocados en avanzar rápidamente. Desarrollamos soluciones de vanguardia con modelos de lenguaje grande (LLMs) que generan un impacto directo en el negocio y mejoran la experiencia del cliente. Trabajamos estrechamente con las áreas de negocio y operación para llevar estas soluciones a producción, enfrentando los retos de la escala y la implementación. Si eres orientado a resultados y te apasiona la innovación, este es el lugar adecuado para ti. Sobre la posición Esta es una posición de contribuidor individual. Estamos buscando a una persona con experiencia en desarrollo de APIs en Python y en manejo de datos (idealmente perfiles que tengan experiencia como Data Engineers o Data Scientist) para desarrollar servicios productivos que se apalancan en LLMs. ¿Qué estamos buscando? Al menos 2 años de experiencia en desarrollo y puesta en producción de APIs con Python. Manejo de bases de datos SQL y NoSQL (como MySQL, PostgreSQL, MongoDB). Experiencia en el uso de tecnologías de orquestación de contenedores como Kubernetes. Experiencia en la gestión de colas de trabajo y sistemas de mensajería. Trabajo con control de versiones usando Git. Experiencia en colaboración con data scientists, ML engineers, backend engineers, y product managers. Conocimientos técnicos demostrados a través de proyectos ejecutados. Experiencia sólida en AWS es un plus. Experiencia desarrollando RESTful APIs. Experiencia en desarrollo de APIs que interactúan con LLMs es un plus. ¿Qué te ofrecemos? Sueldo competitivo. Prestaciones de Ley . Seguro de Gastos Médicos Mayores. Seguro de Vida. Vacaciones superiores a la ley. Descuentos en productos Kavak. Red de descuentos y convenios. Te animamos a postularte, aun si no cumples con todos los requisitos, siempre y cuando sean apasionados por innovar, tengan un alto nivel de compromiso, estén orientados a resultados y puedan aprender rápidamente. Al aplicar a cualquiera de nuestras vacantes aceptas los Términos & Condiciones y la Política de Privacidad, que encuentras en nuestra pagina web www.kavak.com",https://mx.linkedin.com/jobs/view/gen-ai-engineer-at-kavak-com-4024143881,4024143881,"We are looking for talented professionals to join our Gen-AI team, focused on developing cutting-edge solutions with large language models (LLMs) that generate a direct impact on the business and improve customer experience. This position requires developing production APIs in Python, managing SQL and NoSQL databases, and working with container orchestration technologies such as Kubernetes.","Python, SQL, NoSQL, MySQL, PostgreSQL, MongoDB, Kubernetes, Git, AWS",2,,True,2.0,0,0,0,1,1,0,0,0,0,1,0,1,0,0,1,0,0
Principal Data Scientist - Data Sourcing,Stori,Mexico City Metropolitan Area,HYBRID,Entry level,Full-time,"Technology, Information and Internet",2024-08-16 11:41:09.361695,30,Engineering,Information Technology,,"About Stori Stori is a fast-growing, venture-backed financial technology company, on a mission to democratize credit access for 400 million underbanked LatAm consumers. Stori currently operates in Mexico and has a global team with offices in Arlington Virginia, Mexico City, and Asia. We have quickly made our mark as one of the top digital banks in Mexico with more than two million applicants for our credit card product since launching. Stori is one of the top-funded startups in the region with US$250 million raised to date. We are backed by top global venture capital funds, such as GGV Capital, GIC, Lightspeed Venture Partners, General Catalyst, Goodwater Capital, Mexico's Tresalia Capital, Vision Plus Capital, BAI Capital and Source Code Capital; who have successfully invested in startups such as Affirm, Airbnb, Alibaba, Stripe, and TikTok. Stori has a standout founder team among fintechs, leveraging 100+ years of accumulated experience in consumer finance, banking and technology across Mastercard, Intel, Capital One, Morgan Stanley, GE Capital, and HSBC in the U.S., Mexico and Asia. The team has launched and managed many multi-million-customer credit card products globally, providing a wide breadth of experience and knowledge to our team. We welcome diversity of background, experience and thinking. Storians are passionate about our mission and take pride in the products we build. Our culture thrives off of a flat structure and an inclusive environment where all of our employees can be their authentic selves, with boundless opportunities for professional growth. About the Role: You will join the data science and machine learning department as a dedicated associate in data sourcing. You will be the main point of contact to source, evaluate and acquire high-quality data from various vendors and external sources. Day to day, your key responsibilities include: Collaborating with data scientists and business analysts to identify and understand data requirements for credit risk management. Partner with data scientists to assess the value and relevance of data sources to ensure they meet business needs. Partnering with the procurement team to negotiate data acquisition contracts. Managing and maintaining strong relationships with data vendors to ensure ongoing data quality and compliance with agreements. What we are looking for: Experience: Bachelor's or Master's degree in Economics, Finance, Mathematics, Statistics, or other quantitative discipline or a related field. Working experience with MX public or alternative data sourcing. At least 3 years of working experience with SQL programming for data analysis At least 3 years of working experience with business analytics Skills and attitudes Proven ability to drive projects independently Strong oral and written communication skills, especially around analytical concepts and methods Demonstrated ability to work under pressure and to meet tight deadlines with proactiveness, decisiveness and flexibility Passion in data: Data is the foundation of everything at the Stori Data Science team. We believe in the power of machine learning but data is always our most trustworthy friend. Curiosity: We believe curiosity is the best mentor to data scientists. We are not only looking for data scientists, but more importantly, we are looking for partners that can inspire us with their wonders. Problem solving: Data scientists at Stori solve puzzles. We use data to understand our customers, we also use data to provide solutions in helping customers. Bonus Points: At least 3 years of working experience in credit industry Working experience with vendor management Proven ability to lead a team to deliver complex model development from end to end Passion in problem solving with data and data analytics Self-motivated with intellectual curiosity Proven ability to quickly learn new technologies, concepts and tools What we offer Make a positive impact on the lives of our customers via financial inclusion Professional development opportunities International exposure & work experience Company swag Legally required benefits",https://mx.linkedin.com/jobs/view/principal-data-scientist-data-sourcing-at-stori-3983488116,3983488116,"You will join the data science and machine learning department as a dedicated associate in data sourcing. Your responsibilities include sourcing, evaluating and acquiring high-quality data, collaborating with data scientists to understand data requirements, assessing data source value, negotiating acquisition contracts, and maintaining vendor relationships to ensure data quality.","SQL, Data Analysis, Vendor Management",3,Bachelor,True,3.0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0
Data Scientist Sr Manager (Hybrid),Stori,Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Full-time,"Technology, Information and Internet",2024-08-25 11:41:09.361695,25,Engineering,Information Technology,,"About Stori Stori is a fast-growing, venture-backed financial technology company, on a mission to democratize credit access for 400 million underbanked LatAm consumers. Stori currently operates in Mexico and has a global team with offices in Arlington Virginia, Mexico City, and Asia. We have quickly made our mark as one of the top digital banks in Mexico with more than two million applicants for our credit card product since launching. Stori is one of the top-funded startups in the region with US$250 million raised to date. We are backed by top global venture capital funds, such as GGV Capital, GIC, Lightspeed Venture Partners, General Catalyst, Goodwater Capital, Mexico's Tresalia Capital, Vision Plus Capital, BAI Capital and Source Code Capital; who have successfully invested in startups such as Affirm, Airbnb, Alibaba, Stripe, and TikTok. Stori has a standout founder team among fintechs, leveraging 100+ years of accumulated experience in consumer finance, banking and technology across Mastercard, Intel, Capital One, Morgan Stanley, GE Capital, and HSBC in the U.S., Mexico and Asia. The team has launched and managed many multi-million-customer credit card products globally, providing a wide breadth of experience and knowledge to our team. We welcome diversity of background, experience and thinking. Storians are passionate about our mission and take pride in the products we build. Our culture thrives off of a flat structure and an inclusive environment where all of our employees can be their authentic selves, with boundless opportunities for professional growth. About the Role: This role reports directly to the Head of the Data Science and Machine Learning Department and functions as a crucial horizontal support element for the Fraud department. The team is tasked with fraud detection and prevention across key processes, which include applicant onboarding, various transactions, and card management. Key Responsibilities: As the data scientist manager and a lead in the fraud department, you will Collaborate with a cross-functional team of analysts, engineers, and agents to detect fraudulent activities within large datasets, including both structured and unstructured data; Manage the development of production models from inception to implementation, in coordination with MLOps, Data Engineering, and Engineering teams; Influencing the business agenda within the fraud domain through your expertise in machine learning, contributing to the rapid growth of the company's product offerings and enhancing card transaction experience. Mentor junior analysts and data scientists, providing guidance in both analytical and modeling domains. What we are looking for Experience: Bachelor's or Master's degree in Economics, Finances, Statistics, Mathematics, Physics, or other quantitative discipline; 5+ years of experience in data analysis, utilizing Python and SQL programming. 5+ years of hands-on experience in developing and implementing Machine Learning models and algorithms; 2+ years of experience with big data and cloud technologies, including but not limited to Hadoop, Spark, and AWS; 2+ years of practical experience in Fraud detection or prevention. Skills and attitudes Proven ability to drive projects independently; Solid oral and written communication skills, particularly in conveying analytical concepts and methods; A collaborative team player who excels in effective communication, cross-functional collaboration, and aligning efforts for the company's overall benefit; Exhibits a demonstrated capacity to perform under pressure, meet tight deadlines, and respond proactively, decisively, and flexibly to challenges; Possesses a deep passion for data, a keen interest in business operations, and an ever-ready attitude to confront problems head-on. Bonus Points: 3+ years of experience in the credit industry; Demonstrated experience collaborating with product managers and backend engineers for the execution and monitoring of model based decisioning system; A proven track record of quickly mastering new technologies, concepts, and tools, especially in the areas of machine learning and artificial intelligence. What we offer Make a positive impact on the lives of our customers via financial inclusion Professional development opportunities International exposure & work experience Company swag Legally required benefits",https://mx.linkedin.com/jobs/view/data-scientist-sr-manager-hybrid-at-stori-4004852265,4004852265,"The role reports directly to the Head of the Data Science and Machine Learning Department and functions as crucial support for the Fraud department. Responsibilities include collaborating with analysts, engineers, and agents to detect fraudulent activities within large datasets, managing the development of production models, and mentoring junior analysts and data scientists. The position requires experience in data analysis, machine learning, big data, cloud technologies, and fraud detection.","Python, SQL, Machine Learning, Hadoop, Spark, AWS",5+ years,Bachelor,True,5.0,0,0,1,1,0,0,0,0,0,1,0,0,1,0,1,0,0
Data Science Mid-Senior (Híbrido en México),MindTech,Mexico City Metropolitan Area,HYBRID,Entry level,Full-time,IT Services and IT Consulting,2024-06-17 11:41:09.361695,25,Engineering,Information Technology,,"En Mindtech, estamos buscando un talentoso Data Scientist Mid-Senior para unirse al equipo. El candidato ideal tendrá experiencia en la construcción y despliegue de modelos de Machine Learning, así como una sólida comprensión de las tecnologías en la nube y el análisis de datos. Este rol es perfecto para alguien que busca una oportunidad para crecer y contribuir significativamente en un entorno híbrido desde la Ciudad de México. Responsabilidades Desarrollar y optimizar modelos de Machine Learning para resolver problemas complejos de negocio. Analizar grandes volúmenes de datos para extraer insights accionables y apoyar la toma de decisiones. Colaborar con equipos multifuncionales para entender sus necesidades y proporcionar soluciones basadas en datos. Implementar y mantener soluciones de Machine Learning en Google Cloud Platform (GCP). Utilizar Python y SQL para manipular datos y desarrollar algoritmos de aprendizaje automático. Asegurar la calidad de los modelos mediante pruebas rigurosas y validación continua. Crear reportes y visualizaciones para comunicar resultados y recomendaciones de manera efectiva. Requisitos Licenciatura en Ciencias de la Computación, Estadística, Matemáticas, Ingeniería de Datos, o campo relacionado. Mínimo 3 años de experiencia en ciencia de datos o un rol similar. Experiencia comprobada trabajando con Google Cloud Platform (GCP). Dominio de Python y SQL. Experiencia en el desarrollo y despliegue de modelos de Machine Learning. Conocimiento en técnicas de análisis estadístico y algoritmos de aprendizaje automático. Habilidades sólidas de resolución de problemas y optimización de modelos. Excelentes habilidades de comunicación y capacidad para trabajar en equipo. Si eres apasionado por los datos y la inteligencia artificial, y te entusiasma la idea de trabajar en un entorno innovador y colaborativo, te invitamos a postularte para esta emocionante oportunidad en Mindtech. Únete a nuestro equipo y contribuye a moldear el futuro de la tecnología de datos y el Machine Learning.",https://mx.linkedin.com/jobs/view/data-science-mid-senior-h%C3%ADbrido-en-m%C3%A9xico-at-mindtech-3944799859,3944799859,"At Mindtech, we are looking for a talented Mid-Senior Data Scientist to join the team. The ideal candidate will have experience in building and deploying Machine Learning models, as well as a solid understanding of cloud technologies and data analysis. Responsibilities include developing and optimizing Machine Learning models to solve complex business problems, analyzing large volumes of data to extract actionable insights, collaborating with cross-functional teams to understand their needs, and implementing solutions on Google Cloud Platform (GCP).","Python, SQL, Google Cloud Platform (GCP), Machine Learning, Statistical Analysis",3,Bachelor,False,3.0,0,0,0,1,0,1,0,0,0,1,0,0,1,0,1,0,0
Data Scientist Lead,Connectingology,Mexico City Metropolitan Area,HYBRID,,Full-time,"Technology, Information and Internet",2024-03-19 11:41:09.361695,25,Engineering,Information Technology,,"Funciones: Colaborar con diversas áreas comprendiendo sus requisitos y necesidades Desarrollo de de código para manipulación de grandes conjuntos de datos. Diseño e implementación de soluciones analíticas avanzadas para cubrir las necesidades pertinentes del negocio. Desarrollo de procesos ETL, extracción y manipulación de datos. Generación de variables con clientes Entrenamiento y selección de modelos. Puesta en producción de los diferentes modelos colocándolos en APIS y/o Dockers Representa y visualiza los resultados en formatos apropiados presentando insights al negocio. Dirigir al equipo de Data Scientist desarrollando planes de acción y administración de los proyectos. Requisitos: Licenciatura concluida en Matemáticas, Actuaría, Analítica Avanzada. IT Procesos ETL Lenguajes de programación SQL, Python, Spark, sas, BI, Tableau Ingeniería de datos // Procesos ETL // End to en en proyectos de implementación // Diferencias entre procesos batch y streaming // Desarrollo de equipo de trabajo - Administración de equipo",https://mx.linkedin.com/jobs/view/data-scientist-lead-at-connectingology-3850216096,3850216096,"Responsibilities include collaborating with various areas to understand their requirements, developing code for manipulating large datasets, designing and implementing advanced analytical solutions, developing ETL processes, training and selecting models, deploying models via APIs and/or Docker, visualizing results and presenting insights to the business. The role involves guiding the Data Science team, developing action plans, and managing projects.","SQL, Python, Spark, SAS, Business Intelligence, Tableau, Data Engineering, ETL Processes",,Bachelor,False,,0,0,1,0,0,1,1,0,1,1,0,0,0,0,1,0,0
Data Engineer (AI Development Company),rocket code,Mexico City Metropolitan Area,HYBRID,Entry level,Full-time,Non-profit Organizations and Primary and Secondary Education,2024-08-25 11:41:09.361695,25,Analyst,,,"Join the AI Revolution with rocket code! At rocket code, we're not just developers — we're dreamers, doers, and disruptors. We are at the forefront of making AI work for you , turning market buzz into groundbreaking realities. Our AI-first approach is revolutionizing the tech landscape, and we need passionate individuals to join us on this exciting journey. Why rocket code? Imagine being part of a team that is not only leading the digital frontier but also redefining it. With our global presence in Mexico, the United States, Spain, and soon Brazil, we offer a dynamic environment where innovation and creativity thrive. We've developed over 100 platforms across various industries, including fintech, insurtech, energy, manufacturing, telecommunications, and e-commerce. At Rocket Code, every day is an opportunity to push boundaries and create impactful solutions. Our mission is to transform existing technology into digital experiences that generate a profoundly positive impact. We aim to be the constellation that guides the digital universe, illuminating paths to authentic progress and prosperity for our clients and their communities. Every solution we create is a shining star of innovation and excellence. Our Commitment: At rocket code, we believe in the power of technology to create a positive societal impact. We are dedicated to social responsibility and sustainability, implementing sustainable practices in all our projects and operations. Your Future at rocket code: We're seeking brilliant, innovative, and passionate tech enthusiasts to join our team. If you're ready to be part of a company that not only solves problems but also inspires and leaves a lasting mark on the digital world, Rocket Code is the place for you. Join us and be part of the change! Data Engineer Responsibilities: Define configuration specifications and business analysis requirements Perform quality assurance Define reporting and alerting requirements Own and develop relationship with clients, focusing in delivery the best knowledge about the company and its KPI´s using the company data Help design, document and maintain system & data processes Report on common sources of technical issues or questions and make recommendations to the product team Communicate key insights and findings to product team Constantly be on the lookout for ways to improve monitoring, discover issues and deliver better value to our customers Constantly be on the lookout for new technologies, to deliver the best value to our customers Requirements Data Engineer Qualifications / Skills: Experience in analyzing data to draw business-relevant conclusions and in data visualization techniques and tools Basic knowledge in generating process documentation Strong written and verbal communication skills including technical writing skills Proven experience in requirements and testing Education, Experience: Analysis of data Python/R programming languages Databases experience with Relational and non-relational databases (SQL, Postgresql, Mysql, MongoDb, Firebase, DynamoDB etc) Visualization tools: Tableau, QuickSight, PowerBI or Matplotlib/seaborn in Python Mathematical Statistics: Understand fundamental statistical concepts, probability, distributions, regression and hypothesis testing Workflow Orchestration Platform (Airflow, Luigi, Apache NiFi or Step Functions) Machine learning Big Data: Familiarity with big data concepts and tools such as Hadoop and Spark desirable Benefits Benefits and work scheme: Home office Flexible hours (We keep active communication through Slack) Contests and other rocket activities Career plan to develop talent and potential",https://mx.linkedin.com/jobs/view/data-engineer-ai-development-company-at-rocket-code-4009056385,4009056385,"Join the AI Revolution as a Data Engineer, responsible for defining configuration specifications, performing quality assurance, and developing relationships with clients. You will analyze data to draw business-relevant conclusions, design and maintain data processes, report technical issues, and constantly seek ways to improve customer value through technology.","Python, R, SQL, PostgreSQL, MySQL, MongoDB, Firebase, DynamoDB, Tableau, QuickSight, PowerBI, Matplotlib, Seaborn, Airflow, Luigi, Apache NiFi, Step Functions, Hadoop, Spark",,,True,,0,0,1,0,0,0,0,0,1,1,0,0,0,0,1,0,0
Data Scientist Procurement Data Management & Analytics,Corteva Agriscience,Mexico City Metropolitan Area,HYBRID,,Full-time,Farming,2024-09-13 11:41:09.361695,25,Other,,,"236443W-01 Description We are seeking an experienced Data Scientist with 4+ years of hands-on experience in working with complex data sets. You will collaborate with cross-functional teams within the Procurement function to extract insights and support business objectives through data analytics. The ideal candidate will demonstrate proven experience executing data transformations, applying statistical techniques, performing regression testing, and building and fine-tuning classification models. Expertise in Python or R programming, experience working with largely categorical information, a history of working within Azure, and a track record for building automations is all essential for this position. Having a background in procurement or supply chain is an added advantage. Key Responsibilities Data Modeling and Pipeline Management Build and fine-tune classification models in the areas of spend management, contract management, and operational effectiveness. Develop and maintain data pipelines and architectures for efficient data processing and analysis. Stay informed of new techniques for predictive/prescriptive modeling. Automation Development Identify and action upon opportunities to automate repetitive tasks from within the team. Monitor and maintain automated processes to ensure optimal performance. Mentor junior team members on automation skillsets. Insights & Reporting Perform exploratory data analyses, which may include machine learning, to uncover trends, patterns, and insights from large and complex datasets. Develop, test, and implement data-driven solutions to support business objectives. Oversee the quality and effectiveness of team dashboards and reports. Data Management & Quality Design and implement data collection and data quality processes. Ensure data integrity and consistency across multiple sources and systems. Develop and maintain documentation for data processes and analysis specifications. Collaboration & Communication Work closely with data engineers and business analysts to integrate data insights into production systems. Communicate findings and insights to non-technical stakeholders through reports and presentations. Qualifications Education: Master's degree in Data Science, Analytics, Statistics, Computer Science, Mathematics, Engineering, or a related field. Experience: 4+ years of professional experience in data analytics, with a proven track record of building and tuning classification models. Language: Proficiency in English is required. Technical Skills Strong proficiency in Python or R programming. Experience utilizing statistical methods and machine learning techniques. Expertise in building and deploying predictive models. Proficiency in Microsoft Azure, including Azure Data Factory and Databricks, or a demonstrated ability to learn new tools and platforms Understanding of data visualization tools, with a preference for Power BI. Experience with SQL for data manipulation and querying. Data Management Experience with data manipulation and cleaning tools (e.g., tidyverse, Pandas, Numpy). Familiarity with data warehousing solutions (e.g., SQL Server, Amazon Redshift, Google BigQuery). Soft Skills Strong problem-solving skills and attention to detail. Excellent communication skills, with the ability to convey technical concepts to a non-technical audience. Ability to work independently and as part of a team in a fast-paced environment. Preferred Qualifications Certification in Data Analysis or related fields. Experience with cloud platforms (e.g., AWS, Azure, Google Cloud). Knowledge of Agile methodologies and version control systems (e.g., Git). Procurement Background: Experience in procurement is an added advantage.",https://mx.linkedin.com/jobs/view/data-scientist-procurement-data-management-analytics-at-corteva-agriscience-4023228717,4023228717,"We are seeking an experienced Data Scientist with 4+ years of hands-on experience in working with complex data sets. You will collaborate with cross-functional teams within the Procurement function to extract insights and support business objectives through data analytics. The ideal candidate will demonstrate proven experience executing data transformations, applying statistical techniques, performing regression testing, and building and fine-tuning classification models. Expertise in Python or R programming, experience working with largely categorical information, a history of working within Azure, and a track record for building automations is all essential for this position.","Python, R, Azure, SQL, Databricks, Power BI, Pandas, Numpy",4+ years,Masters,True,4.0,0,0,1,1,0,0,0,0,1,1,0,0,0,0,1,0,0
Senior Customer Data Scientist,H2O.ai,Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Full-time,Software Development and Data Infrastructure and Analytics,2024-09-11 11:41:09.361695,25,Engineering,Customer Service,,"About This Opportunity Are you a data scientist or machine learning engineer who enjoys solving real-world problems by applying cutting edge Gen AI/ML algorithms? Are you passionate about working with customers to solve their business challenges? Can you explain complex machine learning concepts in simple business terms? If the answer is “yes”, then we have a position for you! What You Will Do Deliver data science and/or machine learning professional services to the customers. This will entail working closely with cross-functional teams to gather requirements, preprocess, and analyze data to develop data-driven solutions. Support customers by helping to build custom data models, transformation, scorers/optimization loss functions/metrics that can be leveraged with H2O Driverless AI and help improve training performance for the customer use cases/domains. Ability to design and run training sessions for our customers in data science concepts as well as using H2O products. Training will need to be able to be delivered to audiences with varying data science skills and abilities. Help customers understand the nuances of data science, expert settings of H2O Driverless AI and H2O open source, and the strategies of experiment tuning that you would use to incrementally improve model performance. This also includes explaining model performance, model interpretability, and post deployment model monitoring concepts so as to ensure the business is making the right decisions on the model predictions. Participate in the development of ML solutions and AI applications for internal use, contributing to the advancement of our technology stack. What We Are Looking For Proven experience in data science, machine learning, and AI with a minimum of 4 years of hands-on experience. Experience with solving machine learning problems using H2O products (plus), Python, R Knowledge and experience of using a variety of machine learning techniques (supervised/unsupervised, clustering, decision tree learning, neural networks, etc.) and their real-world advantages/drawbacks/tuning techniques. Knowledge and experience of using advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) for practical applications. Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc. Experience of visualizing and presenting (EDA) to stakeholders using H2O Wave (plus), or other standard data visualization libraries in the Python and R stacks or using Tableau/PowerBi. Understanding and experience with post production model monitoring concepts and tools like H2O ML Ops (plus) MLFlow etc. In depth understanding of machine learning algorithms and experience applying Gen AI/ML to solve real work problems, including deployment of end to end ML pipelines Interest in Generative AI and Large Language Models (Prompt Engineering, Retrieval Augmented Generation, LLMOps, Making custom LLM models, fine tuning etc, Guardrails) Strong problem-solving skills and the ability to work independently and as part of a team. Excellent communication and presentation skills, with the ability to convey complex technical concepts to non-technical stakeholders. Why H2O.ai? Market leader in total rewards Remote-friendly culture Flexible working environment Be part of a world-class team Career growth H2O.ai is committed to creating a diverse and inclusive culture. All qualified applicants will receive consideration for employment without regard to their race, ethnicity, religion, gender, sexual orientation, age, disability status or any other legally protected basis. H2O.ai is an innovative AI cloud platform company, leading the mission to democratize AI for everyone. Thousands of organizations from all over the world have used our cutting-edge technology across a variety of industries. We’ve made it easy for people at all levels to generate breakthrough solutions to complex business problems and advance the discovery of new ideas and revenue streams. We push the boundaries of what is possible with artificial intelligence. H2O.ai employs the world’s top Kaggle Grandmasters, the community of best-in-the-world machine learning practitioners and data scientists. A strong AI for Good ethos and responsible AI drive the company’s purpose. Please visit www.H2O.ai to learn more.",https://mx.linkedin.com/jobs/view/senior-customer-data-scientist-at-h2o-ai-4022450977,4022450977,"We are looking for a data scientist or machine learning engineer to solve real-world problems using cutting-edge Gen AI/ML algorithms. You will deliver data science and machine learning services to customers, working with cross-functional teams to analyze data and develop data-driven solutions. Support customers in building custom data models and train them in data science concepts using H2O products. You'll also participate in developing ML solutions and AI applications for internal use.","Python, R, H2O Driverless AI, H2O open source, Tableau, PowerBi, MLFlow",4,,True,4.0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,1,0,0
Data science & Product Management Lead (Mexico),Grupago,Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Full-time,Non-profit Organizations and Primary and Secondary Education,2024-08-18 11:41:09.361695,49,Product Management,,,"We are an early-stage, venture-backed fintech that focuses on bringing affordable credit and financial services to small, informal business owners (micro-PYMEs) across LatAm - starting with Mexico. We launched last year with a unique group-focused installment loan product, and now have expanded to launch a unique credit card. We are the world's first credit card to include a group lending feature, and the first credit card in Mexico focused on lending to the mainstream market of informal small business entrepreneurs, which comprise 90% of all businesses in the country. We are backed by top venture investors across the US and Mexico, and our co-founding team has spent their careers working in fintech and entrepreneurship. You can read more about us in El Financiero, Reforma, El Heraldo de México, Business Insider México and elsewhere. This role will include a competitive salary, bonus, and equity compensation. Requirements We are looking for a hard-working and highly entrepreneurial data scientist / machine learning engineer and product management lead to join our team and work with the co-founders to build and refine our initial machine learning model for automated credit issuance. You will have primary ownership over managing our machine learning model to allow us to instantly approve new credit lines at low loss rates. You will have immense responsibilities and ownership across a small and highly capable team. Your main responsibilities are to: Build our automated credit model Continuously improve and refine models focused on loss rates and profitability Work closely with the CEO and MX country manager to apply modeling and data science to other aspects of our business - especially acquisition and unit profitability Our ideal candidate would also be comfortable in also helping lead core parts of product management - including overseeing engineering sprints, writing user stories, and setting a roadmap. We are open to highly intelligent, motivated candidates who have limited product management experience but are willing to learn fast. Benefits In addition to working at an early stage fast moving startup - you will qualify for equity (stock option grants), competitive compensation and any bonuses, paid time off and holidays. Learn more at www.grupago.mx",https://mx.linkedin.com/jobs/view/data-science-product-management-lead-mexico-at-grupago-4003185858,4003185858,We are looking for a hard-working and highly entrepreneurial data scientist / machine learning engineer and product management lead to join our team and work with the co-founders to build and refine our initial machine learning model for automated credit issuance. You will have primary ownership over managing our machine learning model to allow us to instantly approve new credit lines at low loss rates. You will continuously improve and refine models focused on loss rates and profitability and apply modeling and data science to other aspects of our business.,"Python, Machine Learning, Data Science, Product Management, Agile Methodologies",,,True,,1,0,0,0,0,1,0,0,0,0,0,0,1,0,1,0,0
DATA SCIENCE CONSULTANT CIUDAD DE MÉXICO,Management Solutions,Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Full-time,Business Consulting and Services,2023-10-21 11:41:09.361695,66,Information Technology,,,"You will be working in key projects for leading organizations in data mining & knowledge Discovery, predictive modeling, trend modeling, Simulation models (Monte Carlo), Review of credit rating and scoring models and quant support to the business and R&D projects. Requirements Final year students. Should desirably have knowledge of modeling techniques (logit, GLM, time series, decision trees, random forests, clustering), statistical programming languages (SAS, R, Python, Matlab) and big data tools and platforms (Hadoop, Hive, etc.). Solid academic record. Strong computer skills. Postgraduate studies and/or specialised courses are an asset, especially in Data Science, Quantitative Finance or similar. Knowledge of other languages is desirable. Get up and go attitude, maturity, responsibility and strong work ethic. Strong ability to learn quickly. Able to integrate easily into multidisciplinary teams. We Offer The best environment to develop talent We offer you the possibility to join a firm that provides all you need to develop your talent to the fullest: Working in the highest-profile consulting projects in the industry, for the largest companies, leaders of their respective markets, alongside top industry management as they face challenges at the national and global level, as part of an extraordinary team of professionals whose values and corporate culture are a benchmark for the industry Ongoing training plan, with approximately 10% of business turnover spent in training Specialist knowledge courses, external expert courses, professional skills courses and language courses. Last yearour staff as a whole received over 330,000 hours oftraining spanning more than 700 courses. Clearly defined career plan Internal promotion based solely on merit. Partnership-based management model offers all professionalsthe opportunity to become part of the Firm’s group of partners. Complementary experiencies University: we maintain a close relationship with the world’s most prestigious universities Social Action: we organize more than 30 community supportactivities. Sports Club: internal and external tournaments.",https://mx.linkedin.com/jobs/view/data-science-consultant-ciudad-de-m%C3%A9xico-at-management-solutions-3731728491,3731728491,"You will work on key projects for leading organizations in data mining, predictive modeling, simulation models, and quant support to the business and R&D projects. Requirements include modeling techniques knowledge and statistical programming languages. Solid academic record, strong computer skills, and a get-up-and-go attitude are necessary. Ability to integrate into multidisciplinary teams is important.","SAS, R, Python, Matlab, Hadoop, Hive, Logit, GLM, Time Series, Decision Trees, Random Forests, Clustering",,Undergraduate Student,False,,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0
"Machine Learning Engineer, Productivity Services",Autodesk,Mexico City Metropolitan Area,HYBRID,Entry level,Full-time,"Software Development, Design Services, and IT Services and IT Consulting",2024-09-08 11:41:09.361695,200,Engineering,Information Technology,,"Job Requisition ID # 23WD73028 Position Overview Do you thrive in an environment where you can work on engaging and challenging projects? Do you have a start-up mentality? Every year Autodesk hires talented engineers to join our global teams and benefit from unlimited access to our technology and industry mentors. If this sounds like you… let's talk. We are growing our Infrastructure and Cloud Engineering team within the Enterprise Systems & Experience organization to enhance the company's IT systems, applications, and processes with AI technologies. Our engineering culture will empower you to make effective decisions, work collaboratively, and take accountability for engineering projects at the company's core. Our team is seeking a highly motivated and experienced Machine Learning Engineer to join our team. As a Machine Learning Engineer, you will be responsible for building and deploying the AI models needed for our projects. You will work closely with our data engineers to ensure that our AI solutions are accurate, efficient, and scalable. Responsibilities Deploy machine learning models for our AI solutions Collaborate with data engineers and data scientists to ensure that data is available and accessible for model development and deployment Optimize machine learning models for accuracy, efficiency, and scalability Develop and maintain code for model training, testing, and deployment Work closely with other teams to integrate machine learning models into our AI solutions Monitor and troubleshoot machine learning models to ensure accuracy and performance Develop and maintain documentation for machine learning models and code Deals well with ambiguous or undefined problems; ability to think abstractly Comfortable performing requirements analysis, interfacing with stakeholders of various levels and documenting solutions Excellent interpersonal skills Ability to articulate technical topics to non-technical audiences both in writing and using diagrams Energetic team player who works well across boundaries and readily adapts to change and enjoys rapid development Confident of your skills, abilities and willing to share what you know, while learning from others Minimum Qualifications Master's degree in Machine Learning, Computer Science, Applied Artificial Intelligence, or a related field 3+ years of experience in machine learning engineering or a related field Strong programming skills in Python Experience with PyTorch Machine Learning expertise in NLP & LLMs algorithms Familiarity with cloud computing platforms such as AWS, Azure, or Google Cloud Preferred Qualifications Machine Learning expertise in ranking, recommendations, classification algorithms Experience with TensorFlow Experience with Kubernetes/Container resources for deployments Learn More About Autodesk Welcome to Autodesk! Amazing things are created every day with our software – from the greenest buildings and cleanest cars to the smartest factories and biggest hit movies. We help innovators turn their ideas into reality, transforming not only how things are made, but what can be made. We take great pride in our culture here at Autodesk – our Culture Code is at the core of everything we do. Our values and ways of working help our people thrive and realize their potential, which leads to even better outcomes for our customers. When you’re an Autodesker, you can be your whole, authentic self and do meaningful work that helps build a better future for all. Ready to shape the world and your future? Join us! Salary transparency Salary is one part of Autodesk’s competitive compensation package. Offers are based on the candidate’s experience and geographic location. In addition to base salaries, we also have a significant emphasis on discretionary annual cash bonuses, commissions for sales roles, stock or long-term incentive cash grants, and a comprehensive benefits package. Diversity & Belonging We take pride in cultivating a culture of belonging and an equitable workplace where everyone can thrive. Learn more here: https://www.autodesk.com/company/diversity-and-belonging Are you an existing contractor or consultant with Autodesk? Please search for open jobs and apply internally (not on this external site).",https://mx.linkedin.com/jobs/view/machine-learning-engineer-productivity-services-at-autodesk-3732081425,3732081425,"We are seeking a highly motivated and experienced Machine Learning Engineer to join our Infrastructure and Cloud Engineering team. As a Machine Learning Engineer, you will be responsible for building and deploying AI models, collaborating with data engineers to ensure data availability, optimizing models for accuracy and efficiency, and monitoring their performance. The role requires a Master's degree in Machine Learning or a related field and at least 3 years of experience in machine learning engineering.","Python, PyTorch, NLP, LLMs, AWS, Azure, Google Cloud, TensorFlow, Kubernetes",3+ years,Masters,True,3.0,0,0,0,1,1,0,0,0,0,0,0,0,1,0,1,0,0
Senior AI Engineer,Stori,Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Full-time,"Technology, Information and Internet",2024-08-16 11:41:09.361695,25,Engineering,Information Technology,,"About Stori Stori is a fast-growing, venture-backed financial technology company, on a mission to democratize credit access for 400 million underbanked LatAm consumers. Stori currently operates in Mexico and has a global team with offices in Arlington Virginia, Mexico City, and Asia. We have quickly made our mark as one of the top digital banks in Mexico with more than two million applicants for our credit card product since launching. Stori is one of the top-funded startups in the region with US$250 million raised to date. We are backed by top global venture capital funds, such as GGV Capital, GIC, Lightspeed Venture Partners, General Catalyst, Goodwater Capital, Mexico's Tresalia Capital, Vision Plus Capital, BAI Capital and Source Code Capital; who have successfully invested in startups such as Affirm, Airbnb, Alibaba, Stripe, and TikTok. Stori has a standout founder team among fintechs, leveraging 100+ years of accumulated experience in consumer finance, banking and technology across Mastercard, Intel, Capital One, Morgan Stanley, GE Capital, and HSBC in the U.S., Mexico and Asia. The team has launched and managed many multi-million-customer credit card products globally, providing a wide breadth of experience and knowledge to our team. We welcome diversity of background, experience and thinking. Storians are passionate about our mission and take pride in the products we build. Our culture thrives off of a flat structure and an inclusive environment where all of our employees can be their authentic selves, with boundless opportunities for professional growth. The Role: As an AI Engineer, you will help lay the foundations of how Stori uses Generative AI to bring financial services to millions of customers in Mexico and Latin America in a personalized and scalable way. Your work will play a crucial role not just in building Gen AI and LLM-based products such as conversational chatbots and voicebots; but also in the creation of a shared platform that will be leveraged by all other engineering squads at Stori as we infuse Generative AI into the core of many of our products. Your experience building with LLMs will be critical in creating the next stage in the evolution of the banking industry in the region as we create the next generation of financial services. Important: This is not an AI research role. You will be building production-grade AI products and shared services for real users and other developers. Main responsibilities: Prototyping & Building LLM-based Applications: Develop LLM-based applications and shared services to be used both by Stori's millions of users. AI Platform Development : Design and implement a robust developer platform that allows other Product & Engineering teams to easily use the power of AI models within other products, expanding the use of Generative AI across the whole organization. Release, Measure, Improve: Ensure our AI-based products are well-instrumented with the required data and observability tools. Use data to consistently improve said products. Testing and Deployment : Streamline the testing processes and integrate continuous integration/continuous deployment (CI/CD) pipelines to facilitate smoother and faster deployment of code into production. Organization-wide Collaboration: Work closely with multiple teams across the company to help infuse their products with AI. Documentation and Training : Create comprehensive documentation and provide training to the development team, ensuring best practices are understood and adopted. What we are looking for: Experience with Large Language Models (LLMs): You've previously built–and ideally launched– products that made use of LLMs. These could include chatbots, agents, RAG systems, classification services, analysis of unstructured data, generation of synthetic data, etc. Personal projects also count! Extra points if you've used open source models. Knowledge of Gen AI-related tools and libraries: You know your way around libraries such as LangChain and LlamaIndex and you're familiar with tools such as Langsmith or Langfuse.Mastery of Python: You have 3-5 years of experience as a Sr Software Engineer working with Python. Comfortable doing traditional backend work: Building production-level AI features also requires traditional backend work, we expect you to be comfortable with this to make sure everything is well integrated and running smoothly. Technical Expertise : Strong knowledge in scalable system design, microservices (Go preferred), CI/CD pipelines, containerization technologies (e.g., Docker, Kubernetes), and cloud services. Problem-Solving Skills : Excellent analytical and problem-solving abilities, with a focus on practical and efficient solutions. Adaptability: You can work–and hopefully thrive–in a constantly changing industry where new AI developments happen weekly, model documentation is not always up to date, and best practices are constantly evolving. You're not scared of building a prototype and throwing your code away to build a better version based on user and performance data. Communication Skills : Strong communication and interpersonal skills, capable of working collaboratively with cross-functional teams and effectively communicating technical concepts to non-technical team members. Educational Background : A Bachelor's or Master's degree in Computer Science, Software Engineering, or a related field. Language Proficiency : Fluency in Spanish and English, both written and spoken. In this institution, discrimination based on race, religion, sexual orientation, physical or socioeconomic condition, or any other reason is prohibited. Discrimination is understood as the denial, exclusion, distinction, impairment, impediment, or restriction of any or some of the human rights of individuals, groups, and communities in a situation of discrimination, attributable to natural or legal persons or public entities, whether intentional or unintentional, willful or culpable, through action or omission, based on ethnic or national origin, language, sex, gender, indigenous identity, gender role expression, age, disability, legal, social or economic status, physical appearance, health conditions, genetic characteristics, pregnancy, religion, political, academic or philosophical opinions, political identity or affiliation, sexual orientation or preference, marital status, manner of thinking, dressing, behaving or gesturing, having tattoos or body piercings, or any other factor that has the effect of nullifying or impairing the recognition, enjoyment or exercise of fundamental rights and freedoms, as well as equality for individuals. What we offer Make a positive impact on the lives of our customers via financial inclusion Professional development opportunities International exposure & work experience Company swag Legally required benefits",https://mx.linkedin.com/jobs/view/senior-ai-engineer-at-stori-3996563377,3996563377,"As an AI Engineer, you will help lay the foundations of how Stori uses Generative AI to deliver personalized financial services. Your work will focus on building production-grade AI products such as conversational chatbots and voicebots, and creating a platform for other engineering teams to leverage AI models. This role includes developing applications, ensuring data observability, streamlining testing and deployment, and collaborating with multiple teams.","Python, Large Language Models (LLMs), CI/CD, Docker, Kubernetes, Go, LangChain, LlamaIndex, Langsmith, Langfuse",3-5,Bachelor,True,3.0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0
"Senior Machine Learning Engineer, Credit Risk",Aviva,Mexico City Metropolitan Area,HYBRID,,Full-time,"Technology, Information and Internet",2024-09-01 11:41:09.361695,25,Engineering,Information Technology,,"About Aviva We are a Mexico City-based technology startup following a unique approach to unsecured credit for underserved communities. Aviva’s physical onboarding kiosks build a bridge to those living in remote communities and provide a documentless 3-minute video onboarding for everyone in need of liquidity. This asset-light acquisition strategy, combined with a superior risk model based on computer vision and natural language processing, will allow Aviva to offer the lowest interest rates available to today’s underserved. What you will do We are looking for a ML engineer to pursue innovative approaches to credit decision: deciding whether to approve a new client, to offer a new loan to a past client, deciding the parameters of the loans, deciding which collection actions to take,... We have several ongoing projects you may be interested in (such as using our lie detector to inform loan decisions). However, we will welcome fresh ideas to tackle our business problems. In the medium-term, we would like to lead new projects end-to-end (from conversations with stakeholders to properly define the problem, to deployment and monitoring of models). Requirements Must-haves Degree in STEM field > 3 years of professional experience, using machine learning on tabular data. Good python skills Familiarity with Git. Creative and strategic approach in solving hard people and technical problems Nice-to-haves We do not expect you to fulfill all the requirements below. But we are more likely to hire someone satisfying several of them. Master degree Verifiable track record of designing great ML models for tabular data (for instance, with good rankings in some Kaggle competitions). Experience in the financial industry. Experience with auto-regressive models (for instance, with Recurrent Neural Networks) . Experience with Reinforcement Learning. Great python skills (deep knowledge of the language, writing clean code, designing the code architecture of large projects). Experience with end-to-end ML systems, cloud platforms, data pipelines and model monitoring. Some knowledge of some of our tech stack: LightGBM, DVC, Pants, FastAPI, Docker, GitHub Actions, TrueFoundry Benefits Attractive compensation package with stock options Fast-paced environment with many growth opportunities Relocation package 15 annual vacation days + 7 annual personal days Possibility to work remote 3-4 days per week. We are also open to fully-remote candidates, if they are a great match.",https://mx.linkedin.com/jobs/view/senior-machine-learning-engineer-credit-risk-at-aviva-4010468522,4010468522,"We are looking for a Machine Learning engineer to pursue innovative approaches to credit decision-making, such as deciding whether to approve loans or parameters of loans. The role includes leading new projects from stakeholder conversations to deployment and monitoring of models.","Python, Machine Learning, Git, LightGBM, DVC, FastAPI, Docker, GitHub Actions",3+ years,,True,3.0,0,1,0,0,1,0,0,0,0,0,0,1,1,0,1,0,0
GTE DATA SCIENTIST AML,Santander México,Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Full-time,Financial Services,2024-09-08 11:41:09.361695,44,Management,"Finance,",Information Technology,"Country: Mexico Grupo Santander es el banco líder que a través de más de 160 años de reinvención, ha llegado a ser una organización sin fronteras con presencia en más de 40 países, 95 nacionalidades y equipos multiculturales que comparten 4 idiomas. Lo importante para nosotros son nuestros clientes, colaboradores, accionistas y la sociedad, como parte de nuestra misión, que es contribuir al progreso de las personas y empresas, actuando siempre de forma Sencilla, Personal y Justa. Requerimientos: Licenciatura en Ciencia de Datos, Finanzas, Actuaría, Matemáticas o carrera afín. Deseable especialización en ciencia de datos Inglés avanzado Experiencia: Mínima de 2 años de experiencia en desarrollo y diseño de modelos Machine Learning. Deseable en desarrollo de modelos para monitoreo transaccional de TM. Programación y paquetería de ciencia de datos: Python, SQL, Numpy, Pandas, plataforma AWS, etc. People skills: capacidad de análisis y procesamiento de datos, resolución de problemas, orientación a resultados, negociación, trabajo en equipo y proactividad. Principales funciones: Realizar analíticas cuantitativas y cualitativas de comportamiento de clientes con machine learning. Generación de analíticas para la detección de irregularidades con analítica avanzada Diseño, actualización, calibración modelos con uso de tecnologías de machine learning Diseño de cuadros de mando para el análisis de tendencias de los resultados de modelos Seguimiento y gestión de revisiones periódicas por parte de supervisores, autoridades locales y corporativo Generar documentación de modelos Ubicación: Santa Fe, CDMX En Banco Santander garantizamos el trato transparente, justo y equitativo para candidatos/as y colaboradores/as, asegurando que no exista menoscabo en ningún derecho, beneficio o prestación derivada de su edad, condición social o económica, cultura, nacionalidad, orientación sexual, identidad o expresión de género, sexo, estado civil, embarazo, discapacidad, religión, creencias, apariencia física o cualquier otra situación protegida por las leyes federales, estatales o locales.",https://mx.linkedin.com/jobs/view/gte-data-scientist-aml-at-santander-m%C3%A9xico-4017920091,4017920091,"Requirements: Bachelor's degree in Data Science, Finance, Actuarial Science, Mathematics or related field. Advanced English desired. Experience: Minimum of 2 years in development and design of Machine Learning models. Desirable experience in developing models for transaction monitoring. Programming and data science tools: Python, SQL, Numpy, Pandas, AWS platform, etc. Main functions: Perform quantitative and qualitative analytics of customer behavior using machine learning. Generate analytics for the detection of irregularities with advanced analytics. Design, update, and calibrate models using machine learning technologies. Design dashboards for trend analysis of model results. Follow-up and management of periodic reviews by supervisors, local authorities, and corporate.","Python, SQL, Numpy, Pandas, AWS",2,Bachelor,True,2.0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,1,0,0
Senior Applied AI & ML Research Engineer,Thomson Reuters,Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Full-time,"Financial Services, Legal Services, and IT Services and IT Consulting",2024-09-01 11:41:09.361695,56,Engineering,Information Technology,,"Do you love creating innovative solutions for customers? Thomson Reuters Labs is looking to set up a new Lab in Mexico. We are seeking a passionate Senior Research Engineer who will bring expertise in AI and ML and is interested in building data-driven capabilities that drive transformation. As a member of Thomson Reuters Labs in Mexico, you will have a direct impact on our company by helping to create new and innovative capabilities that will delight our customers. What does Thomson Reuters Labs do? We experiment, we build, we deliver. We support the organization and our customers through applied research and the development of new products and technologies. TR Labs innovates collaboratively across our core segments in Legal, Tax & Accounting, Government, and Reuters News. As a Senior Research Engineer at Thomson Reuters Labs, you will be part of a global interdisciplinary team of experts. We hire engineers and specialists across a variety of AI research areas to drive the company’s digital transformation.  The science and engineering of AI are rapidly evolving.  We are looking for an adaptable learner who can think in code and likes to learn and develop new skills as they are needed; someone comfortable with jumping into new problem spaces. Is this you? Come join us! About The Role In this opportunity as a Senior Research Engineer, you will: Develop and Deliver: Applying modern software development practices, you will be involved in the entire software development lifecycle, building, testing and delivering high-quality solutions. Build Scalable ML Solutions: You will create large scale data processing pipelines to help researchers build and train novel machine learning algorithms.  You will develop high performing scalable systems in the context of large online delivery environments. Be a Team Player: Working in a collaborative team-oriented environment, you will share information, value diverse ideas, partner with cross-functional and remote teams. Be an Agile Person:  With a strong sense of urgency and a desire to work in a fast-paced, dynamic environment, you will deliver timely solutions. Be Innovative: You are empowered to try new approaches and learn new technologies. You will contribute innovative ideas, create solutions, and be accountable for end-to-end deliveries. Be an Effective Communicator: Through dynamic engagement and communication with cross-functional partners and team members, you will effectively articulate ideas and collaborate on technical developments. About You Essential skills & experience Have a Bachelor of Science degree, computer science or related field At least 5 years software engineering experience, ideally in the context of machine learning and natural language processing Are skilled and have a deep understanding of Python software development stacks and ecosystems, experience with other programming languages and ecosystems is ideal. Can understand, apply, integrate and deploy Machine Learning capabilities and techniques into other systems. Are familiar with the Python data science stack through exposure to libraries such as Numpy, Scipy, Pandas, Dask, spaCy, NLTK, scikit-learn Take pride in writing clean, reusable, maintainable and well-tested code Have a desire to learn and embrace new and emerging technology Are familiar with probabilistic models and have an understanding of the mathematical concepts underlying machine learning methods Preferred Skills & Experience Experience integrating Machine Learning solutions into production-grade software and have an understanding of ModelOps and MLOps principles Demonstrate proficiency in automation, system monitoring, and cloud-native applications, with familiarity in AWS or Azure (or a related cloud platform) Had previous exposure to Natural Language Processing (NLP) problems and have familiarity with key tasks such as Named Entity Recognition (NER), Information Extraction, Information Retrieval, etc. Can understand and translate between language and methodologies used both in research and engineering fields Have been successfully taking and integrating Machine Learning solutions to production-grade software Hands-on experience in other programming and scripting languages (Java, TypeScript, JavaScript, etc.) What's in it For You? You will join our inclusive culture of world-class talent, where we are committed to your personal and professional growth through: Hybrid Work Model: We’ve adopted a flexible hybrid working environment (2-3 days a week in the office depending on the role) for our office-based roles while delivering a seamless experience that is digitally and physically connected Wellbeing: Comprehensive benefit plans; flexible and supportive benefits for work-life balance: flexible vacation, two company-wide Mental Health Days Off; work from another location for up to a total of 8 weeks in a year, 4 of those weeks can be out of the country and the remaining in the country, Headspace app subscription; retirement, and employee incentive programs; resources for mental, physical, and financial wellbeing. Culture: Globally recognized and award-winning reputation for equality, diversity and inclusion, flexibility, work-life balance, and more. Learning & Development: LinkedIn Learning access; internal Talent Marketplace with opportunities to work on projects cross-company; Ten Thousand Coffees Thomson Reuters café networking. Social Impact: Ten employee-driven Business Resource Groups; two paid volunteer days annually; Environmental, Social, and Governance (ESG) initiatives for local and global impact. Purpose-Driven Work: We have a superpower that we’ve never talked about with as much pride as we should – we are one of the only companies on the planet that helps its customers pursue justice, truth, and transparency. Together, with the professionals and institutions we serve, we help uphold the rule of law, turn the wheels of commerce, catch bad actors, report the facts, and provide trusted, unbiased information to people all over the world. Do you want to be part of a team helping re-invent the way knowledge professionals work? How about a team that works every day to create a more transparent, just and inclusive future? At Thomson Reuters, we’ve been doing just that for almost 160 years. Our industry-leading products and services include highly specialized information-enabled software and tools for legal, tax, accounting and compliance professionals combined with the world’s most global news services – Reuters. We help these professionals do their jobs better, creating more time for them to focus on the things that matter most: advising, advocating, negotiating, governing and informing. We are powered by the talents of 26,000 employees across more than 70 countries, where everyone has a chance to contribute and grow professionally in flexible work environments that celebrate diversity and inclusion. At a time when objectivity, accuracy, fairness and transparency are under attack, we consider it our duty to pursue them. Sound exciting? Join us and help shape the industries that move society forward. Accessibility As a global business, we rely on diversity of culture and thought to deliver on our goals. To ensure we can do that, we seek talented, qualified employees in all our operations around the world regardless of race, color, sex/gender, including pregnancy, gender identity and expression, national origin, religion, sexual orientation, disability, age, marital status, citizen status, veteran status, or any other protected classification under applicable law. Thomson Reuters is proud to be an Equal Employment Opportunity/Affirmative Action Employer providing a drug-free workplace. We also make reasonable accommodations for qualified individuals with disabilities and for sincerely held religious beliefs in accordance with applicable law. Protect yourself from fraudulent job postings click here to know more. More information about Thomson Reuters can be found on https://thomsonreuters.com.",https://mx.linkedin.com/jobs/view/senior-applied-ai-ml-research-engineer-at-thomson-reuters-3944221683,3944221683,"Thomson Reuters Labs is looking for a passionate Senior Research Engineer to develop and deliver AI and ML solutions, build scalable data processing pipelines, and collaborate in a dynamic team environment. The role involves applying modern software development practices and contributing innovative ideas to drive transformation.","Python, Machine Learning, Natural Language Processing, Numpy, Scipy, Pandas, Dask, spaCy, NLTK, scikit-learn, Java, TypeScript, JavaScript, AWS, Azure",5+,Bachelor,True,5.0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,1,0,0
"Sr. Data Scientist, Email Platform",Salesforce,Mexico City Metropolitan Area,HYBRID,,Full-time,"Software Development, IT Services and IT Consulting, and Technology, Information and Internet",2024-09-08 11:41:09.361695,35,Engineering,Information Technology,,"To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts. Job Category Data Job Details About Salesforce We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place. This Role; Our vision is to use the best of AI, predictive modeling, segmentation and decisioning to serve the Salesforce Marketing organization. We are seeking a Senior Data Scientist who has a strong background in machine learning (ML), specifically in the areas of next best content recommendations, prediction of best email frequency, and resolving next best journey for the subscriber. Our goal is to develop predictive models that resolve best email to send at the best time to our subscribers, ensuring the ethical use of data in the algorithm design process. At Salesforce, Trust is our number one value, and we ensure our implementation will be trained to prevent bias, preserve privacy, and ensure cultural sensitivity. Responsibilities Work with large and sophisticated data sets to solve a wide array of challenging problems using different analytical, statistical, and machine learning approaches Own the full lifecycle of model development from ideation and data exploration, algorithm design, validation, and testing. Work closely with data engineers to develop modeling data sets and pipelines; deploy models in production, setup model monitoring and in-production tuning processes Partner with product and engineering teams to understand existing product instrumentation and help bridge gaps in data streams to assist data science initiatives Analyze product usage patterns to better understand customer behavior including acquisition, engagement, conversion, and retention Architect and implement AI/ML models to recommend personalized email content Leverage powerful GenAI capabilities to drive optimization in the areas such as audience segmentation, creative optimization, personalization, lifecycle marketing and media mix modeling Drive A/B and multivariate tests and design of feature-level experiments to validate hypotheses and influence product development decisions Partner with multi-functional teams and leaders to identify new opportunities requiring the use of modern analytical and modeling techniques Communicate insights and recommendations to marketing leaders and influence strategic decision-making. Required Skills 4+ years of experience in Product Data Science, including in-depth experience with experimentation. Experience with predictive modeling, machine learning, and experimentation/causal inference methods Experience with data querying languages (e.g., SQL), scripting languages (e.g., Python), and/or statistical/mathematical software (e.g., R) 4-6+ years of experience using advanced statistical and machine learning techniques such as clustering, linear and logistic regressions, PCA, gradient boosting machines (GBM), support vector machines (SVM), neural networks (e.g., ANN, RNN, CNN), and other deep learning algorithms (e.g., Wide & Deep). Must have multiple, robust examples of using these techniques to support marketing efforts and to solve business problems on large-scale data sets Experience using cloud platforms such as GCP and AWS for model development and operationalization is preferred Experience translating business questions into data analytics approaches Experience crafting data visualizations and storytelling to efficiently communicate analysis results to both technical and non-technical audiences Experience developing and operationalizing consistent approaches to experimentation, using appropriate statistical techniques to reduce bias and interpret statistical significance Possess natural curiosity and technical competence, being capable of asking critical questions and always ready to address any challenges Accommodations If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form. Posting Statement At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com. Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce. ﻿Salesforce welcomes all.",https://mx.linkedin.com/jobs/view/sr-data-scientist-email-platform-at-salesforce-3982251574,3982251574,"We are seeking a Senior Data Scientist with a strong background in machine learning to develop predictive models for email recommendations and optimize data use ethically. Responsibilities include working with large data sets, model development, data exploration, and partnership with product teams to analyze customer behavior. The role involves crafting visualizations and communicating insights to influence strategic decisions.","Python, SQL, R, Machine Learning, Cloud Platforms (GCP, AWS), Statistical Analysis",4+,,True,4.0,0,0,0,1,0,1,0,0,0,1,0,0,1,0,1,0,0
Sr AI Engineer,Aspen Technology,Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Full-time,Software Development,2024-09-11 11:41:09.361695,25,Engineering,Information Technology,,"The driving force behind our success has always been the people of AspenTech. What drives us, is our aspiration, our desire and ambition to keep pushing the envelope, overcoming any hurdle, challenging the status quo to continually find a better way. You will experience these qualities of passion, pride and aspiration in many ways — from a rich set of career development programs to support of community service projects to social events that foster fun and relationship building across our global community. The Role As a Senior AI Engineer in our rapidly growing Technology Group, you will provide technical leadership in developing innovative solutions for the next generation of AspenTech’s Manufacturing and Supply Chain solutions. We are looking for sharp, disciplined, and highly quantitative individuals who have a passion for playing with complex data and cutting-edge technologies, in all its forms, including data mining, mathematical modeling, cognitive computing and expert systems. You will leverage your skills and passion for Machine Learning, AI and Cognitive Computing to drive AspenTech’s Manufacturing and Supply Chain suite by developing ground-breaking software. Your Impact Collaborate with data scientists, engineers, and software developers to develop new machine learning applications for the Energy industry in the intersection of AI and Process Systems Engineering. Collaborate with customers, product managers and technical staff to develop technology strategies to promote continuous innovation in our Manufacturing and Supply Chain offerings. Investigate new and developing technologies as they appear in industry and academia and determine how to leverage these new technologies into our software applications What You'll Need Master’s degree in Computer Science, Chemical Engineering, Mathematics, Operations Research, or a related major; PhD preferred. 5+ years of experience in data science and software development in the modeling, optimization, and control of chemical, oil and gas, and/or refining processes. Track record of experience in Python programming, including data science specific packages, such as Pandas, Numpy, TensorFlow, PyTorch, Scikit-Learn, etc. Demonstrated experience with machine learning algorithms (regression, semi-supervised learning, deep learning, reinforcement learning, time series analysis, predictive modeling, cognitive computing). Strong expertise required in one of these areas: numerical methods, mathematical modeling, optimization. Experience with LLM, generative AI, MLops, Graph Knowledge, and/or cloud technologies is a plus. Participated in the design, development, evaluation, and deployment of scalable data-driven models and analytical solutions for machine learning application. Problem-solving ability and attention to details. Demonstrated ability to use scientific research to deliver value to customers and are motivated to deliver results in a fast-paced environment. Excellent interpersonal, communication, writing, and presentation skills. Demonstrated ability to convey complex information in a clear and concise manner.",https://mx.linkedin.com/jobs/view/sr-ai-engineer-at-aspen-technology-4021112831,4021112831,"As a Senior AI Engineer, you will provide technical leadership in developing innovative solutions for AspenTech’s Manufacturing and Supply Chain solutions, applying skills in Machine Learning, AI, and Cognitive Computing. You will collaborate with data scientists and engineers to create machine learning applications for the Energy industry, drive innovation, and leverage new technologies into software applications.","Python, Pandas, Numpy, TensorFlow, PyTorch, Scikit-Learn, Machine Learning, Cognitive Computing, LLM, Generative AI, MLops, Cloud Technologies",5+ years,Masters,True,5.0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0
"Desarrollador Sr. ChatBots  y Generative AI (AI, NLP, Python, JavaScript, JAVA)",Acute Talent,Mexico City Metropolitan Area,HYBRID,,Full-time,"Technology, Information and Internet",2024-09-12 11:41:09.361695,25,Other,,,"Ubicación : Santa Fe, Ciudad de México Experiencia Requerida : Mínimo 8 años Modalidad de Trabajo : Presencial Estamos en la búsqueda de un Desarrollador Sr. Experto en Desarrollo de ChatBots con un enfoque en Fintech y Sistemas Financieros, que además tenga experiencia en Generative AI . Esta posición es clave para desarrollar soluciones innovadoras de atención al cliente y automatización en el sector financiero, utilizando las tecnologías más avanzadas de Inteligencia Artificial, Procesamiento de Lenguaje Natural (NLP), y Generative AI . Buscamos un profesional altamente capacitado, con experiencia demostrable en el desarrollo de ChatBots y en la creación de modelos de IA generativa, capaz de crear soluciones escalables, seguras y adaptadas a las necesidades del sector financiero. Responsabilidades Principales : Desarrollo de ChatBots para Fintech: Crear y desplegar chatbots específicamente diseñados para el sector financiero, gestionando consultas, transacciones, soporte técnico y tareas financieras automatizadas. Programación: Dominio de lenguajes como Python, JavaScript, y/o Java para desarrollar aplicaciones de chatbot personalizadas, integradas con plataformas y servicios financieros. Generative AI: Desarrollar e implementar soluciones basadas en Generative AI, utilizando modelos como GPT, para mejorar la interacción y personalización del chatbot en tiempo real, generando respuestas más naturales y relevantes en contextos financieros. Inteligencia Artificial y Machine Learning: Implementar técnicas avanzadas de IA y Machine Learning enfocadas en la optimización de procesos financieros y mejora en la interacción con los usuarios. Procesamiento de Lenguaje Natural (NLP): Desarrollar algoritmos de NLP que permitan al chatbot manejar términos y consultas específicas de los sistemas financieros y productos de Fintech, como créditos, inversiones, pagos y consultas de balance. Integración con APIs Financieras: Conectar el chatbot con APIs de sistemas financieros (bancos, CRMs financieros, plataformas de pago, blockchain) para realizar consultas en tiempo real, automatizar procesos y ejecutar transacciones. Cumplimiento Regulatorio: Garantizar que las soluciones desarrolladas cumplan con las normativas regulatorias del sector financiero (por ejemplo, KYC, AML, GDPR), integrando mecanismos de verificación de identidad y seguridad en la interacción del chatbot. Diseño de Conversaciones Financieras: Crear flujos conversacionales eficientes para realizar tareas como consultas de saldo, transferencias bancarias, solicitudes de crédito, y recomendaciones de productos financieros. Seguridad: Asegurar la máxima seguridad en la interacción del chatbot con los usuarios, implementando prácticas de cifrado de datos, autenticación de usuarios y protocolos de seguridad específicos del sector financiero. Pruebas y Despliegue: Realizar pruebas exhaustivas en entornos financieros simulados y reales para asegurar un funcionamiento impecable, garantizando la continuidad del servicio en caso de fallos o ciberataques. Mantenimiento y Actualización: Monitorear y actualizar el chatbot de forma continua, optimizando su rendimiento y ampliando sus capacidades según las nuevas necesidades del sector Fintech y las regulaciones financieras. Requisitos: Requisitos Técnicos : Lenguajes de Programación: Dominio avanzado de Python, JavaScript, y/o Java. Inteligencia Artificial y Generative AI: Experiencia en frameworks de AI como GPT, OpenAI, o similares, y habilidades para integrar Generative AI en flujos conversacionales y automatización de respuestas. NLP: Conocimientos avanzados en el uso de BERT, spaCy, NLTK, Dialogflow o equivalentes, enfocados en tareas de procesamiento de lenguaje financiero. Conexión con Sistemas Financieros: Experiencia en integración de APIs como Open Banking o Plaid para consultas en tiempo real y transacciones automatizadas. Ciberseguridad: Profundos conocimientos de seguridad informática, incluyendo cifrado de datos, OAuth 2.0, y autenticación en dos pasos (2FA). Plataformas Fintech: Familiaridad con Rasa, Dialogflow, Microsoft Bot Framework o equivalentes para el desarrollo de chatbots financieros. Requisitos de la Industria Fintech : Generative AI Aplicada a Finanzas: Habilidad para generar respuestas dinámicas y personalizadas utilizando modelos de AI generativa. Automatización Financiera: Experiencia en el diseño de chatbots para pagos, transferencias, consultas de saldos y recomendaciones financieras automatizadas. Análisis Predictivo: Capacidad para implementar algoritmos que predigan comportamientos financieros y alertas de fraude. Blockchain: Conocimiento en la integración de soluciones blockchain y criptomonedas en chatbots para pagos y transacciones. Requisitos Deseables : Experiencia previa en el desarrollo de soluciones para bancos, neobancos, plataformas de préstamos P2P o insurtechs. Certificaciones en Machine Learning, Inteligencia Artificial o Desarrollo de Software en el ámbito financiero. Familiaridad con metodologías ágiles (Scrum, Kanban) en entornos de desarrollo financiero. Requisitos Personales : Experiencia Mínima: Mínimo 8 años de experiencia en desarrollo de software, con al menos 4 años de experiencia en el desarrollo de chatbots e inteligencia artificial para Fintech o sistemas financieros. Capacidad para adaptarse a entornos de trabajo dinámicos y gestionar múltiples proyectos simultáneamente. Excelentes habilidades de comunicación y trabajo en equipo. Beneficios : Salario competitivo, acorde con la experiencia. Oportunidades de crecimiento y desarrollo profesional en el sector Fintech. Acceso a programas de formación continua en tecnologías emergentes. Excelente ambiente laboral en oficinas modernas en Santa Fe, Ciudad de México.",https://mx.linkedin.com/jobs/view/desarrollador-sr-chatbots-y-generative-ai-ai-nlp-python-javascript-java-at-acute-talent-4022248845,4022248845,"We are looking for a Senior Developer expert in ChatBot development with a focus on Fintech and Financial Systems, who also has experience in Generative AI. This position is key to developing innovative customer service solutions and automation in the financial sector, using advanced technologies in Artificial Intelligence, Natural Language Processing (NLP), and Generative AI. The role involves creating and deploying chatbots for the financial sector, programming in languages such as Python, JavaScript, and/or Java, implementing Generative AI solutions, and ensuring compliance with financial regulations.","Python, JavaScript, Java, AI frameworks (GPT, OpenAI), NLP (BERT, spaCy, NLTK, Dialogflow), APIs (Open Banking, Plaid), Cybersecurity (encryption, OAuth 2.0, 2FA), Rasa, Microsoft Bot Framework",8+ years,,False,8.0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
"Big Data Engineer 68582, 68583, 68584, 68585, 68586, 68587",Hays,Mexico City Metropolitan Area,HYBRID,Entry level,Full-time,Staffing and Recruiting,2024-08-16 11:41:09.361695,25,Engineering,Information Technology,,"Tu nueva compañía Únete a una empresa líder en servicios de tecnología de la información y comunicaciones, especializada en la transformación digital. Ofrecemos soluciones innovadoras en áreas como ciberseguridad, computación en la nube, automatización y conectividad, ayudando a las empresas a maximizar su potencial y adaptarse a las nuevas tecnologías. Tu nuevo cargo Como Big Data Engineering, serás responsable del diseño, desarrollo y operación de sistemas de datos a gran escala que operan a nivel de petabytes. Te enfocarás en pipelines de datos en tiempo real, análisis de streaming, big data distribuido e infraestructura de machine learning. Interactuarás con ingenieros, gerentes de producto, desarrolladores de BI y arquitectos para proporcionar soluciones técnicas escalables y robustas. Además, realizarás análisis de datos para identificar problemas de calidad en cualquier etapa del ciclo de vida de los datos, proporcionando soluciones y recomendaciones. Trabajarás en estrecha colaboración con el negocio, EDM, ingeniería de datos y arquitectura para asegurar la alineación de reglas y procesos de datos con los estándares de la compañía. Que necesitas para ser exitoso Para esta posición, necesitarás entre 6 y 8 años de experiencia en desarrollo de Big Data, demostrando conocimientos actualizados en ingeniería de datos y desarrollo de pipelines complejos. Es indispensable tener experiencia en modelos ágiles, diseño, desarrollo e implementación de sistemas distribuidos a gran escala, y habilidades avanzadas en SQL. Además, se valorará la experiencia con tecnologías Big Data como Hadoop, Hive, Kafka, Presto, Spark y HBase, así como en el uso de Java y Python para escribir pipelines de datos. La capacidad para trabajar con tecnologías en la nube (GCP, Azure) y la experiencia en REST API para consumo de datos también son importantes. La experiencia en el sector retal es un plus significativo. Que recibirás a cambio Tendrás un salario fijo mensual y un paquete competitivo de compensaciones y beneficios. Trabaja en un entorno donde la innovación y la excelencia son el motor de todo lo que hacemos, con oportunidades de crecimiento y desarrollo en un ambiente dinámico y colaborativo. Que necesitas hacer ahora Si estás interesado en este cargo, haz click en ""aplicar ahora"" para reenviar una copia actualizada de tu CV, o llámanos ahora. Si este cargo no se ajusta mucho a tu perfil, pero estás en búsqueda de un cambio laboral, ponte en contacto con nosotros para que tengamos una conversación confidencial sobre tu carrera. #1036324 - Maria De La Rosa",https://mx.linkedin.com/jobs/view/big-data-engineer-68582-68583-68584-68585-68586-68587-at-hays-3987361738,3987361738,"As a Big Data Engineer, you will be responsible for the design, development, and operation of large-scale data systems that operate at the petabyte level. You will focus on real-time data pipelines, streaming analytics, distributed big data, and machine learning infrastructure. You will interact with engineers, product managers, BI developers, and architects to provide scalable and robust technical solutions. You will also analyze data to identify quality issues at any stage of the data lifecycle, providing solutions and recommendations.","SQL, Hadoop, Hive, Kafka, Presto, Spark, HBase, Java, Python, GCP, Azure, REST API",6-8,,True,6.0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0
Big Data Engineer,Multiplica Talent,Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Full-time,Non-profit Organizations and Primary and Secondary Education,2024-09-11 11:41:09.361695,25,Engineering,,,"¡Multiplica Talent, te está buscando! Somos una consultora especializada en ofrecer las mejores oportunidades laborales al mejor talento digital del mercado. Tenemos 20 años de experiencia reclutando a personas capacitadas, innovadoras y con ganas de crecer para nuestros clientes. Actualmente colaboramos con empresas en LATAM, USA, Europa y África y contamos con talentos que trabajan presencialmente y/o remoto en diferentes partes del mundo. Nuestros talentos son los agentes de cambio que están creando las organizaciones del futuro. ¡Sé parte de este cambio! Requirements Diseñar e implementar entornos de Big Data en producción utilizando tecnologías modernas. Construir, validar y optimizar soluciones de Big Data a gran escala en entornos de datos heterogéneos. Desarrollar y gestionar ETLs en batch (Spark y Scala) y en streaming (Apache Flink). Tu experiencia: Más de 3 años de experiencia trabajando con Scala, Spark, patrones de diseño de software y TDD Experiencia trabajando con Big Data - Spark es imprescindible - Hadoop, Hive y/o Kafka serían una ventaja Experiencia con diferentes estructuras de bases de datos, incluyendo SQL (Postgres, MySQL) y NoSQL (DynamoDB, DocumentDB, Redis, Elasticsearch) Experiencia y conocimientos en integración y gestión de datos con grandes volúmenes de datos Experiencia con ecosistemas en la nube, especialmente AWS (EMR, EC2, IAM, GLUE, ATHENA, S3, CloudFormation, LakeFormation, Redshift, DynamoDB, RDS, ECS y ECR) sería una gran ventaja Experiencia trabajando en entornos ágiles, paradigma de integración continua/DevOps y conjunto de herramientas (Git, Jenkins, Sonar, Nexus, Jira y Splunk) Título universitario en Ciencias de la Computación, Sistemas de Información, Matemáticas u otros campos STEM relacionados o experiencia laboral equivalente Nivel de inglés profesional Deseable: Experiencia con almacenamiento de datos, Apache Iceberg y herramientas de visualización Experiencia con aplicaciones NRT: Apache Flink, Spark streaming Benefits Incorporación inmediata a una empresa dinámica y ágil con un proyecto de crecimiento y expansión Trabajo en modo start-up Remuneración competitiva y un atractivo paquete de beneficios Posibilidad de crecimiento dentro de la empresa Colaboración en proyectos internacionales y posibilidad de contacto con diferentes países Excelente ambiente de trabajo, clubes sociales y eventos frecuentes (ahora virtuales) Prestaciones de ley y superiores ¿Te gustaría crecer con nosotros? ¡Únete a nuestro equipo!",https://mx.linkedin.com/jobs/view/big-data-engineer-at-multiplica-talent-4022705150,4022705150,"Multiplica Talent is looking for a Big Data Engineer to design and implement production Big Data environments using modern technologies. The role involves building, validating, and optimizing large-scale Big Data solutions in heterogeneous data environments and managing ETLs in batch (Spark and Scala) and streaming (Apache Flink). The ideal candidate has over 3 years of experience with Scala, Spark, software design patterns, and TDD. Experience with Big Data technologies is essential, especially Spark, with Hadoop, Hive, or Kafka being advantageous. Knowledge of different database structures, including SQL (Postgres, MySQL) and NoSQL (DynamoDB, DocumentDB, Redis, Elasticsearch) is required, along with experience in data integration and management. Cloud ecosystem experience, especially with AWS, is a significant advantage. Experience in agile environments and a continuous integration/DevOps toolkit is necessary. A university degree in Computer Science, Information Systems, Mathematics, or related STEM fields is required, or equivalent work experience. Professional English proficiency is desirable.","Scala, Spark, Apache Flink, Hadoop, Hive, Kafka, SQL, Postgres, MySQL, NoSQL, DynamoDB, DocumentDB, Redis, Elasticsearch, AWS, EMR, EC2, IAM, GLUE, ATHENA, S3, CloudFormation, LakeFormation, Redshift, RDS, ECS, ECR, Git, Jenkins, Sonar, Nexus, Jira, Splunk",3+,Bachelor,True,3.0,0,0,1,1,1,0,0,0,0,1,0,1,0,0,0,0,0
Data Science Practitioner,Accenture México,Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Full-time,Business Consulting and Services,2024-09-13 11:41:09.361695,38,Health Care Provider,,,"DARE TO BE A PART OF THE CHALLENGE! COME AND JOIN OUR TEAM TOGETHER WE CAN MAKE THE DIFFERENCE! Did you know that Accenture is leading the digital transformation in the World? Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Our main purpose is to collaborate with our clients, so they can become high-performance businesses. Accenture is present in more than 200 offices, 120 cities, 56 countries and approximately 743,000 employees worldwide. Offer Career development according to your profile and interests. Work in one of the best companies and feel proud. Access to an innovative methodology and tools. Direct contact with experts worldwide. Use of work schemes and cutting-edge technologies. Constant training. Work environment based on teamwork and collaboration. Participation in International Projects Develop advanced analytics models, gather client requirements, prepare data to build models. HERE'S WHAT YOU WILL NEED: Advanced proficiency in Data Engineering A minimum of 2 years of experience in relevant related skills Bachelor's Degree Python, Azure Accenture does not discriminate based on race, religion, color, sex, age, disability, nationality, sexual orientation, gender identity or expression, or for any other reason covered by local law.",https://mx.linkedin.com/jobs/view/data-science-practitioner-at-accenture-m%C3%A9xico-4004275193,4004275193,"Develop advanced analytics models, gather client requirements, and prepare data to build models. Requires advanced proficiency in Data Engineering.","Python, Azure",2,Bachelor,True,2.0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0
Senior Big Data Engineer,Zillow,Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Full-time,Real Estate,2024-09-01 11:41:09.361695,35,Engineering,Information Technology,,"About the team At Zillow Group, our mission is to empower people to unlock life's next chapter. We're currently seeking a Big Data Engineer to join the Growth Analytics team! Our team is deeply committed to understanding our customers’ journey on our site through meticulous analysis and measurement. We collaborate closely with Zillow’s Leadership on the New Construction team to uncover opportunities through data, delivering revolutionary and intuitive tools to find and buy your dream home. Additionally, we partner with engineering teams to build and maintain key analytics tools and infrastructure. The team closely collaborates with the product organization and Zillow’s New Construction and Growth product leadership team to create an integrated consumer financing experience. We operate with a flat team structure, allowing direct communication with Senior Leadership. En Zillow Group, nuestra misión es capacitar a las personas para desbloquear el siguiente capítulo de la vida. Actualmente estamos buscando un Ingeniero de Big Data para unirse al equipo de Growth Analytics. Nuestro equipo está profundamente comprometido con la comprensión del viaje de nuestros clientes en nuestro sitio a través de análisis y mediciones meticulosas. Colaboramos estrechamente con el Liderazgo de Zillow en el equipo de Nueva Construcción para descubrir oportunidades a través de los datos, ofreciendo herramientas revolucionarias e intuitivas para encontrar y comprar la casa de sus sueños. Además, nos asociamos con equipos de ingeniería para construir y mantener herramientas analíticas clave e infraestructura. El equipo colabora estrechamente con la organización de producto y el equipo de liderazgo de producto de Nueva Construcción y Crecimiento de Zillow para crear una experiencia integrada de financiación al consumidor. Trabajamos con una estructura de equipo plana, lo que permite una comunicación directa con la alta dirección. About the role In this role, you’ll collaborate closely with Zillow's New Construction and Growth product leadership teams to uncover deep insights about the customer funnel through best-in-class visualizations and deep dive analytics. Your main objective will be to influence business strategy and build out analytics roadmaps. Specifically, you will: Complete ad hoc analysis for key New Construction and Growth Product stakeholders Create compelling, clear, and powerful visualizations of our data Develop content and deliver key strategic insights to the executive audience via Business and Metrics review meetings Understand the new construction and Zillow growth business goals, providing thought leadership in creating, maintaining, and documenting a robust set of metrics Proactively identify areas of opportunity in the new construction business funnel, operational processes, and product suite to drive worthwhile outcomes Collaborate with product and engineering teams to discuss problems, design analytics framework, pull in the most relevant data for the business, and develop solutions This role has been categorized as a teleworker position. Teleworkers do not have a permanent corporate office workplace and, instead, work from a physical location of their choice which must be identified to the Company. Employees may live in any part of Mexico, but preferably in Mexico City, as we would encourage attendance for occasional in-office events. In addition to a competitive base salary and benefits, this position is also eligible for equity awards based on factors such as experience, performance and location. En este puesto, colaborarás estrechamente con los equipos de liderazgo de producto de Nueva Construcción y Crecimiento de Zillow para descubrir conocimientos profundos sobre el embudo de clientes a través de las mejores visualizaciones y análisis de inmersión profunda. Su principal objetivo será influir en la estrategia de negocio y construir hojas de ruta de análisis. En concreto Completar análisis ad hoc para las partes interesadas clave de New Construction y Growth Product. Crear visualizaciones convincentes, claras y potentes de nuestros datos. Desarrollar contenidos y ofrecer perspectivas estratégicas clave a la audiencia ejecutiva a través de reuniones de revisión de negocio y métricas. Entender los nuevos objetivos de negocio de construcción y crecimiento de Zillow, proporcionando liderazgo de pensamiento en la creación, mantenimiento y documentación de un sólido conjunto de métricas. Identificar proactivamente las áreas de oportunidad en el embudo de negocio de la nueva construcción, los procesos operativos y el conjunto de productos para impulsar resultados que merezcan la pena. Colaborar con los equipos de producto e ingeniería para discutir problemas, diseñar el marco analítico, extraer los datos más relevantes para el negocio y desarrollar soluciones. Este puesto se ha clasificado como de teletrabajador. Los teletrabajadores no tienen una oficina corporativa permanente y, en su lugar, trabajan desde una ubicación física de su elección que debe ser identificada a la Compañía. Los empleados pueden vivir en cualquier parte de México, pero preferentemente en la Ciudad de México, ya que fomentaríamos la asistencia a eventos ocasionales en la oficina. Además de un salario base y unas prestaciones competitivas, este puesto también puede optar a recompensas en acciones en función de factores como la experiencia, el rendimiento y la ubicación. Who you are You are a curious and passionate problem-solver who thrives in complexity and uncertainty. Join us and use your expertise to find opportunities and guide our business into the future with powerful insights and recommendations. We're looking for a Big Data Engineer who has: An undergraduate or Master's degree in a quantitative field (e.g. science, engineering, economics, quantitative finance, operations research, statistics, or similar) or proven experience within business analytics. Strong business sense and the ability to work cross-functionally, connecting customer problems to business strategy. 3+ years of work experience involving quantitative data analysis and complex problem-solving. Strong proficiency in Python Programming (or Java ), SQL , Tableau , and Excel, along with some knowledge of data pipelines . Experience with Product analytics tools such as Amplitude, MixPanel, or BI Tools such as Tableau , Mode, Thoughtspot, Metabase, etc. Collaboration across the company - needs to be able to partner with many different teams History of leading (independently) projects at scale (company/org wide) Eres un solucionador de problemas curioso y apasionado que prospera en la complejidad y la incertidumbre. Únete a nosotros y utiliza tu experiencia para encontrar oportunidades y guiar nuestro negocio hacia el futuro con ideas y recomendaciones potentes. Buscamos un Ingeniero de Big Data que tenga: Un título de grado o máster en un campo cuantitativo (por ejemplo, ciencia, ingeniería, economía, finanzas cuantitativas, investigación de operaciones, estadística o similar) o experiencia probada dentro de la analítica empresarial. Gran sentido empresarial y capacidad para trabajar de forma interdisciplinar, conectando los problemas de los clientes con la estrategia empresarial. Más de 3 años de experiencia laboral en análisis cuantitativo de datos y resolución de problemas complejos. Gran dominio de la programación en Python (o Java), SQL, Tableau y Excel, junto con algunos conocimientos de canalización de datos. Experiencia con herramientas de análisis de productos como Amplitude, MixPanel, o herramientas de BI como Tableau, Mode, Thoughtspot, Metabase, etc. Colaboración en toda la empresa - necesita ser capaz de asociarse con muchos equipos diferentes. Historial de liderar (de forma independiente) proyectos a gran escala (en toda la empresa/organización)",https://mx.linkedin.com/jobs/view/senior-big-data-engineer-at-zillow-3986713593,3986713593,"We are currently seeking a Big Data Engineer to join the Growth Analytics team. This role involves collaborating closely with product leadership teams to uncover insights about the customer journey through visualizations and analytics. Responsibilities include completing ad hoc analyses, creating data visualizations, delivering strategic insights, understanding business goals, identifying opportunities in the new construction business funnel, and collaborating with product and engineering teams to develop solutions. This position is categorized as a teleworker role, allowing employees to work from a location of their choice in Mexico.","Python, Java, SQL, Tableau, Excel, Amplitude, MixPanel, BI Tools, Data Pipelines",3+,Bachelor,True,3.0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,1,0,0
Data Analytics Engineer,Stori,Mexico City Metropolitan Area,HYBRID,Entry level,Full-time,"Technology, Information and Internet",2024-08-16 11:41:09.361695,25,Information Technology,,,"About Stori Stori is a fast-growing, venture-backed financial technology company, on a mission to democratize credit access for 400 million underbanked LatAm consumers. Stori currently operates in Mexico and has a global team with offices in Arlington Virginia, Mexico City, and Asia. We have quickly made our mark as one of the top digital banks in Mexico with more than two million applicants for our credit card product since launching. Stori is one of the top-funded startups in the region with US$250 million raised to date. We are backed by top global venture capital funds, such as GGV Capital, GIC, Lightspeed Venture Partners, General Catalyst, Goodwater Capital, Mexico's Tresalia Capital, Vision Plus Capital, BAI Capital and Source Code Capital; who have successfully invested in startups such as Affirm, Airbnb, Alibaba, Stripe, and TikTok. Stori has a standout founder team among fintechs, leveraging 100+ years of accumulated experience in consumer finance, banking and technology across Mastercard, Intel, Capital One, Morgan Stanley, GE Capital, and HSBC in the U.S., Mexico and Asia. The team has launched and managed many multi-million-customer credit card products globally, providing a wide breadth of experience and knowledge to our team. We welcome diversity of background, experience and thinking. Storians are passionate about our mission and take pride in the products we build. Our culture thrives off of a flat structure and an inclusive environment where all of our employees can be their authentic selves, with boundless opportunities for professional growth. The Role Stori's Analytics Engineering team's primary objective is to build easy-to-use, trustworthy, and reliable data products to serve the analytical needs across different product and business functions. Analytics Engineer Jr in Stori solve problems that get in the way of doing analysis. In this role, you are essential to our data strategy in reducing burdens associated with our data models and analytical tools and platforms. You will help business partners to diagnose what is getting in the way of efficient analytics today. Identifying and addressing the root causes will allow Stori to make quick, data informed decisions by removing bottlenecks and automating each stage of the data ops lifecycle. One day, this might mean modeling our core data in a better way. The next day, it might mean onboarding a new analytics tool. It can also mean working with source data teams to map out the right data structure to get to a single source of truth on vital business constructs. Our data analysts are critical to our analytics success because they enable our data analysts and data scientists to answer business questions using our data. Your impact Design and develop the batch data transformation pipelines to merge and transform large raw datasets to analytical datasets that users can quickly derive the insights from. Work with product managers and operation teams to understand the business pipeline, review new products and identify related data sources to provide prescriptive analysis. Perform the data validation on complex business logic, and reconciliation across different data sources. Identify, understand, analyze, and interpret trends or patterns in complex data sets. Perform data quality monitoring to maintain and assure data integrity. Develop the data dictionary and training to educate the business partners on how to best use and interpret the data. Solve data issues and perform root cause analysis to proactively resolve product and operational issues. What we are looking for A bachelor degree or foreign equivalent in Computer Science, Electronic Engineer, Mathematics, Information System, or Statistics. A professional with at least 2 years of experience with Data Analytics. Preferably 2+ years of Python development experience. Preferably 2+ years of SQL knowledge (including the experience of writing queries) and experience with relational databases. Experience with modern reporting and data visualization tools (QuickSight, Tableau, Looker, etc.) Strong analytical skills with the ability to collect, organize and analyze significant amounts of information with attention to detail and accuracy. Technical expertise in data models, database utilization, data mining, and segmentation techniques. Good presentation and communication skills, ability to explain complex technical problems in simple words. What we offer Make a positive impact on the lives of our customers via financial inclusion Professional development opportunities International exposure & work experience Company swag Legally required benefits",https://mx.linkedin.com/jobs/view/data-analytics-engineer-at-stori-3997813779,3997813779,"The primary objective of Stori's Analytics Engineering team is to build trustworthy data products for analytical needs across various functions. As an Analytics Engineer Jr, you will identify and solve problems impacting analysis, assist in data strategy, and help optimize data models and tools. Responsibilities include designing data transformation pipelines, validating data, performing data quality monitoring, and creating a data dictionary to educate business partners.","Python, SQL, Data Analytics, Tableau, QuickSight, Looker",2+ years,Bachelor,True,2.0,0,0,0,0,0,1,0,0,1,1,0,0,0,0,1,0,0
Bilingual data engineer / BigQuery,Grupo Scanda,Mexico City Metropolitan Area,HYBRID,,Full-time,"Technology, Information and Internet",2024-08-16 11:41:09.361695,25,Information Technology,,,"Alia es una empresa líder en el sector de tecnologías de la información, comprometida con la innovación y el desarrollo de soluciones tecnológicas de vanguardia. Nuestro ambiente laboral fomenta la creatividad, el trabajo en equipo y el crecimiento profesional de nuestros colaboradores. Conocimientos y habilidades : Sólidas hábilidades en SQL Haber interactuado en proyectos con equipos globales. Habilidades de comunicación y para el trabajo en equipo Responsabilidades del puesto Desarrollar y mantener bases de datos en BigQuery para analizar grandes volúmenes de datos. Diseñar y optimizar procesos de extracción, transformación y carga de información. Colaborar con el equipo de desarrollo para implementar soluciones basadas en datos. Realizar análisis y visualización de datos para identificar patrones y tendencias. Función de alianzas comerciales de TI y gestión de la cartera. Colaborar con las partes interesadas clave en la organización comercial (marketing y ventas) para identificar oportunidades y priorizar las iniciativas de TI. Esforzarse por comprender los desafíos del mercado y las nuevas tecnologías para asesorar a las funciones comerciales sobre las prioridades del cliente, ventajas competitivas y riesgos relacionados con la tecnología de la información. Comunicar decisiones, prioridades e información relevante del proyecto dentro de la organización. Ofrecemos: Salario mensual competitivo de $45,000.00 brutos mensuales Esquema híbrido (home office - oficina) Zona de trabajo: Polanco, CDMX (a unos pasos del centro comercial ""Miyana"") Horario: lunes a viernes de 9:00 am a 6:00 pm Oportunidades de crecimiento y desarrollo profesional Si te interesa la posición, envíanos tu CV actualizado por este medio. Requisitos: Requisitos del puesto Estudios mínimos: Ingeniería o licenciatura en sistemas o afín. Inglés avanzado (oral y escrito, ya que tratarás con clientes que solo hablan inglés). Un plus: si tienes certificaciones en CPG o BigQuary. Al menos 2 años de experiencia en: Desarrollo en BigQuery. Desarrollo de Warehouse/DataLakes. Uso de Google Cloud Platform (GCP). Desarrollo de modelos de datos dimensionales. Creación de API's en Google cloud. Manejo de Google storage.",https://mx.linkedin.com/jobs/view/bilingual-data-engineer-bigquery-at-grupo-scanda-3988605693,3988605693,"The role involves developing and maintaining databases in BigQuery for analyzing large volumes of data, designing and optimizing extraction, transformation, and loading processes, collaborating with the development team to implement data-driven solutions, performing data analysis and visualization to identify patterns and trends, and managing IT business alliances and portfolio. The position also requires communication with key stakeholders in the business organization to identify opportunities and prioritize IT initiatives, understanding market challenges and new technologies to advise business functions on customer priorities and technology-related risks.","SQL, BigQuery, Google Cloud Platform (GCP), Data Warehousing, Data Lakes, APIs, Google Storage",2,Bachelor,True,2.0,0,0,1,1,0,1,1,0,0,1,0,0,0,0,0,0,0
Data Solutions Engineer,Citibanamex,Mexico City Metropolitan Area,HYBRID,,Full-time,"Banking, Financial Services, and Investment Banking",2024-09-08 11:41:09.361695,29,Engineering,Information Technology,,"The DB Marketing Analyst 2 is a developing professional role. Applies specialty area knowledge in monitoring, assessing, analyzing and/or evaluating processes and data. Identifies policy gaps and formulates policies. Interprets data and makes recommendations. Researches and interprets factual information. Identifies inconsistencies in data or results, defines business issues and formulates recommendations on policies, procedures or practices. Integrates established disciplinary knowledge within own specialty area with basic understanding of related industry practices. Good understanding of how the team interacts with others in accomplishing the objectives of the area. Develops working knowledge of industry practices and standards. Limited but direct impact on the business through the quality of the tasks/services provided. Impact of the job holder is restricted to own team. Responsibilities: Independently supports the implementation of database marketing programs. Leads small projects from implementation to completion. Identifies project objectives according to business specifications. Develops and monitors project task plans and timelines to manage execution steps of programs. Partners with the business to develop segmentation execution reports. Uses discretionary judgment when providing process change recommendations to management and other team members. Collaborates with peers and business partners in: selection strategy development, operating procedures development, audit and business reporting, change management and issue resolution. Uses business and technical knowledge to ensure that process flow improvements and strategies comply with business requirements and security guidelines. Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency. Incumbents work with large and complex data sets (both internal and external data) to evaluate, recommend, and support the implementation of business strategies. Ability to manage processes efficiently and resolve technical problems. Execute and optimize recurring processes seeking to automate them and improve operational efficiency Qualifications: 0-2 years relevant experience Knowledge of SQL programming using tools such as SAS, Python, Pyspark Have the ability to manipulation data. Possess analytic ability and problem-solving skills. Excellent communication and interpersonal skills, be organized, detail oriented, and adaptive to matrix work environment. Ability to build partnerships with cross-functional teams. Openly learn new technologies. Communication skills. Basic English Education: Bachelors/University degree such us: computer science, engineer, mathematics or related This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required. Escolaridad: Ingenería, CIencias de la computación. Experiencia en SQL. Experiecia en SAS, Python, Pyspark. Conocimiento en metodologías ágiles. Capacidad para solucionar tareas. Experiencia trabajando con diversos equipos multidisiplinarios. Inglés básico-intermedio. ------------------------------------------------------ Job Family Group: Marketing ------------------------------------------------------ Job Family: Database Marketing & Analytics ------------------------------------------------------ Time Type: Full time ------------------------------------------------------ Citi is an equal opportunity and affirmative action employer. Qualified applicants will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran. Citigroup Inc. and its subsidiaries (""Citi”) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi . View the "" EEO is the Law "" poster. View the EEO is the Law Supplement . View the EEO Policy Statement . View the Pay Transparency Posting",https://mx.linkedin.com/jobs/view/data-solutions-engineer-at-citibanamex-4017389046,4017389046,"The DB Marketing Analyst 2 is a developing professional role focused on monitoring, assessing, analyzing, and evaluating processes and data. Responsibilities include independently supporting the implementation of database marketing programs, leading small projects, developing segmentation reports, and collaborating with peers. The role requires managing large data sets and improving operational efficiencies while ensuring compliance with business requirements and security guidelines. Candidates need strong analytical skills, problem-solving abilities, and effective communication skills.","SQL, SAS, Python, Pyspark, Agile Methodologies",0-2 years,Bachelor,True,0.0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0
Data Engineer Jr,GBM,Mexico City Metropolitan Area,HYBRID,Entry level,Full-time,Investment Banking,2024-09-14 11:41:09.361695,38,Information Technology,,,"Acerca de GBM Somos una organización de gestión de patrimonio y activos y banca privada con 35 años de experiencia, inversión digital innovadora y productos de ahorro. Nuestra misión es permitir vidas significativas a través de soluciones financieras inteligentes. Acerca del equipo Somos una comunidad joven con ideas y soluciones innovadoras. Un equipo de creativos, colectivos, propietarios y soñadores, y por supuesto, ¡sabemos cómo divertirnos! Creemos que la mejor idea gana y siempre estamos tratando de que cobre vida. Descripción del puesto El Data Engineer JR colaborará con diferentes equipos para entender sus necesidades y diseñar soluciones para disponibilizar los datos. Mapeará las fuentes de datos, extraerá lo necesario y los transformará en algo útil. Migrará sistemas antiguos a nuevas tecnologías. Y será una parte activa en el desarrollo de la innovación y estrategia de la empresa. Funciones principales: Desarrollar y mantener procesos de extracción, transformación y carga (ETL) para integrar datos de diversas fuentes. Implementar procesos de limpieza y validación de datos para garantizar su integridad. Construir y mantener las estructuras de datos dentro del Data Lake y DWH. Estructurar y preparar datasets para proyectos de análisis de datos. Asegurar que los sistemas de almacenamiento y procesamiento de datos sean eficientes y escalables. Apoyar y dar soporte a los usuarios con preguntas técnicas específicas sobre herramientas de datos, Datalake y DWH. Requisitos: En Sistemas, Matemáticas aplicadas o experiencia laboral equivalente 1 a 2 años de experiencia en rol similar como Data Engineer Experiencia con bases de datos y su manejo (SQL y noSQL) Experiencia en desarrollo con lenguajes de programación como Python, Scala o R Experiencia desarrollando pipelines de datos o ETL’s Deseable experiencia con servicios cloud (AWS; Azure, Google Cloud) Deseable experiencia con SQL Server Integration Services (SSIS) Competencias Resolución de problemas Facilidad para entender la información en bases de datos Proactividad Orientado a objetivos Habilidades de comunicación Ofrecemos Salario y paquete de compensación competitivo Prestaciones superiores de ley Contratación directamente Formación y plan de carrera ¡Únete al equipo!* Para postularte es indispensable que leas y aceptes nuestro  Aviso de Privacidad para Candidatos que se alinea a la ley de protección de datos personales y especifica el uso que le daremos a los mismos únicamente con fines de reclutamiento.",https://mx.linkedin.com/jobs/view/data-engineer-jr-at-gbm-4025993753,4025993753,"The Junior Data Engineer will collaborate with different teams to understand their needs and design solutions to make data available. They will map data sources, extract necessary data, and transform it into something useful. They will migrate legacy systems to new technologies and be an active part of the company's innovation and strategy development. Main responsibilities include developing and maintaining extraction, transformation, and loading (ETL) processes to integrate data from various sources, implementing data cleaning and validation processes to ensure integrity, building and maintaining data structures within the Data Lake and Data Warehouse (DWH), structuring and preparing datasets for data analysis projects, ensuring data storage and processing systems are efficient and scalable, and supporting users with specific technical questions about data tools, Data Lakes, and DWH.","SQL, NoSQL, Python, Scala, R, ETL, AWS, Azure, Google Cloud, SQL Server Integration Services (SSIS)",1-2,Bachelor,False,1.0,0,0,0,1,0,0,1,0,0,1,0,0,0,0,1,0,0
Analytics Team Data Engineer,Accenture México,Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Full-time,Business Consulting and Services,2024-09-13 11:41:09.361695,35,Information Technology,,,"DARE TO BE A PART OF THE CHALLENGE! COME AND JOIN OUR TEAM TOGETHER WE CAN MAKE THE DIFFERENCE! Did you know that Accenture is leading the digital transformation in the World? Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Our main purpose is to collaborate with our clients, so they can become high-performance businesses. Accenture is present in more than 200 offices, 120 cities, 56 countries and approximately 743,000 employees worldwide. Offer Career development according to your profile and interests. Work in one of the best companies and feel proud. Access to an innovative methodology and tools. Direct contact with experts worldwide. Use of work schemes and cutting-edge technologies. Constant training. Work environment based on teamwork and collaboration. Participation in International Projects You will be part of an exciting team that collaborates and manages to perform at their best. As an expert in Data Engineering, you will be responsible for making team decisions and providing solutions to problems for your immediate team and across multiple teams. Your expertise will be crucial in engaging with multiple teams and contributing to key decisions. Join us and be a part of our dynamic and innovative environment! Identify AI use cases in an industry and/or function by understanding an organization’s goals and areas of need Develop the business case, determine ROI, and create the transformation roadmap Understand and document as-is processes and current landscape Define functional and non-functional specifications Re-invent future processes with AI Develop AI solutions leveraging domain expertise through feature extraction, algorithm selection, and model validation Advise the organization on adoption of responsible AI solutions and governance Train users on new processes, maintain solutions, track results, and communicate the realized value HERE'S WHAT YOU WILL NEED: Advanced proficiency in Data Engineering A minimum of 2 years of experience in relevant related skills Bachelor's Degree Experience in SQL, Analytics, Python, GCP BONUS POINTS IF YOU HAVE: Intermediate proficiency in Data Pipelines Intermediate proficiency in Data Processing Beginner proficiency in Data Migrations Accenture does not discriminate based on race, religion, color, sex, age, disability, nationality, sexual orientation, gender identity or expression, or for any other reason covered by local law.",https://mx.linkedin.com/jobs/view/analytics-team-data-engineer-at-accenture-m%C3%A9xico-4004277025,4004277025,"As an expert in Data Engineering, you will identify AI use cases within an organization, develop business cases, and create transformation roadmaps. You will document current processes, define specifications, and reinvent future processes using AI. Additionally, you will advise on responsible AI solutions and train users on new processes while tracking results and communicating value.","SQL, Python, GCP, Data Engineering, Data Pipelines, Data Processing",2,Bachelor,True,2.0,0,0,0,1,0,1,1,0,0,1,0,0,0,0,1,0,0
Data Engineer,Stori,Mexico City Metropolitan Area,HYBRID,Entry level,Full-time,"Technology, Information and Internet",2024-08-16 11:41:09.361695,25,Information Technology,,,"About Stori Stori is a fast-growing, venture-backed financial technology company, on a mission to democratize credit access for 400 million underbanked LatAm consumers. Stori currently operates in Mexico and has a global team with offices in Arlington Virginia, Mexico City, and Asia. We have quickly made our mark as one of the top digital banks in Mexico with more than two million applicants for our credit card product since launching. Stori is one of the top-funded startups in the region with US$250 million raised to date. We are backed by top global venture capital funds, such as GGV Capital, GIC, Lightspeed Venture Partners, General Catalyst, Goodwater Capital, Mexico's Tresalia Capital, Vision Plus Capital, BAI Capital and Source Code Capital; who have successfully invested in startups such as Affirm, Airbnb, Alibaba, Stripe, and TikTok. Stori has a standout founder team among fintechs, leveraging 100+ years of accumulated experience in consumer finance, banking and technology across Mastercard, Intel, Capital One, Morgan Stanley, GE Capital, and HSBC in the U.S., Mexico and Asia. The team has launched and managed many multi-million-customer credit card products globally, providing a wide breadth of experience and knowledge to our team. We welcome diversity of background, experience and thinking. Storians are passionate about our mission and take pride in the products we build. Our culture thrives off of a flat structure and an inclusive environment where all of our employees can be their authentic selves, with boundless opportunities for professional growth. The Role As a Data engineer at Stori you will leverage cutting edge data pipeline and data management tools to innovate, design, build, and maintain well-managed data pipeline and data infrastructure solutions and capabilities to tackle BIG DATA challenges for the whole organization. This role will be responsible for developing data pipelines that load and transform raw data from various sources to our internal data lake and analytical data warehouse, set up data movement monitoring to ensure the data completeness, timeliness, and accuracy, and develop data infrastructure for source systems. Your Impact Develop data pipelines that load and transform raw data from various sources to our internal analytical data warehouse, with proper monitoring set up to ensure data integrity and timeliness Work closely with internal analysts and stakeholders to translate the analytical data needs to technical data pipeline solutions Optimize the data structure and analytical platform to enable efficient data analysis, feature engineering, or ML development on BIG DATA Explore and develop new tools to manage the data access, data artefacts management and knowledge sharing, data defects management to serve the data needs of the whole analyst community in the company What we are looking for A bachelor degree or foreign equivalent in Computer Science, Electronic Engineering, or a related quantitative analytical field. Experience with developing various types of production data pipelines & ETLs (Extract, Transform, Load) for batch and real-time data processing Experience with RDBMS, SQL and NoSQL databases Experience with Python or Node.js preferred Familiarity with technologies like AWS Serverless, S3, Lambda, Redshift, Athena, Glue, EMR, Kinesis, SQS, FIrehose, Redis, Kafka Experience with CI/CD (Continuous Integration, Continuous Delivery), Automated Testing, Automated Delivery Proven interpersonal, collaboration, diplomatic, influencing, planning and organizational skills. Consistently demonstrate clear and concise written and verbal communication. Demonstrated ability to work under pressure and to meet tight deadlines with proactive, decisiveness and flexibility. What we offer Make a positive impact on the lives of our customers via financial inclusion Professional development opportunities International exposure & work experience Company swag Legally required benefits",https://mx.linkedin.com/jobs/view/data-engineer-at-stori-4001822310,4001822310,"As a Data Engineer, you will innovate, design, build, and maintain data pipeline and infrastructure solutions to tackle Big Data challenges. You will develop data pipelines that load and transform raw data from various sources to the internal analytical data warehouse, ensure data integrity and timeliness, and optimize the data structure for efficient analysis and machine learning development.","Python, Node.js, SQL, NoSQL, AWS, S3, Lambda, Redshift, Athena, Glue, EMR, Kinesis, SQS, Firehose, Redis, Kafka",,Bachelor,True,,0,1,0,1,0,0,0,0,0,1,0,0,0,0,1,0,0
Data Engineer,Minsait,Mexico City Metropolitan Area,HYBRID,Associate,Full-time,IT Services and IT Consulting,2024-09-08 11:41:09.361695,54,Information Technology,,,"Trae tu talento a una compañía global de consultoría y tecnología, con presencia en los 5 continentes y más de 40.000 profesionales. En Minsait tendrás una carrera profesional adaptada a tus objetivos personales, con formación continua y en un entorno flexible. Participarás en proyectos internacionales, con equipos multiculturales o locales, según tus preferencias, en un entorno diverso y con igualdad de oportunidades. Nos encontramos en búsqueda de: Data Engineer Ingeniería en Sistemas Computacionales o afín Programación Orientada a Objetos (Python/Scala/Java) - Indispensable 6 meses de experiencia Manejo de Spark - 6 meses de experiencia POO – Indispensable Buenas prácticas de desarrollo SQL Creación de Querys con JOINS, WHERE, GROUP BY - Indispensable Control de versiones GIT - Deseable Conocimiento de los comandos: clone, commit, push, rebase, merge, pull request Conocimiento de metodologías ágiles - SCRUM (Deseable) Conocimiento o experiencia con AWS (Deseable) Trabajo en equipo (Determinante) Facilidad para aprender e investigar Experiencia DATIO/BBVA (deseable) Conocimientos Funcionales: * Habilidades suaves de comunicaciones interpersonales, manejo de expectativa cliente, trabajo en equipo, entusiasmo, iniciativa, dedicación, visión, prioriza tareas y se adapta rápidamente a los cambios. Beneficios: •Sueldo 100% nominal, acorde a nivel de experiencia. •Contratación directa. •Prestaciones de ley (IMSS, Infonavit, Afore, Aguinaldo). •13% fondo de ahorro. •10% Vales de despensa. •Gastos médicos mayores (familiar) •Seguro de vida •Seguro dental y visual •12 días de vacaciones. •Total pass: Te brindara acceso a +2,500 gimnasios, + 200 K tipo de clases presenciales y + 300 entrenamientos on-line. •Plan de carrera y desarrollo. •Cursos ilimitados y sin costo en Udemy. Interesados, postularse por este medio o al correo de contacto.",https://mx.linkedin.com/jobs/view/data-engineer-at-minsait-4018460940,4018460940,"Bring your talent to a global consulting and technology company with a presence in all five continents and over 40,000 professionals. In Minsait, you will have a career tailored to your personal goals, with continuous training in a flexible environment. You will participate in international projects with multicultural or local teams based on your preferences. We are looking for a Data Engineer with a background in Computer Systems Engineering or a related field. Object-Oriented Programming (Python/Scala/Java) is essential, along with 6 months of experience in Spark and SQL, including the creation of queries with JOINS, WHERE, and GROUP BY. Knowledge of version control with GIT, agile methodologies like SCRUM, and AWS is desirable. Teamwork skills and the ability to learn and research quickly are crucial.","Python, Scala, Java, Spark, SQL, GIT, AWS, SCRUM",6 months,Masters,False,6.0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0
Technical Execution - BTP AI Team,SAP,Mexico City Metropolitan Area,HYBRID,,Full-time,"Software Development, IT Services and IT Consulting, and Business Consulting and Services",2024-09-08 11:41:09.361695,25,Customer Service,,,"We help the world run better At SAP, we enable you to bring out your best. Our company culture is focused on collaboration and a shared passion to help the world run better. How? We focus every day on building the foundation for tomorrow and creating a workplace that embraces differences, values flexibility, and is aligned to our purpose-driven and future-focused work. We offer a highly collaborative, caring team environment with a strong focus on learning and development, recognition for your individual contributions, and a variety of benefit options for you to choose from. About The Team The Global Services BTP leadership is creating a new AI team focusing on driving adoption and consumption of the BTP platform through the sourcing, design, and execution of customer AI proof of concepts. This team will work in close collaboration throughout the organization to help craft the set of SAP Best Practices for AI development within and around BTP. Our (current) motto is : Inspire, Innovate, Implement: AI on BTP. We will inspire customers on the art of the possible with AI and SAP, we will innovate new techniques, technologies, and methodologies to bring them to life and we will manifest our vision into reality through POCs. We are looking to hire an end-to-end team starting with a set of functional architects, who are business process experts to isolate and identify the value of new AI driven processes across multiple industries. Secondly, we are hiring a deeply capable technical team of experts in data strategy, data science, python, vectorization and knowledge graphs, BTP functionalities (Datasphere, SAP Build, CPI, UX, AI collaboration Hub, AI API Hub, etc), ML, AI training and more. Lastly, the team will require a Program Manager to project manage the various POCs, internal team initiatives and share GTM responsibilities with the team leader. While all roles will have their unique technical and functional aptitudes, the best candidates for this team will be insatiably curious, have unbounded creativity, a deep desire to teach and learn and a passion for sharing our stories with our customers, partners, and SAP colleagues. Each team member must be willing to receive and GIVE feedback to the team to maximize knowledge transfer, lessons learned and best practice development. Let’s invent some fire together! What We Are Looking For The BTP AI team will require a mixture of resources to cover the full stack of technologies to facilitate successful Proofs of Concepts. Each candidate must demonstrate strong technical aptitude in a minimum of one domain with secondary knowledge in others. Our platforms and technologies change quickly so a clear demonstration of your flexibility, learning and ability to execute will be critical to your success. The below is a list of Job Roles that are necessary from the team. Senior team members should be able to conduct multiple Job Roles. As demand improves, additional specific resources will be hired to fill areas identified as bottlenecks. All roles must have experience with the latest Generative AI LLMs. If you satisfy one or more of these roles, please apply. AI/ML Engineer: Role: Develops machine learning models and algorithms, processes data, and implements AI solutions. Experience in training SAP, custom, 3P or open source AI models Skills: Proficiency in programming languages (Python, R), knowledge of ML frameworks (TensorFlow, PyTorch), data preprocessing, model training and evaluation. Data Scientist: Role: Analyzes and interprets complex data to provide insights, builds predictive models, and helps in the decision-making process. Skills: Statistical analysis, data visualization, machine learning, proficiency in data science tools (Jupyter, Pandas), and strong analytical thinking. Data/Integration Engineer: Role: Manages and organizes data infrastructure, ensuring data is available, clean, and accessible for analysis. The goal is to centralize this function into Datasphere as much as possible but TBD. Skills: ETL processes, database management, data pipeline construction, knowledge of big data technologies. Datasphere/BW experience is a plus. AI Solutions Architect: Role: Designs AI system reference architectures fitting common patterns in use cases. Design a composable framework of functionality for maximal reusability. Defines and ensure highest quality in publishing BTP AI Best Practices both internally and externally. Presents to various internal communities and potentially SAP Insider events. Skills: System design, knowledge of cloud services, understanding of AI/ML lifecycle, and experience with microservices and APIs. Full understanding of SAP AI framework and how to integrate with classical AI approaches, open source and public assets. UX/UI Designer: Role: Designs intuitive and user-friendly interfaces for AI applications, ensuring a positive user experience leveraging SAP Build. Skills: User experience design, user interface design, prototyping tools, and user research. This position is open for all LATAM. Bring out your best SAP innovations help more than four hundred thousand customers worldwide work together more efficiently and use business insight more effectively. Originally known for leadership in enterprise resource planning (ERP) software, SAP has evolved to become a market leader in end-to-end business application software and related services for database, analytics, intelligent technologies, and experience management. As a cloud company with two hundred million users and more than one hundred thousand employees worldwide, we are purpose-driven and future-focused, with a highly collaborative team ethic and commitment to personal development. Whether connecting global industries, people, or platforms, we help ensure every challenge gets the solution it deserves. At SAP, you can bring out your best. We win with inclusion SAP’s culture of inclusion, focus on health and well-being, and flexible working models help ensure that everyone – regardless of background – feels included and can run at their best. At SAP, we believe we are made stronger by the unique capabilities and qualities that each person brings to our company, and we invest in our employees to inspire confidence and help everyone realize their full potential. We ultimately believe in unleashing all talent and creating a better and more equitable world. SAP is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to the values of Equal Employment Opportunity and provide accessibility accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment with SAP and are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to Recruiting Operations Team: Careers@sap.com. For SAP employees: Only permanent roles are eligible for the SAP Employee Referral Program, according to the eligibility rules set in the SAP Referral Policy. Specific conditions may apply for roles in Vocational Training. EOE AA M/F/Vet/Disability Qualified applicants will receive consideration for employment without regard to their age, race, religion, national origin, ethnicity, age, gender (including pregnancy, childbirth, et al), sexual orientation, gender identity or expression, protected veteran status, or disability. Compensation Range Transparency : SAP believes the value of pay transparency contributes towards an honest and supportive culture and is a significant step toward demonstrating SAP’s commitment to pay equity. SAP provides the hourly base salary rate range applicable for the posted role. The targeted range for this position is USD. The actual amount to be offered to the successful candidates will be within that range, dependent upon the key aspects of each case which may include education, skills, experience, scope of the role, location, etc. as determined through the selection process. SAP offers limited benefits for employees hired into hourly or like roles subject to appliable plan/policy terms. A summary of benefits and eligibility requirements can be found by clicking this link: SAP North America Benefits. Requisition ID: 401051 | Work Area: Consulting and Professional Services | Expected Travel: 0 - 50% | Career Status: Professional | Employment Type: Regular Full Time | Additional Locations:",https://mx.linkedin.com/jobs/view/technical-execution-btp-ai-team-at-sap-3980089156,3980089156,"The Global Services BTP leadership is creating a new AI team focusing on driving adoption and consumption of the BTP platform through sourcing, design, and execution of customer AI proof of concepts. The team will work closely to help craft best practices for AI development within and around BTP. The AI team requires functional architects, technical experts in data strategy, data science, Python, ML, and AI training, as well as a Program Manager to manage POCs and internal initiatives. Roles include AI/ML Engineer, Data Scientist, Data/Integration Engineer, AI Solutions Architect, and UX/UI Designer, all needing strong technical aptitude, flexibility, and experience with Generative AI LLMs.","Python, R, TensorFlow, PyTorch, Jupyter, Pandas, ETL processes, big data technologies, cloud services, microservices, APIs, SAP Datasphere, SAP Build",,,True,,0,0,0,0,0,0,1,0,0,0,0,0,1,0,1,0,0
Data Engineer,Azkait,Mexico City Metropolitan Area,HYBRID,,Full-time,"Technology, Information and Internet",2024-05-18 11:41:09.361695,25,Information Technology,,,"AZKAIT es una empresa Mexicana que busca y conecta el mejor talento IT con empresas Latinoamericanas y de Estados Unidos. Estamos en la búsqueda de tu talento como Data Engineer Objetivo: Trabajar en soluciones de ingeniería de datos para aprovechar las mejores prácticas y herramientas/ tecnologías líderes en la industria para perfilar datos, desarrollar una ingestión eficiente y construir capas de datos semánticos. Requisitos: Sólidas habilidades en: Programación Python Sólida experiencia en SQL Experiencia con canalización de datos y herramienta de gestión de flujo de trabajo Experiencia con servicios en la nube y herramientas de Data Analytics Experiencia con Snowflake (deseable) ¿Qué ofrecemos? ﻿Esquema de contratación 100% nómina SGMM para el colaborador y su familia directa Seguro de Vida Vales de despensa PTU de ley Aguinaldo de 30 días Vacaciones de ley Certificaciones gratuitas Contrato 3 meses a prueba // posterior indeterminado Lugar de trabajo: Modalidad de trabajo híbrido, la empresa cuenta con diversos sites: CDMX, Querétaro, Monterrey o Guadalajara.",https://mx.linkedin.com/jobs/view/data-engineer-at-azkait-3917658896,3917658896,"AZKAIT is looking for a Data Engineer to work on data engineering solutions using industry-leading practices and technologies to profile data, develop efficient ingestion, and build semantic data layers.","Python, SQL, Data Pipeline, Workflow Management Tools, Cloud Services, Data Analytics, Snowflake",,,False,,0,0,0,0,0,1,0,0,0,1,0,0,0,0,1,0,0
Senior Data Analytics Engineer,Stori,Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Full-time,"Technology, Information and Internet",2024-09-01 11:41:09.361695,25,Information Technology,,,"About Stori Stori is a fast-growing, venture-backed financial technology company, on a mission to democratize credit access for 400 million underbanked LatAm consumers. Stori currently operates in Mexico and has a global team with offices in Arlington Virginia, Mexico City, and Asia. We have quickly made our mark as one of the top digital banks in Mexico with more than two million applicants for our credit card product since launching. Stori is one of the top-funded startups in the region with US$250 million raised to date. We are backed by top global venture capital funds, such as GGV Capital, GIC, Lightspeed Venture Partners, General Catalyst, Goodwater Capital, Mexico's Tresalia Capital, Vision Plus Capital, BAI Capital and Source Code Capital; who have successfully invested in startups such as Affirm, Airbnb, Alibaba, Stripe, and TikTok. Stori has a standout founder team among fintechs, leveraging 100+ years of accumulated experience in consumer finance, banking and technology across Mastercard, Intel, Capital One, Morgan Stanley, GE Capital, and HSBC in the U.S., Mexico and Asia. The team has launched and managed many multi-million-customer credit card products globally, providing a wide breadth of experience and knowledge to our team. We welcome diversity of background, experience and thinking. Storians are passionate about our mission and take pride in the products we build. Our culture thrives off of a flat structure and an inclusive environment where all of our employees can be their authentic selves, with boundless opportunities for professional growth. The Role Stori's Data team's primary objective is to build easy-to-use, trustworthy, and reliable data products to serve the analytical needs across different product and business functions. Data Analytics Engineers in Stori solve problems that get in the way of doing analysis. In this role, you are essential to our data strategy in reducing burdens associated with our data models and analytical tools and platforms. You will help business partners to diagnose what is getting in the way of efficient analytics today. Identifying and addressing the root causes will allow Stori to make quick, data informed decisions by removing bottlenecks and automating each stage of the data ops lifecycle. One day, this might mean modeling our core data in a better way. The next day, it might mean onboarding a new analytics tool. It can also mean working with source data teams to map out the right data structure to get to a single source of truth on vital business constructs. Our data analysts are critical to our analytics success because they enable our data analysts and data scientists to answer business questions using our data. Your Impact Design and develop the batch data transformation pipelines to merge and transform large raw datasets to analytical datasets that users can quickly derive the insights from. Work with product managers and operation teams to understand the business pipeline, review new products and identify related data sources to provide prescriptive analysis. Perform the data validation on complex business logic, and reconciliation across different data sources Identify, understand, analyze, and interpret trends or patterns in complex data sets.Perform data quality monitoring to maintain and assure data integrity. Develop the data dictionary and training to educate the business partners on how to best use and interpret the data. Solve data issues and perform root cause analysis to proactively resolve product and operational issues. What we are looking for A bachelor degree or foreign equivalent in Computer Science, Electronic Engineer, Mathematics, Information System, or Statistics. A professional with at least 2 years of experience with Data Analytics. Preferably 3+ years of Python development experience. Preferably 3+ years of SQL knowledge (including the experience of writing queries) and experience with relational databases. Experience with modern reporting and data visualization tools (QuickSight, Tableau, Looker, etc.) Strong analytical skills with the ability to collect, organize and analyze significant amounts of information with attention to detail and accuracy. Technical expertise in data models, database utilization, data mining, and segmentation techniques. Good presentation and communication skills, ability to explain complex technical problems in simple words. What we offer Make a positive impact on the lives of our customers via financial inclusion Professional development opportunities International exposure & work experience Company swag Legally required benefits",https://mx.linkedin.com/jobs/view/senior-data-analytics-engineer-at-stori-4011540524,4011540524,"Stori's Data team's primary objective is to build easy-to-use, trustworthy, and reliable data products for analytical needs across different product and business functions. Data Analytics Engineers help solve problems that hinder analysis, ensuring efficient data operations. Key responsibilities include designing and developing batch data transformation pipelines, validating data, performing root cause analysis, and educating business partners on data usage. The role requires strong analytical skills and technical expertise in data models and database utilization.","Python, SQL, QuickSight, Tableau, Looker, Data Modeling, Data Mining",2+,Bachelor,True,2.0,0,0,0,0,0,1,0,1,1,1,0,0,0,0,1,0,0
Data platform engineer,Marsh McLennan,Mexico City Metropolitan Area,HYBRID,,Full-time,Insurance and Business Consulting and Services,2024-09-01 11:41:09.361695,25,Engineering,Information Technology,,"MercerTech DnAi Platform engineering team is seeking candidates for the following position based in the CDMX office and be onsite 3 days a week: Sr. Data Platform Engineer MercerTech DnAi Platform engineering team is seeking an experienced Mid-Level Data plat Engineer with experient on data with AWS cloud who has expertise in the administration, development and implementation of large-scale data projects in the hybrid data platform (on-prem and cloud both) SR. DATA PLATFORM ENGINEER What can you expect? You will be responsible for overseeing the design, implementation, and maintenance of the data platform built on Kubernetes, AWS services and other SAAS solutions. You will be responsible to setup the platform and its toolkit like Databricks, Snowflake, IDMC with best possible standards for different projects to work on it. You will also collaborate with projects’ business teams to understand their requirements, technical needs and help the team design their architecture using the combination of data tools aligning with MMC’s technology standards and security. you will also be involved in onboarding new technologies onto the platform and ensuring smooth operations through regular maintenance, governance, and guideline definition. You should be an expert an ETL processing toolsets to have the capability to guide the developers to optimize their jobs What is in it for you? A company with a strong Brand and strong results to match Culture of internal mobility, collaboration and valued partnership from the business. Employee Resource Groups which provide access to leaders, relevant volunteer and mentoring opportunities and interactions with counterparts in industry groups and client organizations. Entitled to vacation, floating holidays, time off to give back to your community, sick days, and national holidays (with early dismissal). We will count on you to: Work with our partners to understand business and technology problems or opportunities. Conceptualize and implement the setup and management of the data platform built on Kubernetes , AWS services and other cloud saas solutions like Databricks, Snowflake, IDMC, Mongo Atlas across different regions. Configure and optimize the techstack including Spark, NiFi, Python, R, Databricks, IDMC by Informatica, Snowflake AWS S3, Glue, and Athena for efficient performance and scalability to create the best-in-class data ingestion and processing data platform. Understand data landscape i.e., tooling, tech stack, source systems etc. and work closely with development teams to improve data collection, quality, reporting and analytics capabilities. Provide guidance on selecting the appropriate tools in appropriate AWS regions to meet project objectives and performance requirements. Setup the skilled team who can support the projects to build efficient data pipelines. Collaborate with analytics and business teams to suggest and improve data platform that support business intelligence tools, increasing data accessibility, and fostering data-driven decision-making across the organization. Collaborate with different stakeholders like MMC infra, MMC security, MMC architecture teams to achieve high availability and scalability over the data platform. Continuous learning and implementation of latest technologies Troubleshoot incidents, identify root causes, fix, and document problems, and implement preventive measures. Setup process, guidance, and documentations necessary to share the best practices guidelines for other to follow. Work with data governance team on technology obsolescence, component re-use and platform modernization. Crisis management and problem-solving Be innovative in your design thinking and use your expertise to influence the MMC technology roadmap. Take your architectural designs through our on boarding processes to ensure they meet MMC’s standards and conventions. Participate in cost estimations during budget cycles. Empower the development teams to deliver your architectural designs What you need to have: Bachelor's or Master's degree in Computer Science, Engineering, or related field. Extensive experience in data engineering roles with a focus on building and managing data platforms. Exposure to Big Data / Data Lake frameworks like Spark, Spark Streaming, Python, R, NiFi, AWS S3, Redshift, Glue, Athena etc and tools like Databricks, IDMC, Snowflake, MongoDB Understanding of BI Tools like PowerBI, Qlik is an added advantage. Excellent communication and collaboration skills with the ability to work effectively with cross-functional teams. Ability to design and architect the solution when provided with the business requirement. An inquisitive mind set with a track record of seeking out and implementing new technologies and architectural patterns. Self-motivated to excel in a remote position, collaborating effectively with a remote team. You are a self-starter; you can take initiative without waiting for direction. Ability to take decisions during crisis. The ability to work in a fast-paced environment with changing priorities and deadlines. You are used to working and communicating with both business and technical stakeholders at varying levels of seniority. What makes you stand out? Strong AWS experience. Experience in either one of Databricks or Snowflake Experience in Informatica data quality and governance tools. (IDMC) If you are interested, please send your CV in English. Interviews will be held in English . Marsh McLennan (NYSE: MMC) is the world’s leading professional services firm in the areas of risk, strategy and people. The Company’s 85,000 colleagues advise clients in 130 countries. With annual revenue of over $20 billion, Marsh McLennan helps clients navigate an increasingly dynamic and complex environment through four market-leading businesses. Marsh provides data-driven risk advisory services and insurance solutions to commercial and consumer clients. Guy Carpenter develops advanced risk, reinsurance and capital strategies that help clients grow profitably and pursue emerging opportunities. Mercer delivers advice and technology-driven solutions that help organizations redefine the world of work, reshape retirement and investment outcomes, and unlock health and well being for a changing workforce. Oliver Wyman s serves as a critical strategic, economic and brand advisor to private sector and governmental clients. For more information, visit marshmclennan.com, or follow us on LinkedIn and Twitter. Marsh McLennan is committed to creating a diverse, inclusive and flexible work environment. We aim to attract and retain the best people and embrace diversity of age, background, disability, ethnic origin, family duties, gender orientation or expression, marital status, nationality, parental status, personal or social status, political affiliation, race, religion and beliefs, sex/gender, sexual orientation or expression, skin color, or any other characteristic protected by applicable law. Marsh McLennan is committed to hybrid work, which includes the flexibility of working remotely and the collaboration, connections and professional development benefits of working together in the office. All Marsh McLennan colleagues are expected to be in their local based teams will identify at least one “anchor day” per week on which their full team will be together in person. office or working onsite with clients at least three days per week. R_267587",https://mx.linkedin.com/jobs/view/data-platform-engineer-at-marsh-mclennan-3945747187,3945747187,"The Sr. Data Platform Engineer will be responsible for the design, implementation, and maintenance of a data platform built on Kubernetes, AWS services, and other SaaS solutions such as Databricks, Snowflake, and IDMC. Responsibilities include setting up the platform, optimizing the tech stack for data ingestion and processing, and collaborating with various teams to improve data accessibility and foster data-driven decision-making. The role requires extensive experience in data engineering, exposure to Big Data frameworks, and the ability to manage and build efficient data pipelines.","AWS, Kubernetes, Databricks, Snowflake, IDMC, MongoDB, Spark, Python, R, NiFi, S3, Redshift, Glue, Athena, PowerBI, Qlik",Extensive experience in data engineering roles,Bachelor,True,,0,0,1,1,1,0,0,0,1,1,0,0,0,0,1,0,0
Data Analytics Engineer Sr,Stori,Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Full-time,"Technology, Information and Internet",2024-09-08 11:41:09.361695,25,Information Technology,,,"About Stori Stori is a fast-growing, venture-backed financial technology company, on a mission to democratize credit access for 400 million underbanked LatAm consumers. Stori currently operates in Mexico and has a global team with offices in Arlington Virginia, Mexico City, and Asia. We have quickly made our mark as one of the top digital banks in Mexico with more than two million applicants for our credit card product since launching. Stori is one of the top-funded startups in the region with US$250 million raised to date. We are backed by top global venture capital funds, such as GGV Capital, GIC, Lightspeed Venture Partners, General Catalyst, Goodwater Capital, Mexico's Tresalia Capital, Vision Plus Capital, BAI Capital and Source Code Capital; who have successfully invested in startups such as Affirm, Airbnb, Alibaba, Stripe, and TikTok. Stori has a standout founder team among fintechs, leveraging 100+ years of accumulated experience in consumer finance, banking and technology across Mastercard, Intel, Capital One, Morgan Stanley, GE Capital, and HSBC in the U.S., Mexico and Asia. The team has launched and managed many multi-million-customer credit card products globally, providing a wide breadth of experience and knowledge to our team. We welcome diversity of background, experience and thinking. Storians are passionate about our mission and take pride in the products we build. Our culture thrives off of a flat structure and an inclusive environment where all of our employees can be their authentic selves, with boundless opportunities for professional growth. The Role As a Data Analytics Engineer Sr at Stori, you will leverage your analytical and technical expertise to support our accounting and regulatory reporting functions. Your role will be critical in ensuring data accuracy, compliance, and the generation of reports and reconciliations processes. On any given day, you will be challenged on three types of work – Innovation, Business Intelligence, and Data Management: Innovation Develop and enhance data-driven solutions for accounting processes, including the automation of reconciliations and regulatory reporting to improve accuracy and efficiency. Use Open Source/Digital technologies to mine complex, voluminous, and different varieties of data sources and platforms. Build well-managed data solutions, tools, and capabilities to enable self-service frameworks for data consumers. Demonstrate the ability to explore and quickly grasp new technologies to progress varied initiatives. Business Intelligence Collaborate closely with teams to launch new products or features, ensuring they are aligned with accounting, regulatory and compliance reporting objectives. Partner with the business to provide consultancy and translate the business needs to design and develop tools, techniques, metrics, and dashboards for insights and data visualization. Drive analysis that provides meaningful insights on business strategies. Data Management Drive an understanding and adherence to the principles of data quality management, including metadata, lineage, and business definitions. Work with business teams to understand their needs and translate them into technical requirements. Work collaboratively with appropriate Tech teams to manage security mechanisms and data access governance. Build and execute tools to monitor and report on data quality. Requirements A bachelor's degree or foreign equivalent in Engineering, Science, Operations Research, Information Technology, Statistics, Mathematics, Economics, Finance, Analytics, or a related quantitative analytical field. Advanced skills in SQL and Python for data manipulation and analysis. Proven interpersonal, collaboration, diplomatic, influencing, planning, and organizational skills. Consistently demonstrate clear and concise written and verbal communication. Proven ability to effectively use complex analytical, interpretive, and problem-solving techniques. Demonstrated ability to work under pressure and to meet tight deadlines with proactive, decisiveness, and flexibility. English Fluent/proficient. 2 or more years of experience in quantitative and qualitative analysis using SQL or Python. 2 or more years of working experience in data analytics. Deep understanding of credit product operations (credit cards, loans, asset financing, etc.). Understanding of financial regulations and accounting principles, especially within the fintech industry. Experience with regulatory and compliance reporting in a financial services context. What we offer Make a positive impact on the lives of our customers via financial inclusion Professional development opportunities International exposure & work experience Company swag Legally required benefits",https://mx.linkedin.com/jobs/view/data-analytics-engineer-sr-at-stori-4016872618,4016872618,"As a Data Analytics Engineer Sr, you will leverage your analytical and technical expertise to support accounting and regulatory reporting functions. Your role is critical for ensuring data accuracy, compliance, and generating reports. You will work on Innovation, Business Intelligence, and Data Management, developing solutions for accounting processes and collaborating with teams to provide consultancy and design tools for data visualization.","SQL, Python, Data Management, Data Visualization, Business Intelligence, Open Source Technologies",2+,Bachelor,True,2.0,0,0,0,0,0,1,1,0,0,1,0,0,0,0,1,0,0
Data Engineer,Hays,Mexico City Metropolitan Area,HYBRID,Entry level,Full-time,Staffing and Recruiting,2024-08-16 11:41:09.361695,25,Information Technology,,,"Tu nueva compañía Empresa multinacional con presencia en EU y LATAM Tu nuevo cargo Data Engineer Que necesitas para ser exitoso 5 años de experiencia en analisis de datos Data warehouse (Diseño y llenado) Manejo de (Hadoop, Hive, Kafka, Presto, Apache, Spark, Splunk) Conocimiento de la nube GCP SQL y Python Inglés: Intermedio Que recibirás a cambio Sueldo competitivo Prestaciones superiores a las de la ley Esquema de trabajo: Remoto Que necesitas hacer ahora Si estás interesado en este cargo, haz click en ""aplicar ahora"" para reenviar una copia actualizada de tu CV, o llámanos ahora. Si este cargo no se ajusta mucho a tu perfil, pero estás en búsqueda de un cambio laboral, ponte en contacto con nosotros para que tengamos una conversación confidencial sobre tu carrera. #1036308 - Maria De La Rosa",https://mx.linkedin.com/jobs/view/data-engineer-at-hays-3987363592,3987363592,"Your new position is as a Data Engineer, requiring 5 years of experience in data analysis, data warehouse design and filling, knowledge of cloud GCP, and proficiency in SQL and Python.","Hadoop, Hive, Kafka, Presto, Apache Spark, Splunk, SQL, Python, GCP",5,,True,5.0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0
Data Engineer,Match Consulting,Mexico City Metropolitan Area,HYBRID,,Full-time,"Technology, Information and Internet",2024-09-08 11:41:09.361695,25,Information Technology,,,"Inversora de bienes raíces altamente reconocida dentro de su ramo se encuentra en búsqueda de un Data Engineer especializado en IA. Licenciatura en: Ciencias de la Computación, Ingeniería de Software, o un campo relacionado. Se requieren mínimo 3 años de experiencia en ingeniería de datos y manejo de grandes volúmenes de datos, para ser responsable de diseñar, construir y mantener la infraestructura de datos necesaria para soportar las soluciones de IA y análisis de datos de la empresa. Trabajará en la creación de pipelines de datos eficientes y escalables, asegurando la disponibilidad y calidad de los datos. Principales Responsabilidades: Diseño de Arquitectura de Datos: Crear arquitecturas de datos escalables y eficientes que soporten grandes volúmenes de datos y diferentes tipos de procesamiento. Creación de Pipelines ETL/ELT: Diseñar y desarrollar pipelines de Extract, Transform, Load (ETL) o Extract, Load, Transform (ELT) que integren, transformen y carguen datos desde diferentes fuentes hacia sistemas de almacenamiento. Automatización de Procesos: Automatizar los procesos de ingestión y transformación de datos para asegurar que los pipelines sean eficientes y minimicen el trabajo manual. Validación y Limpieza de Datos: Implementar mecanismos para validar y limpiar datos, asegurando que sean precisos, completos y consistentes antes de su uso en análisis y modelos de IA. Monitoreo y Mantenimiento: Configurar sistemas para monitorear la calidad de los datos y mantener los procesos de datos, corrigiendo problemas de calidad o fallos en los pipelines. Optimización de Consultas y Almacenamiento: Mejorar el rendimiento de consultas y el almacenamiento de datos para asegurar tiempos de respuesta rápidos y el uso eficiente de los recursos. Escalabilidad: Asegurar que la infraestructura de datos pueda escalar para manejar el crecimiento en el volumen de datos y la demanda de procesamiento. Implementación de Seguridad de Datos: Aplicar medidas de seguridad para proteger los datos sensibles, incluyendo cifrado, control de acceso y auditoría. Cumplimiento Normativo: Asegurarse de que el manejo de datos cumpla con las regulaciones y normativas pertinentes, como GDPR, HIPAA, etc. Trabajo con Científicos de Datos: Colaborar con científicos de datos para entender sus necesidades y asegurar que la infraestructura de datos soporte efectivamente sus modelos y análisis. Interacción con Equipos de Desarrollo: Coordinar con equipos de desarrollo de software para integrar soluciones de datos en aplicaciones y sistemas existentes. Documentación: Mantener una documentación clara y detallada de la arquitectura de datos, los pipelines y los procesos para facilitar la gestión y la colaboración. Evaluación y Mejora: Evaluar el rendimiento y la eficacia de la infraestructura de datos y los pipelines, proponiendo y realizando mejoras continuas. Uso de Herramientas y Tecnologías: Implementar y utilizar herramientas y tecnologías como Apache Hadoop, Apache Spark, Kafka, bases de datos SQL y NoSQL, y plataformas en la nube (AWS, Azure, Google Cloud) según las necesidades de la empresa. Requisitos: Educación: Título en Ciencias de la Computación, Ingeniería de Software, o un campo relacionado. Experiencia: Mínimo 3 años de experiencia en ingeniería de datos y manejo de grandes volúmenes de datos. Conocimientos Técnicos en: Experiencia con herramientas de procesamiento de datos como Hadoop, Spark. Conocimiento de bases de datos SQL y NoSQL. Habilidad para trabajar con APIs y ETL. Habilidades Blandas: Excelentes habilidades de comunicación y colaboración. Habilidad para trabajar en entornos ágiles y manejar múltiples proyectos simultáneamente. Idiomas nivel avanzado de Inglés y español tanto escrito como hablado. Lomas de Chapultepec, CDMX Horario de Lunes a viernes de 09:00 am a 06:00 pm Salario competitivo más prestaciones adicionales",https://mx.linkedin.com/jobs/view/data-engineer-at-match-consulting-4015547029,4015547029,"A highly recognized real estate investment firm is looking for a Data Engineer specialized in AI. The role involves designing, building, and maintaining the data infrastructure necessary to support AI solutions and data analytics. Responsibilities include creating scalable data architectures, designing and developing ETL/ELT pipelines, automating data ingestion and transformation processes, ensuring data quality and consistency, monitoring data quality, optimizing queries, implementing data security measures, and complying with relevant regulations.","Python, Apache Hadoop, Apache Spark, Kafka, SQL, NoSQL, AWS, Azure, Google Cloud",3,Bachelor,True,3.0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0
SR Data Analytics Engineer,Stori,Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Full-time,"Technology, Information and Internet",2024-04-18 11:41:09.361695,25,Information Technology,,,"About Stori Stori is a fast-growing, venture-backed financial technology company, on a mission to democratize credit access for 400 million underbanked LatAm consumers. Stori currently operates in Mexico and has a global team with offices in Arlington Virginia, Mexico City, and Asia. We have quickly made our mark as one of the top digital banks in Mexico with more than two million applicants for our credit card product since launching. Stori is one of the top-funded startups in the region with US$250 million raised to date. We are backed by top global venture capital funds, such as GGV Capital, GIC, Lightspeed Venture Partners, General Catalyst, Goodwater Capital, Mexico's Tresalia Capital, Vision Plus Capital, BAI Capital and Source Code Capital; who have successfully invested in startups such as Affirm, Airbnb, Alibaba, Stripe, and TikTok. Stori has a standout founder team among fintechs, leveraging 100+ years of accumulated experience in consumer finance, banking and technology across Mastercard, Intel, Capital One, Morgan Stanley, GE Capital, and HSBC in the U.S., Mexico and Asia. The team has launched and managed many multi-million-customer credit card products globally, providing a wide breadth of experience and knowledge to our team. We welcome diversity of background, experience and thinking. Storians are passionate about our mission and take pride in the products we build. Our culture thrives off of a flat structure and an inclusive environment where all of our employees can be their authentic selves, with boundless opportunities for professional growth. The Role Stori's Analytics Engineering team's primary objective is to build easy-to-use, trustworthy, and reliable data products to serve the analytical needs across different product and business functions. Analytics Engineer Jr in Stori solve problems that get in the way of doing analysis. In this role, you are essential to our data strategy in reducing burdens associated with our data models and analytical tools and platforms. You will help business partners to diagnose what is getting in the way of efficient analytics today. Identifying and addressing the root causes will allow Stori to make quick, data informed decisions by removing bottlenecks and automating each stage of the data ops lifecycle. One day, this might mean modeling our core data in a better way. The next day, it might mean onboarding a new analytics tool. It can also mean working with source data teams to map out the right data structure to get to a single source of truth on vital business constructs. Our data analysts are critical to our analytics success because they enable our data analysts and data scientists to answer business questions using our data. Your impact Design and develop the batch data transformation pipelines to merge and transform large raw datasets to analytical datasets that users can quickly derive the insights from. Work with product managers and operation teams to understand the business pipeline, review new products and identify related data sources to provide prescriptive analysis. Perform the data validation on complex business logic, and reconciliation across different data sources. Identify, understand, analyze, and interpret trends or patterns in complex data sets. Perform data quality monitoring to maintain and assure data integrity. Develop the data dictionary and training to educate the business partners on how to best use and interpret the data. Solve data issues and perform root cause analysis to proactively resolve product and operational issues. What we are looking for A bachelor degree or foreign equivalent in Computer Science, Electronic Engineer, Mathematics, Information System, or Statistics. A professional with at least 2 years of experience with Data Analytics. Preferably 2+ years of Python development experience. Preferably 2+ years of SQL knowledge (including the experience of writing queries) and experience with relational databases. Experience with modern reporting and data visualization tools (QuickSight, Tableau, Looker, etc.) Strong analytical skills with the ability to collect, organize and analyze significant amounts of information with attention to detail and accuracy. Technical expertise in data models, database utilization, data mining, and segmentation techniques. Good presentation and communication skills, ability to explain complex technical problems in simple words. What we offer Make a positive impact on the lives of our customers via financial inclusion Professional development opportunities International exposure & work experience Company swag Legally required benefits",https://mx.linkedin.com/jobs/view/sr-data-analytics-engineer-at-stori-3887596953,3887596953,"The primary objective of Stori's Analytics Engineering team is to build easy-to-use, trustworthy, and reliable data products to serve the analytical needs across different product and business functions. As a Junior Analytics Engineer, you will help reduce burdens associated with data models and analytical tools, diagnose barriers to efficient analytics, and automate stages of the data ops lifecycle. Your tasks will include designing and developing data transformation pipelines, performing data validation and quality monitoring, analyzing complex data sets to identify trends, and educating business partners on data interpretation.","Python, SQL, QuickSight, Tableau, Looker, Data Models, Data Mining, Statistical Analysis",2+,Bachelor,True,2.0,0,0,0,0,0,1,0,0,1,1,0,0,0,0,1,0,0
Principal Data Analytics Engineer,Stori,Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Full-time,"Technology, Information and Internet",2024-08-16 11:41:09.361695,25,Information Technology,,,"About Stori Stori is a fast-growing, venture-backed financial technology company, on a mission to democratize credit access for 400 million underbanked LatAm consumers. Stori currently operates in Mexico and has a global team with offices in Arlington Virginia, Mexico City, and Asia. We have quickly made our mark as one of the top digital banks in Mexico with more than two million applicants for our credit card product since launching. Stori is one of the top-funded startups in the region with US$250 million raised to date. We are backed by top global venture capital funds, such as GGV Capital, GIC, Lightspeed Venture Partners, General Catalyst, Goodwater Capital, Mexico's Tresalia Capital, Vision Plus Capital, BAI Capital and Source Code Capital; who have successfully invested in startups such as Affirm, Airbnb, Alibaba, Stripe, and TikTok. Stori has a standout founder team among fintechs, leveraging 100+ years of accumulated experience in consumer finance, banking and technology across Mastercard, Intel, Capital One, Morgan Stanley, GE Capital, and HSBC in the U.S., Mexico and Asia. The team has launched and managed many multi-million-customer credit card products globally, providing a wide breadth of experience and knowledge to our team. We welcome diversity of background, experience and thinking. Storians are passionate about our mission and take pride in the products we build. Our culture thrives off of a flat structure and an inclusive environment where all of our employees can be their authentic selves, with boundless opportunities for professional growth. The Role: As a Principal Data Analytics Engineer at Stori you will leverage your analytics and engineering skills along with cutting edge big data technology to innovate, design, build, and maintain well-managed data products to solve complex business problems. This role will be responsible for leading the development of high quality, monitored and documented data products that will enable advanced analytics used for the decision making of several business analysts and business leaders. Main responsibilities: Be responsible for designing, developing and maintaining data products used to unlock analytics capabilities to the business. Interact with business analysts and other stakeholders to gather new data product requirements, break them down into concrete deliverables, estimate development effort and prioritize among other initiatives based on their impact. Track the progress of planned initiatives, identifying, solving and communicating risks and blockers that could impact on the delivery due dates. Identify, estimate and prioritize technical initiatives that help to improve the maintainability, stability and quality of the data products. Develop critical features and implement engineering best practices throughout the lifecycle of data products to improve the quality of the deliverables. Interact with other technical teams like Data Infrastructure, Data Governance, DevOps, Security to adhere their solution and policies to the data products as well as suggest improvements. Lead, hire and retain new talent in the team What we are looking for: Bachelor degree in Computer Science, Software Engineering or equivalent work experience 5+ years of experience working as a Data Analytics Engineer or Data Engineer building highly scalable data products Proven experience using SQL and Python Experience with data processing technologies (i.e.: DBT, Spark, Pandas), orchestration solutions (ie: Airflow, Prefect) and reporting tools (i.e. Quicksight, Looker) Experience working with Cloud Providers, ideally AWS. Experience leading small teams (1 to 3 people) of Data Engineers and/or Data Analytics Engineers Strong planning and organizational skills Advanced written and spoken communication skills in English Past experience in the financial sector is desirable but not required What we offer Make a positive impact on the lives of our customers via financial inclusion Professional development opportunities International exposure & work experience Company swag Legally required benefits",https://mx.linkedin.com/jobs/view/principal-data-analytics-engineer-at-stori-3980586697,3980586697,"As a Principal Data Analytics Engineer, you will leverage your analytics and engineering skills along with cutting-edge big data technology to innovate, design, build, and maintain data products that solve complex business problems. You will be responsible for leading the development of high-quality data products that enable advanced analytics for business decision-making and will interact with business analysts and stakeholders to gather requirements and prioritize initiatives.","SQL, Python, DBT, Spark, Pandas, Airflow, Prefect, Quicksight, Looker, AWS",5+ years,Bachelor,True,5.0,0,0,1,1,0,0,0,0,1,1,0,0,0,0,1,0,0
Data Engineer,NEORIS,Mexico City Metropolitan Area,HYBRID,Entry level,Full-time,IT Services and IT Consulting,2024-09-13 11:41:09.361695,200,Information Technology,,,"En NEORIS es un acelerador Digital que ayuda a las compañías a entrar en el futuro, teniendo 20 años de experiencia como Socios Digitales de algunas de las mayores compañías del mundo. Somos más de 4,000 profesionales en 11 países, con nuestra cultura multicultural de startup en donde cultivamos innovación, aprendizaje continuo para crear soluciones de alto valor para nuestros clientes. Estamos en búsqueda de Data Engineer , Requerimientos Licenciatura en Ciencias de la Computación, tecnologías de la Información o campo relacionado. Experiencia comprobada trabajando con tecnologías de la Plataforma Azure Fuerte en SQL y gestión de bases de datos. Experiencia sólida en Informática Power Center para integración de datos y procesos ETL. Comprensión sólida de los conceptos de almacenamiento de datos y modelado dimensional. Excelentes habilidades para resolver problemas y atención al detalle. Capacidad para trabajar de forma independiente y colaborativa en un entorno de ritmo rápido. Fuertes habilidades de comunicación e interpersonales. Inglés: Intermedio (B1/B2) Ofrecemos Esquema 100% Nominal Prestaciones de Ley Paquete de Beneficios Programa Bienestar Plan de desarrollo profesional Colaboración multicultural Te invitamos a conocernos en http://www.neoris.com , Facebook, LinkedIn, Twitter o Instagram: @NEORIS. Maria Guadalupe Moreno Flores",https://mx.linkedin.com/jobs/view/data-engineer-at-neoris-3973523117,3973523117,"NEORIS is seeking a Data Engineer. Requirements include a degree in Computer Science, Information Technology, or a related field. Proven experience working with Azure platform technologies, strong SQL skills, and database management. Solid experience in Informatica PowerCenter for data integration and ETL processes. Strong understanding of data warehousing concepts and dimensional modeling. Excellent problem-solving skills and attention to detail. Ability to work independently and collaboratively in a fast-paced environment. Strong communication and interpersonal skills. Intermediate English proficiency (B1/B2).","Azure, SQL, Informatica PowerCenter, ETL, Data Warehousing, Dimensional Modeling",,Bachelor,True,,0,0,0,1,0,1,1,0,0,1,0,0,0,0,0,0,0
Intermediate Data Engineer,AgileThought,Mexico City Metropolitan Area,HYBRID,Associate,Full-time,IT Services and IT Consulting,2024-09-12 11:41:09.361695,25,Information Technology,,,"En AgileThought retamos el status quo y construimos soluciones digitales transformadoras para resolver los problemas de nuestros clientes. Trabajamos con la más alta vanguardia de tecnología, conocemos las necesidades empresariales de nuestros cliente y con base en ello contratamos a los mejores consultores para brindar soluciones. Esta oportunidad es para ti si... Te encanta resolver problemas comerciales complejos y trabajar con clientes que valoran tu experiencia técnica. No tienes miedo de fallar y prosperas en un entorno de constante evolución. Disfrutas trabajando en un equipo diverso y multidisciplinario que apunta hacia objetivos y resultados comunes. En el día a día como consultor de AgileThought... Trabajan en equipo y bajo la dirección de consultores más veteranos, colaborando estrechamente con sus colegas, orientando a los miembros más jóvenes del equipo y manteniendo una comunicación eficaz con las partes interesadas del proyecto. Este puesto requiere experiencia en gestión de datos, seguridad de datos, modelado de datos y desarrollo de canalizaciones. En AgileThought la persona ideal... Experiencia con procesos de integración de datos y ETL (extraer, transformar, cargar). Sólidos conocimientos de SQL y sistemas de gestión de bases de datos (DBMS) como Oracle, MySQL y SQL Server, BigQuery, BigTable, Teradata. Dominio del lenguaje de programación Python. Experiencia con tecnología en la nube GCP. Experiencia en BigQuery, DataFusion, DataProc o AirFlow. Experiencia en metodologías ágiles - Scrum Modalidad híbrida: Se asisten 3 veces a la semana en área Polanco, Ciudad de México. Lo que ofrecemos... Equipos globales que te motivan a ser mejor Increíbles beneficios que mejoran tu estilo de vida Flexibilidad y balance Atractivas oficinas en diversas ubicaciones para uso opcional y colaboración entre equipos. ¡Únete al equipo! ¡Queremos trabajar con gente inteligente, creativa e interesante! ¿No ves una posición en la que encajes perfectamente? ¡Mantente atento a nuestra página de vacantes, donde a medida que crecemos agregamos nuevas oportunidades! ¡Queremos conocerte! La letra pequeña... Si tienes alguna solicitud o comentario durante el proceso de entrevista, comunícate con nosotros para apoyarte. AgileThought es una empresa que ofrece igualdad de oportunidades y está comprometido con la diversidad y la inclusión en el lugar de trabajo. Todos los solicitantes calificados recibirán consideración para el empleo sin distinción de raza, color, religión, genero, nacionalidad, condición de discapacidad, o cualquier otra característica protegida por la ley federal, estatal o local. ¡Reimaginemos juntos el futuro de la tecnología!",https://mx.linkedin.com/jobs/view/intermediate-data-engineer-at-agilethought-4022234441,4022234441,"At AgileThought, we challenge the status quo and build transformative digital solutions to solve our clients' problems. This role involves working in a diverse and multidisciplinary team to solve complex business problems. The position requires experience in data management, data security, data modeling, and pipeline development. The ideal candidate has experience with data integration and ETL processes, strong knowledge of SQL and database management systems (DBMS) like Oracle, MySQL, SQL Server, BigQuery, BigTable, and Teradata. Proficiency in Python and experience with cloud technology GCP, BigQuery, DataFusion, DataProc, or AirFlow, as well as agile methodologies like Scrum, is essential.","Python, SQL, ETL, Oracle, MySQL, SQL Server, BigQuery, BigTable, Teradata, GCP, DataFusion, DataProc, AirFlow, Agile Methodologies",,,True,,1,0,1,1,0,0,1,0,0,1,0,0,0,0,1,0,0
Data Engineer,GlobalLogic,Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Full-time,Software Development,2024-09-01 11:41:09.361695,42,Information Technology,,,"GlobalLogic family Expand your skills by collaborating with a diverse team of highly talented people in an open, laidback environment and ¡Be part of the forefront of digital transformation! We offer an opportunity to participate in creating market-defining products using the latest technologies with clients across all industries and sectors. GlobalLogic prioritizes work-life balance, which is why we offer flexible opportunities and options. About the role The Data Engineer is expected to demonstrate increased proficiency in newly acquired industry-related skills. It will perform routine data assignments that require skilled background experience and knowledge of established programming procedures. This person works according to clear-cut and complete specifications. Responsibilities Issue Handling: Receive and manage dashboard-related requests through a help desk system. Troubleshooting: Investigate and resolve minor data discrepancies or functionality issues. Identify root causes and escalate issues to the appropriate teams (e.g., upstream data issues) End-user Enablement: Educate and empower Sales users to resolve issues independently whenever possible. Provide clear guidance and explanations to ensure correct dashboard interpretation. Issue Logging and Escalation: Maintain a detailed log of reported issues and have a review cadence to update Stakeholders (including communications to Field) on the current status and resolutions. Initiate escalation to full-time employee teams for complex or recurring problems, following established protocols. For new types of issues raised by Sales without a solution, escalate with full-time employees and the Program Management team so that a new process can be developed by them Qualifications 6-8 years of experience working as a Data Engineer/ETL. Strong written, oral communication and interpersonal skills. Hands on experience of troubleshooting the data issues and data management tasks and proven analytics experience. Strong hands-on experiences in writing SQL queries to view, analyze the data and the compute metrics. Strong hands-on experiences in writing Python Scripting Experience with Google Cloud and BI tools & technologies; BigQuery, BigData, CloudSQL, DataStudio/Looker, Colab etc. Organize existing documents, identify documentation holes, and spearhead efforts. Write, publish, and maintain high-quality proactive education and help content, such as FAQs, articles, product and project-related communications. About GlobalLogic: GlobalLogic is a Hitachi Group Company, leader in digital engineering. Based across 16 countries. We help brands across the globe design and build innovative products, platforms, and digital experiences for the modern world. By integrating experience design, complex engineering, and data expertise—we help our clients imagine what’s possible and accelerate their transition into tomorrow’s digital businesses. Headquartered in Silicon Valley, GlobalLogic operates design studios and engineering centers around the world, extending our deep expertise to customers in the automotive, communications, financial services, healthcare and life sciences, manufacturing, media and entertainment, semiconductor, and technology industries. Our Benefits 100% Nominal Major medical insurance & life insurance 30 days of Christmas bonus Saving fund 13% Food vouchers Restaurant vouchers & more…",https://mx.linkedin.com/jobs/view/data-engineer-at-globallogic-4010219153,4010219153,"The Data Engineer is expected to demonstrate increased proficiency in industry-related skills and will perform routine data assignments that require skilled background experience. Responsibilities include handling dashboard-related requests, troubleshooting data discrepancies, educating end users, maintaining issue logs, and initiating escalations for complex problems.","SQL, Python, Google Cloud, BigQuery, BigData, CloudSQL, DataStudio, Looker, Colab",6-8 years,,True,6.0,0,0,1,1,0,0,0,0,1,1,0,0,0,0,1,0,0
Data Analytics Engineer Senior,Stori,Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Full-time,"Technology, Information and Internet",2024-05-18 11:41:09.361695,25,Information Technology,,,"About Stori Stori is a fast-growing, venture-backed financial technology company, on a mission to democratize credit access for 400 million underbanked LatAm consumers. Stori currently operates in Mexico and has a global team with offices in Arlington Virginia, Mexico City, and Asia. We have quickly made our mark as one of the top digital banks in Mexico with more than two million applicants for our credit card product since launching. Stori is one of the top-funded startups in the region with US$250 million raised to date. We are backed by top global venture capital funds, such as GGV Capital, GIC, Lightspeed Venture Partners, General Catalyst, Goodwater Capital, Mexico's Tresalia Capital, Vision Plus Capital, BAI Capital and Source Code Capital; who have successfully invested in startups such as Affirm, Airbnb, Alibaba, Stripe, and TikTok. Stori has a standout founder team among fintechs, leveraging 100+ years of accumulated experience in consumer finance, banking and technology across Mastercard, Intel, Capital One, Morgan Stanley, GE Capital, and HSBC in the U.S., Mexico and Asia. The team has launched and managed many multi-million-customer credit card products globally, providing a wide breadth of experience and knowledge to our team. We welcome diversity of background, experience and thinking. Storians are passionate about our mission and take pride in the products we build. Our culture thrives off of a flat structure and an inclusive environment where all of our employees can be their authentic selves, with boundless opportunities for professional growth. The Role As a Sr Analytics Engineer at Stori you will leverage analytic and technical skills to innovate, build, and maintain well-managed data solutions and capabilities to tackle business problems. On any given day you will be challenged on three types of work – Innovation, Business Intelligence, and Data Management: Innovation Use Open Source/Digital technologies to mine complex, voluminous, and different varieties of data sources and platforms. Build well-managed data solutions, tools, and capabilities to enable self-service frameworks for data consumers. Demonstrate ability to explore and quickly grasp new technologies to progress varied initiatives. Business Intelligence Partner with the business to provide consultancy and translate the business needs to design and develop tools, techniques, metrics, and dashboards for insights and data visualization. Drive analysis that provides meaningful insights on business strategies. Data Management Drive an understanding and adherence to the principles of data quality management including metadata, lineage, and business definitions. Work with business teams to understand the business needs and translate them into technical requirements. Work collaboratively with appropriate Tech teams to manage security mechanisms and data access governance. Build and execute tools to monitor and report on data quality. Requirements A bachelor's degree or foreign equivalent in Engineering, Science, Operations Research, Information Technology, Statistics, Mathematics, Economics, Finance, Analytics, or a related quantitative analytical field. SQL and Python. Proven interpersonal, collaboration, diplomatic, influencing, planning, and organizational skills. Consistently demonstrate clear and concise written and verbal communication. Proven ability to effectively use complex analytical, interpretive, and problem-solving techniques Demonstrated ability to work under pressure and to meet tight deadlines with proactive, decisiveness, and flexibility. English Fluent/proficient. 2 or more years of experience in quantitative and qualitative analysis using SQL or Python. 2 or more years of working experience in data analytics or data management 2 or more years of experience in the finance industry What we offer Make a positive impact on the lives of our customers via financial inclusion Professional development opportunities International exposure & work experience Company swag Legally required benefits",https://mx.linkedin.com/jobs/view/data-analytics-engineer-senior-at-stori-3925327164,3925327164,"As a Senior Analytics Engineer, you will leverage analytic and technical skills to innovate, build, and maintain well-managed data solutions to tackle business problems. Your responsibilities will include using open source technologies to mine complex data sources, partnering with the business to provide consultancy and develop insights, and ensuring data quality management. This role requires a bachelor's degree in a quantitative analytical field and proficiency in SQL and Python.","SQL, Python, Data Visualization, Data Management, Business Intelligence",2,Bachelor,True,2.0,0,0,0,0,0,1,1,0,0,1,0,0,0,0,1,0,0
Sr Data Engineer Hybrid,Stori,Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Full-time,"Technology, Information and Internet",2024-03-19 11:41:09.361695,25,Information Technology,,,"About Stori Stori is a fast-growing, venture-backed financial technology company, on a mission to democratize credit access for 400 million underbanked LatAm consumers. Stori currently operates in Mexico and has a global team with offices in Arlington Virginia, Mexico City, and Asia. We have quickly made our mark as one of the top digital banks in Mexico with more than two million applicants for our credit card product since launching. Stori is one of the top-funded startups in the region with US$250 million raised to date. We are backed by top global venture capital funds, such as GGV Capital, GIC, Lightspeed Venture Partners, General Catalyst, Goodwater Capital, Mexico's Tresalia Capital, Vision Plus Capital, BAI Capital and Source Code Capital; who have successfully invested in startups such as Affirm, Airbnb, Alibaba, Stripe, and TikTok. Stori has a standout founder team among fintechs, leveraging 100+ years of accumulated experience in consumer finance, banking and technology across Mastercard, Intel, Capital One, Morgan Stanley, GE Capital, and HSBC in the U.S., Mexico and Asia. The team has launched and managed many multi-million-customer credit card products globally, providing a wide breadth of experience and knowledge to our team. We welcome diversity of background, experience and thinking. Storians are passionate about our mission and take pride in the products we build. Our culture thrives off of a flat structure and an inclusive environment where all of our employees can be their authentic selves, with boundless opportunities for professional growth. Main responsibilities: Act as a ""tech lead"" for internal analytical data products - work with business team and engineering leadership to prioritize development roadmaps and plan future projects, prioritize and plan the team's work, communicate with stakeholders on progress, and unblock team members. As an IC and team lead, build and maintain data pipelines using Redshift, Redshift, Dynamo, Athena, Glue, EMR, Kinesis, SQS, FIrehose, Redis, CDK, Step Functions, etc. These pipelines will process terabytes of information in batch and real-time, and will: Be re-used by various upstream data producers to land their data to company analytical database or customer data center Used in various of downstream business dashboards and machine learning models for batch or real-time customer decisioning and experience improving Calculate real-time business-critical metrics that are used by executives and engineers to make prioritization decisions Identify opportunities to simplify workflows, automate tasks, and build components that are reusable across multiple use-cases and teams. Buildoutateamofdataengineersasbusinessneedsgrow. What we are looking for: Athena, Glue, EMR, Kinesis, SQS, FIrehose, Redis, CDK, Step Functions Experience: 8+ years experience in Data Engineering or back-end Software Engineering 5+ years experience in building and managing high performance engineer team with Agile framework 5+ years experience in building batch and real-time data pipelines that extract, transform, and load the data into analytical data warehouses or data lake Creative, resourceful, and enthusiastic about seeking new solutions to problems and opportunities Skills and attitudes Expert in SQL, git, and a programming language (ie Python, Java, etc) Strong proficiency in Python Familiarity with technologies like AWS Serverless, S3, Lambda, Redshift, Dynamo, Experience with CI/CD (Continuous Integration, Continuous Delivery), Automated Testing, Automated Delivery Business-proficiency in English customer feature data pipelines/microservices Bonus Points: Experience in building customer data center or large scale real-time/batch Experience in developing real-time data pipeline for fintech companies Experience with DBT and airflow What we offer Make a positive impact on the lives of our customers via financial inclusion Professional development opportunities International exposure & work experience Company swag Legally required benefits",https://mx.linkedin.com/jobs/view/sr-data-engineer-hybrid-at-stori-3841326572,3841326572,"The main responsibilities include acting as a tech lead for internal analytical data products, building and maintaining data pipelines using various AWS services, and identifying opportunities to optimize workflows. The position requires extensive experience in data engineering and managing high-performance teams.","AWS Redshift, DynamoDB, AWS Athena, AWS Glue, AWS EMR, AWS Kinesis, AWS SQS, AWS Firehose, Redis, CDK, Step Functions, SQL, Python, Java, Git, CI/CD, Automated Testing, DBT, Airflow",8+,,True,8.0,0,0,1,1,0,0,0,0,0,1,0,1,0,0,1,0,0
Data Engineer (ETL Developer),Azkait,Mexico City Metropolitan Area,HYBRID,,Full-time,"Technology, Information and Internet",2024-06-17 11:41:09.361695,25,Information Technology,,,"AZKA IT is a Mexican company that seeks and connects the best IT talent with Latin American and United States companies. We are looking for your talent as Data Engineer (ETL Developer) Requirements: Design and implement processes to extract data from various sources such as databases, files, APIs, using SSIS and Azure platform. Develop data transformation logic to clean, standardize, and enrich raw data to meet data model requirements. Create workflows to load transformed data into target systems. Automate ETL processes and organize data workflows. Monitor ETL workflows and data pipelines for data performance, reliability, and consistency. Document ETL designs, data mappings, and technical specifications. Ensure data security and compliance. Benefits: ﻿IMSS, Infonavit and PTU of the law. 100% of payroll 30-day Christmas bonus SGMM for the resource and his direct family Life Insurance for 1 million pesos (individual) Dental insurance (individual) Free courses and certifications Food vouchers Discount cards in department stores and medical networks. Work Monday through Friday. Contract 3 months trial at the beginning, then indeterminate.",https://mx.linkedin.com/jobs/view/data-engineer-etl-developer-at-azkait-3933524748,3933524748,"We are looking for a Data Engineer (ETL Developer) to design and implement processes to extract data from various sources such as databases, files, and APIs, using SSIS and the Azure platform. The role involves developing data transformation logic to clean and standardize raw data, creating workflows to load transformed data into target systems, and automating ETL processes. You will also monitor ETL workflows for performance and reliability, document designs and data mappings, and ensure data security and compliance.","SSIS, Azure, SQL, APIs, ETL, Data Transformation, Data Workflows",,,False,,0,0,0,1,0,0,1,0,0,1,0,0,0,0,0,0,0
Data Engineer,Babel,Mexico City Metropolitan Area,HYBRID,Entry level,Full-time,IT Services and IT Consulting,2024-08-25 11:41:09.361695,25,Information Technology,Consulting,,"We are One Team. We make it happen. We are Unstoppable. BABEL es una consultora tecnológica multinacional especializada en aplicar sus servicios y conocimiento tecnológico en los procesos de aceleración digital de sus clientes, grandes empresas y organismos públicos. ¿Cuál es nuestro plan estratégico? En Babel estamos entusiasmados con los progresos de nuestro Plan Marte 2025 . Queremos llegar a 300 millones de euros de facturación y conseguir un EBITDA de 36 millones con una plantilla de 5.000 babelievers en el mundo! El buen hacer y el compromiso del equipo esta dando sus frutos y nos encontramos en buena ruta para alcanzar estas metas, lo cual refleja la solidez y visión de nuestra organización. Mirando hacia el futuro, ya hemos diseñado el nuevo plan estratégico Hyperspace 2029 , un desafío aún mayor, que promete ser un viaje emocionante, lleno de oportunidades para crecer y desarrollarse profesionalmente. Alcanzar 1000 millones de facturación, un reto que estamos seguros de que con la colaboración y el talento de nuestra gente, será otra historia de éxito que escribiremos juntos. ¿Qué buscamos? Al menos 4 años de experiencia en las siguientes herramientas: Lenguajes de programación: JAVA /JavaScript / Python Manejador de Base de Datos: Oracle con conocimientos en desarrollo PL-SQL y fine tunning de Bases de Datos ETL: Python IDE de desarrollo: Eclipse, intelij, Gitlab Conocimientos Deseables: ETL: SSIS, ODI, SPARK, Informática, KAFKA Bases de Datos: SQL Server, DB2, Casandra, etc. Consideraciones de la posición: Asistencia a oficina: Dependiendo la necesidad de interacción con el resto del equipo. Máximo 3 veces a la semana Trabajo en fin de semana: Probablemente el primer mes en el proceso de estabilización del proceso en desarrollo. #babel ¿Qué ofrecemos? Babel, the great way to achieve the success. ¿Quieres formar parte de un equipo en expansión, comprometido e innovador que hace historia cada día? En Babel te acompañamos en tu camino hacia el éxito. Creemos en el talento de las personas y lo queremos potenciar ofreciéndote un gran entorno de trabajo basado en la colaboración y la solidaridad. Trabajar en Babel es mucho más que trabajar en una empresa, es unirse a un equipo de personas con una misión compartida y a un modelo de compañía centrado en valores. Además, Esquema 100% Nomina SGM Mayores, SGM Menores Apoyo de Home Office Beneficios corporativos superiores ¿Aceptas el desafío? ¡Te esperamos! En cumplimiento de la normativa vigente en materia de protección de datos, le informamos que el responsable de sus datos personales es GRUPO BABEL y los utilizará para la realización de procesos internos de selección de personal, basado en su consentimiento, mediante la facilitación de sus datos curriculares y en la aplicación de medidas precontractuales. Los datos podrán ser comunicados a las entidades que conforman el GRUPO BABEL con el fin ofrecerle el puesto de trabajo que se adapte a su perfil profesional y las establecidas legalmente. Puede acceder, rectificar y suprimir los datos, así como otros derechos que le asisten sobre protección de datos a través de data.protection@babelgroup.com. Podrá obtener información adicional, sobre protección de datos, dirigiéndose a nuestra política de privacidad.",https://mx.linkedin.com/jobs/view/data-engineer-at-babel-4006448635,4006448635,"BABEL is a multinational technology consulting firm specializing in applying its technological services and knowledge to the digital acceleration processes of its clients, including large companies and public bodies. They are looking for candidates with at least 4 years of experience in programming languages such as JAVA, JavaScript, and Python, as well as experience with Oracle databases, PL-SQL development, and database fine-tuning. Experience with ETL processes using Python and desirable knowledge of SSIS, ODI, SPARK, and KAFKA is also beneficial.","JAVA, JavaScript, Python, Oracle, PL-SQL, Eclipse, IntelliJ, Gitlab, SQL Server, DB2, Cassandra, SSIS, ODI, SPARK, KAFKA",4+,,True,4.0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,1,0,0
Data Scientist,Cinepolis Corporativo,Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,Entertainment Providers,2024-09-08 11:47:09.018617,200,Engineering,"Science,",Information Technology,"Conócenos Somos una empresa global, orgullosamente mexicana, con más de 51 años en la industria del entretenimiento. Contamos con más de 800 cines y más de 6,677 salas en 19 países: México, Argentina, Bahréin, Brasil, Chile, Colombia, Costa Rica, El Salvador, España, Estados Unidos, Guatemala, Honduras, India, Indonesia, Omán, Panamá, Perú, Arabia Saudita y Emiratos Árabes Unidos. Somos más de 32,244 Cinepolitos a nivel global; y gracias a la experiencia de nuestros Cinepolitos hemos logrado ser el 3er lugar mundial en número de salas, 2º lugar mundial en número de boletos vendidos y 1er lugar mundial en ocupación promedio por sala. Para seguir creciendo y creando momentos inolvidables, buscamos personas como tú, que quieran escribir su historia con nosotros e iluminar la película de sus vidas con grandes sonrisas y momentos inolvidables. Data Scientist Lugar de Trabajo: CDMX/Morelia Modalidad presencial Tu próximo rol Como Data Scientist, serás responsable de analizar, diseñar, e implementar iniciativas del equipo de Data Science, tales como la evaluación del impacto de promociones personalizadas, evaluación de cambios de precios, desarrollo de algoritmos para incentivar una mayor asistencia al cine, y modelos de recomendaciones de productos. Esto a través de lenguajes computacionales (Python/Pyspark/R) aplicados al manejo de datos, aprendizaje de máquinas, inferencia estadística y métodos econométricos. ¡Imagínate haciendo esto! Desarrollar, mantener y mejorar pipelines de Machine Learning necesarios para la operación del negocio (p.ej. para la programación de películas o generación de predicciones de demanda) Manejar y analizar grandes bases de datos, a través de lenguajes de programación como Python, R y SQL, usando frameworks como Pyspark, para atender las solicitudes de análisis e información de diversas áreas. Colaborar con el equipo de Data Engineering y con otras áreas internas, tales como Mercadotecnia y Comercialización, para validación y limpieza de datos necesarios para el desarrollo de modelos cuantitativos. Diseñar y evaluar el efecto de intervenciones, tales como promociones nacionales, cambios de precios o nuevos procesos operativos, a través de técnicas de inferencia causal y RCTs. Comunicar los aprendizajes al interior de la organización, particularmente con C-level, direcciones y ejecutivos clave, a través de presentaciones u otros documentos de alto nivel. ¿Qué necesitas? Licenciatura en Computación, Física, Matemáticas, Economía, Data Science o similar. Experiencia de 2 años en programación orientada a objetos usando Python, Java y R. Deseable dominio de PySpark, diseño de experimentos (A/B/X testing), aprendizaje de máquinas, arquitectura en la nube. Disponibilidad para laborar en modalidad presencial. Inglés intermedio. Tenemos un reto para quienes quieran Trabajar en una empresa global orgullosamente mexicana Desarrollar tus habilidades y poder aprender de los mejore Experimentar lo que es realmente trabajar en un entorno dinámico, divertido y acelerado. Desarrollar y escalar proyectos de alto impacto para la organización Te proponemos Ofrecemos un excelente paquete de compensación y beneficios, además, tendrás la oportunidad de trabajar con un grupo global experimentado de profesionales. Dar el siguiente paso en tu carrera profesional junto a un equipo global, productivo y multi cultural. En Cinépolis tenemos el claro objetivo de impulsar la diversidad y la inclusión en todas las dimensiones: género, LGBTQ+, habilidades, etnia y generaciones. Juntos nos embarcamos en un viaje en el que todos y cada uno de nosotros, individual y colectivamente, acogemos y celebramos las diferencias individuales. Crear experiencias inspiradoras que tocan la vida de las personas, y las historias más importantes son las de nuestros equipos, porque juntos impulsamos nuestro crecimiento de manera responsable y damos forma al futuro cuidando a la comunidad y el medio ambiente. Te ofrecemos Contratación directa Beneficios (Prestaciones de ley, Cortesías mensuales, seguro gastos médicos mayores, segudo de vida, vales de despensa, caja de ahorro) Horario Flexible Capacitación Conoce más sobre cómo es trabajar en Cinépolis, visítanos en: https://www.linkedin.com/company/cinepolisjobs @Cinépolis se enorgullece de ser un empleador que ofrece igualdad de oportunidades de empleo. No discriminamos por motivos de raza, religión, color, origen nacional, sexo (incluido el embarazo, el parto, decisiones de salud reproductiva o condiciones médicas relacionadas), orientación sexual, identidad de género, expresión de género, edad, condición de veterano protegido, condición como individuo con discapacidad, información genética, opiniones o actividad política, u otras características protegidas legalmente aplicables. @Cinépolis no acepta referencias o currículums no solicitados de ninguna fuente que no sea directamente de los candidatos o proveedores preferidos. No consideraremos referencias no solicitadas.",https://mx.linkedin.com/jobs/view/data-scientist-at-cinepolis-corporativo-4014156753,4014156753,"As a Data Scientist, you will be responsible for analyzing, designing, and implementing initiatives for the Data Science team, such as evaluating the impact of personalized promotions, assessing price changes, developing algorithms to increase cinema attendance, and product recommendation models. This will involve using programming languages (Python/Pyspark/R) for data management, machine learning, statistical inference, and econometric methods. You will also develop, maintain, and improve machine learning pipelines necessary for business operations, manage and analyze large datasets, collaborate with the Data Engineering team, design and evaluate causal interventions, and communicate findings to C-level executives.","Python, R, SQL, PySpark, Machine Learning, Statistical Inference, Econometrics, A/B Testing",2,Bachelor,True,2.0,0,0,1,0,0,0,0,0,0,1,0,0,1,0,1,0,0
Junior Data Scientist,NielsenIQ,Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,Market Research,2024-09-14 11:47:09.018617,25,General Business,,,"Overview Company Description As the world's largest research organization, Nielsen is powered by talented creative scientists. Our Data Scientist Business Leaders come from diverse disciplines such as statistics, research methodology, mathematics, psychology, business, engineering, physics and demography. These professionals drive innovation, new product ideation, develops complex analysis and delivery of data insights to measure what consumers buy. Job Description What You’ll Do Support Internal and External Clients with the understanding of Data Science design and methodology Accompanies senior leaders meet with clients to understand business needs and help offer innovative solutions Assists on creating new solutions use cases, proof of concept and prototypes by exploring diverse data sets using tools such as python/r Collaborates with other Data Science team units Automate and develop solutions for existing processes Efficient and effective with basic guidance and coaching Qualifications Experience Professionals with degrees in Math, Data Science, Statistics, Actuarial Science, or related fields involving statistical analysis of large data sets 0-2 years of experience in market research or relevant field Qualifications Soft skills qualifications Passionate about innovation and technology Problem-Solving skills Ability to effectively convey complex concepts to non-experts Intellectual curiosity and persistence to find answers to questions Eager to continuously learn and adapt to changing technologies and tools Good command of written and spoken English Good collaborative and interpersonal skills to communicate at all levels. (Preferred) Entrepreneur mindset (Preferred) Analytical and Technical skills: Basic understanding of Statistics Good aptitude for data analysis Critical/ logical thinking Experienced with programming languages such as Python Familiar with contemporary database systems Familiarity with marketing analytics, including designing experiment and consumer behavior analysis Additional Information Our Benefits Flexible working environment Volunteer time off LinkedIn Learning Employee-Assistance-Program (EAP) About NIQ NIQ is the world’s leading consumer intelligence company, delivering the most complete understanding of consumer buying behavior and revealing new pathways to growth. In 2023, NIQ combined with GfK, bringing together the two industry leaders with unparalleled global reach. With a holistic retail read and the most comprehensive consumer insights—delivered with advanced analytics through state-of-the-art platforms—NIQ delivers the Full View™. NIQ is an Advent International portfolio company with operations in 100+ markets, covering more than 90% of the world’s population. For more information, visit NIQ.com Want to keep up with our latest updates? Follow us on: LinkedIn | Instagram | Twitter | Facebook Our commitment to Diversity, Equity, and Inclusion NIQ is committed to reflecting the diversity of the clients, communities, and markets we measure within our own workforce. We exist to count everyone and are on a mission to systematically embed inclusion and diversity into all aspects of our workforce, measurement, and products. We enthusiastically invite candidates who share that mission to join us. We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class. Our global non-discrimination policy covers these protected classes in every market in which we do business worldwide. Learn more about how we are driving diversity and inclusion in everything we do by visiting the NIQ News Center: https://nielseniq.com/global/en/news-center/diversity-inclusion",https://mx.linkedin.com/jobs/view/junior-data-scientist-at-nielseniq-4023547801,4023547801,"As a Data Scientist, you will support internal and external clients in understanding data science design and methodology, collaborate with senior leaders to address business needs, and contribute to creating innovative solutions through diverse data sets using tools such as Python and R. You will also automate and develop solutions for existing processes, while displaying problem-solving skills and an eagerness to learn.","Python, R, Statistics, Data Analysis, Database Systems",0-2,Bachelor,True,0.0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,1,0,0
"Senior Data Scientist, Content Data Science and Engineering",Netflix,Mexico City Metropolitan Area,ON-SITE,,Full-time,Entertainment Providers,2024-09-12 11:47:09.018617,200,Other,,,"Netflix is one of the world’s leading entertainment services with 278 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time. The Role Our mission to entertain the world is anchored in our content, and data is a crucial component in shaping our comprehensive content strategy. We focus on creating analytical products that support our content partners in their complex and nuanced decision-making processes. We are a highly collaborative team that partners across Netflix to drive impact. We are seeking a talented Senior Data Scientist to provide key insights to our content decision makers in our Latin American region. You will generate insights by scoping and executing deep dive analysis with local partner analytics teams, Consumer Insights and Finance & Strategy. In success, you will collaborate on existing priorities but also will propose and execute on new opportunities. This role features ample opportunity for project ownership and will support impactful decision-making. In This Role, You Will Be a strategic thought partner with business stakeholders to define high impact analytical problems and innovative ways to solve them with data. Develop statistical models explaining viewership, content engagement, and other key behavioral patterns Build dashboards and visualization that enables stakeholders to self-serve metrics and trends effectively. Actively socialize and educate, aiding on interpretation Translate analytic insights into actionable recommendations for business or content improvement, and communicate these findings clearly to a broad audience Identify and proactively socialize regional insights, including those that may generalize to opportunities in other markets What You’ll Bring Exceptional interpersonal and communication skills to influence stakeholders using clear insights and recommendations Exceptional thought partnership to build credibility and relationships with stakeholders Strong statistical knowledge: understanding of predictive modeling; ability to tease out incrementality vs. correlations, confounder identification and amelioration, etc. Basic understanding of experimentation including power calculations and interpretation of results Strong SQL skills and experience with distributed analytic processing technologies (S3, Presto, Hive & Spark) Strong skills in Python or R Highly effective in engaging with diverse stakeholders and adept at cultivating strong partnerships. Passionate about communicating difficult concepts to non-technical audiences Self-starter who thrives under a high level of autonomy. Exceptional interpersonal and communication skills. Enthusiastic about Netflix culture We are an equal opportunity employer and celebrate diversity, recognizing that diversity of thought and background builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, ethnicity, religion, color, place of birth, sex, gender identity or expression, sexual orientation, age, marital status, military service status or disability status.",https://mx.linkedin.com/jobs/view/senior-data-scientist-content-data-science-and-engineering-at-netflix-4005142747,4005142747,"The mission to entertain the world is supported by data, which is crucial in shaping the content strategy. The Senior Data Scientist role involves generating insights through deep dive analysis with local partner analytics teams and providing key analytics for content decision makers in the Latin American region. Responsibilities include defining analytical problems, developing statistical models for viewership and engagement, building dashboards for self-service metrics, and translating insights into actionable recommendations while engaging with stakeholders.","Python, R, SQL, S3, Presto, Hive, Spark, Statistical Modeling, Data Visualization",,,True,,0,0,1,0,0,1,0,0,0,1,0,0,0,0,1,0,0
Data Scientist,Etsy,Mexico City Metropolitan Area,ON-SITE,Entry level,Full-time,Software Development,2024-08-25 11:47:09.018617,114,Engineering,Information Technology,,"Company Description Etsy is the global marketplace for unique and creative goods. We build, power, and evolve the tools and technologies that connect millions of entrepreneurs with millions of buyers around the world. As an Etsy Inc. employee, whether a team member of Etsy, Reverb, or Depop, you will tackle unique, meaningful, and large-scale problems alongside passionate coworkers, all the while making a rewarding impact and Keeping Commerce Human. What’s the role? This is a full-time position reporting to the Manager, Product Analytics. In addition to salary, you will also be eligible for an equity package, an annual performance bonus, and our competitive benefits that support you and your family as part of your total rewards package at Etsy. This role requires your presence in Etsy’s Mexico City office in an in-person or flex capacity. Learn more about our Flex and Office-based work modes and workplace safety policies here. What’s this team like at Etsy? Data scientists at Etsy use rigorous methods to generate insights that inform product, engineering, and business decisions across the company. We collaborate with partner teams through all stages of development: actively uncovering opportunity areas, crafting experiments to test hypotheses, analyzing the impact of our efforts, and highlighting takeaways Learning new skills and techniques is not only a requirement but a perk of the job! We are always looking for opportunities to grow. Our mission is to guide our partner teams with data and insights and tell the story of how we attract and retain our users — to teams, to senior management, and to the community What does the day-to-day look like? Partner with the Recommendations team, whose focus is giving shoppers reasons to come back to Etsy again and again. Work closely and collaboratively with management within the Product org to help shape Etsy’s strategy and vision Conduct analysis on buyers’ and sellers’ behavior, helping us better optimize the features that are most important to our members Design and analyze rigorous experiments, help teams set great hypotheses, and deliver robust analysis of experiment results Transform raw data into important and impactful analysis characterized by strong data governance, technique clarity, and clear documentation Improve or automate internal analytics processes to drive efficiency Of course, this is just a sample of the kinds of work this role will require! You should assume that your role will encompass other tasks, too, and that your job duties and responsibilities may change from time to time at Etsy's discretion, or otherwise applicable with local law. Qualities that will help you thrive in this role are: 2+ years experience as a data scientist or data analyst in which you have extracted from large datasets. Fluency in both English and Spanish Experience in A/B experimentation and statistical analysis of experimental data Mastery of SQL, and experience with R/Python and other scripting/automation techniques. Bonus points for experience with Looker, Tableau, or other data visualization software Curious mindset to drive creative problem-solving and business impact Proficiency in causal inference analysis is strongly preferred Experience in an e-Commerce setting is a plus Additional Information What's Next If you're interested in joining the team at Etsy, please share your resume with us and feel free to include a cover letter if you'd like. As we hope you've seen already, Etsy is a place that values individuality and variety. We don't want you to be like everyone else -- we want you to be like you! So tell us what you're all about. Our Promise At Etsy, we believe that a diverse, equitable and inclusive workplace furthers relevance, resilience, and longevity. We encourage people from all backgrounds, ages, abilities, and experiences to apply. Etsy is proud to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. If, due to a disability, you need an accommodation during any part of the interview process, please let your recruiter know. While Etsy supports visa sponsorship, sponsorship opportunities may be limited to certain roles and skills.",https://mx.linkedin.com/jobs/view/data-scientist-at-etsy-3982234772,3982234772,"The role requires conducting analysis on buyers' and sellers' behavior, optimizing important features, designing and analyzing rigorous experiments, transforming raw data into impactful analysis, and improving internal analytics processes. It involves partnering with the Recommendations team and collaborating with management within the Product organization.","SQL, R, Python, A/B Testing, Statistical Analysis, Looker, Tableau",2+ years,,True,2.0,0,0,0,0,0,1,0,0,1,1,0,0,1,0,1,0,0
Data Scientist Manager - Fraud (Hybrid),Stori,Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,"Technology, Information and Internet",2024-02-18 11:47:09.018617,65,Engineering,Information Technology,,"About Stori Stori is a fast-growing, venture-backed financial technology company, on a mission to democratize credit access for 400 million underbanked LatAm consumers. Stori currently operates in Mexico and has a global team with offices in Arlington Virginia, Mexico City, and Asia. We have quickly made our mark as one of the top digital banks in Mexico with more than two million applicants for our credit card product since launching. Stori is one of the top-funded startups in the region with US$250 million raised to date. We are backed by top global venture capital funds, such as GGV Capital, GIC, Lightspeed Venture Partners, General Catalyst, Goodwater Capital, Mexico's Tresalia Capital, Vision Plus Capital, BAI Capital and Source Code Capital; who have successfully invested in startups such as Affirm, Airbnb, Alibaba, Stripe, and TikTok. Stori has a standout founder team among fintechs, leveraging 100+ years of accumulated experience in consumer finance, banking and technology across Mastercard, Intel, Capital One, Morgan Stanley, GE Capital, and HSBC in the U.S., Mexico and Asia. The team has launched and managed many multi-million-customer credit card products globally, providing a wide breadth of experience and knowledge to our team. We welcome diversity of background, experience and thinking. Storians are passionate about our mission and take pride in the products we build. Our culture thrives off of a flat structure and an inclusive environment where all of our employees can be their authentic selves, with boundless opportunities for professional growth. About the Role: This role reports directly to the Head of the Data Science and Machine Learning Department, serving as a horizontal support across various customer management areas. These areas include line management, customer experience, and collections. Key Responsibilities: As a lead in the area of advanced analytics and modeling: Guide and mentor a team of data scientists in analyzing complex datasets to derive meaningful insights; Collaborate with program business analysts to convert data-driven findings into practical business strategies; Transform business problems into actionable modeling challenges; Manage the development of production models from inception to implementation, in coordination with MLOps, Data Engineering, and Engineering teams; Strategically design and conduct tests to assess behavioral patterns or business hypotheses. What we are looking for: Experience: Bachelor's or Master's degree in Economics, Finances, Statistics, Mathematics, Physics, or other quantitative discipline; Expert in SQL with proficiency in Python or another scripting language, with the interest and initiative to learn relevant new technologies; Experience building predictive models, customer lifetime value models, or other financial models (DCFs); Experience leading or collaborating with data scientists for business problem solving or model development; 2+ years of working experience in designing and executing A/B tests; 4+ years of work experience in data-centric or business modeling roles. Skills and attitudes Proven ability to drive projects independently; Solid oral and written communication skills, particularly in conveying analytical concepts and methods; A collaborative team player who excels in effective communication, cross-functional collaboration, and aligning efforts for the company's overall benefit; Exhibits a demonstrated capacity to perform under pressure, meet tight deadlines, and respond proactively, decisively, and flexibly to challenges; Possesses a deep passion for data, a keen interest in business operations, and an ever-ready attitude to confront problems head-on. Bonus Points: 3+ years of working experience in the credit industry; Demonstrated experience collaborating with product managers and backend engineers for the execution and monitoring of tests or decisioning processes; A proven track record of rapidly acquiring proficiency in new technologies, concepts, and tools. What we offer Make a positive impact on the lives of our customers via financial inclusion Professional development opportunities International exposure & work experience Company swag Legally required benefits",https://mx.linkedin.com/jobs/view/data-scientist-manager-fraud-hybrid-at-stori-3816902252,3816902252,"This role involves leading advanced analytics and modeling efforts, guiding a team of data scientists to analyze complex datasets, and collaborating with business analysts to derive actionable business strategies. The position requires transforming business problems into modeling challenges, managing the development of production models, and conducting tests to assess behavioral patterns or business hypotheses.","SQL, Python, Data Science, Machine Learning, A/B Testing",4+ years,Bachelor,True,4.0,0,0,0,0,0,1,0,0,0,1,0,0,1,0,1,0,0
Sr Data Scientist - Hybrid,Stori,Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,"Technology, Information and Internet",2024-02-18 11:47:09.018617,57,Engineering,Information Technology,,"About Stori Stori is a fast-growing, venture-backed financial technology company, on a mission to democratize credit access for 400 million underbanked LatAm consumers. Stori currently operates in Mexico and has a global team with offices in Arlington Virginia, Mexico City, and Asia. We have quickly made our mark as one of the top digital banks in Mexico with more than two million applicants for our credit card product since launching. Stori is one of the top-funded startups in the region with US$250 million raised to date. We are backed by top global venture capital funds, such as GGV Capital, GIC, Lightspeed Venture Partners, General Catalyst, Goodwater Capital, Mexico's Tresalia Capital, Vision Plus Capital, BAI Capital and Source Code Capital; who have successfully invested in startups such as Affirm, Airbnb, Alibaba, Stripe, and TikTok. Stori has a standout founder team among fintechs, leveraging 100+ years of accumulated experience in consumer finance, banking and technology across Mastercard, Intel, Capital One, Morgan Stanley, GE Capital, and HSBC in the U.S., Mexico and Asia. The team has launched and managed many multi-million-customer credit card products globally, providing a wide breadth of experience and knowledge to our team. We welcome diversity of background, experience and thinking. Storians are passionate about our mission and take pride in the products we build. Our culture thrives off of a flat structure and an inclusive environment where all of our employees can be their authentic selves, with boundless opportunities for professional growth. The role As a customer centered company, customer understanding is the top mission of data scientists at Stori. Among all the sources to be used in customer understandings, Stori data scientists use ""Data"" as the most reliable one. On any given day you will be challenged on three types of work – Modeling and Monitoring, Data Analytical Problem Solving and Innovation: Modeling (guided or independently): Communicate with the business intent holders to understand the new business initiatives Design a model as a product Data collection, processing and transformation Explore new data sources Build, Demonstrate, Maintain and Iterate modeling solutions from end to end Analytical Problem Solving Translate vague context and phenomenon into structure analytical problems and leverage statistical knowledge, machine learning models and visualization to derive meaningful insights on business intents and strategies using data and drive action Leverage advanced statistical techniques like incrementality, experiment design, regression analysis, clustering, causal inference, synthetic control selection to measure digital marketing KPIs, ROI on ad spending, marketing effectiveness, lifetime value (LTV) and referral loop factor etc. Build new metrics, dashboards and insights to measure the performance and impact of the growth marketing team activities in order to optimize and scale their actions Innovation We embrace the rapid development in technology and science. You will be encouraged to explore advanced tools or information sources that can help the team in problem understanding, problem solving and product maintenance. An ideal team partner shares: Passion, Curiosity and Problem Solving with cross functional teams As a data scientist at Stori, you will be facing varied problems throughout the life cycle of credit. Though we encourage talents with varied backgrounds to join us, to solve the puzzles with us together, we believe these are the keys: Passion in data: Data is the foundation of everything at the Stori Data Science team. We believe in the power of machine learning but data is always our most trustworthy friend. Curiosity: We believe curiosity is the best mentor to data scientists. We are not only looking for data scientists, but more importantly, we are looking for partners that can inspire us with their wonders. Problem solving: Data scientists at Stori solve puzzles. We use data to understand our customers, we also use data to provide solutions in helping customers. Collaboration: Work effectively in close partnership with marketing and branding leadership, using data and insights to drive strategy including creation and evaluation of marketing programs. Basic Qualifications. Advanced degree in Computer Science, AI, Physics, Statistics, Applied Math or other quantitative fields 3+ years of work experience with Python and SQL programming for data analysis 3+ years of work experience in data science Solid oral and written communication skills, especially around analytical concepts and methods Demonstrated ability to work under pressure and to meet tight deadlines with proactiveness, decisiveness and flexibility Passion in problem solving with data and data analytics Self-motivated with intellectual curiosity Proven ability to quickly learn new technologies, concepts and tools Preferred Qualifications. 2+ years of experience with Credit industry or in growth marketing team 2+ years of experience coaching junior data scientists and analysts 5+ years of work experience with Python programming 5+ years of work experience with Machine learning or Statistical Modeling Experience in A/B testing design and execution Working experience with AWS Experience managing projects independently What we offer Make a positive impact on the lives of our customers via financial inclusion Professional development opportunities International exposure & work experience Company swag Legally required benefits",https://mx.linkedin.com/jobs/view/sr-data-scientist-hybrid-at-stori-3823559522,3823559522,"As a data scientist at Stori, you will focus on customer understanding using data as the primary source. Your role involves Modeling and Monitoring, Data Analytical Problem Solving, and Innovation. You will design models, analyze data to derive insights on business strategies, and explore advanced tools for problem understanding and solving. An ideal candidate has a passion for data, curiosity, problem-solving skills, and the ability to collaborate effectively with teams.","Python, SQL, Machine Learning, Statistical Modeling, AWS, Data Analysis, A/B Testing",3+ years,,True,3.0,0,0,0,1,0,1,0,0,0,1,0,0,1,0,1,0,0
Data Scientist 2,PayPal,Mexico City Metropolitan Area,ON-SITE,,Full-time,"Software Development, Financial Services, and Technology, Information and Internet",2024-09-09 11:47:09.018617,194,Engineering,Information Technology,,"The Company PayPal has been revolutionizing commerce globally for more than 25 years. Creating innovative experiences that make moving money, selling, and shopping simple, personalized, and secure, PayPal empowers consumers and businesses in approximately 200 markets to join and thrive in the global economy. We operate a global, two-sided network at scale that connects hundreds of millions of merchants and consumers. We help merchants and consumers connect, transact, and complete payments, whether they are online or in person. PayPal is more than a connection to third-party payment networks. We provide proprietary payment solutions accepted by merchants that enable the completion of payments on our platform on behalf of our customers. We offer our customers the flexibility to use their accounts to purchase and receive payments for goods and services, as well as the ability to transfer and withdraw funds. We enable consumers to exchange funds more safely with merchants using a variety of funding sources, which may include a bank account, a PayPal or Venmo account balance, PayPal and Venmo branded credit products, a credit card, a debit card, certain cryptocurrencies, or other stored value products such as gift cards, and eligible credit card rewards. Our PayPal, Venmo, and Xoom products also make it safer and simpler for friends and family to transfer funds to each other. We offer merchants an end-to-end payments solution that provides authorization and settlement capabilities, as well as instant access to funds and payouts. We also help merchants connect with their customers, process exchanges and returns, and manage risk. We enable consumers to engage in cross-border shopping and merchants to extend their global reach while reducing the complexity and friction involved in enabling cross-border trade. Our beliefs are the foundation for how we conduct business every day. We live each day guided by our core values of Inclusion, Innovation, Collaboration, and Wellness. Together, our values ensure that we work together as one global team with our customers at the center of everything we do – and they push us to ensure we take care of ourselves, each other, and our communities. Job Description Summary: Data Scientist role in Business Intelligence with a focus on Risk, Servicing Operations, generating insights and conducing analytics with data-driven approach Job Description: PayPal’s Data Scientists deeply understand our business objectives and the potential financial impact through Fraud Risk, Losses, and OpEx. As a Data Scientist in business intelligence team, you will collaborate with teams to develop strategies and insights supporting fraud prevention, loss impacts, and operational efficiencies, partnering with teams to deliver solutions and providing analytics and governance over financial and operational metrics. These solutions will adapt PayPal’s advanced proprietary fraud prevention and experience mechanisms, enabling growth. In your day-to-day role you will: Design: Create comprehensive dashboards, reports, and communications that effectively communicate trends, forecast projections, and support cross-functional partners in decision-making and alerting of business impacts. Planning: Communicate and collaborate with various partners, supporting by sharing insights that track back to shared goals and Objectives and Key Results (OKRs) to support PayPal’s growth while maintaining consistency across financial and reputational risks. Collaboration: Support collaborative partnerships between Data Science and the core teams and business partners to enable solution delivery and meet business objectives. Governance: Contribute to decision-making around business problems, data integrity, critical design concepts, and end-to-end project management with KPIs and milestones cross-functionally. For the majority of employees, PayPal's balanced hybrid work model offers 3 days in the office for effective in-person collaboration and 2 days at your choice of either the PayPal office or your home workspace, ensuring that you equally have the benefits and conveniences of both locations. Our Benefits: At PayPal, we’re committed to building an equitable and inclusive global economy. And we can’t do this without our most important asset—you. That’s why we offer benefits to help you thrive in every stage of life. We champion your financial, physical, and mental health by offering valuable benefits and resources to help you care for the whole you. We have great benefits including a flexible work environment, employee shares options, health and life insurance and more. To learn more about our benefits please visit https://www.paypalbenefits.com Who We Are: To learn more about our culture and community visit https://about.pypl.com/who-we-are/default.aspx Commitment to Diversity and Inclusion PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state, or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at paypalglobaltalentacquisition@paypal.com. Belonging at PayPal: Our employees are central to advancing our mission, and we strive to create an environment where everyone can do their best work with a sense of purpose and belonging. Belonging at PayPal means creating a workplace with a sense of acceptance and security where all employees feel included and valued. We are proud to have a diverse workforce reflective of the merchants, consumers, and communities that we serve, and we continue to take tangible actions to cultivate inclusivity and belonging at PayPal. Any general requests for consideration of your skills, please Join our Talent Community. We know the confidence gap and imposter syndrome can get in the way of meeting spectacular candidates. Please don’t hesitate to apply. REQ ID R0115102",https://mx.linkedin.com/jobs/view/data-scientist-2-at-paypal-3996831422,3996831422,"Data Scientist role in Business Intelligence focused on Risk and Servicing Operations, generating insights and conducting analytics with a data-driven approach. The Data Scientist will deeply understand business objectives and potential financial impacts through Fraud Risk, Losses, and OpEx. Responsibilities include creating dashboards, collaborating with teams to support fraud prevention and operational efficiencies, and contributing to decision-making around data integrity and project management.","Python, R, SQL, Data Visualization, Machine Learning, Statistical Analysis, Dashboards",,,True,,0,0,0,0,0,1,0,0,0,1,0,0,1,0,1,0,0
Artificial Intelligence Specialist- Python Cloud,"Bluetab América, an IBM Company",Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-08 11:47:09.018617,26,Information Technology,,,"En /bluetab seguimos con el desarrollo de negocio. Nuestros equipos están en pleno crecimiento Nos alejamos del concepto de consultoría tradicional, ¿Sabes por qué?: Contratamos para nosotros. Somos fieles a nuestra cultura y queremos compartir contigo nuestra filosofía de trabajo cooperativo, en equipo y de formación continua. Siempre podemos aprender más. Confiamos en la gente y que es posible trabajar bajo pasión, y que sientas en nuestro apoyo tanto en lo profesional como en lo personal. Ningún mar en calma hizo experto a un marinero. ¿Somos exigentes? Sí, porque nuestros retos los son, pero te desarrollarás entre cracks, en entornos innovadores y con las últimas tendencias tecnológicas. Esto es lo que te aporta ser /bluetaber… Queremos invitarte a formar parte del equipo como: IA- Cloud ¿Qué buscamos? ¡Que te apasione lo que haces!, ¡Que ames la tecnología, la formación continua y los nuevos retos! Perfil ideal del candidato Experiencia: Historial comprobado en el desarrollo e implementación de modelos de ML, preferiblemente en NLP. Experiencia en integrar modelos de ML con sistemas de ingeniería de producción para la entrega de predicciones en tiempo real. Mentalidad de resolución de problemas, Ciencia de los datos, Ciencia cognitiva, Matemáticas (estadística, probabilidad y álgebra lineal) Amplia experiencia en herramientas de repositorios. Amplia experiencia en GIT (Línea de comandos y CLI) Conocimiento de Gitflow, Github Flow Conocimiento en estrategias de branching Conocimiento en herramientas de Continuous Integration/Continuous delivery (Jenkins, Azure devops) Conocimiento en soluciones de Inteligencia Artificial del mercado Conocimiento en soluciones de Inteligencia Artificial orientada al análisis cognitivo de Datos y Preferencias de los usuarios. Conocimiento de Generative AI Funciones: Desarrollar y mantener los pipelines de machine learning, desplegar los modelos en producción y monitorear su desempeño. Colaborar estrechamente con quants e ingenieros de software, el ingeniero garantizará una integración perfecta de los modelos de machine learning en nuestras aplicaciones. Construir y mejorar nuestro proceso de machine learning (ML) y herramientas relacionadas para respaldar el desarrollo, la experimentación, la integración continua, la entrega continua, la verificación/validación y el monitoreo de modelos de M Habilidades técnicas: Experiencia en construir e implementar modelos de machine learning en organizaciones grandes o pequeñas. Amplia experiencia en machine learning, especialmente en Procesamiento de Lenguaje Natural (NLP, por sus siglas en inglés) y Modelos de Lenguaje Grandes (LLMs, por sus siglas en inglés). Dominio de marcos de trabajo de ML como TensorFlow, PyTorch, Scikit, Keras o similar. Fuertes habilidades de programación en Python (Indispensable) Conocimiento práctico en Cloud, ya sea AWS, GCP, AZURE (Indispensable) Habilidades blandas: Comunicación de resultados Organizado Proactivo Tu comodidad nos importa. Los bluetabers trabajamos en un entorno confortable, agradable y con proyección de carrera. Eso se traduce en: Contrato indefinido con un salario competitivo. El salario se relaciona en función de los conocimientos técnicos detectados en el proceso y rol asignado, procurando respetar el sentido de equidad y siendo susceptible de mejora tras las evaluaciones continuas de desempeño. Formación continua. Plan de carrera individual definido ya sea técnico, funcional o gestión (¡Decide tu camino, pero sigue formándote!). Beneficios sociales más allá de tu salario: Fondo de Ahorro Seguro de gastos médicos menores y de mayores a nivel familiar, seguro de vida. Vales de despensa. Vacaciones superiores a la ley. Bolsa de capacitación Bono de bienestar Tendrás un Career Coach para que te guíe en tu desarrollo profesional. Capacitación constante Días de descanso adicionales a la ley. ""Bluetab"" es una empresa del grupo IBM. Bluetab será la entidad contratante. Al proceder con esta solicitud, usted entiende que Bluetab compartirá su información personal con otras filiales de IBM involucradas en su proceso de reclutamiento, selección y contratación, donde quiera que éstas se encuentren. Encontrará más información sobre cómo IBM protege su información personal, incluidas las medidas en caso de transferencia transfronteriza de datos, aquí: https://www.ibm.com/careers/us-en/privacy-policy/ Si te gusta la tecnología y la resolución de problemas tanto como a nosotros, ¡Nos encantaría conocerte!",https://mx.linkedin.com/jobs/view/artificial-intelligence-specialist-python-cloud-at-bluetab-am%C3%A9rica-an-ibm-company-4018420992,4018420992,"We are looking for a candidate who is passionate about technology and continuous learning to join our team as an AI-Cloud Specialist. The ideal candidate should have a proven track record in developing and implementing machine learning models, preferably in natural language processing (NLP). They should also have experience integrating ML models with production engineering systems for real-time predictions and possess problem-solving skills. Responsibilities include developing and maintaining machine learning pipelines, deploying models in production, and closely collaborating with software engineers to ensure seamless integration of ML models into applications.","Machine Learning, Natural Language Processing (NLP), Python, TensorFlow, PyTorch, Scikit-learn, Keras, Git, Jenkins, Azure DevOps, Cloud (AWS, GCP, Azure), Generative AI",,,True,,0,0,0,1,0,0,0,0,0,0,0,1,1,0,1,0,0
Data Scientist,S&P Global,Mexico City Metropolitan Area,ON-SITE,,Full-time,Financial Services,2024-09-08 11:47:09.018617,78,Engineering,Information Technology,,"About The Role Grade Level (for internal use): 10 The role: Data Scientist – S&P Global Commodity Insights The Team S&P Global is looking for a data scientist who will part of our Data Science and Modelling team, the ideal candidate should be highly motivated and goal-oriented, with an encouraging attitude of working in a very dynamic work environment with a wide range of stakeholders and functional teams. The Impact As a Data Scientist at S&P Global, you will apply your advanced analytics skills to transform our vast datasets into tangible business value. You will slice and dice data, analyse information, communicate your findings and collaborate on product development. Outcome of your work will serve multiple business purposes, from commercialized software solution development, driving internal business decisions, to consulting external clients. Responsibilities The candidate will drive business decisions based on the insight obtained from the data. Strong problem-solving skills with an emphasis on product development. Selecting features, building and optimizing machine learning techniques to improve the accuracy of new products. Design, build, and deploy machine learning and statistical models to analyze satellite data, extract actionable insights, and support the creation of innovative satellite-based products. Ensure models are scalable, accurate, and optimized for performance. Close collaboration with software developers and machine learning engineers in the implementation of analytical models into production or commercialization. Develop and utilize algorithms to perform error analysis to improve model uniformity and accuracy. Work closely with cross-functional teams, including engineers, product managers, and domain experts, to translate complex satellite data into practical applications. Contribute to the development and refinement of product features by providing data-driven recommendations and ensuring alignment with user needs and market trends. Comfort working in a very dynamic, research-oriented team with several projects under construction in parallel. Required Qualifications Advanced degree in a highly quantitative field: Computer Science, Machine Learning, Geology, Statistics, Mathematics, etc. +3 years in a similar role Proficiency with data mining, knowledge of probability theory and advanced statistical techniques, ML, NLP, etc. Experience with regression analysis (beyond linear regression), supervised learning, unsupervised learning or time-series analysis. Experience with scientific scripting languages (e.g., Python, R, Matlab) Experience accessing and manipulating data in SQL database environments. Excellent communication and presentation skills. The candidate must be able to effectively communicate with management, reservoir characterization teams, engineering teams, clients, and other stake holders. Preferred Qualifications Recent work or internship experience in an advanced data analytics role. Experience with object-oriented programming in Python. Knowledge of deep learning, computer vision and related toolkits: Tensorflow, PyTorch, Keras, OpenCV etc. NOTE: Send resume in English, as conversational and written English skills is a must for this role. Location: Mexico - Remote, Colombia About S&P Global Commodity Insights At S&P Global Commodity Insights, our complete view of global energy and commodities markets enables our customers to make decisions with conviction and create long-term, sustainable value. We’re a trusted connector that brings together thought leaders, market participants, governments, and regulators to co-create solutions that lead to progress. Vital to navigating Energy Transition, S&P Global Commodity Insights’ coverage includes oil and gas, power, chemicals, metals, agriculture and shipping. S&P Global Commodity Insights is a division of S&P Global (NYSE: SPGI). S&P Global is the world’s foremost provider of credit ratings, benchmarks, analytics and workflow solutions in the global capital, commodity and automotive markets. With every one of our offerings, we help many of the world’s leading organizations navigate the economic landscape so they can plan for tomorrow, today. For more information, visit http://www.spglobal.com/commodity-insights. What’s In It For You? Our Purpose Progress is not a self-starter. It requires a catalyst to be set in motion. Information, imagination, people, technology–the right combination can unlock possibility and change the world. Our world is in transition and getting more complex by the day. We push past expected observations and seek out new levels of understanding so that we can help companies, governments and individuals make an impact on tomorrow. At S&P Global we transform data into Essential Intelligence®, pinpointing risks and opening possibilities. We Accelerate Progress. Our People We're more than 35,000 strong worldwide—so we're able to understand nuances while having a broad perspective. Our team is driven by curiosity and a shared belief that Essential Intelligence can help build a more prosperous future for us all. From finding new ways to measure sustainability to analyzing energy transition across the supply chain to building workflow solutions that make it easy to tap into insight and apply it. We are changing the way people see things and empowering them to make an impact on the world we live in. We’re committed to a more equitable future and to helping our customers find new, sustainable ways of doing business. We’re constantly seeking new solutions that have progress in mind. Join us and help create the critical insights that truly make a difference. Our Values Integrity, Discovery, Partnership At S&P Global, we focus on Powering Global Markets. Throughout our history, the world's leading organizations have relied on us for the Essential Intelligence they need to make confident decisions about the road ahead. We start with a foundation of integrity in all we do, bring a spirit of discovery to our work, and collaborate in close partnership with each other and our customers to achieve shared goals. Benefits We take care of you, so you can take care of business. We care about our people. That’s why we provide everything you—and your career—need to thrive at S&P Global. Our Benefits Include Health & Wellness: Health care coverage designed for the mind and body. Flexible Downtime: Generous time off helps keep you energized for your time on. Continuous Learning: Access a wealth of resources to grow your career and learn valuable new skills. Invest in Your Future: Secure your financial future through competitive pay, retirement planning, a continuing education program with a company-matched student loan contribution, and financial wellness programs. Family Friendly Perks: It’s not just about you. S&P Global has perks for your partners and little ones, too, with some best-in class benefits for families. Beyond the Basics: From retail discounts to referral incentive awards—small perks can make a big difference. For more information on benefits by country visit: https://spgbenefits.com/benefit-summaries Diversity, Equity, And Inclusion At S&P Global At S&P Global, we believe diversity fuels creative insights, equity unlocks opportunity, and inclusion drives growth and innovation – Powering Global Markets. Our commitment centers on our global workforce, ensuring that our people are empowered to bring their whole selves to work. It doesn’t stop there, we strive to better reflect and serve the communities in which we live and work, and advocate for greater opportunity for all. Equal Opportunity Employer S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. US Candidates Only: The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. 20 - Professional (EEO-2 Job Categories-United States of America), ANLYTC202.1 - Middle Professional Tier I (EEO Job Group) Job ID: 306298 Posted On: 2024-08-26 Location: Virtual, Mexico",https://mx.linkedin.com/jobs/view/data-scientist-at-s-p-global-3999020043,3999020043,"S&P Global is looking for a data scientist to join their Data Science and Modelling team, who will apply advanced analytics skills to transform vast datasets into business value. Responsibilities include driving business decisions based on data insights, building and optimizing machine learning techniques, designing and deploying models to analyze satellite data, and collaborating with cross-functional teams to develop practical applications.","Python, R, Matlab, SQL, Machine Learning, NLP, Tensorflow, PyTorch, Keras, OpenCV",3+ years,,True,3.0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,1,0,0
"Business Data Scientist, gTech Ads",Google,Mexico City Metropolitan Area,ON-SITE,,Full-time,"Information Services and Technology, Information and Internet",2024-09-11 11:47:09.018617,69,Sales,"Advertising,",Marketing,"Please submit your resume in English - we can only consider applications submitted in this language. Only applications of candidates with Mexican citizenship will be evaluated for this role in compliance with the provisions of Article 7 of the Federal Labor Law. Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Mexico City, CDMX, Mexico; Buenos Aires, Argentina . Minimum qualifications: Master's degree in Statistics, Mathematics, Bioinformatics, Economics, a quantitative field, or equivalent practical experience. 4 years of experience in a data science field. Experience with statistical software (e.g., R, Python, MATLAB) and database languages (e.g., SQL). Experience leveraging data insights into storytelling for business stakeholders. Preferred qualifications: PhD in Statistics or a related quantitative discipline. 5 years of experience in statistical data analysis (e.g., generalized linear models, multivariate analysis, clustering or segmentation, and sampling methods). Experience in controlled experiment design and causal inference methods. Experience with machine learning on computing systems (e.g., Hadoop, MapReduce, or a similar system). Ability to prioritize requests, teach others, learn techniques, partner in a environment with competing demands, collaborate with stakeholders, and communicate analysis insights to non-technical audiences. Ability to take initiative with excellent leadership and communication skills. About The Job As a Business Data Scientist, you will perform data analytics, lead initiatives in experimentation and measurement, and advance machine learning modeling capability to support global marketing programs. In collaboration with multidisciplinary teams, you will tap into the underlying data, develop and align on metrics or methodologies, and generate insights that enable marketers to develop marketing programs. You will design, prototype, and build out analysis pipelines to support initiatives and Marketing campaigns at scale. You will perform analysis, design, and execute on experimentation, and conduct incrementally measurement analysis to inform on strategic decisions of the marketing programs across the entire Ads Marketing space. You will build investigative frameworks and measurement capabilities to generate data driven insights that lead business growth. You will present and communicate to marketing partners and leadership to inform on decision making. Google creates products and services that make the world a better place, and gTech’s role is to help bring them to life. Our teams of trusted advisors support customers globally. Our solutions are rooted in our technical skill, product expertise, and a thorough understanding of our customers’ complex needs. Whether the answer is a bespoke solution to solve a unique problem, or a new tool that can scale across Google, everything we do aims to ensure our customers benefit from the full potential of Google products. To learn more about gTech, check out our video . Responsibilities Work with large, complex data sets and solve complex analysis problems, applying advanced investigative methods (e.g., statistical and machine learning models). Conduct analysis that includes problem formulation, data gathering and requirements specification, processing, analysis, ongoing deliverables, and presentations. Design and analyze controlled experiments or counterfactual causal inference studies to examine the incremental impact of Ads marketing programs. Build and prototype analysis pipelines iteratively to provide insights at scale. Develop comprehensive knowledge of Google data structures and metrics, advocating for changes where needed. Interact cross-functionally, making business recommendations (e.g., cost-benefit, forecasting, experiment analysis) with effective presentations of findings at multiple levels of stakeholders through visual displays of quantitative information. Develop and automate reports, and iteratively build and prototype dashboards to provide insights at scale, solving for business priorities. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",https://mx.linkedin.com/jobs/view/business-data-scientist-gtech-ads-at-google-4004471180,4004471180,"As a Business Data Scientist, you will perform data analytics, lead initiatives in experimentation and measurement, and advance machine learning modeling capability to support global marketing programs. You will work with large, complex data sets, solve complex analysis problems, conduct analysis including problem formulation and data gathering, and design controlled experiments. You will build and prototype analysis pipelines, present findings to stakeholders, and develop automated reports and dashboards.","R, Python, MATLAB, SQL, Hadoop, MapReduce, Machine Learning, Statistical Analysis, Data Visualization",4+,Masters,True,4.0,0,0,1,0,0,1,0,0,0,1,0,0,1,0,1,0,0
Associate Data Science,PwC,Mexico City Metropolitan Area,ON-SITE,Associate,Full-time,Professional Services,2024-09-08 11:47:09.018617,26,Engineering,Information Technology,,"Line of Service Tax Industry/Sector Not Applicable Specialism TRS Consulting Management Level Associate Job Description & Summary Implementación de proyectos, mantenimiento a proyectos en tema tecnológico, manejo de Alteryx, Análisis de datos (data analytics), Python. Las principales actividades son para automatización de procesos fiscales. Preferred skills Bachelor's degree, advanced English level. Minimum years experience required From 6 months to 3 years. Required Skills Alteryx, Data Analytics, Python (Programming Language) Optional Skills Desired Languages (If blank, desired languages not specified) Travel Requirements Available for Work Visa Sponsorship? Government Clearance Required? Job Posting End Date diciembre 31, 2024",https://mx.linkedin.com/jobs/view/associate-data-science-at-pwc-4014138327,4014138327,"Implementation and maintenance of technology projects, including the use of Alteryx and data analytics, with a focus on the automation of tax processes.","Alteryx, Data Analytics, Python",0.5 to 3,Bachelor,True,0.0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,1,0,0
Data Scientist Procurement Data Management & Analytics,Corteva Agriscience,Mexico City Metropolitan Area,ON-SITE,,Full-time,Farming,2024-09-13 11:47:09.018617,25,Other,,,"236443W-01-2 Description We are seeking an experienced Data Scientist with 4+ years of hands-on experience in working with complex data sets. You will collaborate with cross-functional teams within the Procurement function to extract insights and support business objectives through data analytics. The ideal candidate will demonstrate proven experience executing data transformations, applying statistical techniques, performing regression testing, and building and fine-tuning classification models. Expertise in Python or R programming, experience working with largely categorical information, a history of working within Azure, and a track record for building automations is all essential for this position. Having a background in procurement or supply chain is an added advantage. Key Responsibilities Data Modeling and Pipeline Management Build and fine-tune classification models in the areas of spend management, contract management, and operational effectiveness. Develop and maintain data pipelines and architectures for efficient data processing and analysis. Stay informed of new techniques for predictive/prescriptive modeling. Automation Development Identify and action upon opportunities to automate repetitive tasks from within the team. Monitor and maintain automated processes to ensure optimal performance. Mentor junior team members on automation skillsets. Insights & Reporting Perform exploratory data analyses, which may include machine learning, to uncover trends, patterns, and insights from large and complex datasets. Develop, test, and implement data-driven solutions to support business objectives. Oversee the quality and effectiveness of team dashboards and reports. Data Management & Quality Design and implement data collection and data quality processes. Ensure data integrity and consistency across multiple sources and systems. Develop and maintain documentation for data processes and analysis specifications. Collaboration & Communication Work closely with data engineers and business analysts to integrate data insights into production systems. Communicate findings and insights to non-technical stakeholders through reports and presentations. Qualifications Education: Master's degree in Data Science, Analytics, Statistics, Computer Science, Mathematics, Engineering, or a related field. Experience: 4+ years of professional experience in data analytics, with a proven track record of building and tuning classification models. Language: Proficiency in English is required. Technical Skills Strong proficiency in Python or R programming. Experience utilizing statistical methods and machine learning techniques. Expertise in building and deploying predictive models. Proficiency in Microsoft Azure, including Azure Data Factory and Databricks, or a demonstrated ability to learn new tools and platforms Understanding of data visualization tools, with a preference for Power BI. Experience with SQL for data manipulation and querying. Data Management Experience with data manipulation and cleaning tools (e.g., tidyverse, Pandas, Numpy). Familiarity with data warehousing solutions (e.g., SQL Server, Amazon Redshift, Google BigQuery). Soft Skills Strong problem-solving skills and attention to detail. Excellent communication skills, with the ability to convey technical concepts to a non-technical audience. Ability to work independently and as part of a team in a fast-paced environment. Preferred Qualifications Certification in Data Analysis or related fields. Experience with cloud platforms (e.g., AWS, Azure, Google Cloud). Knowledge of Agile methodologies and version control systems (e.g., Git). Procurement Background: Experience in procurement is an added advantage.",https://mx.linkedin.com/jobs/view/data-scientist-procurement-data-management-analytics-at-corteva-agriscience-4023226846,4023226846,"We are seeking an experienced Data Scientist with 4+ years of hands-on experience in working with complex data sets. You will collaborate with cross-functional teams within the Procurement function to extract insights and support business objectives through data analytics. The ideal candidate will demonstrate proven experience executing data transformations, applying statistical techniques, performing regression testing, and building and fine-tuning classification models.","Python, R, Azure, SQL, Power BI, Databricks, Pandas, NumPy, tidyverse",4+,Masters,True,4.0,0,0,1,1,0,0,0,0,1,1,0,0,0,0,1,0,0
AI Engineer for AI Anime Avatar App 🤖,Coral,Mexico City Metropolitan Area,ON-SITE,Entry level,Contract,Staffing and Recruiting,2024-03-19 11:47:09.018617,25,Engineering,Information Technology,,"As the AI Engineer at Botnet, you will play a crucial role in managing models, prompt engineering, and memory for our consumer app. Botnet allows creators to make bots and clones of themselves, enabling their fans and others to interact and message. Responsibilities Technical Responsibilities Develop and manage AI models to enhance user experience and engagement Collaborate with cross-functional teams to implement prompt engineering techniques Optimize memory usage for efficient performance of the app Data Responsibilities Collect and analyze user data to identify patterns and improve AI algorithms Work closely with data scientists to integrate machine learning capabilities into the app Ensure data privacy and security measures are implemented and maintained Deployment and Maintenance Responsibilities Deploy and monitor AI models in production environments Continuously evaluate and improve the performance of AI algorithms Troubleshoot and resolve any issues related to AI functionality Requirements Technical Skills Minimum of 3 years of experience in AI engineering or related field Proficiency in machine learning frameworks such as Stable Diffusion Strong programming skills in Python Experience with natural language processing (NLP) techniques Soft Skills Excellent problem-solving and analytical skills Strong communication and collaboration abilities Ability to work effectively in a fast-paced, agile development environment Mentality Proactive and self-motivated mindset Strong attention to detail Continuous learner with a passion for staying updated with the latest AI trends and technologies",https://mx.linkedin.com/jobs/view/ai-engineer-for-ai-anime-avatar-app-%F0%9F%A4%96-at-coral-3860718951,3860718951,"As the AI Engineer, you will manage models, implement prompt engineering techniques, and optimize memory for the consumer app, enhancing user experience and engagement through AI solutions. Responsibilities include collecting and analyzing user data, collaborating with data scientists, deploying AI models, and ensuring optimal performance while maintaining data privacy and security.","Python, Machine Learning, Natural Language Processing, Stable Diffusion, Agile Methodologies",3,,True,3.0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0
Sr. Data Scientist,Nissan Motor Corporation,Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,Motor Vehicle Manufacturing,2024-09-08 11:47:09.018617,71,Engineering,Information Technology,,"Data Analytics Team is looking for a Sr. Data Scientist . The DS is responsible for leading the design and development of complex data integration solutions in a highly collaborative software engineering environment. Acts as the liaison between technical teams and business stakeholders to facilitate, conceptualize and define integrated data solutions; making sure these solutions align with Data Architecture best practices & achieve companywide objectives Main responsibilities: Develop and maintain a broad understanding of data architecture and systems. Lead the design and development of logical and physical data models for transactional and analytical datastores, considering on-premise and cloud/hybrid options. Ensure domain-driven data architecture evolution & collaboration across domains. Evangelize data platform, standards, patterns, and best practices across business partners. Work closely with business users and developers to create and maintain data dictionary and data lineage. Help investigate and resolve data anomalies including data quality issues and ambiguous/redundant data definitions. Recommend data integrity checks and controls to ensure enterprise-wide data quality. Provide technical guidance and support for data warehouse and data initiatives including cloud migration pathways for legacy databases. Prescribe optimal data framework, database selection & unity with global standards under the guidance of Nissan's Enterprise Data Architect. Work closely with data consumers (data analysts, data scientists, data engineers, etc.) to know needs and challenges, produce solutions and process improvement recommendations. Assist with data platform optimization and scalability improvement efforts. Ensure compliance with data policies, state and federal laws, regulations, and standards. Enhance data security and data auditing capabilities. Profile: Bachellor Degree in Computer Systems or related At least 5 years of experience in data engineering and data modeling Mandatory Knowledge in: Search Maker, AWS, Machine Learning, Python. Nice to have Kowledge in: SQL data bases, ETL, data modeling, informatica, snowflake, Tableau, power BI or other data visualizing tool. Desirable AWS certifications: developer, data analytics, machine learning, cloud practitioner or solution architect English Level: Advance (mandatory) Nissan (NMEX,NEdM, NRFS, NRFM y ANZEN) realiza contrataciones con base al cumplimiento del perfil de puesto en la vacante, sin distinción (ni discriminación por género, identidad y/o expresión de género, orientación sexual, ) raza, color, idioma, religión, opinión política o de cualquier otra índole, origen nacional o social, posición económica, nacimiento o cualquier otra condición. Nissan (NMEX,NEdM, NRFS, NRFM and ANZEN) hires based on the fulfillment of the job profile in the vacancy, without distinction or discrimination based on gender, gender identity and/or expression, sexual orientation, race, color, language, religion, political or any other opinion, national or social origin, economic position, birth or any other condition. Alvaro Obregon Ciudad de Mexico Mexico",https://mx.linkedin.com/jobs/view/sr-data-scientist-at-nissan-motor-corporation-3979904414,3979904414,"The Data Analytics Team is looking for a Senior Data Scientist responsible for leading the design and development of complex data integration solutions in a collaborative software engineering environment. This role includes acting as a liaison between technical teams and business stakeholders, developing logical and physical data models for transactional and analytical datastores, ensuring collaboration across domains, and evangelizing data standards and best practices. Responsibilities also include resolving data anomalies, providing technical support for data warehouse initiatives, optimizing data frameworks, ensuring compliance with data policies, and enhancing data security.","AWS, Python, Machine Learning, SQL, ETL, Informatica, Snowflake, Tableau, Power BI",5,Bachelor,True,5.0,0,0,0,1,0,0,1,0,1,1,0,0,1,0,1,0,0
"Software Engineer II, AI/ML, Core",Google,Mexico City Metropolitan Area,ON-SITE,,Full-time,"Information Services and Technology, Information and Internet",2024-09-14 11:47:09.018617,139,Information Technology,Engineering,,"Only applications of candidates with Mexican citizenship will be evaluated for this role in compliance with the provisions of Article 7 of the Federal Labor Law. Please submit your resume in English - we can only consider applications submitted in this language. Minimum qualifications: Bachelor’s degree or equivalent practical experience. 1 year of experience with software development in one or more programming languages (e.g., Python, C, C++, Java, JavaScript). 1 year of experience with data structures or algorithms. 1 year of experience with machine learning algorithms and tools (e.g., TensorFlow), artificial intelligence, deep learning, or natural language processing. Preferred qualifications: Master's degree or PhD in Computer Science or related technical field. Experience developing accessible technologies. Experience in backend coding languages such as GOLang, Rust, or Java. Experience in ML model coding languages (e.g., Python). About The Job Google's software engineers develop the next-generation technologies that change how billions of users connect, explore, and interact with information and one another. Our products need to handle information at massive scale, and extend well beyond web search. We're looking for engineers who bring fresh ideas from all areas, including information retrieval, distributed computing, large-scale system design, networking and data storage, security, artificial intelligence, natural language processing, UI design and mobile; the list goes on and is growing every day. As a software engineer, you will work on a specific project critical to Google’s needs with opportunities to switch teams and projects as you and our fast-paced business grow and evolve. We need our engineers to be versatile, display leadership qualities and be enthusiastic to take on new problems across the full-stack as we continue to push technology forward. The Core team builds the technical foundation behind Google’s flagship products. We are owners and advocates for the underlying design elements, developer platforms, product components, and infrastructure at Google. These are the essential building blocks for excellent, safe, and coherent experiences for our users and drive the pace of innovation for every developer. We look across Google’s products to build central solutions, break down technical barriers and strengthen existing systems. As the Core team, we have a mandate and a unique opportunity to impact important technical decisions across the company. Responsibilities Write product or system development code. Participate in, or lead design reviews with peers and stakeholders to decide amongst available technologies. Review code developed by other developers and provide feedback to ensure best practices (e.g., style guidelines, checking code in, accuracy, testability, and efficiency). Contribute to existing documentation or educational content and adapt content based on product/program updates and user feedback. Triage product or system issues and debug/track/resolve by analyzing the sources of issues and the impact on hardware, network, or service operations and quality. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",https://mx.linkedin.com/jobs/view/software-engineer-ii-ai-ml-core-at-google-3989186042,3989186042,"Minimum qualifications include a bachelor's degree or equivalent practical experience, 1 year of software development experience with programming languages such as Python, C, C++, Java, or JavaScript, and 1 year of experience with data structures, algorithms, and machine learning algorithms and tools like TensorFlow, as well as artificial intelligence, deep learning, or natural language processing. Preferred qualifications include a master's degree or PhD in Computer Science or a related field, experience developing accessible technologies, and backend coding experience with languages like GOLang, Rust, or Java.","Python, C, C++, Java, JavaScript, TensorFlow, GOLang, Rust, Machine Learning, Artificial Intelligence, Deep Learning, Natural Language Processing",1 year,Bachelor,True,1.0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0
Gerente Sr. Data Science,Totalplay,Mexico City Metropolitan Area,ON-SITE,Executive,Full-time,Telecommunications and Advertising Services,2024-09-13 11:47:09.018617,59,Business Development,"Engineering,",Information Technology,"En Totalplay buscamos agentes de cambio con mentalidad positiva e innovadora, dispuesta a trabajar en equipo para la solución de problemas y seguir desarrollando exitosamente los negocios en los que tenemos presencia a nivel nacional. Gerente Sr. Data Science Objetivo: Monetizar información almacenada en la nube que genera el consumo de los suscriptores y desarrollar e implementar estategias de aprendizaje máquina y algoritmos de Big Data. Principales funciones: Ser responsable del área técnica de Data Science para ventas de publicidad. Diseñar la estrategia técnica para el uso y comercialización de data. Coordinar el comite de estrategía analitica Garantizar la correcta operacionalización de Modelos de IA Construcción de Indicadores internos y externos para campañas de publicidad Principales responsabilidades: Desarrollar desde el inicio un servicio de información monetizable. Analizar información y crear audiencias que sean de interés para clientes de publicidad y agencias de medios. Identificar Patrones Subyacentes de nichos de mercado a explotar. Crear visualizaciones que resumen hallazgos de valor para el accionar del negocio. Revisar la calidad de los análisis realizados y de los reportes presentados. Experiencia y conocimientos: Funnel de Ventas y Publicidad, construcción de segementaciones Ciencia de datos Programación Estadística Big Data Python AWS SQL ML IA Ofrecemos: Sueldo competitivo más bono anual Prestaciones de ley Gastos médico mayores Seguro de vida Beneficios Grupo Salinas Desarrollo profesional en uno de las compañías más importantes y exitosas del país. Si cumples con el perfil postúlate por este medio.",https://mx.linkedin.com/jobs/view/gerente-sr-data-science-at-totalplay-4023529816,4023529816,"At Totalplay, we seek agents of change with a positive and innovative mindset, willing to work in a team to solve problems and successfully develop the businesses in which we have a national presence. Senior Data Science Manager Objective: Monetize information stored in the cloud generated by subscriber consumption and develop and implement machine learning strategies and Big Data algorithms. Main functions: Be responsible for the technical area of Data Science for advertising sales. Design the technical strategy for data usage and commercialization. Coordinate the analytical strategy committee. Ensure the proper operationalization of AI Models. Construct internal and external indicators for advertising campaigns. Main responsibilities: Develop from scratch a monetizable information service. Analyze information and create audiences of interest for advertising clients and media agencies. Identify underlying patterns of market niches to exploit. Create visualizations that summarize findings of value for business actions. Review the quality of analyses and reports presented.","Python, AWS, SQL, Machine Learning, Artificial Intelligence, Big Data, Statistical Programming",,,True,,0,0,1,1,0,0,0,0,0,1,0,0,1,0,1,0,0
"Scientist II, Data & Specification Management",Mondelēz International,Mexico City Metropolitan Area,ON-SITE,Entry level,Full-time,"Food and Beverage Manufacturing, Food and Beverage Services, and Manufacturing",2024-09-11 11:47:09.018617,25,Engineering,Information Technology,,"Job Description Please note this is a 9-month temporary role. Are You Ready to Make It Happen at Mondelēz International? Join our Mission to Lead the Future of Snacking. Make It With Pride. In this role, you provide end-to-end specification management support. Your responsibilities include interpreting technical reports, analyzing the results of assessments of compliance, planning and implementing assigned processes and taking corrective actions when necessary, and developing strong working relationships in your function and cross functionally as well. You are a technological resource and considered an expert in your technical or scientific area. How You Will Contribute You will provide specification management support to ensure compliance with quality standards and provide technical support for specifications processes. You will also complete various projects-either multiple small projects at the same time but with phased deadlines or more complex medium projects. This role requires excellent communication skills because you will work across functions on specifications reviews, approvals and change notifications and talk with suppliers about raw material specifications. In this role, you will offer suggestions on how to improve projects in your area and ensure data consistency and completeness. Some of your other duties will include archiving obsolete specifications, running maintenance and audit programs for specifications, troubleshooting and providing day-to-day user support and training. What You Will Bring A desire to drive your future and accelerate your career and the following experience and knowledge: Working knowledge of SAP PLM system or similar specification management systems Good analytical skill and use of tools for data analysis Organizational agility Prioritization skills The Data & System Management Team is responsible to bring oversight and governance to the MDLZ SAP-PLM system modifications & updates and end-to-end (E2E) data processes & flow. This role requires a thorough working knowledge of the SAP-PLM system and integration E2E to other systems such as SAP-MDG, ECC & PIM. The individual would need a moderate understanding of data flow through SAP PLM and through interfaces, which will involve a close partnership with R&D Product, Packaging & Regulatory and business support teams. The role will be responsible to ensure correct system enhancement implementation and Data management. The individual would need a moderate understanding of how and what Ingredient Spec Management, Packaging Development, Product Development & Regulatory populate their respective specification data into SAP-PLM. Additionally, they will need a moderate understanding of the SAP-MDG & PIM systems and how data translates & transforms into these systems from SAP-PLM. Experience in PLM functionalities. Proficiency in English as this is a global position. Good analytical Skills and Work with large amounts of data such as facts, figures, and mathematics/formulas and undertake analytical activities and delivers analysis outputs Advanced Excel skills for data analysis, including pivot tables, VLOOKUP, and Excel functions. Creating data files that can integrate many sources of information Strong business acumen and good communication Good organizational skills to manage multiple tasks simultaneously. Enthusiasm and full accountability for the results, self standing, open and ready to learn on the job Strong business acumen and good communication Working effectively in a team environment, often with cross-functional teams. Strong facilitation and communication skills to support team discussions on data management No Relocation support available Business Unit Summary Mondelēz International entered the China market in 1984. Headquartered in Shanghai, Mondelēz Greater China is a leading company in the snacks business, including biscuits, Chocolate, candy & gum, and beverages. With over 4,000 employees, Mondelēz has established manufacturing plants in East, South and North China as well as a Global Biscuit R&D Technical Center in Suzhou. The Chinese name Yi Zi (亿滋) represents the company’s vision to bring an abundance of deliciousness to consumers. Mondelēz International is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, sexual orientation or preference, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law. Job Type Temporary (Fixed Term) Data & Specification Management Product Quality, Safety and Compliance",https://mx.linkedin.com/jobs/view/scientist-ii-data-specification-management-at-mondel%C4%93z-international-4023055132,4023055132,"In this role, you provide end-to-end specification management support, interpret technical reports, analyze compliance assessments, and implement assigned processes. You will develop relationships across functions, provide technical support for specifications processes, and manage projects with varying complexities. Excellent communication skills are required to work with suppliers and on specifications reviews. The job includes archiving specifications, maintenance programs, troubleshooting, and day-to-day user support. Knowledge of the SAP PLM system or similar, along with strong analytical skills and data management capabilities, is essential.","SAP PLM, SAP MDG, SAP ECC, SAP PIM, Excel",,,True,,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0
Senior Applied AI & ML Research Engineer,Reuters News Agency,Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,Media Production,2024-06-17 11:47:09.018617,25,Engineering,Information Technology,,"Job Description Senior Applied AI & ML Research Engineer Do you love creating innovative solutions for customers? Thomson Reuters Labs is looking to set up a new Lab in Mexico. We are seeking a passionate Senior Research Engineer who will bring expertise in AI and ML and is interested in building data-driven capabilities that drive transformation. As a member of Thomson Reuters Labs in Mexico, you will have a direct impact on our company by helping to create new and innovative capabilities that will delight our customers. What does Thomson Reuters Labs do? We experiment, we build, we deliver. We support the organization and our customers through applied research and the development of new products and technologies. TR Labs innovates collaboratively across our core segments in Legal, Tax & Accounting, Government, and Reuters News. As a Senior Research Engineer at Thomson Reuters Labs, you will be part of a global interdisciplinary team of experts. We hire engineers and specialists across a variety of AI research areas to drive the company’s digital transformation.  The science and engineering of AI are rapidly evolving.  We are looking for an adaptable learner who can think in code and likes to learn and develop new skills as they are needed; someone comfortable with jumping into new problem spaces. Is this you? Come join us! About The Role In this opportunity as a Senior Research Engineer, you will: Develop and Deliver: Applying modern software development practices, you will be involved in the entire software development lifecycle, building, testing and delivering high-quality solutions. Build Scalable ML Solutions: You will create large scale data processing pipelines to help researchers build and train novel machine learning algorithms.  You will develop high performing scalable systems in the context of large online delivery environments. Be a Team Player: Working in a collaborative team-oriented environment, you will share information, value diverse ideas, partner with cross-functional and remote teams. Be an Agile Person:  With a strong sense of urgency and a desire to work in a fast-paced, dynamic environment, you will deliver timely solutions. Be Innovative: You are empowered to try new approaches and learn new technologies. You will contribute innovative ideas, create solutions, and be accountable for end-to-end deliveries. Be an Effective Communicator: Through dynamic engagement and communication with cross-functional partners and team members, you will effectively articulate ideas and collaborate on technical developments. About You Essential skills & experience Have a Bachelor of Science degree, computer science or related field At least 5 years software engineering experience, ideally in the context of machine learning and natural language processing Are skilled and have a deep understanding of Python software development stacks and ecosystems, experience with other programming languages and ecosystems is ideal. Can understand, apply, integrate and deploy Machine Learning capabilities and techniques into other systems. Are familiar with the Python data science stack through exposure to libraries such as Numpy, Scipy, Pandas, Dask, spaCy, NLTK, scikit-learn Take pride in writing clean, reusable, maintainable and well-tested code Have a desire to learn and embrace new and emerging technology Are familiar with probabilistic models and have an understanding of the mathematical concepts underlying machine learning methods Preferred Skills & Experience Experience integrating Machine Learning solutions into production-grade software and have an understanding of ModelOps and MLOps principles Demonstrate proficiency in automation, system monitoring, and cloud-native applications, with familiarity in AWS or Azure (or a related cloud platform) Had previous exposure to Natural Language Processing (NLP) problems and have familiarity with key tasks such as Named Entity Recognition (NER), Information Extraction, Information Retrieval, etc. Can understand and translate between language and methodologies used both in research and engineering fields Have been successfully taking and integrating Machine Learning solutions to production-grade software Hands-on experience in other programming and scripting languages (Java, TypeScript, JavaScript, etc.) What's in it For You? You will join our inclusive culture of world-class talent, where we are committed to your personal and professional growth through: Hybrid Work Model: We’ve adopted a flexible hybrid working environment (2-3 days a week in the office depending on the role) for our office-based roles while delivering a seamless experience that is digitally and physically connected Wellbeing: Comprehensive benefit plans; flexible and supportive benefits for work-life balance: flexible vacation, two company-wide Mental Health Days Off; work from another location for up to a total of 8 weeks in a year, 4 of those weeks can be out of the country and the remaining in the country, Headspace app subscription; retirement, and employee incentive programs; resources for mental, physical, and financial wellbeing. Culture: Globally recognized and award-winning reputation for equality, diversity and inclusion, flexibility, work-life balance, and more. Learning & Development: LinkedIn Learning access; internal Talent Marketplace with opportunities to work on projects cross-company; Ten Thousand Coffees Thomson Reuters café networking. Social Impact: Ten employee-driven Business Resource Groups; two paid volunteer days annually; Environmental, Social, and Governance (ESG) initiatives for local and global impact. Purpose-Driven Work: We have a superpower that we’ve never talked about with as much pride as we should – we are one of the only companies on the planet that helps its customers pursue justice, truth, and transparency. Together, with the professionals and institutions we serve, we help uphold the rule of law, turn the wheels of commerce, catch bad actors, report the facts, and provide trusted, unbiased information to people all over the world. Do you want to be part of a team helping re-invent the way knowledge professionals work? How about a team that works every day to create a more transparent, just and inclusive future? At Thomson Reuters, we’ve been doing just that for almost 160 years. Our industry-leading products and services include highly specialized information-enabled software and tools for legal, tax, accounting and compliance professionals combined with the world’s most global news services – Reuters. We help these professionals do their jobs better, creating more time for them to focus on the things that matter most: advising, advocating, negotiating, governing and informing. We are powered by the talents of 26,000 employees across more than 70 countries, where everyone has a chance to contribute and grow professionally in flexible work environments that celebrate diversity and inclusion. At a time when objectivity, accuracy, fairness and transparency are under attack, we consider it our duty to pursue them. Sound exciting? Join us and help shape the industries that move society forward. Accessibility As a global business, we rely on diversity of culture and thought to deliver on our goals. To ensure we can do that, we seek talented, qualified employees in all our operations around the world regardless of race, color, sex/gender, including pregnancy, gender identity and expression, national origin, religion, sexual orientation, disability, age, marital status, citizen status, veteran status, or any other protected classification under applicable law. Thomson Reuters is proud to be an Equal Employment Opportunity/Affirmative Action Employer providing a drug-free workplace. We also make reasonable accommodations for qualified individuals with disabilities and for sincerely held religious beliefs in accordance with applicable law. Protect yourself from fraudulent job postings click here to know more. More information about Thomson Reuters can be found on https://thomsonreuters.com.",https://mx.linkedin.com/jobs/view/senior-applied-ai-ml-research-engineer-at-reuters-news-agency-3929765003,3929765003,"As a Senior Research Engineer, you will develop and deliver software solutions, build scalable machine learning solutions for large data processing, and work collaboratively in a team-oriented environment. You will be involved in the entire software development lifecycle, creating high-performing scalable systems and leveraging modern software development practices while contributing innovative ideas.","Python, Numpy, Scipy, Pandas, Dask, spaCy, NLTK, scikit-learn, Java, TypeScript, JavaScript, AWS, Azure",5,Bachelor,True,5.0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0
"Senior Machine Learning Engineer I, Ads Search Quality",Etsy,Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,Software Development,2024-09-08 11:47:09.018617,25,Engineering,Information Technology,,"Company Description Etsy is the global marketplace for unique and creative goods. We build, power, and evolve the tools and technologies that connect millions of entrepreneurs with millions of buyers around the world. As an Etsy Inc. employee, whether a team member of Etsy, Reverb, or Depop, you will tackle unique, meaningful, and large-scale problems alongside passionate coworkers, all the while making a rewarding impact and Keeping Commerce Human. What’s the role? Etsy is hiring a Senior Machine Learning Engineer to join the Ads Search Quality team. We are looking for individuals who are product and delivery-driven, and are passionate about making ML innovations in digital advertising to help improve the Etsy buyer/seller experience. This is a fantastic opportunity for someone interested in building user-centric ML systems for a two-sided marketplace with 90+ million buyers, 5+ million sellers, and hundreds of millions of unique, handmade, vintage listings. Etsy sellers use Etsy ads for advertising their products and growing their business. Etsy Ads optimizes sellers’ budgets to advertise their listings in the places on Etsy where they perform best. The work on the Ads Search Quality team involves building machine learning systems to power the sponsored search product including retrieval, ranking, and user engagement modeling on Etsy.com and the Etsy app. This is a full-time position reporting to the Senior Engineering Manager, Ads Quality. In addition to salary, you will also be eligible for an equity package, an annual performance bonus, and our competitive benefits that support you and your family as part of your total rewards package at Etsy. This role requires your presence in Etsy’s Mexico City office once or twice per week depending on your proximity to the office. Candidates living within commutable distance of our Mexico City office or in Guadalajara may be the first to be considered. Learn more details about our work modes and workplace safety policies here. What’s this team like at Etsy? Our team develops custom machine-learning models that can drive product vision and customer impact. We ensure that the right ads are put in front of the right buyers We maintain a pipeline that scales for our 90+ million buyers and sellers What does the day-to-day look like? Work cross functionally with product engineering teams and communicate your ideas and model capabilities to product managers Push the state of the art and apply the latest advances in deep learning and machine learning to improve buyer and seller experiences on Etsy Prototype, optimize, and productionize large-scale ML models that help deliver key results Conduct A/B experiments to validate the efficiency of ML models and pipelines Work closely with product managers, ML engineers, full-stack engineers, and designers on product teams to deliver content to tens of millions of users Of course, this is just a sample of the kinds of work this role will require! You should assume that your role will encompass other tasks, too, and that your job duties and responsibilities may change from time to time at Etsy's discretion, or otherwise applicable with local law. Qualities that will help you thrive in this role are: You feel passionate about applying machine learning techniques in addressing real-world problems You have focused interest in one of the following fields: natural language processing, image processing, information retrieval, deep learning. You have some experience training, deploying, monitoring, debugging and iterating on production machine learning systems. You are proficient with databases, SQL, and scripting languages. You have successfully taken requirements from design through to delivery with a team. You write understandable, testable code and you have an eye towards maintainability. You care about the implications of your work on end users. Additional Information What's Next If you're interested in joining the team at Etsy, please share your resume with us and feel free to include a cover letter if you'd like. As we hope you've seen already, Etsy is a place that values individuality and variety. We don't want you to be like everyone else -- we want you to be like you! So tell us what you're all about. Our Promise At Etsy, we believe that a diverse, equitable and inclusive workplace furthers relevance, resilience, and longevity. We encourage people from all backgrounds, ages, abilities, and experiences to apply. Etsy is proud to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. If, due to a disability, you need an accommodation during any part of the interview process, please let your recruiter know. While Etsy supports visa sponsorship, sponsorship opportunities may be limited to certain roles and skills.",https://mx.linkedin.com/jobs/view/senior-machine-learning-engineer-i-ads-search-quality-at-etsy-4001828108,4001828108,"Etsy is hiring a Senior Machine Learning Engineer to join the Ads Search Quality team. This role involves building machine learning systems to enhance the sponsored search product, including retrieval, ranking, and user engagement modeling. Candidates will work cross-functionally, applying deep learning and machine learning to improve buyer and seller experiences, prototype large-scale ML models, and conduct A/B experiments to validate model efficiency. A focus on natural language processing, image processing, information retrieval, and deep learning is essential.","Machine Learning, Deep Learning, Natural Language Processing, Image Processing, SQL, Python, A/B Testing",,,True,,0,0,0,0,0,0,0,0,0,1,0,0,1,0,1,0,0
ML Strategy SA,Amazon Web Services (AWS),Mexico City Metropolitan Area,ON-SITE,,Full-time,IT Services and IT Consulting,2024-09-08 11:47:09.018617,25,Consulting,"Information Technology,",Engineering,"Description Are you passionate about Artificial Intelligence, Machine Learning, Deep Learning and Generative AI? Are you passionate about helping customers build solutions leveraging the state-of-the-art AI/ML/DL tools on Amazon Web Service (AWS)? Come join us! At Amazon, we’ve been investing deeply in artificial intelligence for over 20 years, and many of the capabilities customers experience are driven by machine learning. Amazon.com’s recommendations engine is driven by machine learning (ML), as are the paths that optimize robotic picking routes in our fulfillment centers. Our supply chain, forecasting, and capacity planning are also informed by ML algorithms. Alexa is fueled by Natural Language Understanding and Automated Speech Recognition deep learning; as is our drone initiative, Prime Air, and the computer vision technology in our new retail experience, Amazon Go. We have thousands of engineers at Amazon committed to machine learning and deep learning, and it’s a big part of our heritage. Within AWS, we’re focused on bringing that knowledge and capability to customers through three layers of the AI stack: 1) Frameworks and Infrastructure with tools like Apache MxNet and TensorFlow, 2) Machine Learning Platforms such as Amazon SageMaker for data scientists and 3) API-driven Services like Amazon Lex, Amazon Polly, Amazon Transcribe, Amazon Comprehend, and Amazon Rekognition to quickly add intelligence to applications. AWS is looking for a Machine Learning Solutions Architect (ML SA), who will be the Subject Matter Expert (SME) for helping customers in Brazil to design solutions that leverage the first and second tiers of our ML stack, ML Frameworks/Infrastructure and ML Platforms like Amazon SageMaker. You will partner with Solution Architects, Sales, Business Development and the AI Service teams to enable customer adoption and revenue attainment for Amazon SageMaker and Machine Learning/Deep Learning. You will develop white papers, blogs, reference implementations, labs, and presentations to evangelize AWS AI design patterns and best practices for Machine Learning in Amazon SageMaker and the AWS ML platform. Your Roles And Responsibilities Will Include Work with customer's development and data science teams to deeply understand their business and technical needs and design ML solutions that make the best use of Amazon SageMaker and other AWS Machine Learning platforms. Work with customers to optimize their machine learning and deep learning models in Amazon SageMaker and the AWS ML platform. Thought Leadership – Evangelize AWS ML platforms in Brazil and share ML & SageMaker best practices through forums such as AWS blogs, whitepapers, reference architectures and public-speaking events such as AWS Summit, AWS re:Invent, etc. Partner with SAs, Sales, Business Development and the AI Service teams to accelerate customer adoption and revenue attainment in Brazil of Amazon SageMaker and other AWS ML Platforms. Act as a technical liaison between customers and the AWS machine learning engineering teams to provide customer driven product improvement feedback. Develop and support an AWS internal community of machine learning subject matter experts in Brazil. Basic Qualifications 3+ years working as a data scientist 3+ years design/implementation/consulting experience of Machine Learning/AI/Deep Learning solutions. Strong expertise with machine learning and deep learning models. Solid grounding in statistics, probability theory, data modeling, machine learning algorithms and software development techniques and languages used to implement analytics solutions. Deep experience with data modeling and Big Data solution stacks. Deep knowledge in enterprise IT technologies, including databases, storage, and networks Deep experience with one or more Deep Learning frameworks such as Apache MxNet, TensorFlow, PyTorch, Keras, Gluon, Chainer, CNTK, etc. Technical consulting and architecture with large-scale engagements. Technical degree with statistical fundamentals required. Experience using and adapting to new technologies. Preferred Qualifications Professional experience architecting/operating solutions built on AWS Experience communicating effectively across internal and external organizations, for complex mission-critical solutions Experience with predictive analytics, semi- and unstructured data Experience deploying production-grade machine learning solutions on public platforms Data science background and experience manipulating/transforming data, model selection, model training, cross-validation and deployment at scale. Experience with Machine and Deep Learning toolkits such as MXNet, TensorFlow, Caffe and Torch. Experience with AWS services related to AI/ML highly desirable, particularly Amazon SageMaker, AWS Glue, Amazon EMR, AWS Lambda, IoT, Amazon DynamoDB, Amazon S3, Amazon EC2 Container Service, Greengrass, etc. Company - Amazon Web Services Mexico S. de R.L. de C.V. Job ID: A2766857",https://mx.linkedin.com/jobs/view/ml-strategy-sa-at-amazon-web-services-aws-4020270660,4020270660,"Are you passionate about Artificial Intelligence, Machine Learning, Deep Learning, and Generative AI? As a Machine Learning Solutions Architect, you will help customers design solutions leveraging AWS AI stack, optimize machine learning models using Amazon SageMaker, and evangelize AWS AI design patterns and best practices. Your responsibilities include collaborating with customer teams, developing white papers and blogs, and acting as a technical liaison.","Machine Learning, Deep Learning, Artificial Intelligence, Amazon SageMaker, Apache MxNet, TensorFlow, PyTorch, Keras, Gloun, Chainer, CNTK, AWS, Data Modeling, Big Data Solutions",3+,,True,3.0,0,0,1,1,0,1,0,1,0,0,0,0,1,0,0,0,0
Desarrollador Big Data,IRIUM,Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,Internet Publishing,2023-12-20 11:47:09.018617,45,Engineering,Information Technology,,"En IRIUM nos encontramos en búsqueda de Desarrollador Big Data con el siguiente perfil: Requisitos: Ingeneria en sistemas computacionales o afín Conocimientos básicos de procesamiento de datos y plataformas big data Experiencia en spark, scala, python, programación orientada a objetos Conocimiento o nociones de arquitectura Datio (deseable no obligatorio) Actividades: Desarrollo de procesos de ingesta y ajustes a reglas de transformación de datos Diseño de repositorios para transportación de datos Procesos de validación de datos Ofrecemos: Sueldo Neto Mensual : $45,000 Netos Esquema de Trabajo: Hibrido (3 Días en Oficina y 2 HO) – Obligatorio Zona de Trabajo: Parques Polanco Esquema de Pago: 100% nómina Prestaciones de ley únicamente Powered by JazzHR 5gjQJAbJyB",https://mx.linkedin.com/jobs/view/desarrollador-big-data-at-irium-3787903093,3787903093,"We are looking for a Big Data Developer with the following profile: Requirements: Bachelor's degree in Computer Systems Engineering or related field. Basic knowledge of data processing and big data platforms. Experience in Spark, Scala, Python, and object-oriented programming. Knowledge of Datio architecture (desirable but not mandatory). Activities: Development of ingestion processes and adjustments to data transformation rules. Design of repositories for data transportation. Data validation processes.","Spark, Scala, Python, Object-Oriented Programming",,Bachelor,False,,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0
"Cloud Engineer, AI, Google Cloud (English, Spanish)",Google,Mexico City Metropolitan Area,ON-SITE,,Full-time,"Information Services and Technology, Information and Internet",2024-09-08 11:47:09.018617,41,Project Management,"Consulting,",Engineering,"Only applications of candidates with Mexican citizenship will be evaluated for this role in compliance with the provisions of Article 7 of the Federal Labor Law. Please submit your resume in English - we can only consider applications submitted in this language. Minimum qualifications: Bachelor's degree in Computer Science or equivalent practical experience. 4 years of experience building machine learning solutions and working with technical customers. Experience coding in one or more general purpose languages (e.g.,Python, Java, Go, C or C++) including data structures, algorithms, and software design. Experience designing cloud enterprise solutions and supporting customer projects to completion. Ability to communicate in English and Spanish fluently to engage with local stakeholders. Preferred qualifications: Experience working with recommendation engines, data pipelines, or distributed machine learning. Experience with deep learning frameworks (e.g. Tensorflow, pyTorch, XGBoost). Knowledge of data warehousing concepts, including data warehouse technical architectures, infrastructure components, ETL/ ELT and reporting/analytic tools and environments (e.g.,Apache Beam, Hadoop, Spark, Pig, Hive, MapReduce, Flume). Understanding of auxiliary practical concerns in production machine learning systems. About The Job The Google Cloud Consulting Professional Services team guides customers through the moments that matter most in their cloud journey to help businesses thrive. We help customers transform and evolve their business through the use of Google’s global network, web-scale data centers, and software infrastructure. As part of an innovative team in this rapidly growing business, you will help shape the future of businesses of all sizes and use technology to connect with customers, employees, and partners. As a Cloud AI Engineer, you will design and implement machine learning solutions for customer use cases, leveraging core Google products including TensorFlow, DataFlow, and Vertex AI. You will work with customers to identify opportunities to apply machine learning in their business, and travel to customer sites to deploy solutions and deliver workshops to educate and empower customers. Additionally, you will work with Product Management and Product Engineering to build and constantly drive excellence in our products. In this role, you will be working with aspiring Cloud customers. You will support customer implementation of Google Cloud products through: architecture guidance, best practices, data migration, capacity planning, implementation, troubleshooting, monitoring, etc. Google Cloud accelerates every organization’s ability to digitally transform its business and industry. We deliver enterprise-grade solutions that leverage Google’s cutting-edge technology, and tools that help developers build more sustainably. Customers in more than 200 countries and territories turn to Google Cloud as their trusted partner to enable growth and solve their most critical business problems. Responsibilities Be a trusted technical advisor to customers and solve complex machine learning issues. Coach customers on the practical test in machine learning systems: feature extraction and feature definition, data validation, monitoring, and management of features and models. Work with Customers, Partners, and Google Product teams to deliver tailored solutions into production. Create and deliver best practice recommendations, tutorials, blog articles, and sample code. Travel up to 30% of time in-region for meetings, technical reviews, and onsite delivery activities as needed. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",https://mx.linkedin.com/jobs/view/cloud-engineer-ai-google-cloud-english-spanish-at-google-4013913303,4013913303,"Only applications of candidates with Mexican citizenship will be evaluated. Minimum qualifications include a Bachelor's degree in Computer Science or equivalent practical experience, along with 4 years of experience building machine learning solutions. Experience coding in general-purpose languages like Python, Java, Go, C, or C++, along with knowledge of data structures, algorithms, and software design is required. Candidates should have experience designing cloud enterprise solutions and supporting customer projects. Ability to communicate effectively in English and Spanish is necessary. Preferred qualifications include experience with recommendation engines, data pipelines, distributed machine learning, and deep learning frameworks such as TensorFlow, PyTorch, XGBoost. Knowledge of data warehousing concepts, ETL/ELT processes, and reporting tools is beneficial.","Python, Java, Go, C, C++, TensorFlow, PyTorch, XGBoost, Apache Beam, Hadoop, Spark, Pig, Hive, MapReduce, Flume",4,Bachelor,True,4.0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,1,0,0
"Sr ML Engineer (AzureML, MLOps)",Syneos Health,Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,"Biotechnology Research, Pharmaceutical Manufacturing, and Research Services",2024-08-16 11:47:09.018617,25,Engineering,Information Technology,,"Description JOB TITLE: Sr ML Engineer (MLOps) Syneos Health is the only fully integrated biopharmaceutical solutions organization purpose-built to accelerate customer success. We lead with a product development mindset, seamlessly connecting our capabilities to add high-value insights to speed therapies to patients and provide practical value to help our customers achieve their objectives. Every day we perform better because of how we work together, as one team, each the best at what we do. We bring many talented experts together across a wide range of business-critical services that support our business. Every role within Corporate is vital to furthering our vision of Shortening the Distance from Lab to Life®. Discover what our 30,000 employees, across 110 countries already know: WORK HERE MATTERS EVERYWHERE Why Syneos Health #SyneosHealthLife means we’re committed to our Total Self-culture – where everyone can authentically be themselves. Our Total Self-culture is what unites us globally, and we know every person’s unique contributions make a difference. We believe our success is a direct result of the people who are driving it – you! We value your dedication to caring for our customers and patients, so we want to focus on taking care of you. That’s why we offer a comprehensive benefits program encompassing your total health - physical, mental, and financial. We are continuously building the company we all want to work for and our customers want to work with. Why? Because when we bring together diversity of thoughts, backgrounds, cultures, and perspectives – we’re able to create a place where everyone feels like they belong. Job Summary We are actively seeking a dedicated Azure MLOps Engineer to play a crucial role in our Data Science team's mission. At Syneos Health, we recognize the pivotal role our MLOps team plays in unlocking the full potential of data science, enabling us to deliver unparalleled value through scalable applications. This role offers the unique opportunity to collaborate with our expert data science team, leading the design, implementation, and optimization of machine learning systems on the Azure cloud platform. Your contributions will be vital in establishing robust ML pipelines that empower our data scientists to efficiently develop, deploy, and monitor predictive models, leveraging the comprehensive tools available in Azure's Machine Learning ecosystem. Job Responsibilities Collaborate within an agile, cross-functional team to understand data scientists' needs and build efficient pipelines in response. Develop, maintain, and optimize Azure ML pipelines for quick, dependable model training, deployment, and evaluation. Employ Azure's monitoring tools to track model performance, ensuring sustained accuracy and reliability. Advance our model deployment strategy within Azure, incorporating best practices for version control and rollback mechanisms. Partner with the data platform team to refine our data infrastructure, fostering a productive feedback loop. Conduct Azure MLOps training for team members, promoting adherence to industry best practices. Qualifications QUALIFICATION REQUIREMENTS A Bachelor’s degree in Computer Science, Engineering, Mathematics, or a related field is required. A Master’s degree or PhD is highly desirable. Demonstrable experience in an MLOps, Data Engineering, or similar role within a data-centric organization. Profound understanding and hands-on experience with the Azure cloud platform, specifically Azure Machine Learning and related AI services. Knowledge of machine learning frameworks (e.g., TensorFlow, PyTorch) and foundational machine learning principles. Experience with Azure-specific data pipeline and workflow management tools (e.g., Azure Data Factory, Azure Pipelines). Proficiency in Python and SQL. Experience with additional programming languages is beneficial. Exceptional problem-solving abilities, meticulous attention to detail, and the capacity for innovative thinking. Outstanding communication skills, capable of demystifying complex technical subjects for a non-technical audience. Tech Stack Azure Cloud Services Azure Data Factory Azure Machine Learning At  Syneos Health, we believe in providing an environment and culture in which Our People can thrive, develop and advance. We reward and recognize our people by providing valuable benefits and a quality-of-life balance. The benefits for this position include a company car or car allowance, Health benefits to include Medical, Dental and Vision, Company match 401k, eligibility to participate in Employee Stock Purchase Plan, Eligibility to earn commissions/bonus based on company and individual performance, and flexible paid time off (PTO) and sick time. Because certain states and municipalities have regulated paid sick time requirements, eligibility for paid sick time may vary depending on where you work. Syneos complies with all applicable federal, state, and municipal paid sick time requirements. The annual base salary (US Only) for this position ranges from $102,600 to $178,600. The base salary range represents the anticipated low and high of the Syneos Health range for this position. Actual salary will vary based on various factors such as the candidate’s qualifications, skills, competencies, and proficiency for the role. Get to know Syneos Health Over the past 5 years, we have worked with 94% of all Novel FDA Approved Drugs, 95% of EMA Authorized Products and over 200 Studies across 73,000 Sites and 675,000+ Trial patients. No matter what your role is, you’ll take the initiative and challenge the status quo with us in a highly competitive and ever-changing environment. Learn more about Syneos Health. Additional Information Tasks, duties, and responsibilities as listed in this job description are not exhaustive. The Company, at its sole discretion and with no prior notice, may assign other tasks, duties, and job responsibilities. Equivalent experience, skills, and/or education will also be considered so qualifications of incumbents may differ from those listed in the Job Description. The Company, at its sole discretion, will determine what constitutes as equivalent to the qualifications described above. Further, nothing contained herein should be construed to create an employment contract. Occasionally, required skills/experiences for jobs are expressed in brief terms. Any language contained herein is intended to fully comply with all obligations imposed by the legislation of each country in which it operates, including the implementation of the EU Equality Directive, in relation to the recruitment and employment of its employees. The Company is committed to compliance with the Americans with Disabilities Act, including the provision of reasonable accommodations, when appropriate, to assist employees or applicants to perform the essential functions of the job.",https://mx.linkedin.com/jobs/view/sr-ml-engineer-azureml-mlops-at-syneos-health-3986684143,3986684143,"We are actively seeking a dedicated Azure MLOps Engineer to play a crucial role in our Data Science team's mission. The position involves collaborating within an agile, cross-functional team to understand data scientists' needs and build efficient pipelines. Responsibilities include developing, maintaining, and optimizing Azure ML pipelines for model training, deployment, and evaluation, employing Azure's monitoring tools to track model performance, and advancing model deployment strategies within Azure. A Bachelor's degree in Computer Science, Engineering, Mathematics, or a related field is required, with a Master’s degree or PhD highly desirable. The ideal candidate should have demonstrable experience in an MLOps, Data Engineering, or similar role, profound understanding of the Azure cloud platform, and proficiency in Python and SQL.","Azure Cloud Services, Azure Data Factory, Azure Machine Learning, Python, SQL, TensorFlow, PyTorch",,Bachelor,True,,0,0,0,1,0,0,0,0,0,1,0,0,1,0,1,0,0
ML Strategy SA,myGwork - LGBTQ+ Business Community,Mexico City Metropolitan Area,ON-SITE,,Full-time,"Technology, Information and Internet",2024-09-08 11:47:09.018617,25,Other,,,"This job is with Amazon, an inclusive employer and a member of myGwork – the largest global platform for the LGBTQ+ business community. Please do not contact the recruiter directly. Description Are you passionate about Artificial Intelligence, Machine Learning, Deep Learning and Generative AI? Are you passionate about helping customers build solutions leveraging the state-of-the-art AI/ML/DL tools on Amazon Web Service (AWS)? Come join us! At Amazon, we've been investing deeply in artificial intelligence for over 20 years, and many of the capabilities customers experience are driven by machine learning. Amazon.com's recommendations engine is driven by machine learning (ML), as are the paths that optimize robotic picking routes in our fulfillment centers. Our supply chain, forecasting, and capacity planning are also informed by ML algorithms. Alexa is fueled by Natural Language Understanding and Automated Speech Recognition deep learning; as is our drone initiative, Prime Air, and the computer vision technology in our new retail experience, Amazon Go. We have thousands of engineers at Amazon committed to machine learning and deep learning, and it's a big part of our heritage. Within AWS, we're focused on bringing that knowledge and capability to customers through three layers of the AI stack: 1) Frameworks and Infrastructure with tools like Apache MxNet and TensorFlow, 2) Machine Learning Platforms such as Amazon SageMaker for data scientists and 3) API-driven Services like Amazon Lex, Amazon Polly, Amazon Transcribe, Amazon Comprehend, and Amazon Rekognition to quickly add intelligence to applications. AWS is looking for a Machine Learning Solutions Architect (ML SA), who will be the Subject Matter Expert (SME) for helping customers in Brazil to design solutions that leverage the first and second tiers of our ML stack, ML Frameworks/Infrastructure and ML Platforms like Amazon SageMaker. You will partner with Solution Architects, Sales, Business Development and the AI Service teams to enable customer adoption and revenue attainment for Amazon SageMaker and Machine Learning/Deep Learning. You will develop white papers, blogs, reference implementations, labs, and presentations to evangelize AWS AI design patterns and best practices for Machine Learning in Amazon SageMaker and the AWS ML platform. Your Roles And Responsibilities Will Include Work with customer's development and data science teams to deeply understand their business and technical needs and design ML solutions that make the best use of Amazon SageMaker and other AWS Machine Learning platforms. Work with customers to optimize their machine learning and deep learning models in Amazon SageMaker and the AWS ML platform. Thought Leadership - Evangelize AWS ML platforms in Brazil and share ML & SageMaker best practices through forums such as AWS blogs, whitepapers, reference architectures and public-speaking events such as AWS Summit, AWS re:Invent, etc. Partner with SAs, Sales, Business Development and the AI Service teams to accelerate customer adoption and revenue attainment in Brazil of Amazon SageMaker and other AWS ML Platforms. Act as a technical liaison between customers and the AWS machine learning engineering teams to provide customer driven product improvement feedback. Develop and support an AWS internal community of machine learning subject matter experts in Brazil. Basic Qualifications 3+ years working as a data scientist 3+ years design/implementation/consulting experience of Machine Learning/AI/Deep Learning solutions. Strong expertise with machine learning and deep learning models. Solid grounding in statistics, probability theory, data modeling, machine learning algorithms and software development techniques and languages used to implement analytics solutions. Deep experience with data modeling and Big Data solution stacks. Deep knowledge in enterprise IT technologies, including databases, storage, and networks Deep experience with one or more Deep Learning frameworks such as Apache MxNet, TensorFlow, PyTorch, Keras, Gluon, Chainer, CNTK, etc. Technical consulting and architecture with large-scale engagements. Technical degree with statistical fundamentals required. Experience using and adapting to new technologies. Preferred Qualifications Professional experience architecting/operating solutions built on AWS Experience communicating effectively across internal and external organizations, for complex mission-critical solutions Experience with predictive analytics, semi- and unstructured data Experience deploying production-grade machine learning solutions on public platforms Data science background and experience manipulating/transforming data, model selection, model training, cross-validation and deployment at scale. Experience with Machine and Deep Learning toolkits such as MXNet, TensorFlow, Caffe and Torch. Experience with AWS services related to AI/ML highly desirable, particularly Amazon SageMaker, AWS Glue, Amazon EMR, AWS Lambda, IoT, Amazon DynamoDB, Amazon S3, Amazon EC2 Container Service, Greengrass, etc.",https://mx.linkedin.com/jobs/view/ml-strategy-sa-at-mygwork-lgbtq%2B-business-community-4019520343,4019520343,"AWS is looking for a Machine Learning Solutions Architect who will be the Subject Matter Expert for helping customers in Brazil design solutions that leverage machine learning frameworks and platforms like Amazon SageMaker. Responsibilities include optimizing machine learning and deep learning models, evangelizing AWS ML platforms, and developing materials to share best practices. The role requires strong expertise in machine learning, deep learning frameworks, and solid knowledge of enterprise IT technologies.","AWS, Amazon SageMaker, Apache MxNet, TensorFlow, PyTorch, Keras, Gluon, Chainer, CNTK, SQL, Big Data, Machine Learning Algorithms",3+,,True,3.0,0,0,1,1,0,0,0,0,0,1,0,0,1,0,0,0,0
Principal Clinical Data Science Lead,ICON plc,Mexico City Metropolitan Area,ON-SITE,,Full-time,Biotechnology Research,2024-09-01 11:47:09.018617,25,Education,Training,,"Principal Clinical Data Science Lead - Mexico, Mexico City ICON plc is a world-leading healthcare intelligence and clinical research organization. We’re proud to foster an inclusive environment driving innovation and excellence, and we welcome you to join us on our mission to shape the future of clinical development. We are currently seeking a Principal Clinical Data Science Lead to join our diverse and dynamic team. We have an incredible opportunity for a Principal Clinical Data Science Lead to join ICON's Full Service IOD Clinical Data Science team What You Will Be Doing: The Principal Clinical Data Science Lead (Principal CDSL) leads and serves as the primary contact for end-to-end data review activities performed on clinical trials. They are accountable for achieving clinical data science deliverables on-time, with high-quality, and to agreed financial metrics. The Principal CDSL will serve as the primary point of contact for internal and external team members regarding clinical data review activities and lead these data review activities to ensure delivery of data fit for analysis. They will provide input into clinical system development activities and clinical risk management activities. Develops and oversees timeliness of clinical data science activities during the life cycle of studies as it relates to data review and data delivery milestones Participates in Sponsor and/or third-party audits Forecasts budget, hours, and resourcing for clinical data review activities Performs analytic review as defined in the scope of work and functional plans focusing on errors that matter or have a meaningful impact on the safety of the subject or interpretation of the final analysis Accountable for the development of planning documents related to data review, data analytics, and data deliverables Establishes approach and leads resources to achieve operational and strategic plans Travel (approximately 15%) domestic and/or international Your Profile:: 8+ years of clinical data management experience in a clinical research organization or pharmaceutical company 2+ years of experience working in a clinical research organization (CRO) Experience with all steps within the data science lifecycle and most major data science study tasks, with proficiency in at least one Clinical Data Management system required (e.g., Rave, Inform, Oracle Clinical, OCRDC, UX EDC) Strong project management skills with experience leading multiple projects simultaneously Excellent leadership and communication skills Budget and timeline management experience Data Analytic and Data Validation experience Established Mentor and/or SME experience Bachelor’s degree or local equivalent Equivalent combination of education, training, and relevant experience may be considered in place of the education and experience stated above. All employees must read, write, and speak fluent English and host country language. What ICON can offer you: Our success depends on the quality of our people. That’s why we’ve made it a priority to build a diverse culture that rewards high performance and nurtures talent. In addition to your competitive salary, ICON offers a range of additional benefits. Our benefits are designed to be competitive within each country and are focused on well-being and work life balance opportunities for you and your family. Our benefits examples include: Various annual leave entitlements A range of health insurance offerings to suit you and your family’s needs. Competitive retirement planning offerings to maximize savings and plan with confidence for the years ahead. Global Employee Assistance Programme, LifeWorks, offering 24-hour access to a global network of over 80,000 independent specialized professionals who are there to support you and your family’s well-being. Life assurance Flexible country-specific optional benefits, including childcare vouchers, bike purchase schemes, discounted gym memberships, subsidized travel passes, health assessments, among others. Visit our careers site to read more about the benefits ICON offers. ICON, including subsidiaries, is an equal opportunity and inclusive employer and is committed to providing a workplace free of discrimination and harassment. All qualified applicants will receive equal consideration for employment without regard to race, colour, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. If, because of a medical condition or disability, you need a reasonable accommodation for any part of the application process, or in order to perform the essential functions of a position, please let us know or submit a request here Interested in the role, but unsure if you meet all of the requirements? We would encourage you to apply regardless – there’s every chance you’re exactly what we’re looking for here at ICON whether it is for this or other roles. Are you a current ICON Employee? Please click here to apply",https://mx.linkedin.com/jobs/view/principal-clinical-data-science-lead-at-icon-plc-3934858307,3934858307,"The Principal Clinical Data Science Lead leads and serves as the primary contact for end-to-end data review activities performed on clinical trials. They are accountable for achieving clinical data science deliverables on time, with high quality. This position involves participating in audits, forecasting budget and resourcing, performing analytic reviews, and managing operational plans.","Clinical Data Management systems (e.g., Rave, Inform, Oracle Clinical, OCRDC, UX EDC), Data Analytics, Data Validation",8+ years,Bachelor,True,8.0,0,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0
"Cloud Technical Solutions Engineer, Data Analytics",Google,Mexico City Metropolitan Area,ON-SITE,,Full-time,"Information Services and Technology, Information and Internet",2024-09-01 11:47:09.018617,43,Project Management,"Consulting,",Engineering,"Only applications of candidates with Mexican citizenship will be evaluated for this role in compliance with the provisions of Article 7 of the Federal Labor Law. Please submit your resume in English - we can only consider applications submitted in this language. Minimum qualifications: Bachelor’s degree in Science, Technology, Engineering, Mathematics, or equivalent practical experience. 2 years of experience reading or debugging code (e.g., in one or more of the following: Java, C, C++, .NET, Python, Shell, Perl, JavaScript). 2 years of experience in technical support, professional services, software development, or product operations management. Experience in advocating for customer needs. Preferred qualifications: Experience with distributed, columnar or analytic oriented databases or distributed data processing frameworks. Experience in data analytics, warehousing, ETL development, data science or other Big Data applications. Experience with open source distributed storage and processing utilities in the Apache Hadoop family or workflow orchestration products. Understanding of basic web technologies. Understanding of TCP/IP concepts, Unix/Linux basic administration and commands. Excellent troubleshooting, attention to detail, and communication skills in a fast-paced setting. About The Job In this role you will provide support to the customers seamlessly making the switch to Google Cloud. When customers cannot resolve issues themselves, you will ensure that we have the necessary tools and processes to swiftly resolve the issue. You will troubleshoot technical problems for customers with a mix of debugging, networking, system administration, updating documentation, and when needed, coding/scripting. Our Technical Solutions team is focused on customer needs and you will help Google Cloud by understanding and advocating for our customers issues. You will be required to work in a Shift Pattern or non-standard work hours as required. This may include weekend work. Google Cloud accelerates every organization’s ability to digitally transform its business and industry. We deliver enterprise-grade solutions that leverage Google’s cutting-edge technology, and tools that help developers build more sustainably. Customers in more than 200 countries and territories turn to Google Cloud as their trusted partner to enable growth and solve their most critical business problems. Responsibilities Manage customer issues through effective diagnosis, resolution, or implementation of new investigation tools to increase productivity for customer issues on Google Cloud Platform products. Understand Google's product technology and architectures by troubleshooting, reproducing, determining the root cause for customer reported issues, and building tools for faster diagnosis. Act as a consultant and subject matter expert for internal stakeholders in engineering, sales, and customer organizations to resolve technical deployment obstacles and improve Google Cloud. Work as part of a team of engineers/consultants that globally ensure 24-hour customer support. This will include a need to sometimes work non-standard work hours or shifts. Understand customer issues and advocate for their needs with cross-functional teams, including product and engineering teams to find ways to improve the product and drive quality production. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",https://mx.linkedin.com/jobs/view/cloud-technical-solutions-engineer-data-analytics-at-google-4011347497,4011347497,"Only applications of candidates with Mexican citizenship will be evaluated for this role. Minimum qualifications: Bachelor’s degree in Science, Technology, Engineering, Mathematics, or equivalent practical experience. 2 years of experience reading or debugging code in languages such as Java, C, C++, .NET, Python, Shell, Perl, JavaScript. 2 years of experience in technical support, professional services, software development, or product operations management. Responsibilities include managing customer issues through diagnosis and resolution, troubleshooting technical problems, and advocating for customer needs with cross-functional teams.","Java, C, C++, .NET, Python, Shell, Perl, JavaScript, Apache Hadoop, Data Analytics, ETL Development, Unix/Linux",2 years,Bachelor,True,2.0,0,0,1,0,0,1,1,0,0,0,0,0,0,0,1,0,0
Data Platform Engineer,Apexon,Mexico City Metropolitan Area,ON-SITE,Entry level,Full-time,IT Services and IT Consulting,2024-08-25 11:47:09.018617,25,Engineering,Information Technology,,"Company Description: Apexon is a digital-first technology services firm backed by Goldman Sachs Asset Management and Everstone Capital. We specialize in accelerating business transformation and delivering human-centric digital experiences. For over 17 years, Apexon has been meeting customers wherever they are in the digital lifecycle and helping them outperform their competition through speed and innovation. Job Title: Data Platform Engineer Location: Mexico Job Description: We are seeking skilled Data Platform Engineers to join our expanding data engineering team. These positions are critical to our ongoing efforts to build and optimize our data infrastructure within the AWS ecosystem. You will play a key role in ensuring that our data pipelines are robust, scalable, and capable of supporting the needs of our analytics and data science teams. Key Responsibilities: Develop and Maintain Data Pipelines: Write efficient Python code within Airflow pipelines to automate the ingestion, transformation, and loading of data into Snowflake. Data Integration and API Development: Build and maintain integrations and APIs to facilitate data exchange between various systems and platforms. Data Warehouse Construction: Design, build, and populate data warehouses, ensuring data is structured optimally for querying and analysis. Data Quality and Transformation: Implement data quality checks, de-identification, and tokenization processes to maintain data integrity and privacy. Documentation: Prepare detailed data processing and design documentation, ensuring that all data engineering processes are well-documented and easily understandable by other team members. Technical Requirements: Programming: Proficiency in Python, particularly with PySpark. AWS Services: Experience with AWS Glue, Airflow (MWAA), and other relevant AWS services. Data Warehousing: Hands-on experience with Snowflake or similar data warehousing solutions. ETL/ELT Processes: Strong understanding of data ingestion, transformation, and loading processes. Data Quality: Experience implementing data quality checks and data privacy techniques such as de-identification and tokenization. Qualifications: Education: Bachelor’s degree in Computer Science, Engineering, or related field (or equivalent experience). Experience: 3-5 years of experience in data engineering or a related field. Communication: Strong written and verbal communication skills, with the ability to clearly articulate technical concepts to both technical and non-technical stakeholders. Location: Preference for candidates based in Mexico. Disclaimer: If you feel that this is a good match for your skillsets, please submit a current word version of your resume along with a cover letter describing your skills, experience and salary expectations. We are an Equal Opportunity Employer (EOE). You can read our job applicant privacy policy here .",https://mx.linkedin.com/jobs/view/data-platform-engineer-at-apexon-4009947298,4009947298,"We are seeking skilled Data Platform Engineers to join our expanding data engineering team. These positions are critical to building and optimizing our data infrastructure within the AWS ecosystem, ensuring data pipelines are robust, scalable, and capable of supporting the needs of our analytics and data science teams. Responsibilities include writing efficient Python code within Airflow pipelines to automate data ingestion and transformation, building data integrations and APIs, designing and constructing data warehouses, implementing data quality checks, and preparing documentation.","Python, PySpark, Airflow, AWS Glue, Snowflake, ETL, ELT",3-5 years,Bachelor,True,3.0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,1,0,0
Principal Data Analytics Engineer (Mex - Arg),Stori,Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,"Technology, Information and Internet",2024-04-18 11:47:09.018617,25,Information Technology,,,"About Stori Stori is a fast-growing, venture-backed financial technology company, on a mission to democratize credit access for 400 million underbanked LatAm consumers. Stori currently operates in Mexico and has a global team with offices in Arlington Virginia, Mexico City, and Asia. We have quickly made our mark as one of the top digital banks in Mexico with more than two million applicants for our credit card product since launching. Stori is one of the top-funded startups in the region with US$250 million raised to date. We are backed by top global venture capital funds, such as GGV Capital, GIC, Lightspeed Venture Partners, General Catalyst, Goodwater Capital, Mexico's Tresalia Capital, Vision Plus Capital, BAI Capital and Source Code Capital; who have successfully invested in startups such as Affirm, Airbnb, Alibaba, Stripe, and TikTok. Stori has a standout founder team among fintechs, leveraging 100+ years of accumulated experience in consumer finance, banking and technology across Mastercard, Intel, Capital One, Morgan Stanley, GE Capital, and HSBC in the U.S., Mexico and Asia. The team has launched and managed many multi-million-customer credit card products globally, providing a wide breadth of experience and knowledge to our team. We welcome diversity of background, experience and thinking. Storians are passionate about our mission and take pride in the products we build. Our culture thrives off of a flat structure and an inclusive environment where all of our employees can be their authentic selves, with boundless opportunities for professional growth. The Role Main responsibilities: As an IC and tech lead, create, optimize, and share knowledge throughout the company about best practices on Airflow, DBT, Redshift/SQL, and Spark tools, when also making recommendations of new tools implementation that will improve the company delivery, performance, and resilience. Ensure our data warehouse performance by applying best practices on already created models while sharing best practices based on current usage individually and via group knowledge sharing. Build and maintain data pipelines using Redshift, Dynamo, Athena, Glue, Kinesis, SQS, Firehose, CDK, Step Functions, etc, with these pipelines will process gigabytes of information in batch and real-time. Facilitate design sessions, drive design decisions, and lead code reviews. Comfortable challenging assumptions to improve existing solutions and ensure the team builds the best data product possible. Act as a ""tech lead"" on both internal and cross-functional projects: work with the business team and engineering leadership to prioritize development roadmaps and plan future projects, prioritize and plan the team's work, communicate with stakeholders on progress, and unblock team members Attract and nurture talent, mentor, and develop a world-class engineering team. Hybrid Role What we are looking for: Experience : 8+ years of experience in software engineering with a strong focus on data 5+ years experience in building and managing high-performance engineering teams with an Agile framework 5+ years experience in building batch and real-time data pipelines that extract, transform, and load the data into analytical data warehouses or data lake Creative, resourceful, and enthusiastic about seeking new solutions to problems and opportunities Skills and attitudes Strong proficiency with Python Strong proficiency in SQL, git, Airflow, DBT, database optimization, Docker/ECS. Strong proficiency with a deployment framework (CDK, Cloudformation, Terraform, or Serverless Framework, etc). Familiarity with serverless technologies in AWS: S3, Lambda, Redshift, DynamoDB, Athena, Glue, EMR, Kinesis, SQS, Firehose, Step Functions. Able to create an End-to-end pipeline in Spark. Experience with CI/CD (Continuous Integration, Continuous Delivery), Automated Testing, Automated Delivery Bonus Points: Experience in building and maintaining data warehouse/data lake or large-scale real-time/batch customer feature data pipelines/microservices Experience with Spark-based tools like Databricks or Snowflake NodeJS Knowledge What we offer Make a positive impact on the lives of our customers via financial inclusion Professional development opportunities International exposure & work experience Company swag Legally required benefits",https://mx.linkedin.com/jobs/view/principal-data-analytics-engineer-mex-arg-at-stori-3867106462,3867106462,"As an individual contributor and tech lead, you will create, optimize, and share knowledge about best practices on Airflow, DBT, Redshift/SQL, and Spark tools, and recommend new tool implementations to improve company delivery, performance, and resilience. You will ensure data warehouse performance, build and maintain data pipelines using Redshift, Dynamo, Athena, Glue, Kinesis, SQS, Firehose, and CDK, process gigabytes of information in batch and real-time, drive design sessions, mentor a world-class engineering team, and act as a tech lead on various projects.","Python, SQL, Git, Airflow, DBT, Redshift, DynamoDB, Athena, Glue, Kinesis, SQS, Firehose, CDK, Step Functions, Docker, Terraform, Serverless Framework",8+ years,,True,8.0,0,0,1,0,1,0,0,0,0,1,0,1,0,0,1,0,0
"Business Intelligence Engineer, Supply Chain Data Science",Amazon,Mexico City Metropolitan Area,ON-SITE,,Full-time,Software Development,2024-09-13 11:47:09.018617,73,Strategy/Planning,"Analyst,",Information Technology,"Description Are you a data enthusiast? Does the world’s most complex logistic systems inspire your curiosity? Is your passion to navigate through hundreds of systems, processes, and data sources to solve the puzzles and identify the next big opportunity? Are you a creative big thinker who is passionate about using data and optimization tools to direct decision making and solve complex and large-scale challenges? Do you feel like your skills uniquely qualify you to bridge communication between teams with competing priorities? If so, then this position is for you! We are looking for a motivated individual with strong analytic and communication skills to join the effort in evolving the network we have today into the network we need tomorrow. Amazon’s extensive logistics system is comprised of thousands of fixed infrastructure nodes, with millions of possible connections between them. Billions of packages flow through this network on a yearly basis, making the impact of optimal improvements unparalleled. This magnificent challenge is a terrific opportunity to analyze Amazon’s data and generate actionable recommendations using optimization and simulation. Come build with us! This role will collaborate with diverse set of stakeholder including product managers, program managers, data scientists, software development engineers and other partner teams to analyze large data sets, prove and disprove hypothesis, automate existing solutions and build self-service dashboards and reports. Key job responsibilities E2E design and creation of data pipelines including harmonization of different data sources (Data base, API, user inputs and manual files) using SQL and other scripting language (R,Python,Rust), reporting and automation using Quicksight tableu or similar. Design of automations to send push out information of alerts, business insights etc. Project and stakeholder management Write high quality SQL code to retrieve and analyze data from database tables, and learn and understand a broad range of Amazon’s data resources and know how, when, and which to use and which not to use. Develop queries and visualizations for ad-hoc requests and projects, as well as ongoing reporting. Basic Qualifications Experience using SQL to pull data from a database or data warehouse and scripting experience (Python) to process data for modeling Experience in data mining, ETL, etc. and using databases in a business environment with large-scale, complex datasets Experience with data visualization using Tableau, Quicksight, or similar tools Bachelor's degree in sciences, engineering, finance or equivalent +3 years of experience in business intelligence or related role Fluent in Spanish and English (b2+) 2+ years of experience with AWS or similar. Preferred Qualifications Previous experience working with supply chain or logistics data Experience applying optimization models AWS Certification Company - Servicios Comerciales Amazon Mexico S. de R.L. de C.V. Job ID: A2720252",https://mx.linkedin.com/jobs/view/business-intelligence-engineer-supply-chain-data-science-at-amazon-3990434162,3990434162,"Are you a data enthusiast? Does the world’s most complex logistic systems inspire your curiosity? This position requires a motivated individual with strong analytic and communication skills to analyze large data sets, generate actionable recommendations using optimization and simulation, and collaborate with diverse stakeholders. Responsibilities include designing and creating data pipelines, reporting and automation using SQL and scripting languages, and developing queries and visualizations for ad-hoc requests. The role demands experience in using SQL for data extraction, scripting for data processing, and data visualization using tools like Tableau or Quicksight.","SQL, Python, R, Rust, AWS, Tableau, Quicksight",3+,Bachelor,True,3.0,0,0,0,1,0,0,0,0,1,1,0,0,0,0,1,0,0
Motion and Data Analysis Engineer,SEGULA Technologies,Mexico City Metropolitan Area,ON-SITE,Executive,Full-time,Automotive,2024-09-13 11:47:09.018617,91,Administrative,,,"Company Description Join the world of the future in a fast growing international company! At SEGULA Technologies you will have the opportunity to work on exciting projects and help shaping the future within an engineering company which is at the heart of innovation. From 3D printing, augmented reality, connected vehicle to the factory of the future – new technologies are part of our 13,000 ingenious collaborators’ day-to-day life. Would you like to join in? Whether you are a student, young graduate, engineer or experienced project manager, at SEGULA Technologies you will find the opportunity to give a new meaning to your career. Skills development is a big part of SEGULA Technologies ’ DNA, the company offers the possibility to move between sectors and positions, as well as attractive geographic mobility opportunities. SEGULA Technologies is always looking for new, ingenious, and daring talents worldwide to support all the major industrial actors within the automotive, aeronautics, energy, railway, naval, oil & gas and pharmaceutical sectors. Do you have a touch of genius? Take a new challenge and join us! For more information: https://www.segulatechnologies.com Job Description The Motion & Data Analysis Engineer is responsible to provide accurate studies of vehicle component displacement through video coverage obtained during vehicle crash tests and data analysis of data acquired during impact testing. This engineer must be capable to generate and analyze the 2D and 3D environments in order to create the optimal video camera setup at any facility. Qualifications Basic Qualifications:  Bachelor’s Degree in Engineering (Mechatronic Engineer / Mechanical Engineer /Electronic Engineer) applied sciences, physics, or related engineering field.  Knowledge of optics, photography, videography, kinematics, dynamics, and engineering statics a plus.  Basic understanding of programing concepts. Preferred Qualifications Imaging processing concepts Film analysis knowledge Familiarity with Hypergraph Data Analysis Software and Macros Basic familiarization with Safety Protocols",https://mx.linkedin.com/jobs/view/motion-and-data-analysis-engineer-at-segula-technologies-3971088862,3971088862,The Motion & Data Analysis Engineer is responsible for providing accurate studies of vehicle component displacement through video coverage obtained during vehicle crash tests and data analysis of data acquired during impact testing. This engineer must be capable of generating and analyzing the 2D and 3D environments to create the optimal video camera setup at any facility.,"Mechatronics, Mechanical Engineering, Electronic Engineering, Optics, Photography, Videography, Kinematics, Dynamics, Engineering Statics, Programming Concepts, Imaging Processing, Film Analysis, Hypergraph Data Analysis Software",,Bachelor,True,,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"Business Intelligence Engineer, Supply Chain Data Science",myGwork - LGBTQ+ Business Community,Mexico City Metropolitan Area,ON-SITE,Entry level,Full-time,"Technology, Information and Internet",2024-09-12 11:47:09.018617,25,Business Development,Sales,,"This job is with Amazon, an inclusive employer and a member of myGwork – the largest global platform for the LGBTQ+ business community. Please do not contact the recruiter directly. Description Are you a data enthusiast? Does the world's most complex logistic systems inspire your curiosity? Is your passion to navigate through hundreds of systems, processes, and data sources to solve the puzzles and identify the next big opportunity? Are you a creative big thinker who is passionate about using data and optimization tools to direct decision making and solve complex and large-scale challenges? Do you feel like your skills uniquely qualify you to bridge communication between teams with competing priorities? If so, then this position is for you! We are looking for a motivated individual with strong analytic and communication skills to join the effort in evolving the network we have today into the network we need tomorrow. Amazon's extensive logistics system is comprised of thousands of fixed infrastructure nodes, with millions of possible connections between them. Billions of packages flow through this network on a yearly basis, making the impact of optimal improvements unparalleled. This magnificent challenge is a terrific opportunity to analyze Amazon's data and generate actionable recommendations using optimization and simulation. Come build with us! This role will collaborate with diverse set of stakeholder including product managers, program managers, data scientists, software development engineers and other partner teams to analyze large data sets, prove and disprove hypothesis, automate existing solutions and build self-service dashboards and reports. Key job responsibilities E2E design and creation of data pipelines including harmonization of different data sources (Data base, API, user inputs and manual files) using SQL and other scripting language (R,Python,Rust), reporting and automation using Quicksight tableu or similar. Design of automations to send push out information of alerts, business insights etc. Project and stakeholder management Write high quality SQL code to retrieve and analyze data from database tables, and learn and understand a broad range of Amazon's data resources and know how, when, and which to use and which not to use. Develop queries and visualizations for ad-hoc requests and projects, as well as ongoing reporting. Basic Qualifications Experience using SQL to pull data from a database or data warehouse and scripting experience (Python) to process data for modeling Experience in data mining, ETL, etc. and using databases in a business environment with large-scale, complex datasets Experience with data visualization using Tableau, Quicksight, or similar tools Bachelor's degree in sciences, engineering, finance or equivalent +3 years of experience in business intelligence or related role Fluent in Spanish and English (b2+) 2+ years of experience with AWS or similar. Preferred Qualifications Previous experience working with supply chain or logistics data Experience applying optimization models AWS Certification",https://mx.linkedin.com/jobs/view/business-intelligence-engineer-supply-chain-data-science-at-mygwork-lgbtq%2B-business-community-4021452935,4021452935,"We are looking for a motivated individual with strong analytic and communication skills to evolve Amazon's logistics network, which consists of thousands of fixed infrastructure nodes and millions of connections. This role involves analyzing large datasets, generating actionable recommendations using optimization and simulation, and collaborating with various stakeholders, including product managers and data scientists. Key responsibilities include designing data pipelines, writing SQL code, developing queries, and creating visualizations. The candidate should have experience in business intelligence, data mining, ETL processes, and using databases in complex datasets.","SQL, Python, R, Rust, AWS, Tableau, Quicksight",3+,Bachelor,True,3.0,0,0,0,1,0,0,0,0,1,1,0,0,0,0,1,0,0
"Cloud Support Engineer I - Big Data, AWS",myGwork - LGBTQ+ Business Community,Mexico City Metropolitan Area,ON-SITE,Entry level,Full-time,"Technology, Information and Internet",2024-09-08 11:47:09.018617,25,Information Technology,,,"This job is with Amazon, an inclusive employer and a member of myGwork – the largest global platform for the LGBTQ+ business community. Please do not contact the recruiter directly. Description As a Cloud Support Engineer you will learn at an accelerated pace how to use and leverage many different cloud technologies to help our customers succeed. You will act as the Cloud Ambassador across AWS products, providing our customers with required tools and tactics to scale their impact in world-wide markets. The Big Data role supports our services that leverage data and produce business insights, which may include using machine learning/artificial intelligence (ML/AI). Helping our customers use and integrate Big Data services in what is arguably our industry's most exciting space. The portfolio of services covers EMR (Hadoop), DynamoDB (NoSQL), MangoDB, and Apache Cassandra. AWS Sales, Marketing, and Global Services (SMGS) is responsible for driving revenue, adoption, and growth from the largest and fastest growing small- and mid-market accounts to enterprise-level customers including public sector. The AWS Global Support team interacts with leading companies and believes that world-class support is critical to customer success. AWS Support also partners with a global list of customers that are building mission-critical applications on top of AWS services. Key job responsibilities Your day as a Cloud Support Engineer will include, but not be limited to, the following activities. You will be primarily responsible for solving customer's cases through a variety of contact channels (telephone, email, and web/live chat), applying advanced troubleshooting techniques to provide tailored solutions and working with them to dive deep into the root cause of an issue. You will drive initiatives that improve support-related processes and our customers' experience. These can include tutorials, how-to videos, technical articles, trainings, among others. You will leverage your customer support experience to provide feedback to internal AWS teams on how to improve our services, and work on critical, highly complex customer problems that may span multiple AWS services. You will be continuously learning groundbreaking technologies, and developing new technical skills and other professional competencies. You will act as interviewer in hiring processes, and coach/mentor new team members. This role requires the flexibility to work 5 days a week (occasionally on weekends) on a rotational basis. Schedules may align to Sunday - Thursday, Tuesday - Saturday or Monday - Friday. About The Team AWS Support Engineering is a customer-facing global organization that provides technical support to our customers as well as our internal teams. As a member our team, you will be at the forefront of this transformational technology, operating on a follow-the-sun model. You will be assisting a global list of companies and developers that are taking advantage of a growing set of services and features to run their mission-critical applications. Why AWS? Amazon Web Services (AWS) is the world's most comprehensive and broadly adopted cloud platform. We pioneered cloud computing and never stopped innovating — that's why customers from the most successful startups to Global 500 companies trust our robust suite of products and services to power their businesses. Inclusive Team Culture Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have more than thirteen employee-led affinity groups, reaching over 90,000 employees across hundreds of chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon's culture of inclusion is reinforced within our 16 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust. Work/Life Balance Our team puts a high value on work-life balance. It isn't about how many hours you spend at home or at work, it's about the flow you establish that brings energy to both parts of your life. We believe striking the right balance between your personal and professional life is critical to life-long happiness and fulfillment. We offer flexibility in working hours and encourage you to find your own balance between your work and personal lives. Mentorship & Career Growth Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we're building an environment that celebrates knowledge sharing and mentorship. Our senior members enjoy one-on-one mentoring and thorough, but kind, code reviews. We care about your career growth and strive to assign projects based on what will help each team member develop into a better-rounded Amazonian and enable them to take on more complex tasks in the future. Basic Qualifications 1+ year of experience with Hadoop ecosystems (Apache Spark or Hive) and/or data lake architecture and administration. Knowledge or experience with system administration, and troubleshooting any operating system (Linux and/or Windows) and networking. Ability to communicate effectively in English (written and spoken) within technical and business settings. Preferred Qualifications Bachelor's degree in Engineering/Computer Science/ Mathematics or related field. Knowledge or experience utilizing data analysis techniques such as quantitative or qualitative analysis. Knowledge or experience in various big data or distributed systems (NoSQL, search and streaming). Understanding of cloud computing concepts and/or experience with any cloud platforms (AWS, Azure, Google Cloud). Experience scripting or developing in one or more of the following languages: UNIX Shell, Python, R, Ruby, GO, Java, .NET (C#), JavaScript.",https://mx.linkedin.com/jobs/view/cloud-support-engineer-i-big-data-aws-at-mygwork-lgbtq%2B-business-community-4018434672,4018434672,"As a Cloud Support Engineer, you will learn how to use various cloud technologies to assist customers. This role involves providing support for services utilizing Big Data and may involve machine learning/artificial intelligence. You will solve customer issues through multiple contact channels and drive initiatives to improve support processes and customer experience. The role requires a flexible schedule and focuses on continuous learning and development of technical skills.","Hadoop, Apache Spark, Hive, EMR, DynamoDB, MongoDB, Apache Cassandra, UNIX Shell, Python, R, Ruby, GO, Java, .NET (C#), JavaScript",1+,Bachelor,True,1.0,0,1,1,0,0,0,0,0,0,1,0,0,0,0,1,0,0
Data Analytics Engineer Sr.,Stori,Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,"Technology, Information and Internet",2024-02-18 11:47:09.018617,25,Information Technology,,,"About Stori Stori is a fast-growing, venture-backed financial technology company, on a mission to democratize credit access for 400 million underbanked LatAm consumers. Stori currently operates in Mexico and has a global team with offices in Arlington Virginia, Mexico City, and Asia. We have quickly made our mark as one of the top digital banks in Mexico with more than two million applicants for our credit card product since launching. Stori is one of the top-funded startups in the region with US$250 million raised to date. We are backed by top global venture capital funds, such as GGV Capital, GIC, Lightspeed Venture Partners, General Catalyst, Goodwater Capital, Mexico's Tresalia Capital, Vision Plus Capital, BAI Capital and Source Code Capital; who have successfully invested in startups such as Affirm, Airbnb, Alibaba, Stripe, and TikTok. Stori has a standout founder team among fintechs, leveraging 100+ years of accumulated experience in consumer finance, banking and technology across Mastercard, Intel, Capital One, Morgan Stanley, GE Capital, and HSBC in the U.S., Mexico and Asia. The team has launched and managed many multi-million-customer credit card products globally, providing a wide breadth of experience and knowledge to our team. We welcome diversity of background, experience and thinking. Storians are passionate about our mission and take pride in the products we build. Our culture thrives off of a flat structure and an inclusive environment where all of our employees can be their authentic selves, with boundless opportunities for professional growth. The Role As a Sr Analytics Engineer at Stori you will leverage analytic and technical skills to innovate, build, and maintain well-managed data solutions and capabilities to tackle business problems. On any given day you will be challenged on three types of work – Innovation, Business Intelligence, and Data Management: Innovation Use Open Source/Digital technologies to mine complex, voluminous, and different varieties of data sources and platforms. Build well-managed data solutions, tools, and capabilities to enable self-service frameworks for data consumers. Demonstrate ability to explore and quickly grasp new technologies to progress varied initiatives. Business Intelligence Partner with the business to provide consultancy and translate the business needs to design and develop tools, techniques, metrics, and dashboards for insights and data visualization. Drive analysis that provides meaningful insights on business strategies. Data Management Drive an understanding and adherence to the principles of data quality management including metadata, lineage, and business definitions. Work with business teams to understand the business needs and translate them into technical requirements. Work collaboratively with appropriate Tech teams to manage security mechanisms and data access governance. Build and execute tools to monitor and report on data quality. Requirements A bachelor's degree or foreign equivalent in Engineering, Science, Operations Research, Information Technology, Statistics, Mathematics, Economics, Finance, Analytics, or a related quantitative analytical field. SQL and Python. Proven interpersonal, collaboration, diplomatic, influencing, planning, and organizational skills. Consistently demonstrate clear and concise written and verbal communication. Proven ability to effectively use complex analytical, interpretive, and problem-solving techniques Demonstrated ability to work under pressure and to meet tight deadlines with proactive, decisiveness, and flexibility. English Fluent/proficient. 2 or more years of experience in quantitative and qualitative analysis using SQL or Python. 2 or more years of working experience in data analytics or data management 2 or more years of experience in the finance industry What we offer Make a positive impact on the lives of our customers via financial inclusion Professional development opportunities International exposure & work experience Company swag Legally required benefits",https://mx.linkedin.com/jobs/view/data-analytics-engineer-sr-at-stori-3830416683,3830416683,"As a Sr Analytics Engineer, you will leverage analytic and technical skills to innovate, build, and maintain well-managed data solutions and capabilities to tackle business problems. Responsibilities include using Open Source technologies to mine data, developing tools for business intelligence, and managing data quality principles.","SQL, Python, Data Visualization, Data Management, Business Intelligence",2 or more years,Bachelor,True,2.0,0,0,0,0,0,1,1,0,0,1,0,0,0,0,1,0,0
"Cloud Support Engineer I - Big Data, AWS",Amazon Web Services (AWS),Mexico City Metropolitan Area,ON-SITE,Associate,Full-time,IT Services and IT Consulting,2024-09-08 11:47:09.018617,91,Information Technology,"Consulting,",Engineering,"Description As a Cloud Support Engineer you will learn at an accelerated pace how to use and leverage many different cloud technologies to help our customers succeed. You will act as the Cloud Ambassador across AWS products, providing our customers with required tools and tactics to scale their impact in world-wide markets. The Big Data role supports our services that leverage data and produce business insights, which may include using machine learning/artificial intelligence (ML/AI). Helping our customers use and integrate Big Data services in what is arguably our industry’s most exciting space. The portfolio of services covers EMR (Hadoop), DynamoDB (NoSQL), MangoDB, and Apache Cassandra. AWS Sales, Marketing, and Global Services (SMGS) is responsible for driving revenue, adoption, and growth from the largest and fastest growing small- and mid-market accounts to enterprise-level customers including public sector. The AWS Global Support team interacts with leading companies and believes that world-class support is critical to customer success. AWS Support also partners with a global list of customers that are building mission-critical applications on top of AWS services. Key job responsibilities Your day as a Cloud Support Engineer will include, but not be limited to, the following activities. You will be primarily responsible for solving customer’s cases through a variety of contact channels (telephone, email, and web/live chat), applying advanced troubleshooting techniques to provide tailored solutions and working with them to dive deep into the root cause of an issue. You will drive initiatives that improve support-related processes and our customers’ experience. These can include tutorials, how-to videos, technical articles, trainings, among others. You will leverage your customer support experience to provide feedback to internal AWS teams on how to improve our services, and work on critical, highly complex customer problems that may span multiple AWS services. You will be continuously learning groundbreaking technologies, and developing new technical skills and other professional competencies. You will act as interviewer in hiring processes, and coach/mentor new team members. This role requires the flexibility to work 5 days a week (occasionally on weekends) on a rotational basis. Schedules may align to Sunday - Thursday, Tuesday – Saturday or Monday - Friday. About The Team AWS Support Engineering is a customer-facing global organization that provides technical support to our customers as well as our internal teams. As a member our team, you will be at the forefront of this transformational technology, operating on a follow-the-sun model. You will be assisting a global list of companies and developers that are taking advantage of a growing set of services and features to run their mission-critical applications. Why AWS? Amazon Web Services (AWS) is the world’s most comprehensive and broadly adopted cloud platform. We pioneered cloud computing and never stopped innovating — that’s why customers from the most successful startups to Global 500 companies trust our robust suite of products and services to power their businesses. Inclusive Team Culture Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have more than thirteen employee-led affinity groups, reaching over 90,000 employees across hundreds of chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 16 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust. Work/Life Balance Our team puts a high value on work-life balance. It isn’t about how many hours you spend at home or at work, it’s about the flow you establish that brings energy to both parts of your life. We believe striking the right balance between your personal and professional life is critical to life-long happiness and fulfillment. We offer flexibility in working hours and encourage you to find your own balance between your work and personal lives. Mentorship & Career Growth Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. Our senior members enjoy one-on-one mentoring and thorough, but kind, code reviews. We care about your career growth and strive to assign projects based on what will help each team member develop into a better-rounded Amazonian and enable them to take on more complex tasks in the future. Basic Qualifications 1+ year of experience with Hadoop ecosystems (Apache Spark or Hive) and/or data lake architecture and administration. Knowledge or experience with system administration, and troubleshooting any operating system (Linux and/or Windows) and networking. Ability to communicate effectively in English (written and spoken) within technical and business settings. Preferred Qualifications Bachelor’s degree in Engineering/Computer Science/ Mathematics or related field. Knowledge or experience utilizing data analysis techniques such as quantitative or qualitative analysis. Knowledge or experience in various big data or distributed systems (NoSQL, search and streaming). Understanding of cloud computing concepts and/or experience with any cloud platforms (AWS, Azure, Google Cloud). Experience scripting or developing in one or more of the following languages: UNIX Shell, Python, R, Ruby, GO, Java, .NET (C#), JavaScript. Company - Amazon Web Services Mexico S. de R.L. de C.V. Job ID: A2628999",https://mx.linkedin.com/jobs/view/cloud-support-engineer-i-big-data-aws-at-amazon-web-services-aws-3912841540,3912841540,"As a Cloud Support Engineer, you will learn how to use various cloud technologies to assist customers. This role includes solving customer cases, applying troubleshooting techniques, improving support processes, and developing technical skills. You will work with AWS products, including EMR, DynamoDB, MongoDB, and Apache Cassandra, and support services that utilize machine learning and data analytics. The position requires effective communication in English within technical and business contexts.","Hadoop, Apache Spark, Hive, DynamoDB, MongoDB, Apache Cassandra, UNIX Shell, Python, R, Ruby, GO, Java, .NET (C#), JavaScript",1+ year,Bachelor,True,1.0,0,1,1,0,0,0,0,0,0,1,0,0,0,0,1,0,0
Data Engineer Ssr,MindTech,Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-06-17 11:47:09.018617,25,Information Technology,,,"En Mindtech, estamos buscando un talentoso Data Engineer Mid-Senior para unirse a uno de nuestros clientes. El candidato ideal tendrá experiencia en la manipulación y análisis de grandes volúmenes de datos, así como una sólida comprensión de las tecnologías en la nube. Este rol es perfecto para alguien que busca una oportunidad para crecer y contribuir significativamente en un entorno híbrido desde la Ciudad de México. Responsabilidades Diseñar, desarrollar y mantener pipelines de datos eficientes y escalables. Trabajar con grandes conjuntos de datos para realizar análisis y extraer insights valiosos. Colaborar con equipos multifuncionales para comprender y satisfacer sus necesidades de datos. Implementar y optimizar soluciones de almacenamiento y procesamiento de datos en Google Cloud Platform (GCP). Utilizar Python y SQL para desarrollar y automatizar procesos de análisis de datos. Asegurar la calidad y la integridad de los datos mediante el diseño y la implementación de pruebas de validación de datos. Participar en la creación de dashboards y reportes para la visualización de datos y la toma de decisiones informadas. Requisitos Licenciatura en Ciencias de la Computación, Ingeniería de Software, Ingeniería de Datos, o campo relacionado. Mínimo 3 años de experiencia en ingeniería de datos o un rol similar. Experiencia comprobada trabajando con Google Cloud Platform (GCP). Dominio de Python y SQL. Experiencia en el diseño y desarrollo de pipelines de datos. Conocimiento en la creación de dashboards y reportes con herramientas de visualización de datos. Habilidades sólidas de resolución de problemas y optimización de rendimiento. Excelentes habilidades de comunicación y capacidad para trabajar en equipo. Tecnologías Deseadas Google Cloud Platform (GCP) Python SQL",https://mx.linkedin.com/jobs/view/data-engineer-ssr-at-mindtech-3942328805,3942328805,"At Mindtech, we are looking for a talented Mid-Senior Data Engineer to join one of our clients. The ideal candidate will have experience in handling and analyzing large volumes of data, as well as a solid understanding of cloud technologies. This role is perfect for someone looking for an opportunity to grow and contribute significantly in a hybrid environment from Mexico City. Responsibilities include designing, developing, and maintaining efficient and scalable data pipelines, working with large datasets to perform analysis and extract valuable insights, collaborating with cross-functional teams to understand and meet their data needs, implementing and optimizing storage and data processing solutions on Google Cloud Platform (GCP), using Python and SQL to develop and automate data analysis processes, ensuring data quality and integrity through the design and implementation of data validation tests, and participating in the creation of dashboards and reports for data visualization and informed decision-making.","Python, SQL, Google Cloud Platform (GCP)",3,Bachelor,True,3.0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,1,0,0
Data Engineer/Data wrangler 68514 - 68515,Hays,Mexico City Metropolitan Area,ON-SITE,Entry level,Full-time,Staffing and Recruiting,2024-08-16 11:47:09.018617,25,Information Technology,,,"Tu nueva compañía Empresa multinacional del sector de ciber seguridad y tecnología con presencia en EU y LATAM Tu nuevo cargo Data Wrangler Que necesitas para ser exitoso Dominio de SQL Manejo de herramientas ETL (Tableau, Dataiku, DataBricks) Dominio de Inglés: Intermedio-avanzado Generación de Insights Que recibirás a cambio Sueldo competitivo Prestaciones superiores a las de la ley Esquema de trabajo: Remoto Que necesitas hacer ahora Si estás interesado en este cargo, haz click en ""aplicar ahora"" para reenviar una copia actualizada de tu CV, o llámanos ahora. Si este cargo no se ajusta mucho a tu perfil, pero estás en búsqueda de un cambio laboral, ponte en contacto con nosotros para que tengamos una conversación confidencial sobre tu carrera. #1036312 - Maria De La Rosa",https://mx.linkedin.com/jobs/view/data-engineer-data-wrangler-68514-68515-at-hays-3987366143,3987366143,"Your new company is a multinational in the cybersecurity and technology sector with a presence in the US and LATAM. Your new position is Data Wrangler. You need to have mastery in SQL, experience with ETL tools (Tableau, Dataiku, DataBricks), and an intermediate to advanced command of English to generate insights.","SQL, Tableau, Dataiku, DataBricks, ETL",,,True,,0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,0,0
Lead Data Engineer,NBCUniversal,Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,Entertainment Providers,2024-09-08 11:47:09.018617,30,Other,Project Management,,"Job Description NBCU is seeking a data engineering guru that will apply his/her database expertise to build systems that collect, manage, store, and convert raw data into readable formats that the Analytics/Data Science team members can use to for developing their reporting tools. The role will form part of the Strategy and Insights team but will have cross-functional responsibilities. The ideal candidate would have a solid background in database management, data automation, and data modeling. Responsibilities 4 to 5 years of experience working in Datawarehouse environments developing ETL process using automation tools as Alteryx, Databases as Snowflake and programming languages as Python. Taking the lead on defining how to automate data gathering multiple data sources, transforming data into relational databases, and manage the housing of such data on cross-functional projects that will help in having better access information for decision-making Main priority will revolve around ensuring we are receiving, storing, and structuring data appropriately pertaining to our STB VOD, Affiliate VOD, and TVE VOD audience metrics as well as app performance for Universal+ The individual will also collaborate on other data-driven projects such as unification of the audience and ad inventory data for our digital products, CRM, content inventory, and others Key functions include, but are not limited to: Build robust data pipelines at scale. Data validation scripting in SQL in Snowflake. Design and implement data schemas. Data QA. Create, define, and document processes & Help in data governance initiatives. Design, creates and run ETL processes in Alteryx. Serve as an internal consultant to the NBCUniversal Latin American Networks division as it relates to data needs Collaborate closely with our Analytics/Data Science team members to ensure all data is being structured and housed in a manner that can fulfill the business needs Work closely with our third-party data vendors and our digital product team to ensure data can be collected Leverage knowledge in multiple technologies, Cloud platforms, ETL tools and programming languages (e.g. Alteryx, AWS, Snowflake, Azure, SQL, Python, R, C+, PostgreSQL, Teradata, Java, Hadoop) Qualifications Fully fluent in English and Spanish is a must, Portuguese is a plus 5+ years of relevant data experience is a must Experience working on cloud platforms Advanced knowledge of programming languages especially SQL and Python Advanced knowledge of relational databases and SQL programming language Advanced knowledge of data warehouses and data lakes Previous experience supporting a TV network or OTT platform preferred Intermediate knowledge of data visualization tools Strong quantitative skills, including both analytical abilities as well as math proficiency Previous experience working with Latin America is a plus Degree in Data Science, Engineering, Mathematics, or related field",https://mx.linkedin.com/jobs/view/lead-data-engineer-at-nbcuniversal-4014194109,4014194109,"NBCU is seeking a data engineering expert to build systems that collect, manage, store, and convert raw data into readable formats for the Analytics/Data Science team. The role involves automating data processes, developing ETL processes using tools such as Alteryx and Snowflake, and ensuring proper data management for various audience metrics and app performance. Responsibilities include building data pipelines, data validation scripting in SQL, creating data schemas, and collaborating with cross-functional teams on data-driven projects.","Alteryx, Snowflake, Python, SQL, R, C++, PostgreSQL, Teradata, Java, Hadoop, AWS, Azure",5+,,True,5.0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0
Data Engineer (Snowflake),NEORIS,Mexico City Metropolitan Area,ON-SITE,Entry level,Full-time,IT Services and IT Consulting,2024-09-15 11:47:09.018617,66,Information Technology,,,"En NEORIS es un acelerador Digital que ayuda a las compañías a entrar en el futuro, teniendo 20 años de experiencia como Socios Digitales de algunas de las mayores compañías del mundo. Somos más de 4,000 profesionales en 11 países, con nuestra cultura multicultural de startup en donde cultivamos innovación, aprendizaje continuo para crear soluciones de alto valor para nuestros clientes. Data Engineer con más de 4 años de experiencia para unirse a nuestro equipo de tecnología. El candidato ideal será un profesional fuerte en el desarrollo y gestión de bases de datos utilizando MS SQL y Snowflake. Se requiere un nivel de inglés intermedio (se acepta básico para documentación). Responsabilidades Experiencia solida en modelado de datos con Snowflake. Diseñar, implementar y mantener soluciones de almacenamiento de datos utilizando MS SQL y Snowflake. Desarrollar y optimizar consultas SQL para asegurar la eficiencia y el rendimiento de las bases de datos. Colaborar con equipos de desarrollo para entender los requerimientos de datos y proporcionar soluciones adecuadas. Asegurar la calidad, integridad y seguridad de los datos en todas las etapas del procesamiento. Documentar diseños de bases de datos, flujos de trabajo y procesos de integración. Monitorear el rendimiento de las bases de datos y realizar ajustes y optimizaciones según sea necesario. Solucionar problemas relacionados con el rendimiento y la integridad de los datos. Mantenerse actualizado con las últimas tendencias y tecnologías en gestión de datos y proponer mejoras continuas. Requisitos y Habilidades Técnicas Licenciatura en Ciencias de la Computación, Ingeniería de Sistemas, Informática o campo relacionado. Más de 4 años de experiencia en roles relacionados con la ingeniería de datos. Experiencia avanzada en el desarrollo y administración de bases de datos con MS SQL. Experiencia con Snowflake, incluyendo diseño y optimización de esquemas, así como integración de datos. Fuerte capacidad para escribir y optimizar consultas SQL complejas. Habilidades Blandas Nivel de inglés intermedio (se acepta básico). Habilidad para trabajar en equipo y colaborar con diferentes departamentos. Fuertes habilidades analíticas y de resolución de problemas. Capacidad para gestionar múltiples tareas y proyectos simultáneamente. Atención al detalle y compromiso con la calidad del trabajo Asignación Hibrida en Monterrey, se acepta remoto fuera de esta sede. Ofrecemos 100% Nominal Legal Benefits Benefits Package Wellness Program Professional development plan Multicultural collaboration Come and meet us on: http://www.neoris.com , on Facebook, LinkedIn, Twitter, or Instagram @NEORIS. Hector Antonio Hernandez Sanchez / sanchez.hector@neoris.com",https://mx.linkedin.com/jobs/view/data-engineer-snowflake-at-neoris-3991950988,3991950988,"NEORIS is looking for a Data Engineer with over 4 years of experience to join our technology team. The ideal candidate will have a strong background in developing and managing databases using MS SQL and Snowflake. Responsibilities include solid experience in data modeling with Snowflake, designing and maintaining data storage solutions, optimizing SQL queries for performance, and ensuring data quality and integrity.","MS SQL, Snowflake, SQL, Data Modeling",4+,Bachelor,True,4.0,0,0,0,0,0,1,0,1,0,1,0,0,0,0,0,0,0
Data Engineer II - Argentina / Mexico,Syneos Health,Mexico City Metropolitan Area,ON-SITE,Entry level,Full-time,"Biotechnology Research, Pharmaceutical Manufacturing, and Research Services",2024-09-01 11:47:09.018617,25,Information Technology,,,"Description Data Engineer II (Azure) Syneos Health® is a leading fully integrated biopharmaceutical solutions organization built to accelerate customer success. We translate unique clinical, medical affairs and commercial insights into outcomes to address modern market realities. Every day we perform better because of how we work together, as one team, each the best at what we do. We bring a wide range of talented experts together across a wide range of business-critical services that support our business. Every role within Corporate is vital to furthering our vision of Shortening the Distance from Lab to Life®. Discover what our 29,000 employees, across 110 countries already know: WORK HERE MATTERS EVERYWHERE Why Syneos Health We are passionate about developing our people, through career development and progression; supportive and engaged line management; technical and therapeutic area training; peer recognition and total rewards program. We are committed to our Total Self culture – where you can authentically be yourself. Our Total Self culture is what unites us globally, and we are dedicated to taking care of our people. We are continuously building the company we all want to work for and our customers want to work with. Why? Because when we bring together diversity of thoughts, backgrounds, cultures, and perspectives – we’re able to create a place where everyone feels like they belong. Job Summary The Technology & Data Solutions (TDS) business unit is the Syneos Health accelerator for life sciences innovation. TDS houses our advanced technology acquisitions, homegrown products & applications, actively participates in new M&A and partnership activities, delivers critical insights as part of our integrated strategy for customers and drives enterprise-wide adoption and change management for innovative tech & data solutions. Our work supports getting meaningful new medicines to patients faster, with greater positive impact. The Data Engineer II supports our business goals by designing, implementing, and maintaining data pipelines using cloud-native tools in a modern data stack. Job Responsibilities Work independently to solve open-ended questions. Develop and maintain end-to-end data pipelines using cloud-native solutions to extract, load, and transform data from disparate data sources to a cloud data warehouse. Capable of formatting and distributing custom data extracts through various means (e.g., custom SFTPs, APIs (e.g., RESTful), and other bulk data transfer mediums) and optimizing data storage options based on business requirements. Create models to transform raw data into analytics ready data structures. Competent in helping to develop/design database structure and function, schema design, and database testing protocols. Create connectors for data pipelines to ingest data from disparate sources into a data warehouse. Contribute to the process of defining company data assets (data models) and custom client workflows, as well as standardized data quality protocols. Capable of independently and collaboratively troubleshooting database issues and queries for improving data retrieval times across various systems (e.g., via SQL). Collaborate with both technical and non-technical stakeholders including IT, Data Science, and various team members across a diverse array of business units. Work closely with IT team whenever necessary to help facilitate, troubleshoot, or develop database connectivity between internal/external resources (e.g., on-premises Azure Data Lakes, Data Warehouses, and Data Hubs). Help implement and enforce enterprise reference architecture and ensure that data infrastructure design reflects enterprise business rules as well as data governance and security guidelines. Qualifications Qualifications/Requirements Bachelor’s degree (BS/BA) in Information Systems, Software Engineering, Computer Science, Data Engineering, or related field required. Master’s degree (MS/MA) preferred. Experience with ETL/ELT, taking data from various data sources and formats and ingesting into a cloud-native data warehouse required. Experience with Azure Stack (Data Lake/Blob Storage, PowerBI Services, Azure Data Factory (or equivalent), Databrick) and production level experience with on-premises Microsoft SQL Server required. Experience with one of the following: Python, R, and/or Scala as well as standard analytic libraries/packages (e.g., pandas, Numpy, dplyr, data table, stringr, Slick, and/or Kafka) and related distribution frameworks required. Strong English verbal and written communication skills required. Familiarity with agile and lean concepts that drive towards MVPs and iterative learning to generate the desired business and technology outcomes required. Experience with DataRobot, Domino Data Labs, Salesforce MC, Veeva CRM preferred. Familiarity with modern data stack components like Snowflake, dbt, Stitch, Tableau, and Airflow Familiarity with statistical concepts and analytic modeling (e.g., regression analyses, hypothesis testing, and ML based modeling) preferred. Experience with software engineering best practices like version control with Git and CI/CD preferred. Experience with US healthcare and healthcare data, as well as familiarity with HIPAA guidelines, and best practices for handling and storing PHI and PII preferred. Experience with healthcare marketing analytics, healthcare data (claims), and common medical coding sets (ICD, HCPCs, NPIs) preferred. Get to know Syneos Health Over the past 5 years, we have worked with 94% of all Novel FDA Approved Drugs, 95% of EMA Authorized Products and over 200 Studies across 73,000 Sites and 675,000+ Trial patients. No matter what your role is, you’ll take the initiative and challenge the status quo with us in a highly competitive and ever-changing environment. Learn more about Syneos Health Additional Information Tasks, duties, and responsibilities as listed in this job description are not exhaustive. The Company, at its sole discretion and with no prior notice, may assign other tasks, duties, and job responsibilities. Equivalent experience, skills, and/or education will also be considered so qualifications of incumbents may differ from those listed in the Job Description. The Company, at its sole discretion, will determine what constitutes as equivalent to the qualifications described above. Further, nothing contained herein should be construed to create an employment contract. Occasionally, required skills/experiences for jobs are expressed in brief terms. Any language contained herein is intended to fully comply with all obligations imposed by the legislation of each country in which it operates, including the implementation of the EU Equality Directive, in relation to the recruitment and employment of its employees. The Company is committed to compliance with the Americans with Disabilities Act, including the provision of reasonable accommodations, when appropriate, to assist employees or applicants to perform the essential functions of the job.",https://mx.linkedin.com/jobs/view/data-engineer-ii-argentina-mexico-at-syneos-health-4005414378,4005414378,"The Data Engineer II supports the business goals by designing, implementing, and maintaining data pipelines using cloud-native tools in a modern data stack. This role involves developing and maintaining end-to-end data pipelines, formatting and distributing custom data extracts, creating data models, troubleshooting database issues, and collaborating with various stakeholders. The role requires a Bachelor's degree in Information Systems, Software Engineering, or related field, and experience with ETL/ELT processes, Azure Stack, SQL, Python, R, or Scala.","Azure Data Lake, Azure Blob Storage, PowerBI Services, Azure Data Factory, Databricks, SQL, Python, R, Scala, ETL, ELT, pandas, Numpy, dplyr, data.table, stringr, Slick, Kafka, Snowflake, dbt, Stitch, Tableau, Airflow",,Bachelor,True,,0,0,1,1,0,0,1,0,1,1,0,0,0,0,1,0,0
Data Engineer Tech Lead,Infosys,Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-01 11:47:09.018617,25,Information Technology,,,"Job Description * SKILL SETS EXP LEVELS SECTION * MANDATORY TECHNOLOGIES Microsoft Excel PowerBI Python Main Experience Required BS/BA (with an IT focus) preferred or equivalent experience 8+ years of relevant industry experience, with at least 5 years of hands-on IT experience Experience working with large data sets, formulas driven analysis: concatenations, vlookups, etc. Experience with Waterfall/Agile/Scrum methodologies/processes Mandatory Skills / Requirements Advance Data Analysis skills involving large data sets, leveraging tools like PowerBI and Python and expertise in Microsoft Excel. Fluent communication (written and verbal) in Spanish and English. Proven ability to work with high performing/geographically dispersed teams. Excellent analytical, problem solving, and troubleshooting skills. HIRING TYPE Employee Desired Skills, Technologies And Experience PowerBI skills are a plus Most of the work will be Excel based, using Salsify PIM, PIM knowledge is not mandatory, but a plus. MBA is also a plus * REMARKS SECTION * This position requires hybrid work mode and needs your presence in the office for at least 60% of the workdays every week. About Us Infosys is a global leader in next-generation digital services and consulting. We enable clients in more than 50 countries to navigate their digital transformation. With over four decades of experience in managing the systems and workings of global enterprises, we expertly steer our clients through their digital journey. We do it by enabling the enterprise with an AI-powered core that helps prioritize the execution of change. We also empower the business with agile digital at scale to deliver unprecedented levels of performance and customer delight. Our always-on learning agenda drives their continuous improvement through building and transferring digital skills, expertise, and ideas from our innovation ecosystem.",https://mx.linkedin.com/jobs/view/data-engineer-tech-lead-at-infosys-4008703778,4008703778,"This position requires a focus on advanced data analysis skills involving large data sets, leveraging tools like PowerBI and Python, and expertise in Microsoft Excel. It requires experience with large data sets and formulas-driven analysis, using methodologies such as Waterfall, Agile, and Scrum.","Microsoft Excel, PowerBI, Python, Agile Methodologies, Scrum",8+ years,Bachelor,True,8.0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0
Data Engineer/Integration Lead (AWS),Infosys,Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-13 11:47:09.018617,25,Information Technology,,,"Job Description Required Qualifications: 5+ years of experience in data engineering using Python with a focus on AWS S3, EMR, Glue, Step Functions, Apache NiFi and Spark. Proven track record of building scalable data pipelines in cloud environments. Proficiency in flow design, processors, and data provenance in Apache NiFi. Strong expertise in Spark, Hadoop, and distributed computing on AWS EMR. In-depth knowledge of AWS services (S3, Glue, Redshift, RDS, Lambda, Step Functions). Experience with data formats (JSON, CSV, Parquet, Avro) and transformation techniques. Strong problem-solving skills and ability to troubleshoot complex data processing issues. Excellent communication skills with the ability to document and explain technical details clearly. Preferred Qualifications AWS Certified Solutions Architect or Data Analytics Specialty. Experience with data governance frameworks and compliance requirements. Familiarity with CI/CD pipelines and version control (GitLab, Jenkins). Key Responsibilities Design & Develop Data Pipelines: Architect and implement end-to-end data pipelines using AWS S3, EMR, Glue, Step Functions, Apache NiFi, Spark. Manage data ingestion processes from AWS S3, ensuring secure and efficient data transfer. Implement initial data routing, validation, and transformations using Apache NiFi processors and Spark Data Engines Data Processing & Transformation: Integrate using AWS EMR, Apache NiFi, Spark to perform complex data transformations and analytics. Optimize Spark jobs for processing large-scale datasets with a focus on performance and resource utilization. Handle both historical and incremental data loads, ensuring data consistency and integrity. Data Storage & Management: Define and implement data storage strategies across S3, RDS, and Redshift, adhering to business requirements. Manage data catalog creation and schema management using AWS Glue. Automation & Orchestration: Develop and manage workflows using Apache Airflow, AWS Step Functions to automate data processing tasks. Implement monitoring, error handling, and retries within the orchestration framework. Security & Compliance: Ensure data security with encryption (AES-256, TLS) and IAM role-based access controls. Implement data governance policies using AWS Glue Data Catalog to ensure compliance with regulatory requirements. Performance Monitoring & Optimization: Utilize AWS CloudWatch to monitor the performance of EMR clusters, NiFi flows and data storage. Continuously optimize Spark job configurations and NiFi data flows for maximum throughput and minimal latency. About Us Infosys is a global leader in next-generation digital services and consulting. We enable clients in more than 50 countries to navigate their digital transformation. With over four decades of experience in managing the systems and workings of global enterprises, we expertly steer our clients through their digital journey. We do it by enabling the enterprise with an AI-powered core that helps prioritize the execution of change. We also empower the business with agile digital at scale to deliver unprecedented levels of performance and customer delight. Our always-on learning agenda drives their continuous improvement through building and transferring digital skills, expertise, and ideas from our innovation ecosystem. Infosys provides equal employment opportunities to applicants and employees without regard to race; color; sex; gender identity; sexual orientation; religious practices and observances; national origin; pregnancy, childbirth, or related medical conditions; status as a protected veteran or spouse/family member of a protected veteran; or disability.",https://mx.linkedin.com/jobs/view/data-engineer-integration-lead-aws-at-infosys-4023241770,4023241770,"Required qualifications include 5+ years of experience in data engineering using Python with a focus on AWS S3, EMR, Glue, Step Functions, Apache NiFi, and Spark. Responsibilities include designing and developing data pipelines, managing data ingestion, performing complex data transformations and analytics, defining data storage strategies, automation, and security compliance. Strong problem-solving skills and excellent communication abilities are necessary.","Python, AWS S3, AWS EMR, AWS Glue, AWS Step Functions, Apache NiFi, Apache Spark, Hadoop, AWS Redshift, AWS RDS, AWS Lambda, JSON, CSV, Parquet, Avro, AWS CloudWatch, Apache Airflow, CI/CD, GitLab, Jenkins",5+,,True,5.0,0,0,1,1,0,0,0,0,0,0,0,1,0,0,1,0,0
Data Engineer,Reuters News Agency,Mexico City Metropolitan Area,ON-SITE,Entry level,Full-time,Media Production,2024-08-16 11:47:09.018617,25,Information Technology,,,"Job Description As a Data Engineer with our team, you'll play a pivotal role in shaping the future of our data products and analytical services. Leveraging your expertise in DBT (Data Build Tool), SQL/Snowflake, and AWS/Azure, you'll work with stakeholders across Audit, Tax, and Accounting, to build and maintain robust data pipelines that power our analytics and drive informed decision-making for us and our customers. About The Role Developing/enhancing data warehousing functionality including the use and management of Snowflake data warehouse and the surrounding entitlements, pipelines and monitoring, in partnership with Architects and Data Analysts Innovate with new approaches to meeting data management requirements Effectively communicate and liaise with other data management teams embedded across the organization and data consumers in data science and business analytics teams. Analyze existing data pipelines and assist in enhancing and re-engineering the pipelines as per business requirements. Utilize your experience in the following areas: Azure Cloud Data practices and DevOps tooling Airflow, Data lake, Databricks, SQL, Pyspark, DBT and Snowflake Data Management and Data warehousing processing capabilities Metadata Repositories, Information & Data Catalogs Data governance as it applies to security and privacy Master Data platform capabilities Data Security, Privacy, and Compliance Delivers end-to-end technical solutions for multiple products or complex projects Leads routine projects with manageable risks and resource requirements May manage budgets for small projects or programs Solves complex problems with minimal guidance About You Bachelor’s degree or equivalent required, Computer Science or related technical degree preferred 2+ years of relevant experience in Implementation of data warehouse and data management of data technologies for large scale organizations Worked on Analyzing data pipelines Knowledgeable about Airflow, Data lake, Databricks, SQL, Pyspark, DBT and Snowflake Broad understanding of the technologies used to build and operate data and analytic systems Excellent critical thinking, communication, presentation, documentation, troubleshooting and collaborative problem-solving skills Hands-on experience with programming and scripting languages Fluency in SQL At least one Business Intelligence tool such as PowerBI/Domo/Tableau Location: Mexico City What's in it For You? You will join our inclusive culture of world-class talent, where we are committed to your personal and professional growth through: Hybrid Work Model: We’ve adopted a flexible hybrid working environment (2-3 days a week in the office depending on the role) for our office-based roles while delivering a seamless experience that is digitally and physically connected Wellbeing: Comprehensive benefit plans; flexible and supportive benefits for work-life balance: flexible vacation, two company-wide Mental Health Days Off; work from another location for up to a total of 8 weeks in a year, 4 of those weeks can be out of the country and the remaining in the country, Headspace app subscription; retirement, and employee incentive programs; resources for mental, physical, and financial wellbeing. Culture: Globally recognized and award-winning reputation for equality, diversity and inclusion, flexibility, work-life balance, and more. Learning & Development: LinkedIn Learning access; internal Talent Marketplace with opportunities to work on projects cross-company; Ten Thousand Coffees Thomson Reuters café networking. Social Impact: Ten employee-driven Business Resource Groups; two paid volunteer days annually; Environmental, Social, and Governance (ESG) initiatives for local and global impact. Purpose-Driven Work: We have a superpower that we’ve never talked about with as much pride as we should – we are one of the only companies on the planet that helps its customers pursue justice, truth, and transparency. Together, with the professionals and institutions we serve, we help uphold the rule of law, turn the wheels of commerce, catch bad actors, report the facts, and provide trusted, unbiased information to people all over the world. Do you want to be part of a team helping re-invent the way knowledge professionals work? How about a team that works every day to create a more transparent, just and inclusive future? At Thomson Reuters, we’ve been doing just that for almost 160 years. Our industry-leading products and services include highly specialized information-enabled software and tools for legal, tax, accounting and compliance professionals combined with the world’s most global news services – Reuters. We help these professionals do their jobs better, creating more time for them to focus on the things that matter most: advising, advocating, negotiating, governing and informing. We are powered by the talents of 26,000 employees across more than 70 countries, where everyone has a chance to contribute and grow professionally in flexible work environments that celebrate diversity and inclusion. At a time when objectivity, accuracy, fairness and transparency are under attack, we consider it our duty to pursue them. Sound exciting? Join us and help shape the industries that move society forward. Accessibility As a global business, we rely on diversity of culture and thought to deliver on our goals. To ensure we can do that, we seek talented, qualified employees in all our operations around the world regardless of race, color, sex/gender, including pregnancy, gender identity and expression, national origin, religion, sexual orientation, disability, age, marital status, citizen status, veteran status, or any other protected classification under applicable law. Thomson Reuters is proud to be an Equal Employment Opportunity/Affirmative Action Employer providing a drug-free workplace. We also make reasonable accommodations for qualified individuals with disabilities and for sincerely held religious beliefs in accordance with applicable law. Protect yourself from fraudulent job postings click here to know more. More information about Thomson Reuters can be found on https://thomsonreuters.com.",https://mx.linkedin.com/jobs/view/data-engineer-at-reuters-news-agency-3990973621,3990973621,"As a Data Engineer, you will play a crucial role in shaping the future of data products and analytical services, working with DBT, SQL/Snowflake, and AWS/Azure. You will work with various stakeholders to develop and enhance data warehousing functionality, innovate in data management, communicate effectively with data management teams, analyze existing data pipelines, and deliver end-to-end technical solutions.","DBT, SQL, Snowflake, AWS, Azure, Airflow, Data Lake, Databricks, Pyspark, Business Intelligence (PowerBI, Domo, Tableau)",2+ years,Bachelor,True,2.0,0,0,1,1,0,0,0,0,1,1,0,0,0,0,0,0,0
Data Transformation Engineer,S&P Global,Mexico City Metropolitan Area,ON-SITE,,Full-time,Financial Services,2024-09-08 11:47:09.018617,25,Information Technology,,,"About The Role Grade Level (for internal use): 09 The Team The Forecast Ops team within the Analytics Enablement group drives innovation and efficiency gains for economic forecasting processes. The team creates data pipelines, designs automated processes, and assists forecast product teams with improving their procedures. Responsibilities And Impact We are seeking a talented and motivated Data Transformation Engineer to join our team. The primary responsibility of this role is to develop and maintain scripts in Python and EViews to clean and enrich time-series data. The ideal candidate will have a strong understanding of time-series data and possess excellent technical skills to automate data processing workflows efficiently. Develop and maintain Python and EViews scripts to clean, enrich, and transform time-series data related to economic and industry information. Design and implement automated data pipelines to ensure the efficient processing and integration of large datasets. Collaborate with data analysts, economists, and other stakeholders to understand data requirements and deliver accurate and timely data solutions. Monitor and optimize the performance of data pipelines, ensuring data integrity and quality. Troubleshoot and resolve data-related issues, implementing improvements to enhance data processing efficiency. Document processes, methodologies, and best practices for data transformation and automation. Stay up-to-date with industry trends and advancements in data engineering and automation technologies. What We’re Looking For Basic Required Qualifications: Bachelor's degree in Computer Science, Data Science, Economics, or a related field. Strong proficiency in software used for data processing and automation, preferably Python and EViews. Solid understanding of time-series data and related statistical techniques. Experience with data cleaning, transformation, and enrichment processes. Excellent problem-solving skills and attention to detail. Ability to work independently and collaboratively in a fast-paced environment. Strong communication skills to effectively interact with team members and stakeholders. Additional Preferred Qualifications Experience with other data processing and automation tools and languages, such as R, or other statistical software commonly used for economic time-series analysis, such as SPSS, SAS, or MATLAB. Familiarity with economic and industry time-series data. Knowledge of data visualization techniques and tools. Understanding of database management systems and SQL. About S&P Global Market Intelligence At S&P Global Market Intelligence, a division of S&P Global we understand the importance of accurate, deep and insightful information. Our team of experts delivers unrivaled insights and leading data and technology solutions, partnering with customers to expand their perspective, operate with confidence, and make decisions with conviction. For more information, visit www.spglobal.com/marketintelligence. What’s In It For You? Our Purpose Progress is not a self-starter. It requires a catalyst to be set in motion. Information, imagination, people, technology–the right combination can unlock possibility and change the world. Our world is in transition and getting more complex by the day. We push past expected observations and seek out new levels of understanding so that we can help companies, governments and individuals make an impact on tomorrow. At S&P Global we transform data into Essential Intelligence®, pinpointing risks and opening possibilities. We Accelerate Progress. Our People We're more than 35,000 strong worldwide—so we're able to understand nuances while having a broad perspective. Our team is driven by curiosity and a shared belief that Essential Intelligence can help build a more prosperous future for us all. From finding new ways to measure sustainability to analyzing energy transition across the supply chain to building workflow solutions that make it easy to tap into insight and apply it. We are changing the way people see things and empowering them to make an impact on the world we live in. We’re committed to a more equitable future and to helping our customers find new, sustainable ways of doing business. We’re constantly seeking new solutions that have progress in mind. Join us and help create the critical insights that truly make a difference. Our Values Integrity, Discovery, Partnership At S&P Global, we focus on Powering Global Markets. Throughout our history, the world's leading organizations have relied on us for the Essential Intelligence they need to make confident decisions about the road ahead. We start with a foundation of integrity in all we do, bring a spirit of discovery to our work, and collaborate in close partnership with each other and our customers to achieve shared goals. Benefits We take care of you, so you can take care of business. We care about our people. That’s why we provide everything you—and your career—need to thrive at S&P Global. Our Benefits Include Health & Wellness: Health care coverage designed for the mind and body. Flexible Downtime: Generous time off helps keep you energized for your time on. Continuous Learning: Access a wealth of resources to grow your career and learn valuable new skills. Invest in Your Future: Secure your financial future through competitive pay, retirement planning, a continuing education program with a company-matched student loan contribution, and financial wellness programs. Family Friendly Perks: It’s not just about you. S&P Global has perks for your partners and little ones, too, with some best-in class benefits for families. Beyond the Basics: From retail discounts to referral incentive awards—small perks can make a big difference. For more information on benefits by country visit: https://spgbenefits.com/benefit-summaries Diversity, Equity, And Inclusion At S&P Global At S&P Global, we believe diversity fuels creative insights, equity unlocks opportunity, and inclusion drives growth and innovation – Powering Global Markets. Our commitment centers on our global workforce, ensuring that our people are empowered to bring their whole selves to work. It doesn’t stop there, we strive to better reflect and serve the communities in which we live and work, and advocate for greater opportunity for all. Equal Opportunity Employer S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. US Candidates Only: The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. 20 - Professional (EEO-2 Job Categories-United States of America), ANLYTC202.1 - Middle Professional Tier I (EEO Job Group) Job ID: 303847 Posted On: 2024-09-06 Location: Virtual, Mexico",https://mx.linkedin.com/jobs/view/data-transformation-engineer-at-s-p-global-4018481855,4018481855,"We are seeking a talented and motivated Data Transformation Engineer to develop and maintain scripts in Python and EViews to clean and enrich time-series data. Responsibilities include designing and implementing automated data pipelines, collaborating with stakeholders to understand data requirements, monitoring and optimizing data pipelines, troubleshooting data-related issues, documenting processes, and staying updated with industry trends in data engineering and automation.","Python, EViews, R, SPSS, SAS, MATLAB, SQL",,Bachelor,True,,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0
Data Engineer – TI TPM Mosaic IRC237091,GlobalLogic Latinoamérica,Mexico City Metropolitan Area,ON-SITE,,Full-time,IT Services and IT Consulting,2024-08-16 11:47:09.018617,25,Engineering,,,"Description: Data Engineering to support the Resource Efficiency Data Science (REDS) team in Google Cloud. We develop the analytics to ensure high availability and efficient utilization of Cloud resources e.g. CPUs, RAM, GPUs, Disks. Skills: Python. Strong Scientific Python skills e.g. Pandas, Numpy, Altair skills. 5+ years. Primary partners are data scientists whose python skills are stronger than SQL. I want to keep using Python for data analysis and ETL. SQL. Strong SQL. 5+ years. We deal with highly scaled, multidimensional time series data. Beam. Experience with Beam / Cloud Data Flow. 3+ years, enough to develop best practices. Beam allows us to continue using Python and to shard the data for increased ETL performance (e.g. historical recalculations). Best practices. Strong adherence to best practices e.g. version control, documentation, bug tracking, etc. Location. Location anywhere between PST and EST i.e. no reason to be at any Google office Google Cloud. Nice to have experienced with Google Cloud Requirements: Data Engineering to support the Resource Efficiency Data Science (REDS) team in Google Cloud. We develop the analytics to ensure high availability and efficient utilization of Cloud resources e.g. CPUs, RAM, GPUs, Disks. Skills: Python. Strong Scientific Python skills e.g. Pandas, Numpy, Altair skills. 5+ years. Primary partners are data scientists whose python skills are stronger than SQL. I want to keep using Python for data analysis and ETL. SQL. Strong SQL. 5+ years. We deal with highly scaled, multidimensional time series data. Beam. Experience with Beam / Cloud Data Flow. 3+ years, enough to develop best practices. Beam allows us to continue using Python and to shard the data for increased ETL performance (e.g. historical recalculations). Best practices. Strong adherence to best practices e.g. version control, documentation, bug tracking, etc. Location. Location anywhere between PST and EST i.e. no reason to be at any Google office Google Cloud. Nice to have experienced with Google Cloud Job Responsibilities: Data Engineering to support the Resource Efficiency Data Science (REDS) team in Google Cloud. We develop the analytics to ensure high availability and efficient utilization of Cloud resources e.g. CPUs, RAM, GPUs, Disks. Skills: Python. Strong Scientific Python skills e.g. Pandas, Numpy, Altair skills. 5+ years. Primary partners are data scientists whose python skills are stronger than SQL. I want to keep using Python for data analysis and ETL. SQL. Strong SQL. 5+ years. We deal with highly scaled, multidimensional time series data. Beam. Experience with Beam / Cloud Data Flow. 3+ years, enough to develop best practices. Beam allows us to continue using Python and to shard the data for increased ETL performance (e.g. historical recalculations). Best practices. Strong adherence to best practices e.g. version control, documentation, bug tracking, etc. Location. Location anywhere between PST and EST i.e. no reason to be at any Google office Google Cloud. Nice to have experienced with Google Cloud What We Offer Exciting Projects: Come take your place at the forefront of digital transformation! With clients across all industries and sectors, we offer an opportunity to work on market-defining products using the latest technologies. Collaborative Environment: Expand your skills by collaborating with a diverse team of highly talented people in an open, laidback environment — or even abroad in one of our global centers or client facilities! Work-Life Balance: GlobalLogic prioritizes work-life balance, which is why we offer flexible work schedules.We offer you the best quality of work life so that you exceed the expectations of our clients, while achieving your professional and personal ambitions. Professional Development: Our dedicated Learning & Development team regularly organizes English classes, professional certifications, and technical and soft skill trainings. We also offer the chance to travel internationally Excellent Benefits: We provide our employees with competitive salaries, family medical insurance, extended paternity leave, annual performance bonuses, and referral bonuses. About GlobalLogic GlobalLogic is a leader in digital engineering. We help brands across the globe design and build innovative products, platforms, and digital experiences for the modern world. By integrating experience design, complex engineering, and data expertise—we help our clients imagine what’s possible, and accelerate their transition into tomorrow’s digital businesses. Headquartered in Silicon Valley, GlobalLogic operates design studios and engineering centers around the world, extending our deep expertise to customers in the automotive, communications, financial services, healthcare and life sciences, manufacturing, media and entertainment, semiconductor, and technology industries. GlobalLogic is a Hitachi Group Company operating under Hitachi, Ltd. (TSE: 6501) which contributes to a sustainable society with a higher quality of life by driving innovation through data and technology as the Social Innovation Business.",https://mx.linkedin.com/jobs/view/data-engineer-%E2%80%93-ti-tpm-mosaic-irc237091-at-globallogic-latinoam%C3%A9rica-3999399259,3999399259,"Data Engineering to support the Resource Efficiency Data Science (REDS) team in Google Cloud. We develop the analytics to ensure high availability and efficient utilization of Cloud resources such as CPUs, RAM, GPUs, and Disks. Strong Scientific Python skills are required, including experience with Pandas, Numpy, and Altair. The role requires strong SQL skills and experience with Beam / Cloud Data Flow. Strong adherence to best practices such as version control, documentation, and bug tracking is needed.","Python, Pandas, Numpy, Altair, SQL, Beam, Cloud Data Flow",5+ years,,True,5.0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0
Lead Data Software Engineer,EPAM Systems,Mexico City Metropolitan Area,ON-SITE,Entry level,Full-time,Software Development and IT Services and IT Consulting,2024-09-13 11:47:09.018617,25,Engineering,Information Technology,,"Join EPAM as a Lead Data Software Engineer. In this role, you'll create data pipelines for the data platform we are currently designing, understand features and data mappings, and implement required Airflow DAGs in Python. If you have primary skills in Data Software Engineering, proficiency in Amazon Web Services (AWS), Apache Airflow, PostgreSQL, and a B2 level of English, we'd love to hear from you. Responsibilities Create data pipelines for the data platform we are currently designing Understand features and data mappings Implement required Airflow DAGs in Python to transform, translate, and move data from its raw state to the various states needed for training or inference Requirements Primary skill in Data Software Engineering Must have skills in Amazon Web Services (AWS) Apache Airflow PostgreSQL Required English level: B2 Expected seniority level: A4 Nice to have Skill in OpenSearch Technologies Amazon Web Services (AWS) Apache Airflow PostgreSQL Python We offer Career plan and real growth opportunities Unlimited access to LinkedIn learning solutions International Mobility Plan within 25 countries Constant training, mentoring, online corporate courses, eLearning and more English classes with a certified teacher Support for employee’s initiatives (Algorithms club, toastmasters, agile club and more) Enjoyable working environment (Gaming room, napping area, amenities, events, sport teams and more) Flexible work schedule and dress code Collaborate in a multicultural environment and share best practices from around the globe Hired directly by EPAM & 100% under payroll Law benefits (IMSS, INFONAVIT, 25% vacation bonus) Major medical expenses insurance: Life, Major medical expenses with dental & visual coverage (for the employee and direct family members) 13 % employee savings fund, capped to the law limit Grocery coupons 30 days December bonus Employee Stock Purchase Plan 12 vacations days plus 4 floating days Official Mexican holidays, plus 5 extra holidays (Maundry Thursday and Friday, November 2nd, December 24th & 31st) Relocation bonus: transportation, 2 weeks of accommodation for you and your family and more By applying to our role, you are agreeing that your personal data may be used as in set out in EPAM´s Privacy Notice and Policy. EPAM is a leading global provider of digital platform engineering and development services. We are committed to having a positive impact on our customers, our employees, and our communities. We embrace a dynamic and inclusive culture. Here you will collaborate with multi-national teams, contribute to a myriad of innovative projects that deliver the most creative and cutting-edge solutions, and have an opportunity to continuously learn and grow. No matter where you are located, you will join a dedicated, creative, and diverse community that will help you discover your fullest potential.",https://mx.linkedin.com/jobs/view/lead-data-software-engineer-at-epam-systems-4024924112,4024924112,"Join EPAM as a Lead Data Software Engineer to create data pipelines for the data platform, understand features and data mappings, and implement required Airflow DAGs in Python. The role requires primary skills in Data Software Engineering and proficiency in AWS, Apache Airflow, PostgreSQL, with a B2 level of English.","Python, Amazon Web Services (AWS), Apache Airflow, PostgreSQL, OpenSearch Technologies",,,True,,0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0
Azure Data Engineer,Sequoia Connect,Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,Software Development,2024-09-08 11:47:09.018617,25,Information Technology,Engineering,,"Esta vacante viene de la bolsa de empleo Talenteca.com Vacante para la empresa Sequoia Connect en Benito Juárez, Ciudad de México Our client is a global leader in next-generation digital services and consulting. They enable clients in more than 50 countries to navigate their digital transformation. With over four decades of experience in managing the systems and workings of global enterprises, they expertly steer their clients through their digital journey. They do it by enabling the enterprise with an AI-powered core that helps prioritize the execution of change. They also empower the business with agile digital at scale to deliver unprecedented levels of performance and customer delight. Their always-on learning agenda drives their continuous improvement through building and transferring digital skills, expertise, and ideas from their innovation ecosystem. Responsibilities We are currently searching for an Azure Data Engineer: Work on a hybrid model in any of our client’s locations (Mexico City, Guadalajara, or Monterrey). Provide production support and development in a data engineering environment. Design, implement, and maintain robust and scalable data pipelines on Azure. Troubleshoot performance issues, identify root causes and apply fixes. Implement and manage CI/CD pipelines for data engineering projects using Azure DevOps. Requirements 3+ years of experience designing, implementing, and maintaining data pipelines on Azure with services such as Azure Data Factory, Azure SQL Data Warehouse, Azure Analysis Services, or Azure Databricks/Synapse/Fabric. 2+ years of experience in data platform design/architecture with a multi-layered approach. 2+ years of experience in troubleshooting performance issues. 3+ years of experience in SQL. Ability to implement CI/CD pipelines for data engineering projects. Languages Advanced Oral English. Native Spanish. Note Hybrid (Guadalajara, Mexico City, Monterrey) If you meet these qualifications and are pursuing new challenges, Start your application to join an award-winning employer.Explore all our job openings | Sequoia Career’s Page: * Nivel De Educación Deseada Superior - titulado Nivel De Experiencia Deseada Nivel Experto Función Departamental Tecnología / Internet Industria Desarrollo de Software / Programación Habilidades Azure Databricks Cloud Platform Esta Vacante Viene De La Bolsa De Empleo Talenteca.com https://www.talenteca.com/anuncio?j_id=66d9e1db20000053000a02b4&source=linkedin",https://mx.linkedin.com/jobs/view/azure-data-engineer-at-sequoia-connect-4018737856,4018737856,"We are currently searching for an Azure Data Engineer: Provide production support and development in a data engineering environment. Design, implement, and maintain robust and scalable data pipelines on Azure. Troubleshoot performance issues, identify root causes and apply fixes. Implement and manage CI/CD pipelines for data engineering projects using Azure DevOps.","Azure Data Factory, Azure SQL Data Warehouse, Azure Analysis Services, Azure Databricks, Azure Synapse, Azure DevOps, SQL",3+ years,Bachelor,True,3.0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,0,0,0
Lead Data Engineer,Artius Solutions,Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-04-18 11:47:09.018617,25,Other,,,"Title: Lead Data Engineer Location: Remote / Must have full work authorization, no visas Duration: Full Time Experience: 5-8 years Job Description Health/Vision/Dental insurance provided. Role Description We are looking for motivated people who are experienced with building data warehouses and analytics systems in the cloud (AWS, Azure, GCP, Snowflake). What We Are Looking For We are looking for a Lead Data Engineer to join our growing team of experts. This position will work in the design and development of Snowflake Data Cloud solutions. The work includes data ingestion pipelines, data architecture, data governance and security. The ideal candidate is an experienced data pipeline builder and migrants who enjoy optimizing data systems and building them from the ground up. The Lead Data Engineer will develop database architectures, data warehouses and will ensure optimal data delivery architecture is consistent throughout ongoing customer projects. On this role you will be leading technical teams. The right candidate will be excited by the prospect of working for a start-up company to support our customers' next generation of data initiatives. Qualifications And Experience Bachelor's degree in engineering, computer science or equivalent area. 5+yrs in related technical roles, data management, database development, ETL, Data Warehouses, and pipelines. Experience designing and developing data warehouses (Teradata, Oracle Exadata, Netezza, SQL Server, Spark) Experience building ETL / ELT ingestion pipelines with tools like DataStage, Informatica, Matillion SQL scripting. Cloud experience on AWS (Azure, GCP are nice to have as well) Python Scripting and Scala are required. Ability to prepare reports and present to internal and customer stakeholders. Track record of sound problem solving skills and action-oriented mindset. Strong interpersonal skills including assertiveness and ability to build strong client relationships. Ability to work in Agile teams. Experience hiring, developing and managing a technical team. Advanced English.",https://mx.linkedin.com/jobs/view/lead-data-engineer-at-artius-solutions-3888434999,3888434999,"We are looking for a Lead Data Engineer to join our growing team of experts. This position will work in the design and development of Snowflake Data Cloud solutions, including data ingestion pipelines, data architecture, data governance and security. The Lead Data Engineer will develop database architectures and data warehouses while ensuring optimal data delivery architecture across customer projects. The right candidate will be excited about working for a start-up company to support next-generation data initiatives.","Snowflake, AWS, Azure, GCP, Teradata, Oracle Exadata, Netezza, SQL Server, Spark, DataStage, Informatica, Matillion, Python, Scala",5-8 years,Bachelor,True,5.0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0
Data Engineer SR,NEORIS,Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-08 11:47:09.018617,25,Information Technology,,,"NEORIS is a Digital accelerator that helps companies enter the future, having 20 years of experience as Digital Partners of some of the largest companies in the world. We have more than 4,000 professionals in 11 countries, with our multicultural startup culture where we cultivate innovation, continuous learning to create high-value solutions for our clients. We are looking for ( Data Engineer Sr ), Descripción Buscamos un ingeniero de datos sénior altamente calificado y con experiencia para unirse a nuestro equipo de ciencia de datos. El ingeniero de datos sénior desempeñará un papel fundamental en el diseño, la construcción y el mantenimiento de infraestructuras y canales de datos escalables. Este rol promoverá la definición y adopción de las mejores prácticas para crear activos de datos reutilizables y administrar todo el ciclo de vida de la ingeniería de datos. El candidato ideal tendrá una sólida formación en ingeniería de datos, pasión por la toma de decisiones basada en datos y la capacidad de trabajar en colaboración con científicos de datos y otras partes interesadas. Responsabilidades Clave Desarrollo de canales de datos: diseñar, desarrollar y mantener canales de datos robustos, escalables y eficientes para respaldar iniciativas de ciencia de datos. Integración de datos: integrar datos de diversas fuentes, garantizando la calidad, consistencia y confiabilidad de los datos. Mejores prácticas: definir y promover las mejores prácticas para la ingeniería de datos, incluidos estándares de codificación, pruebas y documentación. Gestión de activos de datos: cree y administre activos de datos reutilizables que puedan aprovecharse en múltiples proyectos y equipos. Colaboración: trabajar en estrecha colaboración con científicos de datos, analistas y otras partes interesadas para comprender los requisitos de datos y ofrecer soluciones que satisfagan sus necesidades. Optimización del rendimiento: optimice los flujos de trabajo de procesamiento de datos para lograr rendimiento, escalabilidad y rentabilidad. Gobernanza de datos: implementar y hacer cumplir políticas de gobernanza de datos para garantizar la seguridad, la privacidad y el cumplimiento de los datos. Gestión del ciclo de vida: supervise todo el ciclo de vida de la ingeniería de datos, desde el diseño y el desarrollo iniciales hasta la implementación, la supervisión y el mantenimiento. Selección de herramientas: evaluar y recomendar herramientas y tecnologías de ingeniería de datos para mejorar las capacidades del equipo. Mentoría: Orientar y guiar a los ingenieros de datos junior, fomentando una cultura de aprendizaje y mejora continua. Habilidades Requeridas Antecedentes educativos: Licenciatura o maestría en Ciencias de la Computación, Ingeniería, Tecnología de la Información o un campo relacionado. Experiencia: Mínimo de 5 a 7 años de experiencia en ingeniería de datos, con un historial comprobado de diseño e implementación de soluciones de datos a gran escala. Competencia técnica: Sólido dominio de lenguajes de programación como Python, Java o Scala, y experiencia con bases de datos SQL y NoSQL. Herramientas de canalización de datos: experiencia práctica con herramientas de gestión de flujo de trabajo y canalización de datos como Apache Airflow, Luigi o similares. Tecnologías de Big Data: Competencia en tecnologías de big data como Hadoop, Spark, Kafka y plataformas de datos basadas en la nube (por ejemplo, AWS, GCP, Azure). Almacenamiento de datos: experiencia con soluciones de almacenamiento de datos como Amazon Redshift, Google BigQuery o Snowflake. Procesos ETL: Experiencia en diseño e implementación de procesos ETL (Extract, Transform, Load). Modelado de datos: Sólida comprensión de los principios y las mejores prácticas del modelado de datos. Control de versiones: Experiencia con sistemas de control de versiones como Git. Resolución de problemas: Excelentes habilidades para resolver problemas y capacidad para solucionar problemas de datos complejos. Habilidades de comunicación: Sólidas habilidades de comunicación verbal y escrita, con capacidad de transmitir conceptos técnicos a partes interesadas no técnicas. Gestión de proyectos: Experiencia comprobada en la gestión de proyectos de ingeniería de datos, incluida la planificación, ejecución y gestión de partes interesadas. Atención al detalle: Alto nivel de precisión y atención al detalle en todos los aspectos del trabajo. Habilidades Plataformas en la nube: experiencia con servicios e infraestructura de datos basados en la nube (por ejemplo, AWS Glue, Google Cloud Dataflow, Azure Data Factory). Ecosistema Databricks: Experiencia con la plataforma Databricks, la capa Delta Lake y la Arquitectura Medallion. Aprendizaje automático: familiaridad con conceptos y marcos de aprendizaje automático. Gobernanza de datos: Conocimiento de los marcos de gobernanza de datos y mejores prácticas. Metodologías Ágiles: Experiencia trabajando en entornos de desarrollo Ágiles. Certificación: Certificaciones relevantes en ingeniería de datos, plataformas en la nube o áreas relacionadas (por ejemplo, AWS Certified Big Data - Specialty, Google Professional Data Engineer) Hector Antonio Hernandez Sanchez",https://mx.linkedin.com/jobs/view/data-engineer-sr-at-neoris-4015185500,4015185500,"We are looking for a highly qualified senior data engineer with experience to join our data science team. The senior data engineer will play a key role in designing, building, and maintaining scalable data infrastructures and channels. This role will promote the definition and adoption of best practices for creating reusable data assets and managing the entire data engineering lifecycle. The ideal candidate will have a strong background in data engineering, a passion for data-driven decision-making, and the ability to collaborate with data scientists and other stakeholders. Responsibilities include developing robust, scalable data channels, integrating data from various sources, promoting best practices, managing reusable data assets, collaborating with stakeholders, optimizing data processing workflows, implementing data governance policies, overseeing the entire data engineering lifecycle, evaluating tools and technologies for data engineering, mentoring junior data engineers, and ensuring attention to detail.","Python, Java, Scala, SQL, NoSQL, Apache Airflow, Luigi, Hadoop, Spark, Kafka, AWS, GCP, Azure, Amazon Redshift, Google BigQuery, Snowflake, ETL, Git",5 to 7 years,Bachelor,True,5.0,0,0,1,1,0,0,1,0,0,1,0,1,0,0,1,0,0
Sr. Data Engineer II - Mexico City,LexisNexis,Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,"Technology, Information and Media",2024-08-25 11:47:09.018617,25,Information Technology,,,"Senior Data Engineer II Do you consider yourself a highly strategic Data Engineer who thrives in an innovative environment? Are you enthusiastic about new technologies and extracting intelligence from world-class data using AI tools? About our Team LexisNexis Legal & Professional, which serves customers in more than 150 countries with 11,800 employees worldwide, is part of RELX, a global provider of information-based analytics and decision tools for professional and business customers. Our company has been a long-time leader in deploying AI and advanced technologies to the legal market to improve productivity and transform the overall business and practice of law, deploying ethical and powerful generative AI solutions with a flexible, multi-model approach that prioritizes using the best model from today’s top model creators for each individual legal use case. About the Role As the Senior Data Engineer II, you will lead the development and implementation of data engineering solutions to support business objectives. You will be instrumental in shaping functional and business strategies and ensuring their effective execution. This position requires expertise in implementing large language model (LLM) based applications, utilizing proprietary and open-source models, and collaborating with LangChain or LlamaIndex for integration and deployment. Conditions of Employment: *All Qualified Applicants must reside in Mexico City *Able to work in person 2-4 days per week as needed *Bilingual English and Spanish Responsibilities Developing and implementing LLM-based applications. Fine-tuning and deploying large language models Implementing production quality ETL jobs. Creating high-quality RAG-based applications that meet the needs of our users and provide a seamless experience. Integrating models with existing systems and APIs. Preprocessing and managing data for training and deployment Collaborating with cross-functional teams to define, design, and ship new features. Writing clean, maintainable, and efficient code Requirements Demonstrate proven experience with large language models and open-source frameworks. Possess experience with data preprocessing, SQL, and NoSQL databases as well as vector stores (e.g., Postgres, Elasticsearch/OpenSearch, ChromaDB, Solr, etc.) Possess exceptional analytical, communication, and problem-solving skills. Be able to collaborate effectively in an agile team environment to gather and analyze data requirements. Have experience with GPU programming, including CUDA or RAPIDs, and familiarity with deployment tools (Docker, Kubernetes). Knowledge of ML Ops (e.g. model deployment) is highly valued. Possess solid knowledge of API integration (RESTful, GraphQL). Display knowledge of Scala, Spark, Ray, or other distributed computing systems. Work in a way that works for you We promote a healthy work/life balance across the organisation. We offer an appealing working prospect for our people. With numerous wellbeing initiatives, shared parental leave, study assistance and sabbaticals, we will help you meet your immediate responsibilities and your long-term goals. Working flexible hours - flexing the times when you work in the day to help you fit everything in and work when you are the most productive Working for you We know that your well-being and happiness are key to a long and successful career. These are some of the benefits we are delighted to offer: Private Medical/Dental Plan Savings Fund Life Insurance Meal/Grocery Voucher About the Business LexisNexis Legal & Professional® provides legal, regulatory, and business information and analytics that help customers increase their productivity, improve decision-making, achieve better outcomes, and advance the rule of law around the world. As a digital pioneer, the company was the first to bring legal and business information online with its Lexis® and Nexis® services.",https://mx.linkedin.com/jobs/view/sr-data-engineer-ii-mexico-city-at-lexisnexis-4002608446,4002608446,"As the Senior Data Engineer II, you will lead the development and implementation of data engineering solutions to support business objectives. This position requires expertise in implementing large language model (LLM) based applications, utilizing both proprietary and open-source models, and collaborating with LangChain or LlamaIndex for integration and deployment.","Large Language Models (LLM), Python, SQL, NoSQL, Postgres, Elasticsearch, OpenSearch, ChromaDB, Solr, CUDA, RAPIDs, Docker, Kubernetes, Scala, Spark, Ray, RESTful APIs, GraphQL",,,True,,0,0,1,0,1,0,0,0,0,1,0,0,0,0,1,0,0
Support Engineer - Data Analytics,Altair,Mexico City Metropolitan Area,ON-SITE,Entry level,Full-time,Software Development,2024-04-18 11:47:09.018617,25,Information Technology,,,"Transforming the Future with the Convergence of Simulation and Data Technical Support Engineer - Data Analytics We are looking for a committed and high-performing Support Engineer to join our customer success team in Mexico City , strengthening our approach to deliver value and business success in a complex enterprise application environment. Your primary goal is to establish a reliable communication channel to our clients, prospects and partners helping them with all kinds of technical inquiries. Furthermore, you will help to deploy and use our products in a data science driven application stack. This includes deployment building and maintenance operations in a diverse enterprise environment. You work closely with our clients supporting them to understand usage and configuration of Altair’s data analytics applications, identify issues and requirements achieving the right level of connectivity, scalability and resilience to successfully drive the use cases and deliver business value. You will work in a rapidly evolving field providing the chance as well as raising the need to learn about new fascinating techniques in the field of data science, predictive analytics, cloud computing and enterprise software. You will have the opportunity to work in a global technology company with a key role in providing customer success and driving user adoption to state of the art data science applications. This is a unique opportunity to be part of a team that has already delivered a variety of market leading products used by a constantly growing data science community. The challenge is to take this success to the next level in terms of user experience, computational power, and business success. What You Will Do Customer technical support – engage with customers, prospects as well as Altair field teams, engineering, product management to identify and resolve issues in a timely manner Drive customer success – work closely with the customers, prospects and partners helping to build state of the art application deployments using software from the Altair portfolio in a complex enterprise environment helping our clients to achieve success in a variety of uses cases Communicate Altair – manage relationships between Altair and our clients to provide a reliable communication channel for all kinds of technical inquiries Work with the team – use your experience and application insight to support Altair teams in a variety of scenarios What You Will Need Mainframe experience, especially with SAS applications stack is highly welcome Analytics or IT management background Experience in using and administrating data science tools (i.e. RapidMiner, SAS, SPSS, R, Python) and/or enterprise applications stacks (AWS, Azure, ActiveDirectory, BI applications, RDBMS such as SQLServer, Oracle, Snowflake, MySQL, DB2, PostgreSQL etc) Willingness to learn about new technologies in the field of data science and enterprise applications, both cloud based an d on premise Knowledge of standard tools for system administration in Windows and Linux environments Strong communication skills and commitment to work with clients via ticket systems, phone calls and web meetings Interest in software development and basic knowledge of scripting and programming languages like SAS, Python and Java English language fluency – another language (German, Spanish, French) is not essential but is a plus How You Will Be Successful Envision the Future Communicate Honestly and Broadly Seek Technology and Business “Firsts” Embrace Diversity and Take Risks What We Offer Competitive Salary Flexible Work Hours 75% Vacation Prime 1 Month Christmas Bonus 12 Days of Vacation SGMM Life Insurance Dental Insurance Saving Fund Pantry Voucher Work Life Balance Employee Stock Purchase Program Equal Employee Opportunity Why Work With Us Altair is a global technology company providing software and cloud solutions in the areas of product development, high-performance computing (HPC) and artificial intelligence (AI). Altair enables organizations in nearly every industry to compete more effectively in a connected world, while creating a more sustainable future. With more than 3,000 engineers, scientists, and creative thinkers in 25 countries, we help solve our customer’s toughest challenges and deliver unparalleled service, helping the innovators innovate, drive better decisions, and turn today’s problems into tomorrow’s opportunities. Our vision is to transform customer decision making with data analytics, simulation, and high-performance computing and artificial intelligence (AI). For more than 30 years, we have been helping our customers integrate electronics and controls with mechanical design to expand product value, develop AI, simulation, and data-driven digital twins to drive better decisions, and deliver advanced HPC and cloud solutions to support unlimited idea exploration. To learn more, please visit altair.com . Ready to go? #ONLYFORWARD At our core we are explorers; adventurers; pioneers. We are the brains behind some of the world’s most revolutionary innovations and are not only comfortable in new and uncharted waters, we dive in headfirst. We are the original trailblazers that make the impossible possible, discovering new solutions to our customer’s toughest challenges. Altair is an equal opportunity employer. Our backgrounds are diverse, and every member of our global team is critical to our success. Altair's history demonstrates a belief that empowering each individual authentic voice reinforces a culture that thrives because of the uniqueness among our team.",https://mx.linkedin.com/jobs/view/support-engineer-data-analytics-at-altair-3901589359,3901589359,"We are looking for a committed and high-performing Support Engineer to join our customer success team in Mexico City. Your primary goal is to establish reliable communication with clients and help them with technical inquiries, deploying and using our products in a data science-driven application stack. You will support clients in understanding usage and configuration of Altair’s data analytics applications, identify issues, and drive user adoption to deliver business value. You will work in a rapidly evolving field, providing the chance to learn about new techniques in data science and enterprise software.","SAS, RapidMiner, SPSS, R, Python, AWS, Azure, Active Directory, SQL Server, Oracle, Snowflake, MySQL, DB2, PostgreSQL, Windows, Linux, Java",,,True,,0,0,0,1,0,0,0,0,0,1,0,0,0,0,1,0,0
EY- GDS - DnA - Cloud Data Engineer - Manager,EY,Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-01 11:47:09.018617,25,Information Technology,,,"EY-GDS- DnA Consulting – TPM Data Engineer Azure As part of our EY- GDS-DnA Consulting team, you will help clients use various methods to transform raw data into useful data systems. You will align data systems with business goals. You must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The ideal candidate should have 3-5 years of experience, Data Engineering, AZURE Cloud, Advanced SQL, Advanced Phyton programming, ETL and ELT Process knowledge, Data structures knowledge, MPP Databases (Teradata, Snowflake), Blob Storage, Azure Data Lake Storage, AZURE cloud. The Data Engineer will interact with different members of the team such as database architects, data analysts, and data scientists on data initiatives and ensure optimal data delivery architecture is consistent with business strategy. Our clients usually have theirs headquarters on USA, however they span across multiple industries, regions, and countries. The opportunity We are looking for Senior Data Engineer with expertise in developing and managing data pipelines, implementing complex stored procedures and best practices with data warehouse and ETL concepts, deploy fully operational data warehouse solutions into production. This is a fantastic opportunity to be part of a leading firm whilst being instrumental in the growth of a new service offering. Your key responsibilities Design and Develop batch and streaming data processing Build data systems and pipelines. Evaluate business needs and objectives. Prepare data for prescriptive and predictive modeling. Build prototypes. Combine raw information from different sources. Explore ways to enhance data quality and reliability. Identify opportunities for data acquisition. Monitor and optimize data storage and data processing Design and implement data security Skills and attributes for success Data Project Management / Tech Lead 5-7 years of experience on Azure Data Factory 5-7 years of experience on Databricks / Synapse Experience on processing real time data. Advanced knowledge on processing large amounts of data (billions of records) 5-7 years of advanced knowledge on SQL, phyton programming, ETL and ELT Process. Advanced knowledge on data structures, MPP Databases, Blob Storage. 5-7 years of experience on AZURE storage (Blob, ADLS) Previous experience as a data engineer or in a similar role. Data engineering certification (AZURE Certified Data Engineer) is a plus. Flexible and adaptable; able to work in ambiguous situations. Able to work effectively at all levels in an organization. Must be a team player and able to work collaboratively with and through others. Must like to learn. To qualify for the role, you must have Bachelor’s in technology or engineering or similar. Experience working with Azure, Snowflake technologies. Ideally, you’ll also have Familiarity with agile methodologies. Familiarity with software such as Jira or ADO. What we look for A Team of people with technical experience and enthusiasm to learn new things in this fast-moving environment Opportunities to work with EY GDS DnA Consulting practice globally with leading businesses across a range of industries What working at EY offers At EY, we’re dedicated to helping our clients, from world’s top companies — and the work we do with them is as varied as they are. You get to work with inspiring and meaningful projects. Our focus is education and coaching alongside practical experience to ensure your personal development. We value our employees, and you will be able to control your own development with an individual progression plan. You will quickly grow into a responsible role with challenging and stimulating assignments. Moreover, you will be part of an interdisciplinary environment that emphasizes high quality and knowledge exchange. Plus, we offer: Support, coaching and feedback from some of the most engaging colleagues around Opportunities to develop new skills and progress your career The freedom and flexibility to handle your role in a way that’s right for you About EY As a global leader in assurance, tax, transaction, and advisory services, we’re using the finance products, expertise, and systems we’ve developed to build a better working world. That starts with a culture that believes in giving you the training, opportunities, and creative freedom to make things better. Whenever you join, however long you stay, the exceptional EY experience lasts a lifetime. And with a commitment to hiring and developing the most passionate people, we’ll make our ambition to be the best employer by 2020 a reality. If you can confidently demonstrate that you meet the criteria above, please contact us as soon as possible. Join us in building a better working world. Apply now",https://mx.linkedin.com/jobs/view/ey-gds-dna-cloud-data-engineer-manager-at-ey-4009437126,4009437126,"As part of the EY-GDS-DnA Consulting team, you will help clients transform raw data into useful data systems and align them with business goals. The ideal candidate should have 3-5 years of experience in Data Engineering, AZURE Cloud, Advanced SQL, Advanced Python programming, ETL and ELT processes, Data structures, MPP Databases (Teradata, Snowflake), Blob Storage, and Azure Data Lake Storage. You will design and develop batch and streaming data processing, build data systems and pipelines, and prepare data for modeling. You must have a Bachelor’s in technology or engineering or a similar field.","Azure, Advanced SQL, Python, ETL, ELT, Teradata, Snowflake, Blob Storage, Azure Data Lake Storage, Databricks, Synapse",3-5,Bachelor,True,3.0,0,0,1,1,0,0,1,0,0,1,0,0,0,0,1,0,0
Lead Data Engineer,Reuters News Agency,Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,Media Production,2024-07-17 11:47:09.018617,25,Information Technology,,,"Job Description Lead Data Engineer Are you passionate about the chance to bring your experience to a world-class company that is market-leading for both content and technology? If yes, we are looking for you! Join our team! We are seeking a highly skilled and experienced Lead Data Engineer to join our dynamic team. The ideal candidate will be responsible for designing, developing, and maintaining scalable data pipelines and ETL/ELT processes, as well as ensuring the integrity and performance of our data systems. You will work closely with cross-functional teams to gather business requirements and translate them into technical specifications, leveraging your expertise in SQL, .NET, and various data transformation and visualization tools. About The Role In this opportunity as a Lead Data Engineer , you will: Design, develop, and maintain scalable data pipelines and ETL/ELT processes using tools like DBT, FiveTran, and AirFlow. Develop, maintain, and optimize complex SQL queries, stored procedures, and data models in MSSQL and Google Big Query. Develop and externalize API endpoints using .NET and OData. Implement and maintain data visualization and analytics dashboards using BI platforms like Google Looker and Power BI. Collaborate with cross-functional teams to gather and analyze business requirements and translate them into technical specifications. Ensure data quality, integrity, and security through effective data governance practices. Monitor, troubleshoot, and resolve data issues, ensuring high availability and performance of data systems. Stay current with industry trends and emerging technologies to continuously improve data solutions. About You You’re a fit for the role if your background includes: Bachelor’s degree in Computer Science, Information Technology, or a related field. 5+ years of professional experience in data engineering, software development, or a similar role. Experience with cloud platforms such as GCP, AWS, or Azure and related services. Strong proficiency in MSSQL, including complex queries, stored procedures, and performance tuning. Extensive experience with data transformation and modeling tools like DBT. Hands-on experience with Google Big Query or similar data warehousing technologies. Proficiency in data visualization and reporting tools. Familiarity with OData and JSON for data integration and management. Experience with ETL/ELT tools and processes, including FiveTran and AirFlow. Strong programming skills in .NET, .NET Core, and C#. Excellent problem-solving skills and attention to detail. Strong communication and collaboration skills. Ability to work independently and manage multiple tasks simultaneously. Experience with Agile development methodologies. To apply, please upload your updated resume in English. Location: CDMX What's in it For You? You will join our inclusive culture of world-class talent, where we are committed to your personal and professional growth through: Hybrid Work Model: We’ve adopted a flexible hybrid working environment (2-3 days a week in the office depending on the role) for our office-based roles while delivering a seamless experience that is digitally and physically connected Wellbeing: Comprehensive benefit plans; flexible and supportive benefits for work-life balance: flexible vacation, two company-wide Mental Health Days Off; work from another location for up to a total of 8 weeks in a year, 4 of those weeks can be out of the country and the remaining in the country, Headspace app subscription; retirement, and employee incentive programs; resources for mental, physical, and financial wellbeing. Culture: Globally recognized and award-winning reputation for equality, diversity and inclusion, flexibility, work-life balance, and more. Learning & Development: LinkedIn Learning access; internal Talent Marketplace with opportunities to work on projects cross-company; Ten Thousand Coffees Thomson Reuters café networking. Social Impact: Ten employee-driven Business Resource Groups; two paid volunteer days annually; Environmental, Social, and Governance (ESG) initiatives for local and global impact. Purpose-Driven Work: We have a superpower that we’ve never talked about with as much pride as we should – we are one of the only companies on the planet that helps its customers pursue justice, truth, and transparency. Together, with the professionals and institutions we serve, we help uphold the rule of law, turn the wheels of commerce, catch bad actors, report the facts, and provide trusted, unbiased information to people all over the world. Do you want to be part of a team helping re-invent the way knowledge professionals work? How about a team that works every day to create a more transparent, just and inclusive future? At Thomson Reuters, we’ve been doing just that for almost 160 years. Our industry-leading products and services include highly specialized information-enabled software and tools for legal, tax, accounting and compliance professionals combined with the world’s most global news services – Reuters. We help these professionals do their jobs better, creating more time for them to focus on the things that matter most: advising, advocating, negotiating, governing and informing. We are powered by the talents of 26,000 employees across more than 70 countries, where everyone has a chance to contribute and grow professionally in flexible work environments that celebrate diversity and inclusion. At a time when objectivity, accuracy, fairness and transparency are under attack, we consider it our duty to pursue them. Sound exciting? Join us and help shape the industries that move society forward. Accessibility As a global business, we rely on diversity of culture and thought to deliver on our goals. To ensure we can do that, we seek talented, qualified employees in all our operations around the world regardless of race, color, sex/gender, including pregnancy, gender identity and expression, national origin, religion, sexual orientation, disability, age, marital status, citizen status, veteran status, or any other protected classification under applicable law. Thomson Reuters is proud to be an Equal Employment Opportunity/Affirmative Action Employer providing a drug-free workplace. We also make reasonable accommodations for qualified individuals with disabilities and for sincerely held religious beliefs in accordance with applicable law. Protect yourself from fraudulent job postings click here to know more. More information about Thomson Reuters can be found on https://thomsonreuters.com.",https://mx.linkedin.com/jobs/view/lead-data-engineer-at-reuters-news-agency-3969222666,3969222666,"We are seeking a highly skilled and experienced Lead Data Engineer responsible for designing, developing, and maintaining scalable data pipelines and ETL/ELT processes, ensuring the integrity and performance of our data systems. You will work closely with cross-functional teams to gather business requirements and translate them into technical specifications, leveraging your expertise in SQL, .NET, and various data transformation and visualization tools.","SQL, .NET, DBT, FiveTran, AirFlow, MSSQL, Google Big Query, OData, Power BI, Google Looker, C#, JSON",5+ years,Bachelor,True,5.0,0,1,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0
Data Engineer / Modelling Analyst - ETL,S&P Global,Mexico City Metropolitan Area,ON-SITE,,Full-time,Financial Services,2024-09-01 11:47:09.018617,97,Information Technology,,,"About The Role Grade Level (for internal use): 10 Data Engineer - S&P Global Commodity Insights S&P Global is looking for a Data Engineer who will be a part of our Data Science and Modelling team. The ideal candidate should be highly motivated and goal-oriented, with an encouraging attitude of working in a very dynamic work environment with a wide range of stakeholders and functional teams. Job Summary: As a Data Engineer at S&P Global, you will utilize your extensive technical skills to architect, build, and maintain our evolving data infrastructure, which is essential for supporting our advanced analytics and machine learning initiatives. You will work closely with various stakeholders to acquire, process, and refine vast datasets, focusing on creating scalable and optimized data pipelines. Your work will be pivotal for enabling data scientists to extract meaningful insights and develop AI-driven solutions that serve various business purposes, from internal decision-making to product development. Responsibilities To collaborate with stakeholders, including data scientists, analysts, and other engineers, to understand and refine requirements related to data processing and transformation needs. To design, construct, install, and maintain large-scale processing systems and other infrastructure. To build high-performance algorithms, prototypes, and conceptual models and enable the efficient retrieval and analysis of data. To implement ETL processes to acquire, validate, and process incoming data from diverse sources. To ensure data architecture and model adhere to compliance, privacy, and security standards. To work in conjunction with data scientists to optimize data science and machine learning algorithms and models. To provide technical expertise in the resolution of data-related issues, including data quality, data lineage, and data processing errors. To manage the deployment of analytics solutions into production and maintain them. To maintain high-quality processes and deliver projects in collaborative Agile team environments. Requirements 7+ years of programming experience particularly in Python 4+ years of experience working with SQL or NoSQL databases. University degree in Computer Science, Engineering, Mathematics, or related disciplines. Strong understanding of big data technologies, Container management tools Demonstrated ability to design and implement end-to-end scalable and performant data pipelines. Experience with workflow management platforms like Airflow. Strong analytical and problem-solving skills. Ability to collaborate and communicate effectively with both technical and non-technical stakeholders in English. Experience building solutions and working in the Agile working environment Experience working with git or other source control tools Nice To Have Experience working with Oil, gas, and energy markets. Familiarity with BI Visualization applications (e.g. Tableau, Power BI, Spotfire). Understanding of cloud-based services, preferably AWS. Experience working with Unified analytics platforms like Databricks. Experience in managing and deploying containerized applications using Cloud-native orchestration tools, Data stream processing tools, Container platforms. Machine learning/Data Science experience. Note: Work from home role. Location - Mexico Virtual, Colombia Virtual, Brazil Virtual About S&P Global Commodity Insights At S&P Global Commodity Insights, our complete view of global energy and commodities markets enables our customers to make decisions with conviction and create long-term, sustainable value. We’re a trusted connector that brings together thought leaders, market participants, governments, and regulators to co-create solutions that lead to progress. Vital to navigating Energy Transition, S&P Global Commodity Insights’ coverage includes oil and gas, power, chemicals, metals, agriculture and shipping. S&P Global Commodity Insights is a division of S&P Global (NYSE: SPGI). S&P Global is the world’s foremost provider of credit ratings, benchmarks, analytics and workflow solutions in the global capital, commodity and automotive markets. With every one of our offerings, we help many of the world’s leading organizations navigate the economic landscape so they can plan for tomorrow, today. For more information, visit http://www.spglobal.com/commodity-insights. What’s In It For You? Our Purpose Progress is not a self-starter. It requires a catalyst to be set in motion. Information, imagination, people, technology–the right combination can unlock possibility and change the world. Our world is in transition and getting more complex by the day. We push past expected observations and seek out new levels of understanding so that we can help companies, governments and individuals make an impact on tomorrow. At S&P Global we transform data into Essential Intelligence®, pinpointing risks and opening possibilities. We Accelerate Progress. Our People We're more than 35,000 strong worldwide—so we're able to understand nuances while having a broad perspective. Our team is driven by curiosity and a shared belief that Essential Intelligence can help build a more prosperous future for us all. From finding new ways to measure sustainability to analyzing energy transition across the supply chain to building workflow solutions that make it easy to tap into insight and apply it. We are changing the way people see things and empowering them to make an impact on the world we live in. We’re committed to a more equitable future and to helping our customers find new, sustainable ways of doing business. We’re constantly seeking new solutions that have progress in mind. Join us and help create the critical insights that truly make a difference. Our Values Integrity, Discovery, Partnership At S&P Global, we focus on Powering Global Markets. Throughout our history, the world's leading organizations have relied on us for the Essential Intelligence they need to make confident decisions about the road ahead. We start with a foundation of integrity in all we do, bring a spirit of discovery to our work, and collaborate in close partnership with each other and our customers to achieve shared goals. Benefits We take care of you, so you can take care of business. We care about our people. That’s why we provide everything you—and your career—need to thrive at S&P Global. Our Benefits Include Health & Wellness: Health care coverage designed for the mind and body. Flexible Downtime: Generous time off helps keep you energized for your time on. Continuous Learning: Access a wealth of resources to grow your career and learn valuable new skills. Invest in Your Future: Secure your financial future through competitive pay, retirement planning, a continuing education program with a company-matched student loan contribution, and financial wellness programs. Family Friendly Perks: It’s not just about you. S&P Global has perks for your partners and little ones, too, with some best-in class benefits for families. Beyond the Basics: From retail discounts to referral incentive awards—small perks can make a big difference. For more information on benefits by country visit: https://spgbenefits.com/benefit-summaries Diversity, Equity, And Inclusion At S&P Global At S&P Global, we believe diversity fuels creative insights, equity unlocks opportunity, and inclusion drives growth and innovation – Powering Global Markets. Our commitment centers on our global workforce, ensuring that our people are empowered to bring their whole selves to work. It doesn’t stop there, we strive to better reflect and serve the communities in which we live and work, and advocate for greater opportunity for all. Equal Opportunity Employer S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. US Candidates Only: The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. 20 - Professional (EEO-2 Job Categories-United States of America), ANLYTC202.1 - Middle Professional Tier I (EEO Job Group), SWP Priority – Ratings - (Strategic Workforce Planning) Job ID: 304528 Posted On: 2024-08-14 Location: Mexico City, Mexico",https://mx.linkedin.com/jobs/view/data-engineer-modelling-analyst-etl-at-s-p-global-3978165164,3978165164,"As a Data Engineer at S&P Global, you will utilize your extensive technical skills to architect, build, and maintain data infrastructure essential for supporting advanced analytics and machine learning initiatives. You will work closely with stakeholders to acquire, process, and refine vast datasets, focusing on creating scalable and optimized data pipelines. Your work will enable data scientists to extract meaningful insights and develop AI-driven solutions for various business purposes.","Python, SQL, NoSQL, ETL, Airflow, Agile Methodologies, Git, Cloud services, AWS, Databricks",7+ years,,True,7.0,1,0,1,1,0,0,1,0,0,1,0,1,0,0,1,0,0
Data Engineer,WTW,Mexico City Metropolitan Area,ON-SITE,Entry level,Full-time,Financial Services,2024-09-08 11:47:09.018617,36,Information Technology,,,"Job Description We are looking for a Data Engineer to join our team. You should value expertise and a passion for the optimization of data and data pipeline architecture. You should be able to recognize and stay up to date on current techniques and tools, but also be pragmatic at knowing what is and isn’t a good fit. Qualifications The Requirements 2+ years’ experience as a data engineer. Experience creating reports using Power BI. Proficient using SQL. Familiarity with cloud ETL tools such as Azure Data Factory. Degree (Associates or Bachelors) in computer science, management information systems or related area Experience with Agile methodologies including Scrum framework and Kanban preferred Willingness to work in a fast-paced collaborative team environment that has tight deadlines. Ability to learn and evaluate new tools, concepts, and challenges quickly. Customer service focus and flexibility in supporting customer requests. Strong analytical and problem-solving skills. Commitment to quality and continuous improvement. Strong written and verbal communication skills. Be available, at times, to work extended work hours. Background in benefits administration a plus Equal Employment Opportunity",https://mx.linkedin.com/jobs/view/data-engineer-at-wtw-4002973604,4002973604,"We are looking for a Data Engineer to join our team. You should value expertise and a passion for the optimization of data and data pipeline architecture. You should be able to recognize and stay up to date on current techniques and tools, but also be pragmatic at knowing what is and isn’t a good fit.","SQL, Power BI, Azure Data Factory, Agile Methodologies, Scrum, Kanban",2+ years,Bachelor,True,2.0,1,0,0,1,0,0,0,0,1,1,0,0,0,0,0,0,0
Data Engineer - EY Global Delivery Services,EY,Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-08 11:47:09.018617,25,Information Technology,,,"EY-GDS - DnA Consulting - Data Engineer Databricks - AWSe As part of our EY- GDS-DnA Consulting team, you will help clients use various methods to transform raw data into useful data systems. You will align data systems with business goals. You must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The ideal candidate should have 3-5 years of experience, Data Engineering, AWS Cloud, Advanced SQL, Advanced Phyton programming, ETL and ELT Process knowledge, Data structures knowledge, MPP Databases (Teradata, Snowflake), Blob Storage, S3 Storage, Redshift. The Data Engineer will interact with different members of the team such as database architects, data analysts, and data scientists on data initiatives and ensure optimal data delivery architecture is consistent with business strategy. Our clients usually have theirs headquarters on USA, however they span across multiple industries, regions, and countries. The opportunity We are looking for Senior Data Engineer with expertise in developing and managing data pipelines, implementing complex stored procedures and best practices with data warehouse and ETL concepts, deploy fully operational data warehouse solutions into production. This is a fantastic opportunity to be part of a leading firm whilst being instrumental in the growth of a new service offering. Your key responsibilities Design and Develop batch and streaming data processing Build data systems and pipelines. Evaluate business needs and objectives. Prepare data for prescriptive and predictive modeling. Build prototypes. Combine raw information from different sources. Explore ways to enhance data quality and reliability. Identify opportunities for data acquisition. Monitor and optimize data storage and data processing Design and implement data security Skills and attributes for success 3-5 years of experience on AWS 3-5 years of experience on Databricks Experience on processing real time data. Advanced knowledge on processing large amounts of data (billions of records) 3-5 years of advanced knowledge on SQL, phyton programming, ETL and ELT Process. Advanced knowledge on data structures, MPP Databases, Blob Storage. 3-5 years of experience on AWS storage (S3) Previous experience as a data engineer or in a similar role. Data engineering certification AWS is a plus. Flexible and adaptable; able to work in ambiguous situations. Able to work effectively at all levels in an organization. Must be a team player and able to work collaboratively with and through others. Must like to learn. To qualify for the role, you must have Bachelor’s in technology or engineering or similar. Experience working with Azure, Snowflake technologies. Ideally, you’ll also have Familiarity with agile methodologies. Familiarity with software such as Jira or ADO. What we look for A Team of people with technical experience and enthusiasm to learn new things in this fast-moving environment Opportunities to work with EY GDS DnA Consulting practice globally with leading businesses across a range of industries What working at EY offers At EY, we’re dedicated to helping our clients, from world’s top companies - and the work we do with them is as varied as they are. You get to work with inspiring and meaningful projects. Our focus is education and coaching alongside practical experience to ensure your personal development. We value our employees, and you will be able to control your own development with an individual progression plan. You will quickly grow into a responsible role with challenging and stimulating assignments. Moreover, you will be part of an interdisciplinary environment that emphasizes high quality and knowledge exchange. Plus, we offer: Support, coaching and feedback from some of the most engaging colleagues around Opportunities to develop new skills and progress your career The freedom and flexibility to handle your role in a way that’s right for you About EY As a global leader in assurance, tax, transaction, and advisory services, we’re using the finance products, expertise, and systems we’ve developed to build a better working world. That starts with a culture that believes in giving you the training, opportunities, and creative freedom to make things better. Whenever you join, however long you stay, the exceptional EY experience lasts a lifetime. And with a commitment to hiring and developing the most passionate people, we’ll make our ambition to be the best employer by 2020 a reality. If you can confidently demonstrate that you meet the criteria above, please contact us as soon as possible. Join us in building a better working world. Apply now",https://mx.linkedin.com/jobs/view/data-engineer-ey-global-delivery-services-at-ey-3967802729,3967802729,"As part of the EY-GDS-DnA Consulting team, you will help clients transform raw data into useful data systems aligned with business goals. The ideal candidate should have 3-5 years of experience in Data Engineering, AWS Cloud, Advanced SQL, Python programming, ETL and ELT processes, and knowledge of data structures and MPP databases such as Teradata and Snowflake. Responsibilities include designing and developing batch and streaming data processing, preparing data for modeling, and optimizing data storage and processing. A Bachelor’s degree in technology or engineering or a similar field is required.","AWS, Databricks, SQL, Python, ETL, ELT, MPP Databases, Blob Storage, S3, Redshift",3-5 years,Bachelor,True,3.0,0,0,1,1,0,0,1,0,0,1,0,0,0,0,1,0,0
Sr Data Engineer (Azure) - Argentina/Mexico,Syneos Health,Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,"Biotechnology Research, Pharmaceutical Manufacturing, and Research Services",2024-09-01 11:47:09.018617,25,Information Technology,,,"Description Sr Data Engineer (LATAM) Syneos Health® is a leading fully integrated biopharmaceutical solutions organization built to accelerate customer success. We translate unique clinical, medical affairs and commercial insights into outcomes to address modern market realities. Every day we perform better because of how we work together, as one team, each the best at what we do. We bring a wide range of talented experts together across a wide range of business-critical services that support our business. Every role within Corporate is vital to furthering our vision of Shortening the Distance from Lab to Life®. Discover what our 29,000 employees, across 110 countries already know: WORK HERE MATTERS EVERYWHERE Why Syneos Health We are passionate about developing our people, through career development and progression; supportive and engaged line management; technical and therapeutic area training; peer recognition and total rewards program. We are committed to our Total Self culture – where you can authentically be yourself. Our Total Self culture is what unites us globally, and we are dedicated to taking care of our people. We are continuously building the company we all want to work for and our customers want to work with. Why? Because when we bring together diversity of thoughts, backgrounds, cultures, and perspectives – we’re able to create a place where everyone feels like they belong. Job Responsibilities Work independently to solve complex open-ended questions. Develop and maintain end-to-end data pipelines using cloud-native solutions to extract, load, and transform data from disparate data sources to a cloud data warehouse. Capable of formatting and distributing custom data extracts through various means (e.g., custom SFTPs, APIs (e.g., RESTful), and other bulk data transfer mediums) and optimizing data storage options based on business requirements. Create models to transform raw data into analytics ready data structures. Competent in helping to develop/design database structure and function, schema design, and database testing protocols. Establish and enforce engineering best practices and standards. Contribute to engineering wiki and document work. Design end-to-end data pipelines using cloud-native solutions to extract, load, and transform data from disparate data sources to a data warehouse. Contribute to the process of defining company data assets (data models) and custom client workflows, as well as standardized data quality protocols. Capable of independently and collaboratively troubleshooting database issues and queries for improving data retrieval times across various systems (e.g., via SQL). Collaborate with both technical and non-technical stakeholders including IT, Data Science, and various team members across a diverse array of business units. Work closely with IT team whenever necessary to help facilitate, troubleshoot, or develop database connectivity between internal/external resources (e.g., on-premises Azure Data Lakes, Data Warehouses, and Data Hubs). Help implement and enforce enterprise reference architecture and ensure that data infrastructure design reflects enterprise business rules as well as data governance and security guidelines. Communicate and collaborate with business and technical stakeholders to gather business needs as well as functional requirements that inform product and resource design and ensure that technical implementation considerations are understood and accepted. Mentor and coach junior team members across the business. Qualifications What we’re looking for Bachelor’s degree (BS/BA) in Information Systems, Software Engineering, Computer Science, Data Engineering, or related field required. Master’s degree (MS/MA) preferred. Candidates located in: Argentina and/or Mexico Experience with ETL/ELT, taking data from various data sources and formats and ingesting into a cloud-native data warehouse required. Experience with Azure Stack (Data Lake/Blob Storage, PowerBI Services, Azure Data Factory (or equivalent), Databrick) and production level experience with on-premises Microsoft SQL Server required. Experience with one of the following: Python, R, and/or Scala as well as standard analytic libraries/packages (e.g., pandas, Numpy, dplyr, data table, stringr, Slick, and/or Kafka) and related distribution frameworks required. Strong verbal and written communication skills required. Familiarity with agile and lean concepts that drive towards MVPs and iterative learning to generate the desired business and technology outcomes required. Experience with DataRobot, Domino Data Labs, Salesforce MC, Veeva CRM. Experience with US healthcare and healthcare data, as well as familiarity with HIPAA guidelines, and best practices for handling and storing PHI and PII. Experience with healthcare marketing analytics, healthcare data (claims), and common medical coding sets (ICD, HCPCs, NPIs). Familiarity with modern data stack components like Snowflake, dbt, Stitch, Tableau, and Airflow preferred. Familiarity with statistical concepts and analytic modeling (e.g., regression analyses, hypothesis testing, and ML based modeling) preferred. Experience with software engineering best practices like version control with Git and CI/CD preferred. Get to know Syneos Health Over the past 5 years, we have worked with 94% of all Novel FDA Approved Drugs, 95% of EMA Authorized Products and over 200 Studies across 73,000 Sites and 675,000+ Trial patients. No matter what your role is, you’ll take the initiative and challenge the status quo with us in a highly competitive and ever-changing environment. Learn more about Syneos Health. Additional Information Tasks, duties, and responsibilities as listed in this job description are not exhaustive. The Company, at its sole discretion and with no prior notice, may assign other tasks, duties, and job responsibilities. Equivalent experience, skills, and/or education will also be considered so qualifications of incumbents may differ from those listed in the Job Description. The Company, at its sole discretion, will determine what constitutes as equivalent to the qualifications described above. Further, nothing contained herein should be construed to create an employment contract. Occasionally, required skills/experiences for jobs are expressed in brief terms. Any language contained herein is intended to fully comply with all obligations imposed by the legislation of each country in which it operates, including the implementation of the EU Equality Directive, in relation to the recruitment and employment of its employees. The Company is committed to compliance with the Americans with Disabilities Act, including the provision of reasonable accommodations, when appropriate, to assist employees or applicants to perform the essential functions of the job.",https://mx.linkedin.com/jobs/view/sr-data-engineer-azure-argentina-mexico-at-syneos-health-4005412468,4005412468,"The Senior Data Engineer will work independently to solve complex questions, developing and maintaining end-to-end data pipelines using cloud-native solutions. This includes extracting, loading, and transforming data from various sources to a cloud data warehouse, optimizing data storage, designing database structures, and troubleshooting database issues. The role involves collaboration with both technical and non-technical stakeholders, as well as mentoring junior team members.","ETL/ELT, Azure Stack, Microsoft SQL Server, Python, R, Scala, pandas, Numpy, dplyr, data.table, stringr, Slick, Kafka, DataRobot, Domino Data Labs, Salesforce MC, Veeva CRM, Snowflake, dbt, Stitch, Tableau, Airflow, Git",,Bachelor,True,,0,0,1,1,0,0,1,0,1,1,0,1,0,0,1,0,0
Senior Data Engineer,Reuters News Agency,Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,Media Production,2024-09-08 11:47:09.018617,25,Information Technology,,,"Job Description As a Senior Data Engineer with our team, you'll play a pivotal role in shaping the future of our data products and analytical services. Leveraging your expertise in DBT (Data Build Tool), SQL/Snowflake, and AWS/Azure, you'll work with stakeholders across Audit, Tax, and Accounting, to build and maintain robust data pipelines that power our analytics and drive informed decision-making for us and our customers. About The Role Developing/enhancing data warehousing functionality including the use and management of Snowflake data warehouse and the surrounding entitlements, pipelines and monitoring, in partnership with Architects and Data Analysts Innovate with new approaches to meeting data management requirements Effectively communicate and liaise with other data management teams embedded across the organization and data consumers in data science and business analytics teams. Analyze existing data pipelines and assist in enhancing and re-engineering the pipelines as per business requirements. Utilize your experience in the following areas: Azure Cloud Data practices and DevOps tooling Airflow, Data lake, Databricks, SQL, Pyspark, DBT and Snowflake Data Warehousing, Modelling and management Data Build tool (DBT) and other SQL automation Python, Matlab, or similar scripting Data Management and Data warehousing processing capabilities Metadata Repositories, Information & Data Catalogs Data governance as it applies to security and privacy Master Data platform capabilities Data Security, Privacy, and Compliance Delivers end-to-end technical solutions for multiple products or complex projects About You Bachelor’s degree or equivalent required, Computer Science or related technical degree preferred 5+ years of relevant experience in Implementation of data warehouse and data management of data technologies for large scale organizations Experience in building and maintaining optimized and highly available data pipelines that facilitate deeper analysis and reporting Worked on Analyzing data pipelines Knowledgeable about Airflow, Data lake, Databricks, SQL, Pyspark, DBT and Snowflake Broad understanding of the technologies used to build and operate data and analytic systems Excellent critical thinking, communication, presentation, documentation, troubleshooting and collaborative problem-solving skills Hands-on experience with programming and scripting languages Fluency in SQL At least one Business Intelligence tool such as PowerBI/Domo/Tableau Location: Mexico City What's in it For You? You will join our inclusive culture of world-class talent, where we are committed to your personal and professional growth through: Hybrid Work Model: We’ve adopted a flexible hybrid working environment (2-3 days a week in the office depending on the role) for our office-based roles while delivering a seamless experience that is digitally and physically connected Wellbeing: Comprehensive benefit plans; flexible and supportive benefits for work-life balance: flexible vacation, two company-wide Mental Health Days Off; work from another location for up to a total of 8 weeks in a year, 4 of those weeks can be out of the country and the remaining in the country, Headspace app subscription; retirement, and employee incentive programs; resources for mental, physical, and financial wellbeing. Culture: Globally recognized and award-winning reputation for equality, diversity and inclusion, flexibility, work-life balance, and more. Learning & Development: LinkedIn Learning access; internal Talent Marketplace with opportunities to work on projects cross-company; Ten Thousand Coffees Thomson Reuters café networking. Social Impact: Ten employee-driven Business Resource Groups; two paid volunteer days annually; Environmental, Social, and Governance (ESG) initiatives for local and global impact. Purpose-Driven Work: We have a superpower that we’ve never talked about with as much pride as we should – we are one of the only companies on the planet that helps its customers pursue justice, truth, and transparency. Together, with the professionals and institutions we serve, we help uphold the rule of law, turn the wheels of commerce, catch bad actors, report the facts, and provide trusted, unbiased information to people all over the world. Do you want to be part of a team helping re-invent the way knowledge professionals work? How about a team that works every day to create a more transparent, just and inclusive future? At Thomson Reuters, we’ve been doing just that for almost 160 years. Our industry-leading products and services include highly specialized information-enabled software and tools for legal, tax, accounting and compliance professionals combined with the world’s most global news services – Reuters. We help these professionals do their jobs better, creating more time for them to focus on the things that matter most: advising, advocating, negotiating, governing and informing. We are powered by the talents of 26,000 employees across more than 70 countries, where everyone has a chance to contribute and grow professionally in flexible work environments that celebrate diversity and inclusion. At a time when objectivity, accuracy, fairness and transparency are under attack, we consider it our duty to pursue them. Sound exciting? Join us and help shape the industries that move society forward. Accessibility As a global business, we rely on diversity of culture and thought to deliver on our goals. To ensure we can do that, we seek talented, qualified employees in all our operations around the world regardless of race, color, sex/gender, including pregnancy, gender identity and expression, national origin, religion, sexual orientation, disability, age, marital status, citizen status, veteran status, or any other protected classification under applicable law. Thomson Reuters is proud to be an Equal Employment Opportunity/Affirmative Action Employer providing a drug-free workplace. We also make reasonable accommodations for qualified individuals with disabilities and for sincerely held religious beliefs in accordance with applicable law. Protect yourself from fraudulent job postings click here to know more. More information about Thomson Reuters can be found on https://thomsonreuters.com.",https://mx.linkedin.com/jobs/view/senior-data-engineer-at-reuters-news-agency-4017183115,4017183115,"As a Senior Data Engineer, you'll play a pivotal role in shaping the future of data products and analytical services. This position involves developing and enhancing data warehousing functionality using Snowflake and Azure, building and maintaining robust data pipelines that drive analytics and informed decision-making. You will analyze existing data pipelines, innovate new data management approaches, and work with various data management teams. The role requires hands-on experience in programming and scripting languages and fluency in SQL.","DBT, SQL, Snowflake, AWS, Azure, Python, Pyspark, Airflow, Databricks, Data Lake, Business Intelligence tools (PowerBI, Domo, Tableau)",5+ years,Bachelor,True,5.0,0,0,1,1,0,0,0,0,1,1,0,0,0,0,1,0,0
Data and Analytics - Azure Data Engineer - Senior - EY GDS,EY,Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-08 11:47:09.018617,25,Engineering,Information Technology,,"EY-GDS- DnA Consulting – Data Engineer Azure-Snowflake (Batch) As part of our EY- GDS-DnA Consulting team, you will help clients use various methods to transform raw data into useful data systems. You will align data systems with business goals. You must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The ideal candidate should have 3-5 years of experience, Data Engineering, KAFKA, Advanced SQL, Advanced Phyton programming, Spark, ETL and ELT Process knowledge, Data structures knowledge, MPP Databases (Teradata, Snowflake), Blob Storage, Azure Data Lake Storage, AZURE cloud. The Data Engineer will interact with different members of the team such as database architects, data analysts, and data scientists on data initiatives and ensure optimal data delivery architecture is consistent with business strategy. Our clients usually have theirs headquarters on USA, however they span across multiple industries, regions, and countries. The opportunity We are looking for Senior Data Engineer with expertise in developing and managing Kafka based data pipelines, implementing complex stored procedures and best practices with data warehouse and ETL concepts, deploy fully operational data warehouse solutions into production on Snowflake to join our GDS Mexico team. This is a fantastic opportunity to be part of a leading firm whilst being instrumental in the growth of a new service offering. Your key responsibilities Design and Develop batch and streaming data processing Build data systems and pipelines. Evaluate business needs and objectives. Prepare data for prescriptive and predictive modeling. Build algorithms and prototypes. Combine raw information from different sources. Explore ways to enhance data quality and reliability. Identify opportunities for data acquisition. Monitor and optimize data storage and data processing Design and implement data security Skills and attributes for success 3-5 years of experience on Apache Kafka, Kafka stream, AZURE Event Hub 3-5 years of experience on processing real time data. Advanced knowledge on processing large amounts of data (billions of records) in minutes. Deep knowledge on producers (ACK/NACK), consumers, and brokers. Deep knowledge on topics, partitions, and segments. 3-5 years of advanced knowledge on SQL, phyton programming, ETL and ELT Process. Advanced knowledge on data structures, MPP Databases, Blob Storage. 3-5 years of experience on AZURE data lake Storage (Teradata, Snowflake), AZURE cloud. Previous experience as a data engineer or in a similar role. Data engineering certification (AZURE Certified Data Engineer) is a plus. Flexible and adaptable; able to work in ambiguous situations. Able to work effectively at all levels in an organization. Must be a team player and able to work collaboratively with and through others. Must like to learn. To qualify for the role, you must have Bachelor’s in technology or engineering or similar. Experience working with Azure, Snowflake technologies. Ideally, you’ll also have Familiarity with agile methodologies. Familiarity with software such as Jira or ADO. What we look for A Team of people with technical experience and enthusiasm to learn new things in this fast-moving environment Opportunities to work with EY GDS DnA Consulting practice globally with leading businesses across a range of industries What working at EY offers At EY, we’re dedicated to helping our clients, from world’s top companies — and the work we do with them is as varied as they are. You get to work with inspiring and meaningful projects. Our focus is education and coaching alongside practical experience to ensure your personal development. We value our employees, and you will be able to control your own development with an individual progression plan. You will quickly grow into a responsible role with challenging and stimulating assignments. Moreover, you will be part of an interdisciplinary environment that emphasizes high quality and knowledge exchange. Plus, we offer: Support, coaching and feedback from some of the most engaging colleagues around Opportunities to develop new skills and progress your career The freedom and flexibility to handle your role in a way that’s right for you About EY As a global leader in assurance, tax, transaction, and advisory services, we’re using the finance products, expertise, and systems we’ve developed to build a better working world. That starts with a culture that believes in giving you the training, opportunities, and creative freedom to make things better. Whenever you join, however long you stay, the exceptional EY experience lasts a lifetime. And with a commitment to hiring and developing the most passionate people, we’ll make our ambition to be the best employer by 2020 a reality. If you can confidently demonstrate that you meet the criteria above, please contact us as soon as possible. Join us in building a better working world. Apply now",https://mx.linkedin.com/jobs/view/data-and-analytics-azure-data-engineer-senior-ey-gds-at-ey-3967810320,3967810320,"As part of our EY-GDS-DnA Consulting team, you will help clients transform raw data into useful data systems, aligning them with business goals. You will design and develop batch and streaming data processing, build data systems and pipelines, evaluate business needs, prepare data for modeling, enhance data quality, and monitor data storage. The ideal candidate should have 3-5 years of experience in Data Engineering, KAFKA, Advanced SQL, Advanced Python programming, Spark, ETL and ELT processes, data structures, MPP Databases (Teradata, Snowflake), Blob Storage, and Azure Data Lake Storage.","Kafka, SQL, Python, ETL, ELT, Spark, Teradata, Snowflake, Blob Storage, Azure Data Lake Storage, Azure Cloud",3-5,Bachelor,True,3.0,0,0,1,1,0,0,1,0,0,1,0,0,0,0,1,0,0
Senior Data Scientist,Stori,Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,"Technology, Information and Internet",2024-09-01 11:47:09.018617,25,Engineering,Information Technology,,"About Stori Stori is a fast-growing, venture-backed financial technology company, on a mission to democratize credit access for 400 million underbanked LatAm consumers. Stori currently operates in Mexico and has a global team with offices in Arlington Virginia, Mexico City, and Asia. We have quickly made our mark as one of the top digital banks in Mexico with more than two million applicants for our credit card product since launching. Stori is one of the top-funded startups in the region with US$250 million raised to date. We are backed by top global venture capital funds, such as GGV Capital, GIC, Lightspeed Venture Partners, General Catalyst, Goodwater Capital, Mexico's Tresalia Capital, Vision Plus Capital, BAI Capital and Source Code Capital; who have successfully invested in startups such as Affirm, Airbnb, Alibaba, Stripe, and TikTok. Stori has a standout founder team among fintechs, leveraging 100+ years of accumulated experience in consumer finance, banking and technology across Mastercard, Intel, Capital One, Morgan Stanley, GE Capital, and HSBC in the U.S., Mexico and Asia. The team has launched and managed many multi-million-customer credit card products globally, providing a wide breadth of experience and knowledge to our team. We welcome diversity of background, experience and thinking. Storians are passionate about our mission and take pride in the products we build. Our culture thrives off of a flat structure and an inclusive environment where all of our employees can be their authentic selves, with boundless opportunities for professional growth. The Role: Main responsibilities: As a customer centered company, customer understanding is the top mission of data scientists at Stori. Among all the sources to be used in customer understandings, Stori data scientists use ""Data"" as the most reliable one. On any given day you will be challenged on three types of work – Modeling and Monitoring, Data Analytical Problem Solving and Innovation: Modeling (guided or independently): Communicate with the business intent holders to understand the new business initiatives Design a model as a product Data collection, processing and transformation Explore new data sources Build, Demonstrate, Maintain and Iterate modeling solutions from end to end Analytical Problem Solving Translate vague context and phenomenon into structure analytical problems and leverage statistical knowledge, machine learning models and visualization to derive meaningful insights on business intents and strategies using data and drive action Leverage advanced statistical techniques like incrementality, experiment design, regression analysis, clustering, causal inference, synthetic control selection to measure digital marketing KPIs, ROI on ad spending, marketing effectiveness, lifetime value (LTV) and referral loop factor etc. Build new metrics, dashboards and insights to measure the performance and impact of the growth marketing team activities in order to optimize and scale their actions Innovation We embrace rapid technological and scientific development. You will be encouraged to explore advanced tools or information sources that can help the team understand problems, solve them, and maintain products. An ideal team partner shares: Passion, Curiosity and Problem Solving with cross-functional teams As a data scientist at Stori, you will be facing varied problems throughout the life cycle of credit. Though we encourage talents with varied backgrounds to join us, to solve the puzzles with us together, we believe these are the keys: Passion in data: Data is the foundation of everything at the Stori Data Science team. We believe in the power of machine learning but data is always our most trustworthy friend. Curiosity: We believe curiosity is the best mentor to data scientists. We are not only looking for data scientists, but more importantly, we are looking for partners that can inspire us with their wonders. Problem solving: Data scientists at Stori solve puzzles. We use data to understand our customers, we also use data to provide solutions in helping customers. Collaboration: Work effectively in close partnership with marketing and branding leadership, using data and insights to drive strategy including creation and evaluation of marketing programs. What we are looking for: Basic Qualifications. Advanced degree in Computer Science, AI, Physics, Statistics, Applied Math, or other quantitative fields 3+ years of work experience with Python and SQL programming for data analysis 3+ years of work experience in data science Solid oral and written communication skills, especially around analytical concepts and methods Demonstrated ability to work under pressure and to meet tight deadlines with proactiveness, decisiveness, and flexibility Passion in problem-solving with data and data analytics Self-motivated with intellectual curiosity Proven ability to quickly learn new technologies, concepts, and tools Preferred Qualifications. 2+ years of experience with the Credit industry or in growth marketing team 2+ years of experience coaching junior data scientists and analysts 5+ years of work experience with Python programming 5+ years of work experience with Machine learning or Statistical Modeling Experience in A/B testing design and execution Working experience with AWS Experience managing projects independently What we offer Make a positive impact on the lives of our customers via financial inclusion Professional development opportunities International exposure & work experience Company swag Legally required benefits",https://mx.linkedin.com/jobs/view/senior-data-scientist-at-stori-4009793033,4009793033,"As a customer-centered company, customer understanding is the top mission of data scientists at Stori. The role involves three types of work – Modeling and Monitoring, Data Analytical Problem Solving, and Innovation. Responsibilities include communicating with business intent holders, designing models, data collection, processing, and transformation, leveraging statistical techniques, building metrics and dashboards, and collaborating with marketing leadership to drive strategy. The ideal partner shares passion, curiosity, and problem-solving skills, with strong expertise in data science.","Python, SQL, Machine Learning, Statistical Modeling, AWS, A/B Testing, Data Analytics",3+ years,,True,3.0,0,0,0,1,0,1,0,0,0,1,0,0,1,0,1,0,0
Principal Data Scientist - Data Sourcing,Stori,Mexico City Metropolitan Area,ON-SITE,Entry level,Full-time,"Technology, Information and Internet",2024-08-16 11:47:09.018617,30,Engineering,Information Technology,,"About Stori Stori is a fast-growing, venture-backed financial technology company, on a mission to democratize credit access for 400 million underbanked LatAm consumers. Stori currently operates in Mexico and has a global team with offices in Arlington Virginia, Mexico City, and Asia. We have quickly made our mark as one of the top digital banks in Mexico with more than two million applicants for our credit card product since launching. Stori is one of the top-funded startups in the region with US$250 million raised to date. We are backed by top global venture capital funds, such as GGV Capital, GIC, Lightspeed Venture Partners, General Catalyst, Goodwater Capital, Mexico's Tresalia Capital, Vision Plus Capital, BAI Capital and Source Code Capital; who have successfully invested in startups such as Affirm, Airbnb, Alibaba, Stripe, and TikTok. Stori has a standout founder team among fintechs, leveraging 100+ years of accumulated experience in consumer finance, banking and technology across Mastercard, Intel, Capital One, Morgan Stanley, GE Capital, and HSBC in the U.S., Mexico and Asia. The team has launched and managed many multi-million-customer credit card products globally, providing a wide breadth of experience and knowledge to our team. We welcome diversity of background, experience and thinking. Storians are passionate about our mission and take pride in the products we build. Our culture thrives off of a flat structure and an inclusive environment where all of our employees can be their authentic selves, with boundless opportunities for professional growth. About the Role: You will join the data science and machine learning department as a dedicated associate in data sourcing. You will be the main point of contact to source, evaluate and acquire high-quality data from various vendors and external sources. Day to day, your key responsibilities include: Collaborating with data scientists and business analysts to identify and understand data requirements for credit risk management. Partner with data scientists to assess the value and relevance of data sources to ensure they meet business needs. Partnering with the procurement team to negotiate data acquisition contracts. Managing and maintaining strong relationships with data vendors to ensure ongoing data quality and compliance with agreements. What we are looking for: Experience: Bachelor's or Master's degree in Economics, Finance, Mathematics, Statistics, or other quantitative discipline or a related field. Working experience with MX public or alternative data sourcing. At least 3 years of working experience with SQL programming for data analysis At least 3 years of working experience with business analytics Skills and attitudes Proven ability to drive projects independently Strong oral and written communication skills, especially around analytical concepts and methods Demonstrated ability to work under pressure and to meet tight deadlines with proactiveness, decisiveness and flexibility Passion in data: Data is the foundation of everything at the Stori Data Science team. We believe in the power of machine learning but data is always our most trustworthy friend. Curiosity: We believe curiosity is the best mentor to data scientists. We are not only looking for data scientists, but more importantly, we are looking for partners that can inspire us with their wonders. Problem solving: Data scientists at Stori solve puzzles. We use data to understand our customers, we also use data to provide solutions in helping customers. Bonus Points: At least 3 years of working experience in credit industry Working experience with vendor management Proven ability to lead a team to deliver complex model development from end to end Passion in problem solving with data and data analytics Self-motivated with intellectual curiosity Proven ability to quickly learn new technologies, concepts and tools What we offer Make a positive impact on the lives of our customers via financial inclusion Professional development opportunities International exposure & work experience Company swag Legally required benefits",https://mx.linkedin.com/jobs/view/principal-data-scientist-data-sourcing-at-stori-3983488116,3983488116,"You will join the data science and machine learning department as an associate in data sourcing, responsible for sourcing, evaluating and acquiring high-quality data from various vendors. Key responsibilities include collaborating with data scientists and analysts to identify data requirements, assessing data sources, negotiating data acquisition contracts, and maintaining relationships with data vendors to ensure data quality.","SQL, Data Analysis, Business Analytics",3+ years,Bachelor,True,3.0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0
DATA SCIENCE CONSULTANT CIUDAD DE MÉXICO,Management Solutions,Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,Business Consulting and Services,2023-10-21 11:47:09.018617,66,Information Technology,,,"You will be working in key projects for leading organizations in data mining & knowledge Discovery, predictive modeling, trend modeling, Simulation models (Monte Carlo), Review of credit rating and scoring models and quant support to the business and R&D projects. Requirements Final year students. Should desirably have knowledge of modeling techniques (logit, GLM, time series, decision trees, random forests, clustering), statistical programming languages (SAS, R, Python, Matlab) and big data tools and platforms (Hadoop, Hive, etc.). Solid academic record. Strong computer skills. Postgraduate studies and/or specialised courses are an asset, especially in Data Science, Quantitative Finance or similar. Knowledge of other languages is desirable. Get up and go attitude, maturity, responsibility and strong work ethic. Strong ability to learn quickly. Able to integrate easily into multidisciplinary teams. We Offer The best environment to develop talent We offer you the possibility to join a firm that provides all you need to develop your talent to the fullest: Working in the highest-profile consulting projects in the industry, for the largest companies, leaders of their respective markets, alongside top industry management as they face challenges at the national and global level, as part of an extraordinary team of professionals whose values and corporate culture are a benchmark for the industry Ongoing training plan, with approximately 10% of business turnover spent in training Specialist knowledge courses, external expert courses, professional skills courses and language courses. Last yearour staff as a whole received over 330,000 hours oftraining spanning more than 700 courses. Clearly defined career plan Internal promotion based solely on merit. Partnership-based management model offers all professionalsthe opportunity to become part of the Firm’s group of partners. Complementary experiencies University: we maintain a close relationship with the world’s most prestigious universities Social Action: we organize more than 30 community supportactivities. Sports Club: internal and external tournaments.",https://mx.linkedin.com/jobs/view/data-science-consultant-ciudad-de-m%C3%A9xico-at-management-solutions-3731728491,3731728491,"You will be working on key projects for leading organizations in data mining & knowledge discovery, predictive modeling, trend modeling, simulation models (Monte Carlo), review of credit rating and scoring models, and quant support to the business and R&D projects. Requirements include final year students with knowledge of modeling techniques (logit, GLM, time series, decision trees, random forests, clustering), statistical programming languages (SAS, R, Python, Matlab), and big data tools and platforms (Hadoop, Hive). A solid academic record and strong computer skills are required. Postgraduate studies and/or specialized courses in Data Science, Quantitative Finance, or similar fields are an asset.","SAS, R, Python, Matlab, Hadoop, Hive",,Bachelor,True,,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0
Senior AI Engineer,Stori,Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,"Technology, Information and Internet",2024-08-16 11:47:09.018617,25,Engineering,Information Technology,,"About Stori Stori is a fast-growing, venture-backed financial technology company, on a mission to democratize credit access for 400 million underbanked LatAm consumers. Stori currently operates in Mexico and has a global team with offices in Arlington Virginia, Mexico City, and Asia. We have quickly made our mark as one of the top digital banks in Mexico with more than two million applicants for our credit card product since launching. Stori is one of the top-funded startups in the region with US$250 million raised to date. We are backed by top global venture capital funds, such as GGV Capital, GIC, Lightspeed Venture Partners, General Catalyst, Goodwater Capital, Mexico's Tresalia Capital, Vision Plus Capital, BAI Capital and Source Code Capital; who have successfully invested in startups such as Affirm, Airbnb, Alibaba, Stripe, and TikTok. Stori has a standout founder team among fintechs, leveraging 100+ years of accumulated experience in consumer finance, banking and technology across Mastercard, Intel, Capital One, Morgan Stanley, GE Capital, and HSBC in the U.S., Mexico and Asia. The team has launched and managed many multi-million-customer credit card products globally, providing a wide breadth of experience and knowledge to our team. We welcome diversity of background, experience and thinking. Storians are passionate about our mission and take pride in the products we build. Our culture thrives off of a flat structure and an inclusive environment where all of our employees can be their authentic selves, with boundless opportunities for professional growth. The Role: As an AI Engineer, you will help lay the foundations of how Stori uses Generative AI to bring financial services to millions of customers in Mexico and Latin America in a personalized and scalable way. Your work will play a crucial role not just in building Gen AI and LLM-based products such as conversational chatbots and voicebots; but also in the creation of a shared platform that will be leveraged by all other engineering squads at Stori as we infuse Generative AI into the core of many of our products. Your experience building with LLMs will be critical in creating the next stage in the evolution of the banking industry in the region as we create the next generation of financial services. Important: This is not an AI research role. You will be building production-grade AI products and shared services for real users and other developers. Main responsibilities: Prototyping & Building LLM-based Applications: Develop LLM-based applications and shared services to be used both by Stori's millions of users. AI Platform Development : Design and implement a robust developer platform that allows other Product & Engineering teams to easily use the power of AI models within other products, expanding the use of Generative AI across the whole organization. Release, Measure, Improve: Ensure our AI-based products are well-instrumented with the required data and observability tools. Use data to consistently improve said products. Testing and Deployment : Streamline the testing processes and integrate continuous integration/continuous deployment (CI/CD) pipelines to facilitate smoother and faster deployment of code into production. Organization-wide Collaboration: Work closely with multiple teams across the company to help infuse their products with AI. Documentation and Training : Create comprehensive documentation and provide training to the development team, ensuring best practices are understood and adopted. What we are looking for: Experience with Large Language Models (LLMs): You've previously built–and ideally launched– products that made use of LLMs. These could include chatbots, agents, RAG systems, classification services, analysis of unstructured data, generation of synthetic data, etc. Personal projects also count! Extra points if you've used open source models. Knowledge of Gen AI-related tools and libraries: You know your way around libraries such as LangChain and LlamaIndex and you're familiar with tools such as Langsmith or Langfuse.Mastery of Python: You have 3-5 years of experience as a Sr Software Engineer working with Python. Comfortable doing traditional backend work: Building production-level AI features also requires traditional backend work, we expect you to be comfortable with this to make sure everything is well integrated and running smoothly. Technical Expertise : Strong knowledge in scalable system design, microservices (Go preferred), CI/CD pipelines, containerization technologies (e.g., Docker, Kubernetes), and cloud services. Problem-Solving Skills : Excellent analytical and problem-solving abilities, with a focus on practical and efficient solutions. Adaptability: You can work–and hopefully thrive–in a constantly changing industry where new AI developments happen weekly, model documentation is not always up to date, and best practices are constantly evolving. You're not scared of building a prototype and throwing your code away to build a better version based on user and performance data. Communication Skills : Strong communication and interpersonal skills, capable of working collaboratively with cross-functional teams and effectively communicating technical concepts to non-technical team members. Educational Background : A Bachelor's or Master's degree in Computer Science, Software Engineering, or a related field. Language Proficiency : Fluency in Spanish and English, both written and spoken. In this institution, discrimination based on race, religion, sexual orientation, physical or socioeconomic condition, or any other reason is prohibited. Discrimination is understood as the denial, exclusion, distinction, impairment, impediment, or restriction of any or some of the human rights of individuals, groups, and communities in a situation of discrimination, attributable to natural or legal persons or public entities, whether intentional or unintentional, willful or culpable, through action or omission, based on ethnic or national origin, language, sex, gender, indigenous identity, gender role expression, age, disability, legal, social or economic status, physical appearance, health conditions, genetic characteristics, pregnancy, religion, political, academic or philosophical opinions, political identity or affiliation, sexual orientation or preference, marital status, manner of thinking, dressing, behaving or gesturing, having tattoos or body piercings, or any other factor that has the effect of nullifying or impairing the recognition, enjoyment or exercise of fundamental rights and freedoms, as well as equality for individuals. What we offer Make a positive impact on the lives of our customers via financial inclusion Professional development opportunities International exposure & work experience Company swag Legally required benefits",https://mx.linkedin.com/jobs/view/senior-ai-engineer-at-stori-3996563377,3996563377,"As an AI Engineer, you will help lay the foundations of how Stori uses Generative AI to bring financial services to millions of customers in Mexico and Latin America. You will build production-grade AI products and shared services, develop LLM-based applications, design a developer platform for AI integration, and collaborate with various teams to enhance products with AI.","Python, Large Language Models (LLMs), LangChain, LlamaIndex, Go, Docker, Kubernetes, CI/CD, Cloud Services",3-5,Bachelor,True,3.0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0
GTE DATA SCIENTIST AML,Santander México,Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,Financial Services,2024-09-08 11:47:09.018617,44,Management,"Finance,",Information Technology,"Country: Mexico Grupo Santander es el banco líder que a través de más de 160 años de reinvención, ha llegado a ser una organización sin fronteras con presencia en más de 40 países, 95 nacionalidades y equipos multiculturales que comparten 4 idiomas. Lo importante para nosotros son nuestros clientes, colaboradores, accionistas y la sociedad, como parte de nuestra misión, que es contribuir al progreso de las personas y empresas, actuando siempre de forma Sencilla, Personal y Justa. Requerimientos: Licenciatura en Ciencia de Datos, Finanzas, Actuaría, Matemáticas o carrera afín. Deseable especialización en ciencia de datos Inglés avanzado Experiencia: Mínima de 2 años de experiencia en desarrollo y diseño de modelos Machine Learning. Deseable en desarrollo de modelos para monitoreo transaccional de TM. Programación y paquetería de ciencia de datos: Python, SQL, Numpy, Pandas, plataforma AWS, etc. People skills: capacidad de análisis y procesamiento de datos, resolución de problemas, orientación a resultados, negociación, trabajo en equipo y proactividad. Principales funciones: Realizar analíticas cuantitativas y cualitativas de comportamiento de clientes con machine learning. Generación de analíticas para la detección de irregularidades con analítica avanzada Diseño, actualización, calibración modelos con uso de tecnologías de machine learning Diseño de cuadros de mando para el análisis de tendencias de los resultados de modelos Seguimiento y gestión de revisiones periódicas por parte de supervisores, autoridades locales y corporativo Generar documentación de modelos Ubicación: Santa Fe, CDMX En Banco Santander garantizamos el trato transparente, justo y equitativo para candidatos/as y colaboradores/as, asegurando que no exista menoscabo en ningún derecho, beneficio o prestación derivada de su edad, condición social o económica, cultura, nacionalidad, orientación sexual, identidad o expresión de género, sexo, estado civil, embarazo, discapacidad, religión, creencias, apariencia física o cualquier otra situación protegida por las leyes federales, estatales o locales.",https://mx.linkedin.com/jobs/view/gte-data-scientist-aml-at-santander-m%C3%A9xico-4017920091,4017920091,"Requirements include a degree in Data Science, Finance, Actuarial Science, Mathematics, or a related field, with a preference for specialization in data science. Advanced English and a minimum of 2 years of experience in developing and designing Machine Learning models are desirable. Responsibilities include performing quantitative and qualitative analytics of customer behavior with machine learning, generating analytics for detecting irregularities with advanced analytics, designing, updating, and calibrating models using machine learning technologies, creating dashboards for trend analysis of model results, managing periodic reviews by supervisors and local and corporate authorities, and generating documentation of models.","Python, SQL, Numpy, Pandas, AWS",2,Bachelor,True,2.0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,1,0,0
Sr AI Engineer,Aspen Technology,Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,Software Development,2024-09-11 11:47:09.018617,25,Engineering,Information Technology,,"The driving force behind our success has always been the people of AspenTech. What drives us, is our aspiration, our desire and ambition to keep pushing the envelope, overcoming any hurdle, challenging the status quo to continually find a better way. You will experience these qualities of passion, pride and aspiration in many ways — from a rich set of career development programs to support of community service projects to social events that foster fun and relationship building across our global community. The Role As a Senior AI Engineer in our rapidly growing Technology Group, you will provide technical leadership in developing innovative solutions for the next generation of AspenTech’s Manufacturing and Supply Chain solutions. We are looking for sharp, disciplined, and highly quantitative individuals who have a passion for playing with complex data and cutting-edge technologies, in all its forms, including data mining, mathematical modeling, cognitive computing and expert systems. You will leverage your skills and passion for Machine Learning, AI and Cognitive Computing to drive AspenTech’s Manufacturing and Supply Chain suite by developing ground-breaking software. Your Impact Collaborate with data scientists, engineers, and software developers to develop new machine learning applications for the Energy industry in the intersection of AI and Process Systems Engineering. Collaborate with customers, product managers and technical staff to develop technology strategies to promote continuous innovation in our Manufacturing and Supply Chain offerings. Investigate new and developing technologies as they appear in industry and academia and determine how to leverage these new technologies into our software applications What You'll Need Master’s degree in Computer Science, Chemical Engineering, Mathematics, Operations Research, or a related major; PhD preferred. 5+ years of experience in data science and software development in the modeling, optimization, and control of chemical, oil and gas, and/or refining processes. Track record of experience in Python programming, including data science specific packages, such as Pandas, Numpy, TensorFlow, PyTorch, Scikit-Learn, etc. Demonstrated experience with machine learning algorithms (regression, semi-supervised learning, deep learning, reinforcement learning, time series analysis, predictive modeling, cognitive computing). Strong expertise required in one of these areas: numerical methods, mathematical modeling, optimization. Experience with LLM, generative AI, MLops, Graph Knowledge, and/or cloud technologies is a plus. Participated in the design, development, evaluation, and deployment of scalable data-driven models and analytical solutions for machine learning application. Problem-solving ability and attention to details. Demonstrated ability to use scientific research to deliver value to customers and are motivated to deliver results in a fast-paced environment. Excellent interpersonal, communication, writing, and presentation skills. Demonstrated ability to convey complex information in a clear and concise manner.",https://mx.linkedin.com/jobs/view/sr-ai-engineer-at-aspen-technology-4021112831,4021112831,"As a Senior AI Engineer, you will provide technical leadership in developing innovative solutions for AspenTech’s Manufacturing and Supply Chain solutions, focusing on machine learning applications for the Energy industry and collaborating with data scientists, engineers, and software developers.","Python, Pandas, Numpy, TensorFlow, PyTorch, Scikit-Learn, Machine Learning, Cognitive Computing",5+ years,Masters,True,5.0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0
"Desarrollador Sr. ChatBots  y Generative AI (AI, NLP, Python, JavaScript, JAVA)",Acute Talent,Mexico City Metropolitan Area,ON-SITE,,Full-time,"Technology, Information and Internet",2024-09-12 11:47:09.018617,25,Other,,,"Ubicación : Santa Fe, Ciudad de México Experiencia Requerida : Mínimo 8 años Modalidad de Trabajo : Presencial Estamos en la búsqueda de un Desarrollador Sr. Experto en Desarrollo de ChatBots con un enfoque en Fintech y Sistemas Financieros, que además tenga experiencia en Generative AI . Esta posición es clave para desarrollar soluciones innovadoras de atención al cliente y automatización en el sector financiero, utilizando las tecnologías más avanzadas de Inteligencia Artificial, Procesamiento de Lenguaje Natural (NLP), y Generative AI . Buscamos un profesional altamente capacitado, con experiencia demostrable en el desarrollo de ChatBots y en la creación de modelos de IA generativa, capaz de crear soluciones escalables, seguras y adaptadas a las necesidades del sector financiero. Responsabilidades Principales : Desarrollo de ChatBots para Fintech: Crear y desplegar chatbots específicamente diseñados para el sector financiero, gestionando consultas, transacciones, soporte técnico y tareas financieras automatizadas. Programación: Dominio de lenguajes como Python, JavaScript, y/o Java para desarrollar aplicaciones de chatbot personalizadas, integradas con plataformas y servicios financieros. Generative AI: Desarrollar e implementar soluciones basadas en Generative AI, utilizando modelos como GPT, para mejorar la interacción y personalización del chatbot en tiempo real, generando respuestas más naturales y relevantes en contextos financieros. Inteligencia Artificial y Machine Learning: Implementar técnicas avanzadas de IA y Machine Learning enfocadas en la optimización de procesos financieros y mejora en la interacción con los usuarios. Procesamiento de Lenguaje Natural (NLP): Desarrollar algoritmos de NLP que permitan al chatbot manejar términos y consultas específicas de los sistemas financieros y productos de Fintech, como créditos, inversiones, pagos y consultas de balance. Integración con APIs Financieras: Conectar el chatbot con APIs de sistemas financieros (bancos, CRMs financieros, plataformas de pago, blockchain) para realizar consultas en tiempo real, automatizar procesos y ejecutar transacciones. Cumplimiento Regulatorio: Garantizar que las soluciones desarrolladas cumplan con las normativas regulatorias del sector financiero (por ejemplo, KYC, AML, GDPR), integrando mecanismos de verificación de identidad y seguridad en la interacción del chatbot. Diseño de Conversaciones Financieras: Crear flujos conversacionales eficientes para realizar tareas como consultas de saldo, transferencias bancarias, solicitudes de crédito, y recomendaciones de productos financieros. Seguridad: Asegurar la máxima seguridad en la interacción del chatbot con los usuarios, implementando prácticas de cifrado de datos, autenticación de usuarios y protocolos de seguridad específicos del sector financiero. Pruebas y Despliegue: Realizar pruebas exhaustivas en entornos financieros simulados y reales para asegurar un funcionamiento impecable, garantizando la continuidad del servicio en caso de fallos o ciberataques. Mantenimiento y Actualización: Monitorear y actualizar el chatbot de forma continua, optimizando su rendimiento y ampliando sus capacidades según las nuevas necesidades del sector Fintech y las regulaciones financieras. Requisitos: Requisitos Técnicos : Lenguajes de Programación: Dominio avanzado de Python, JavaScript, y/o Java. Inteligencia Artificial y Generative AI: Experiencia en frameworks de AI como GPT, OpenAI, o similares, y habilidades para integrar Generative AI en flujos conversacionales y automatización de respuestas. NLP: Conocimientos avanzados en el uso de BERT, spaCy, NLTK, Dialogflow o equivalentes, enfocados en tareas de procesamiento de lenguaje financiero. Conexión con Sistemas Financieros: Experiencia en integración de APIs como Open Banking o Plaid para consultas en tiempo real y transacciones automatizadas. Ciberseguridad: Profundos conocimientos de seguridad informática, incluyendo cifrado de datos, OAuth 2.0, y autenticación en dos pasos (2FA). Plataformas Fintech: Familiaridad con Rasa, Dialogflow, Microsoft Bot Framework o equivalentes para el desarrollo de chatbots financieros. Requisitos de la Industria Fintech : Generative AI Aplicada a Finanzas: Habilidad para generar respuestas dinámicas y personalizadas utilizando modelos de AI generativa. Automatización Financiera: Experiencia en el diseño de chatbots para pagos, transferencias, consultas de saldos y recomendaciones financieras automatizadas. Análisis Predictivo: Capacidad para implementar algoritmos que predigan comportamientos financieros y alertas de fraude. Blockchain: Conocimiento en la integración de soluciones blockchain y criptomonedas en chatbots para pagos y transacciones. Requisitos Deseables : Experiencia previa en el desarrollo de soluciones para bancos, neobancos, plataformas de préstamos P2P o insurtechs. Certificaciones en Machine Learning, Inteligencia Artificial o Desarrollo de Software en el ámbito financiero. Familiaridad con metodologías ágiles (Scrum, Kanban) en entornos de desarrollo financiero. Requisitos Personales : Experiencia Mínima: Mínimo 8 años de experiencia en desarrollo de software, con al menos 4 años de experiencia en el desarrollo de chatbots e inteligencia artificial para Fintech o sistemas financieros. Capacidad para adaptarse a entornos de trabajo dinámicos y gestionar múltiples proyectos simultáneamente. Excelentes habilidades de comunicación y trabajo en equipo. Beneficios : Salario competitivo, acorde con la experiencia. Oportunidades de crecimiento y desarrollo profesional en el sector Fintech. Acceso a programas de formación continua en tecnologías emergentes. Excelente ambiente laboral en oficinas modernas en Santa Fe, Ciudad de México.",https://mx.linkedin.com/jobs/view/desarrollador-sr-chatbots-y-generative-ai-ai-nlp-python-javascript-java-at-acute-talent-4022248845,4022248845,"We are looking for a Senior Developer with expertise in ChatBot development focused on Fintech and Financial Systems, who also has experience in Generative AI. This position is key to developing innovative customer service and automation solutions in the financial sector, utilizing advanced AI technologies, Natural Language Processing (NLP), and Generative AI. Responsibilities include developing chatbots for Fintech, programming in languages like Python, JavaScript, and/or Java, implementing generative AI solutions, using AI and Machine Learning techniques, developing NLP algorithms for financial systems, integrating with financial APIs, ensuring regulatory compliance, designing financial conversations, maintaining security, conducting thorough testing, and continuously updating the chatbot. The technical requirements include advanced knowledge of programming languages, experience with AI frameworks like GPT, advanced NLP skills, experience with integrating financial APIs, strong cybersecurity knowledge, and familiarity with chatbot development platforms. Candidates should have a minimum of 8 years of software development experience, with at least 4 years in chatbot and AI development for Fintech or financial systems, and possess excellent communication and teamwork skills.","Python, JavaScript, Java, NLP, Generative AI, GPT, OpenAI, BERT, spaCy, NLTK, Dialogflow, Rasa, Microsoft Bot Framework, Open Banking, Plaid, OAuth 2.0, 2FA",8,,False,8.0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
"Big Data Engineer 68582, 68583, 68584, 68585, 68586, 68587",Hays,Mexico City Metropolitan Area,ON-SITE,Entry level,Full-time,Staffing and Recruiting,2024-08-16 11:47:09.018617,25,Engineering,Information Technology,,"Tu nueva compañía Únete a una empresa líder en servicios de tecnología de la información y comunicaciones, especializada en la transformación digital. Ofrecemos soluciones innovadoras en áreas como ciberseguridad, computación en la nube, automatización y conectividad, ayudando a las empresas a maximizar su potencial y adaptarse a las nuevas tecnologías. Tu nuevo cargo Como Big Data Engineering, serás responsable del diseño, desarrollo y operación de sistemas de datos a gran escala que operan a nivel de petabytes. Te enfocarás en pipelines de datos en tiempo real, análisis de streaming, big data distribuido e infraestructura de machine learning. Interactuarás con ingenieros, gerentes de producto, desarrolladores de BI y arquitectos para proporcionar soluciones técnicas escalables y robustas. Además, realizarás análisis de datos para identificar problemas de calidad en cualquier etapa del ciclo de vida de los datos, proporcionando soluciones y recomendaciones. Trabajarás en estrecha colaboración con el negocio, EDM, ingeniería de datos y arquitectura para asegurar la alineación de reglas y procesos de datos con los estándares de la compañía. Que necesitas para ser exitoso Para esta posición, necesitarás entre 6 y 8 años de experiencia en desarrollo de Big Data, demostrando conocimientos actualizados en ingeniería de datos y desarrollo de pipelines complejos. Es indispensable tener experiencia en modelos ágiles, diseño, desarrollo e implementación de sistemas distribuidos a gran escala, y habilidades avanzadas en SQL. Además, se valorará la experiencia con tecnologías Big Data como Hadoop, Hive, Kafka, Presto, Spark y HBase, así como en el uso de Java y Python para escribir pipelines de datos. La capacidad para trabajar con tecnologías en la nube (GCP, Azure) y la experiencia en REST API para consumo de datos también son importantes. La experiencia en el sector retal es un plus significativo. Que recibirás a cambio Tendrás un salario fijo mensual y un paquete competitivo de compensaciones y beneficios. Trabaja en un entorno donde la innovación y la excelencia son el motor de todo lo que hacemos, con oportunidades de crecimiento y desarrollo en un ambiente dinámico y colaborativo. Que necesitas hacer ahora Si estás interesado en este cargo, haz click en ""aplicar ahora"" para reenviar una copia actualizada de tu CV, o llámanos ahora. Si este cargo no se ajusta mucho a tu perfil, pero estás en búsqueda de un cambio laboral, ponte en contacto con nosotros para que tengamos una conversación confidencial sobre tu carrera. #1036324 - Maria De La Rosa",https://mx.linkedin.com/jobs/view/big-data-engineer-68582-68583-68584-68585-68586-68587-at-hays-3987361738,3987361738,"As a Big Data Engineer, you will be responsible for the design, development, and operation of large-scale data systems that operate at the petabyte level. You will focus on real-time data pipelines, streaming analysis, distributed big data, and machine learning infrastructure. You will interact with engineers, product managers, BI developers, and architects to provide scalable and robust technical solutions. Additionally, you will analyze data to identify quality issues at any stage of the data lifecycle, providing solutions and recommendations. You will work closely with the business, EDM, data engineering, and architecture to ensure alignment of data rules and processes with company standards.","Big Data, Hadoop, Hive, Kafka, Presto, Spark, HBase, SQL, Java, Python, GCP, Azure, REST API",6-8,,False,6.0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0
BI Developer II,Rackspace Technology,Mexico City Metropolitan Area,REMOTE,,Full-time,IT Services and IT Consulting,2024-09-16 15:12:05.059618,25,Information Technology,,,"We are looking for a BI Developer II with experience in developing and maintaining a business intelligence framework. **Must be fluent in English Responsibilities Works with business requirement team, analysts, and developers to ensure stakeholder requirements are addressed through integration solutions in a manner that aligns with timelines, budgets, and quality expectations Leads the design and development of the Business Intelligence (BI) architecture and continually refines the BI strategy to align with corporate direction Serves as the subject matter expert in the extraction of information from EFD, Star, and Snowflake schemas Builds operational and ad-hoc reports Builds reports that take advantage of OLAP/Dimensional Modeling capabilities Build executive dashboards and corporate scorecards Works with customers to define their requirements and create information delivery solutions that meet their needs utilizing “best practices.” Develops and implements data integration strategy and associated policies as it pertains to lean integration practices Participates in design and development reviews Works with system owners to resolve data transformation issues and to refine transformation Writes software in an open-source setting (number of branches merged) Writes design documents Reviews proposed software branches (number of reviews) Reviews design documents (number of reviews) Participates in project discussions (number of emails etc.) Qualifications Strong skills in Excel and T-SQL recommended Comfort using Qlikview is desirable Advanced level of competence with database structures and design as well as possessing strong SQL development skills with the ability to build reporting tables, stored procedures, and Chron Jobs Basic understanding of relational and columnar database platforms such as MSSQL, My SQL, Oracle, Postgresql, and Cassandra. Working knowledge of CORE and Salesforce Advanced QV skills such as set analysis, variables, actions, triggers, and QVD building Business analysis skills to allow for the creation of report definitions and specifications Basic proficiency in one or more of the following tools: MS Access, .Net, ASP, VB, MongoDB, Hadoop, etc Ability to communicate technical information and ideas so that others will understand Must be able to make appropriate decisions considering the relative costs and benefits of potential actions Must successfully work and promote inclusiveness in small groups Excellent communication skills, both oral and written Ability to develop work plans and follow through on assignments with minimal guidance Ability to work with business and system owners to obtain requirements and manage expectations Requires a Bachelor's degree in Computer Science, MIS, or Business Administration Discover your inner Racker: Racker Life - Fluent, Bi-lingual (Spanish and English) - Role can work remotely in the states of Ciudad de Mexico, Jalisco, Nuevo Leon, Aguascalientes, Queretaro, Estado de Mexico and Puebla - This opportunity is a permanent remote job, but you need to be based in Mexico at one of the above locations. About Rackspace Technology We are the multicloud solutions experts. We combine our expertise with the world’s leading technologies — across applications, data and security — to deliver end-to-end solutions. We have a proven record of advising customers based on their business challenges, designing solutions that scale, building and managing those solutions, and optimizing returns into the future. Named a best place to work, year after year according to Fortune, Forbes and Glassdoor, we attract and develop world-class talent. Join us on our mission to embrace technology, empower customers and deliver the future. More on Rackspace Technology Though we’re all different, Rackers thrive through our connection to a central goal: to be a valued member of a winning team on an inspiring mission. We bring our whole selves to work every day. And we embrace the notion that unique perspectives fuel innovation and enable us to best serve our customers and communities around the globe. We welcome you to apply today and want you to know that we are committed to offering equal employment opportunity without regard to age, color, disability, gender reassignment or identity or expression, genetic information, marital or civil partner status, pregnancy or maternity status, military or veteran status, nationality, ethnic or national origin, race, religion or belief, sexual orientation, or any legally protected characteristic. If you have a disability or special need that requires accommodation, please let us know.",https://mx.linkedin.com/jobs/view/bi-developer-ii-at-rackspace-technology-4025075439,4025075439,"We are looking for a BI Developer II with experience in developing and maintaining a business intelligence framework. The responsibilities include working with business requirement teams, analysts, and developers to ensure stakeholder requirements are addressed through integration solutions, leading the design and development of the BI architecture, serving as the subject matter expert in information extraction, building operational and ad-hoc reports, developing and implementing data integration strategies, and participating in project discussions.","Excel, T-SQL, Qlikview, SQL, MSSQL, MySQL, Oracle, Postgresql, Cassandra, .Net, ASP, VB, MongoDB, Hadoop",,Bachelor,True,,0,0,1,0,0,0,0,0,1,1,0,0,0,0,0,0,0
Analytics Modeling Analyst **Adobe Analytics **Analista**,Accenture México,Mexico City Metropolitan Area,HYBRID,Entry level,Full-time,Business Consulting and Services,2024-09-16 15:12:25.292879,149,Strategy/Planning,Information Technology,,"Responsabilidades Como profesional del modelado analítico, usted será responsable de aprovechar su competencia avanzada para brindar información y recomendaciones al equipo del proyecto. Sus actividades diarias incluirán analizar datos, crear informes y desarrollar modelos para respaldar la toma de decisiones. También se espera que colabore con otros equipos para garantizar la perfecta integración de Adobe Analytics con otros componentes de TI. Será ventajoso tener un dominio intermedio en Arquitectura Tecnológica y Adobe Experience Manager AEM. Adobe Analytics te permite combinar, relacionar y analizar datos desde cualquier lugar digital del recorrido de cliente. Creación de informes versátiles e inteligencia predictiva Analice datos y cree informes con Adobe Analytics Desarrollar modelos para apoyar la toma de decisiones. Colabore con otros equipos para garantizar una integración perfecta de Adobe Analytics con otros componentes de TI. Proporcionar conocimientos y recomendaciones al equipo del proyecto. Ingles minimo B2 Esquem hibrido, asistir 2-3 veces por semana a la oficina",https://mx.linkedin.com/jobs/view/analytics-modeling-analyst-adobe-analytics-analista-at-accenture-m%C3%A9xico-3948774379,3948774379,"As a professional in analytical modeling, you will be responsible for leveraging your advanced expertise to provide insights and recommendations to the project team. Daily activities will include analyzing data, creating reports, and developing models to support decision-making. You are also expected to collaborate with other teams to ensure the seamless integration of Adobe Analytics with other IT components. An intermediate proficiency in Technology Architecture and Adobe Experience Manager (AEM) will be advantageous. Adobe Analytics allows you to combine, relate, and analyze data from any digital customer journey. Create versatile reports and predictive intelligence.","Adobe Analytics, Adobe Experience Manager (AEM), Data Analysis, Reporting, Predictive Modeling",,,True,,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"Manager, Machine Learning",Pfizer,Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,Pharmaceutical Manufacturing,2024-09-16 15:12:39.847442,25,Engineering,Information Technology,,"Role Summary Do you want to make an impact on patient health around the world? Do you thrive in a fast-paced environment that brings together scientific and clinical domains together through data and analytics? Then join Pfizer Digital’s AI & Data Analytics (AIDA) organization where you can leverage cutting-edge technology including AI and ML to inform critical business decisions and improve customer experiences for our patients and physicians. Our collection of global teams drives insights to action for some of the most critical business questions for the company. Our analytics professionals are based in over 30 countries around the world and come from diverse backgrounds including: software engineering, data science, digital analytics, finance, investment banking, corporate development, and consulting. Join one of our teams and be at the forefront of Pfizer’s digital transformation, driving innovation and bringing advance analytics to change patients’ lives. As an AI/ML Engineer, you will be part of a team to develop new capabilities that leverages AI to solve complex problems across the enterprise. In this role, you will be responsible for overseeing the design, implementation, and deployment of AI and machine learning models and algorithms, ensuring their accuracy, scalability, and effectiveness. The ideal candidate will have a strong technical background in machine learning and/or software engineering and a passion for innovation, bridging the gap between data, technology, and people, to deliver the promise of AI/ML to improve patients’ lives. Role Responsibilities Design, develop and deploy machine learning products & approaches to solve business problems across multiple domains, including commercial, medical affairs, and R&D. Engage with stakeholders across the enterprise to understand and solve complex problems through AI/ML (including generative AI methods where appropriate) to inform business strategy and decisions Design and execute advanced analytics and predictive modeling projects using rigorous statistical methods and machine learning techniques Design, develop, deploy and maintain reusable assets and custom pipelines to optimize operational efficiencies in analytics execution Research, identify, and apply new algorithms and technologies to solve complex problems and systematize solutions into reusable assets and capabilities Practice Agile-based project management standards (i.e. daily check-in procedures, workload status, and cost overruns/projections) Identify emerging technologies, evaluate their potential impact, and make informed decisions on adopting new tools, frameworks, and methodologies. Basic Qualifications Proven experience (5+ years) as a software engineer, ML engineer, or data scientist and project lead for a diverse range of projects, with a focus on developing and deploying production-grade solutions. Bachelor’s degree in STEM (Science, Technology, Engineering, Mathematics) majors with quantitative emphasis – Statistics, Computer Science, Economics, Engineering etc. Strong programming skills in languages such as Python, Java, or C++, and proficiency with AI and machine learning frameworks and libraries (e.g., TensorFlow, PyTorch, scikit-learn). Applied knowledge of statistical analysis, experience with R, Excel, etc. Strong background in computer science: algorithms, data structures, machine learning, and distributed systems. Superior analytical skills required; Strong verbal and written communication skills Demonstrated experience interfacing with other internal and external teams to incorporate their innovations and vice versa Preferred Qualifications Advanced understanding of machine learning algorithms, deep learning architectures, and statistical techniques. Experience with foundation models, LLMs, and generative AI. Proficiency in data preprocessing, feature engineering, and dimensionality reduction. Familiarity with software engineering principles (e.g. version control, testing, and deployment) Experience with cloud platforms (e.g., AWS, Azure, GCP) and distributed computing frameworks is a plus. A passion for staying up-to-date with the latest advancements in AI and machine learning technologies and a commitment to continuous learning. Experience working in Agile processes and practices. EEO (Equal Employment Opportunity) & Employment Eligibility Pfizer is committed to equal opportunity in the terms and conditions of employment for all employees and job applicants without regard to race, color, religion, sex, sexual orientation, age, gender identity or gender expression, national origin, or disability. Information & Business Tech",https://mx.linkedin.com/jobs/view/manager-machine-learning-at-pfizer-4027616455,4027616455,"The role of the AI/ML Engineer involves designing, developing, and deploying machine learning products and solutions to address business challenges across various domains, leveraging advanced AI and ML technologies. You will engage stakeholders to inform business strategies through AI/ML, execute advanced analytics projects using rigorous statistical methods, and research new algorithms to create reusable assets. The position requires strong programming skills and experience in software engineering, machine learning, and statistical analysis.","Python, Java, C++, TensorFlow, PyTorch, scikit-learn, R, Excel, AWS, Azure, GCP",5+ years,Bachelor,True,5.0,0,0,0,1,0,0,0,0,1,0,0,0,1,0,1,0,0
Data Science Senior Analyst - C12 - CIUDAD DE MEXICO,Citibanamex,Mexico City Metropolitan Area,ON-SITE,,Full-time,"Banking, Financial Services, and Investment Banking",2024-09-16 15:12:39.847442,25,Information Technology,,,"The Data Science Senior Analyst is a seasoned professional role. Applies in-depth disciplinary knowledge, contributing to the development of new techniques and the improvement of processes and work-flow for the area or function. Integrates subject matter and industry expertise within a defined area. Requires in-depth understanding of how areas collectively integrate within the sub-function as well as coordinate and contribute to the objectives of the function and overall business. Evaluates moderately complex and variable issues with substantial potential impact, where development of an approach/taking of an action involves weighing various alternatives and balancing potentially conflicting situations using multiple sources of information. Requires good analytical skills in order to filter, prioritize and validate potentially complex and dynamic material from multiple sources. Strong communication and diplomacy skills are required. Regularly assumes informal/formal leadership role within teams. Involved in coaching and training of new recruits. Significant impact in terms of project size, geography, etc. by influencing decisions through advice, counsel and/or facilitating services to others in area of specialization. Work and performance of all teams in the area are directly affected by the performance of the individual. Responsibilities: Conducts strategic data analysis, identifies insights and implications and make strategic recommendations, develops data displays that clearly communicate complex analysis. Mines and analyzes data from various banking platforms to drive optimization and improve data quality. Deliver analytics initiatives to address business problems with the ability to determine data required, assess time & effort required and establish a project plan. Consults with business clients to determine system functional specifications. Applies comprehensive understanding of how multiple areas collectively integrate to contribute towards achieving business objectives. Consults with users and clients to solve complex system issues/problems through in-depth evaluation of business processes, systems and industry standards; recommends solutions. Leads system change process from requirements through implementation; provides user and operational support of application to business users. Formulates and defines systems scope and objectives for complex projects through research and fact-finding combined with an understanding of applicable business systems and industry standards. Impacts the business directly by ensuring the quality of work provided by self and others; impacts own team and closely related work teams. Considers the business implications of the application of technology to the current business environment; identifies and communicates risks and impacts. Drives communication between business leaders and IT; exhibits sound and comprehensive communication and diplomacy skills to exchange complex information. Performs other duties and functions as assigned. Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency. Qualifications: 5-8 years experience in business and data analysis, process improvement and project management Ability to effectively use complex analytical, interpretive and problem solving techniques. Demonstrated interpersonal, verbal and written communication skills. Methodical attention to detail Experience using tools for statistical modeling of large data sets Education: Bachelor’s/University degree or equivalent experience This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required. Description Education: Degree in Mathematics, Statistics, Computer Science, or related fields. Experience: At least 5 years in roles related to credit modeling or data analysis Skills: Statistical modeling, data analysis, project management, advanced analytical skills. Functions / Responsibilities Perform advanced analysis using AI models to assess credit risk and predict adverse events. Coordinate the integration of analytical results into decision-making processes. Review and validate model results to ensure accuracy and relevance. Collaborate with the modeling team to develop new techniques and enhance existing models. Communicate analytical findings to senior management and provide data-driven recommendations. ------------------------------------------------------ Job Family Group: Technology ------------------------------------------------------ Job Family: Data Science ------------------------------------------------------ Time Type: Full time ------------------------------------------------------ Citi is an equal opportunity and affirmative action employer. Qualified applicants will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran. Citigroup Inc. and its subsidiaries (""Citi”) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi . View the "" EEO is the Law "" poster. View the EEO is the Law Supplement . View the EEO Policy Statement . View the Pay Transparency Posting",https://mx.linkedin.com/jobs/view/data-science-senior-analyst-c12-ciudad-de-mexico-at-citibanamex-4025577467,4025577467,"The Data Science Senior Analyst is a seasoned professional role that applies in-depth disciplinary knowledge to develop new techniques and improve processes and workflows. The analyst evaluates moderately complex issues with substantial potential impact and requires good analytical skills to filter, prioritize, and validate complex data. Responsibilities include conducting strategic data analysis, delivering analytics initiatives, consulting with business clients, leading system change processes, and ensuring the quality of work. The position also involves performing advanced analysis using AI models to assess credit risk, reviewing model results, and communicating findings to senior management.","Statistical Modeling, Data Analysis, Process Improvement, Project Management, AI Models",5-8,Bachelor,True,5.0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"Customer Experience Data Analyst (Hybrid, Mexico City Office)",OpenTable,Mexico City Metropolitan Area,ON-SITE,,Full-time,"Hospitality, Technology, Information and Internet, and Restaurants",2024-09-16 15:12:39.847442,25,Information Technology,,,"With millions of diners, tens of thousands of restaurants, and 23+ years of experience, OpenTable, part of Booking Holdings, Inc. (NASDAQ: BKNG), is an industry leader with a unique insight into the world of hospitality. We champion restaurants, bars, wineries, and other venues around the world, helping them attract guests, manage capacity, improve operations and maximize revenue. Every employee at OpenTable has a tangible impact on what we do and how we do it. You’ll also be part of a global network that includes OpenTable and KAYAK's portfolio of travel brands including Swoodoo, checkfelix, momondo, Cheapflights, Mundi and HotelsCombined. Hospitality is all about taking care of others, and it defines our culture. You’ll work in a welcoming and inclusive environment, and get the benefits, flexibility, and support you need to succeed. OpenTable is looking for a hands-on Data Analyst who is technically savvy and can work well with all levels of people. We believe strongly in the importance of teamwork and collaboration. We recognize hard work and success, and we strive to cultivate an environment of learning, development, and FUN! Join our dynamic team as a CX Data Analyst and play a pivotal role in transforming customer experience through data-driven insights. In this role, you will harness the power of data analytics to uncover trends, predict customer behavior, and shape strategies that enhance customer satisfaction and loyalty. Your work will directly impact our mission to deliver exceptional service, making every customer interaction meaningful. In This Role, You Will Serve as the main contact for the Support organization for any data-related inquiries, providing timely, actionable insights to drive decision-making and improve customer service outcomes Utilize a suite of tools including Salesforce, Zendesk, Snowflake, Superset, and Level AI to analyze customer interactions and behaviors, translating complex data sets into understandable and actionable strategies Work cross-functionally with the data analytics team, ensuring a cohesive approach to data collection, analysis, and reporting that meets the diverse needs of stakeholders throughout the organization Develop and maintain comprehensive dashboards and reports integrating data across platforms, providing a 360-degree view of customer experiences and support interactions Spearhead projects to forecast customer behaviors and trends, leveraging predictive analytics to inform proactive support strategies and enhance customer satisfaction Other duties as required About You Passionate about using data to drive improvements in customer experience Skilled in analyzing complex datasets with tools like Salesforce, Zendesk, Snowflake, Superset, and Level AI Excellent at communicating complex data insights in a clear, actionable manner A collaborative teammate who excels at working across departments Constantly seeking new ways to leverage data for better decision-making Adaptable, thriving in fast-paced environments and quickly responding to changing needs Please Apply If 2-3 years of experience in data analysis, market research, or a related field Bachelor's Degree in Data Analytics or related field preferred or equivalent education and experience Proficiency in utilizing BI tools like Snowflake and Preset for data analysis Proficient in SQL, Salesforce, Excel and G-Suite (Slides, Sheets, Docs) Experience translating data into actionable insights Strong analytical problem-solving skills Excellent communication skills, both written and verbal, ability to build out effective presentations and share insights Embrace a proactive and adaptable approach, willing to take risks, explore innovative methods, and learn from failures Display curiosity, demonstrating a strong desire to learn and contribute value to all aspects of the OpenTable business Benefits OpenTable provides Mexican Social Security (IMSS) Christmas Bonus - 30 days Paid Time Off - 20 days a year Vacation Premium - 25% Parental Leave Bereavement Leave - 3 days Bonuses Dental Insurance & Life Insurance Major Medical Insurance Diversity, Equity, and Inclusion OpenTable aspires to be a workplace that reflects the diverse communities we serve and a culture that is inclusive and welcoming. Hiring people with different backgrounds, experiences, perspectives, and ideas is critical to innovation and to how we deliver great experiences for our users and our partners. Representation matters. We ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform job responsibilities, and to receive other benefits and privileges of employment. Please contact us to request accommodation.",https://mx.linkedin.com/jobs/view/customer-experience-data-analyst-hybrid-mexico-city-office-at-opentable-4025578240,4025578240,"OpenTable is looking for a hands-on Data Analyst who will transform customer experience through data-driven insights. In this role, you will analyze customer interactions to uncover trends, predict behavior, and enhance satisfaction and loyalty. Your work will include providing actionable insights, utilizing tools like Salesforce, Zendesk, Snowflake, Superset, and Level AI, and developing dashboards that integrate data across platforms for a comprehensive view of customer experiences.","Salesforce, Zendesk, Snowflake, Superset, Level AI, SQL, Excel, G-Suite",2-3 years,Bachelor,True,2.0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0
Senior Engineer (ERP/BI/HANA/DS),Levi Strauss & Co.,Mexico City Metropolitan Area,ON-SITE,,Full-time,"Retail Apparel and Fashion, Design Services, and Retail",2024-09-16 15:12:39.847442,25,Information Technology,,,"Job Description We believe that clothes — and how you make them — can make a difference. Since 1853, we've been dedicated to innovation, constantly striving to meet people's needs. We introduced the first blue jeans and revolutionized khaki pants. We've set the bar for labor and environmental standards in our industry and integrated sustainability into our operations. Our company's 160-year legacy is a testament to our ability to adapt and evolve. We continue reinventing ourselves, striving to delight our consumers, succeed in the marketplace, and uphold our core values. With a global workforce of over 17,000, we support iconic brands like Levi's®, Dockers®, and Denizen®. Our employees are at the heart of our success, and we're committed to fostering innovation, creativity, and collaboration. If you're a professional who values these principles and is looking for a place to grow your career and seize new opportunities, you've come to the right place. At LS&Co, we’re not just undergoing business transformations; we're revolutionizing our operations to position the company for long-term success in the ever-evolving retail landscape. We aim to digitize our Go-to-Market capabilities and revolutionize our supply chain and technology platform by developing and implementing cutting-edge software solutions with advanced analytics. The scale and complexity of our business and system landscape make it an incredibly challenging and exciting environment to work in. We're seeking an experienced SAP Product Analyst who can navigate multiple domains and play a pivotal role in accelerating technology to meet our business needs. This role is a key part of our Global Transformation initiatives in our technology organization. About This Role As a Senior Data Engineer, you will play a crucial role in Analytics for Warehouse Management, SAS, and MDM domains that power a data-driven transformation of our standard business processes across channels and organizations. Your work will directly impact consumer satisfaction. You will develop and deploy solutions to maximize their value and increase consumer satisfaction. You will work with massive datasets, create & optimize data solutions, and ensure data availability, reliability, and performance. Your expertise in BW on HANA, S4HANA, Embedded Analytics, Fiori, SQL, Business Objects, and SAC will be instrumental in our mission to leverage data for business insights. Accountable for building, enhancing, and delivering high-quality data products and analytics-ready solutions. Accountable for WMS, SAS, and MDM processes as a source for analytics. Working with stakeholders to define the overall strategy for the analytics. This involves understanding business goals, identifying data sources, and building solutions. Developing and implementing data engineering solutions that support the organization’s business needs. This may involve working with various technologies, including data BW on HANA, DataSphere, S4HANA Embedded Analytics, Business Objects, and SAC. Understanding of SAP S4HANA embedded analytics capabilities & Fiori. Understanding of SAP Analytics on Cloud products. Design, build, and maintain solutions that drive data insights for business. Collaborate with cross-functional tracks to design and implement solutions that support analytical needs. Optimize solutions to improve performance and scalability. Implement and enforce data governance practices, ensuring data quality, security, and industry compliance. Closely partner with the Enterprise Data and Analytics team and other cross-functional teams to shape and adopt data and technology strategies. About You 5-7 years of experience in SAP BW on HANA modelling is a must. Minimum 4+ years of experience in HANA modelling. Exposure to using ABAP for complex logic. Should have a basic understanding of SAP Business Objects 4.2 Exposure to SAP S4HANA Embedded Analytics and standard and custom development of ABAP CDS View. Keep updated with industry trends and emerging technologies in SAP (SAP Datasphere etc.). Experience in Agile and Waterfall methodology principles. Strong written / verbal communication and presentation skills. Excellent relationship and team-building skills. The ability to work with all levels of staff & leadership. Demonstrated skills in collaborating, persuading, influencing, and negotiating. Ability to self-motivate, adapt, and multi-task in a fast-paced environment. Strong organizational skills with attention to detail and quality. Ability to deal effectively with challenging situations. LOCATION Mexico, D.F., Mexico FULL TIME/PART TIME Full time Current LS&Co Employees, apply via your Workday account.",https://mx.linkedin.com/jobs/view/senior-engineer-erp-bi-hana-ds-at-levi-strauss-co-3931895349,3931895349,"As a Senior Data Engineer, you will play a crucial role in Analytics for Warehouse Management, SAS, and MDM domains that power a data-driven transformation of our standard business processes across channels and organizations. Your work will directly impact consumer satisfaction by developing and deploying data solutions that maximize their value, ensuring data availability, reliability, and performance. You will work with massive datasets and be accountable for building, enhancing, and delivering high-quality data products and analytics-ready solutions. Understanding of BW on HANA, S4HANA, Embedded Analytics, Fiori, SQL, Business Objects, and SAC is required to drive data insights for business and optimize solutions for performance and scalability.","SAP BW on HANA, S4HANA, Embedded Analytics, Fiori, SQL, Business Objects, SAC, ABAP",5-7 years,,True,5.0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
Machine Learning Engineer,Creai,Mexico City Metropolitan Area,REMOTE,Entry level,Full-time,Software Development,2024-09-18 07:38:19.315511,25,Engineering,Information Technology,,"About Creai At Creai, we specialize in harnessing the power of artificial intelligence and machine learning to drive business transformation. Our mission is to help clients reduce costs, increase efficiency, and unlock new opportunities by leveraging cutting-edge AI solutions. We're rapidly growing and are looking for talented engineers to join our team and shape the future of AI-driven innovation. Why This Role Matters As a Machine Learning Software Engineer , you will play a crucial role in developing advanced statistical techniques to manipulate and analyze data. You'll create and evaluate machine learning and AI models that reduce costs, increase profits, and optimize processes for our clients. Your contributions will help build efficient and scalable solutions that effectively solve user problems by integrating multiple systems and services, working with machine learning models, cloud services, and other AI-related applications. Responsibilities Design, develop, and maintain scalable machine learning solutions from conception to production. Collaborate closely with cross-functional teams—including data scientists, product managers, and software engineers—to integrate machine learning algorithms into broader software systems. Analyze large datasets to develop machine-learning models that solve complex problems. Optimize existing machine learning systems to improve efficiency and performance. Utilize cloud services from platforms like AWS, GCP, or Azure to enhance the performance, cost, or scalability of machine learning solutions. Stay updated with the latest machine learning techniques and technologies. Clearly document and present model development and results to stakeholders. Promote the advancement of software engineering practices within the organization by driving continuous improvement in implementing best practices or using new technologies. Requirements Advanced verbal and written communication skills. Strong team-oriented mindset. Excellent problem-solving abilities and a high level of scientific curiosity. Experience in data analysis and predictive modeling. Analytical skills and the ability to tackle complex problems. Strong programming skills in Python, Java, or Scala. Experience with cloud services (AWS, Google Cloud, Azure) and their specific machine learning tools. Experience with machine learning frameworks (e.g., TensorFlow, PyTorch) and libraries (e.g., scikit-learn, pandas). Familiarity with data structures, data modeling, and software architecture. Proven ability to design and implement machine learning solutions from scratch. Academic degree in computer science, software engineering, or related fields, or equivalent experience. Desired Qualifications Data visualization and storytelling skills. Experience training deep learning models (artificial neural networks). Experience with language models (LLMs) like ChatGPT, Gemini, Claude, etc. Work from Anywhere We offer full remote flexibility! You can work from anywhere worldwide as long as you're available to collaborate during our core hours from 9 AM to 5 PM CST. Perks & Benefits We offer unlimited PTO, trusting you to manage your time effectively and take the time off you need. You will receive health insurance, valid for employees in Mexico. We provide a budget to help you set up your ideal remote workspace. We Encourage You to Apply! We know that women and underrepresented minorities often hesitate to apply if they don't meet 100% of the qualifications. We strongly encourage you to apply even if you don't meet all the listed requirements—your unique experience and perspective are valued!",https://mx.linkedin.com/jobs/view/machine-learning-engineer-at-creai-4026080399,4026080399,"As a Machine Learning Software Engineer, you will develop advanced statistical techniques to manipulate and analyze data. You will create and evaluate machine learning and AI models that optimize processes for clients, build efficient solutions, and integrate multiple systems and services.","Python, Java, Scala, AWS, Google Cloud, Azure, TensorFlow, PyTorch, scikit-learn, pandas",,Bachelor,True,,0,0,0,1,0,0,0,0,0,0,0,0,1,0,1,0,0
Full Stack AI Engineer,Creai,Mexico City Metropolitan Area,REMOTE,,Full-time,Software Development,2024-09-18 07:38:19.315511,25,Engineering,Information Technology,,"About Creai At Creai, we specialize in harnessing the power of artificial intelligence and machine learning to drive business transformation. Our mission is to help clients reduce costs, increase efficiency, and unlock new opportunities by leveraging cutting-edge AI solutions. We're snowballing and are looking for talented engineers to join our team and shape the future of AI-driven innovation. Why This Role Matters As a Full Stack Software Engineer for AI, you will play a critical role in developing scalable machine learning systems that directly impact the success of our clients. You will collaborate with cross-functional teams to build, deploy, and maintain AI solutions that solve complex problems and deliver tangible results. Your contributions will help Creai remain at the forefront of AI technology. Responsibilities Develop Scalable AI Solutions: Design, build, and maintain efficient machine learning models and full-stack solutions from prototype to production, optimizing performance, scalability, and cost. Cross-functional collaboration: Work closely with data scientists, software engineers, and product managers to integrate AI models into broader software systems, ensuring seamless functionality. Data Analysis & Model Building: Analyze large datasets, develop predictive models, and apply advanced statistical techniques to address client-specific challenges. Optimize Performance: Continuously improve existing systems and algorithms for speed, efficiency, and reliability. Cloud Services Integration: Utilize cloud platforms (AWS, Google Cloud, Azure) to deploy and scale AI solutions, leveraging services that enhance performance and cost-effectiveness. Stay on the Cutting Edge: Stay informed about the latest AI and machine learning trends and technologies, ensuring that Creai remains competitive. Documentation & Communication: Document development processes and present technical results to technical and non-technical stakeholders. Requirements Strong Technical Expertise: Proficiency in Python and Java or Scala; familiarity with machine learning frameworks like TensorFlow or PyTorch and data libraries like pandas and scikit-learn. Cloud Experience: Hands-on experience with AWS, Google Cloud, or Azure and their machine learning toolsets. Analytical & Problem-Solving Skills: Proven ability to tackle complex problems using data analytics and predictive modeling. Collaboration & Communication: Strong verbal and written communication skills with a team-oriented mindset, capable of working effectively with cross-functional teams. AI/ML Enthusiast: Keen scientific curiosity with a commitment to staying updated on industry trends and best practices. Software Architecture Knowledge: Familiarity with data structures, data modeling, and software architecture principles. Work from Anywhere We offer full remote flexibility! You can work from anywhere worldwide as long as you're available to collaborate during our core hours from 9 AM to 5 PM CST. Perks & Benefits We offer unlimited PTO, trusting you to manage your time effectively and take the time off you need. You will receive health insurance, valid for employees in Mexico. We provide a budget to help you set up your ideal remote workspace. We encourage you to apply! We know that women and underrepresented minorities often hesitate to apply if they don't meet 100% of the qualifications. We strongly encourage you to apply even if you don't meet all the listed requirements—your unique experience and perspective are valued!",https://mx.linkedin.com/jobs/view/full-stack-ai-engineer-at-creai-4026081426,4026081426,"As a Full Stack Software Engineer for AI, you will develop scalable machine learning systems, collaborate with cross-functional teams, analyze large datasets, optimize performance, integrate cloud services, and stay informed about latest AI trends.","Python, Java, Scala, TensorFlow, PyTorch, pandas, scikit-learn, AWS, Google Cloud, Azure",,,True,,0,0,0,1,0,0,0,0,0,0,0,0,1,0,1,0,0
BI Developer II,Rackspace Technology,Mexico City Metropolitan Area,REMOTE,,Full-time,IT Services and IT Consulting,2024-09-18 07:38:19.315511,25,Information Technology,,,"We are looking for a BI Developer II with experience in developing and maintaining a business intelligence framework. **Must be fluent in English Responsibilities Works with business requirement team, analysts, and developers to ensure stakeholder requirements are addressed through integration solutions in a manner that aligns with timelines, budgets, and quality expectations Leads the design and development of the Business Intelligence (BI) architecture and continually refines the BI strategy to align with corporate direction Serves as the subject matter expert in the extraction of information from EFD, Star, and Snowflake schemas Builds operational and ad-hoc reports Builds reports that take advantage of OLAP/Dimensional Modeling capabilities Build executive dashboards and corporate scorecards Works with customers to define their requirements and create information delivery solutions that meet their needs utilizing “best practices.” Develops and implements data integration strategy and associated policies as it pertains to lean integration practices Participates in design and development reviews Works with system owners to resolve data transformation issues and to refine transformation Writes software in an open-source setting (number of branches merged) Writes design documents Reviews proposed software branches (number of reviews) Reviews design documents (number of reviews) Participates in project discussions (number of emails etc.) Qualifications Strong skills in Excel and T-SQL recommended Comfort using Qlikview is desirable Advanced level of competence with database structures and design as well as possessing strong SQL development skills with the ability to build reporting tables, stored procedures, and Chron Jobs Basic understanding of relational and columnar database platforms such as MSSQL, My SQL, Oracle, Postgresql, and Cassandra. Working knowledge of CORE and Salesforce Advanced QV skills such as set analysis, variables, actions, triggers, and QVD building Business analysis skills to allow for the creation of report definitions and specifications Basic proficiency in one or more of the following tools: MS Access, .Net, ASP, VB, MongoDB, Hadoop, etc Ability to communicate technical information and ideas so that others will understand Must be able to make appropriate decisions considering the relative costs and benefits of potential actions Must successfully work and promote inclusiveness in small groups Excellent communication skills, both oral and written Ability to develop work plans and follow through on assignments with minimal guidance Ability to work with business and system owners to obtain requirements and manage expectations Requires a Bachelor's degree in Computer Science, MIS, or Business Administration Discover your inner Racker: Racker Life - Fluent, Bi-lingual (Spanish and English) - Role can work remotely in the states of Ciudad de Mexico, Jalisco, Nuevo Leon, Aguascalientes, Queretaro, Estado de Mexico and Puebla - This opportunity is a permanent remote job, but you need to be based in Mexico at one of the above locations. About Rackspace Technology We are the multicloud solutions experts. We combine our expertise with the world’s leading technologies — across applications, data and security — to deliver end-to-end solutions. We have a proven record of advising customers based on their business challenges, designing solutions that scale, building and managing those solutions, and optimizing returns into the future. Named a best place to work, year after year according to Fortune, Forbes and Glassdoor, we attract and develop world-class talent. Join us on our mission to embrace technology, empower customers and deliver the future. More on Rackspace Technology Though we’re all different, Rackers thrive through our connection to a central goal: to be a valued member of a winning team on an inspiring mission. We bring our whole selves to work every day. And we embrace the notion that unique perspectives fuel innovation and enable us to best serve our customers and communities around the globe. We welcome you to apply today and want you to know that we are committed to offering equal employment opportunity without regard to age, color, disability, gender reassignment or identity or expression, genetic information, marital or civil partner status, pregnancy or maternity status, military or veteran status, nationality, ethnic or national origin, race, religion or belief, sexual orientation, or any legally protected characteristic. If you have a disability or special need that requires accommodation, please let us know.",https://mx.linkedin.com/jobs/view/bi-developer-ii-at-rackspace-technology-4026449484,4026449484,"We are looking for a BI Developer II with experience in developing and maintaining a business intelligence framework. This position involves working with business requirement teams, analysts, and developers to ensure stakeholder requirements are met through integration solutions, leading the design and development of BI architecture, and serving as a subject matter expert in data extraction from multiple schemas. Responsibilities include building operational and ad-hoc reports, executive dashboards, and corporate scorecards, as well as developing and implementing data integration strategies. Strong skills in Excel and T-SQL are recommended, along with advanced SQL development skills. Candidates should have a basic understanding of various database platforms and be comfortable with report creation tools. Excellent communication skills are required, and a Bachelor's degree in Computer Science, MIS, or Business Administration is necessary.","Excel, T-SQL, Qlikview, MSSQL, MySQL, Oracle, PostgreSQL, Cassandra, .Net, ASP, VB, MongoDB, Hadoop",,Bachelor,True,,0,0,1,0,0,0,0,0,1,1,0,0,0,0,0,0,0
Data Analyst & BI - Remoto Mexico,Talent Job Seeker,Mexico City Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Human Resources Services,2024-09-18 07:38:19.315511,200,Information Technology,,,"The Wise Seeker is the leading HR technology company in unbiased talent evaluation.With over 15 years in the industry analyzing the needs and demands of the job market, we are capable of identifying the best talent for each company thanks to our team of professionals and our SaaS platform integrated with Artificial Intelligence.We are efficient, evaluate talent objectively without bias, and close hiring times in record time, delivering optimal results. As a Data Analyst & BI Specialist, you will be responsible for analyzing complex datasets and developing BI solutions to support strategic decision-making. You will work closely with cross-functional teams to identify business needs and deliver data-driven insights. Key Responsibilities Collect, clean, and analyze large datasets to identify trends and patterns. Develop and maintain BI dashboards and reports using tools like Tableau, Power BI, or similar. Collaborate with stakeholders to understand business requirements and translate them into data models and visualizations. Conduct ad-hoc analyses to support business initiatives and decision-making. Monitor key performance indicators (KPIs) and provide insights to improve business processes. Ensure data accuracy and integrity across all reports and dashboards. Stay current with industry trends and best practices in data analysis and BI. Benefits Competitive salary and performance-based bonuses. Flexible working hours and remote work options. Comprehensive health, dental, and vision insurance. Opportunities for professional growth and development. A collaborative and innovative work culture.",https://mx.linkedin.com/jobs/view/data-analyst-bi-remoto-mexico-at-talent-job-seeker-4008482899,4008482899,"As a Data Analyst & BI Specialist, you will be responsible for analyzing complex datasets and developing BI solutions to support strategic decision-making. You will work closely with cross-functional teams to identify business needs and deliver data-driven insights. Key responsibilities include collecting, cleaning, and analyzing large datasets, developing and maintaining BI dashboards and reports, collaborating with stakeholders to understand requirements, conducting ad-hoc analyses, monitoring KPIs, and ensuring data accuracy.","SaaS, Artificial Intelligence, Tableau, Power BI, Data Analytics, Data Visualization",,,True,,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0
Sr. Data Engineer,Pinterest,Mexico City Metropolitan Area,REMOTE,Mid-Senior level,Full-time,"Technology, Information and Internet, Software Development, and IT Services and IT Consulting",2024-09-18 07:38:19.315511,58,Information Technology,,,"About Pinterest Millions of people across the world come to Pinterest to find new ideas every day. It’s where they get inspiration, dream about new possibilities and plan for what matters most. Our mission is to help those people find their inspiration and create a life they love. In your role, you’ll be challenged to take on work that upholds this mission and pushes Pinterest forward. You’ll grow as a person and leader in your field, all the while helping Pinners make their lives better in the positive corner of the internet. Creating a life you love also means finding a career that celebrates the unique perspectives and experiences that you bring. As you read through the expectations of the position, consider how your skills and experiences may complement the responsibilities of the role. We encourage you to think through your relevant and transferable skills from prior experiences. Our new progressive work model is called PinFlex, a term that’s uniquely Pinterest to describe our flexible approach to living and working. Visit our PinFlex landing page to learn more. Pinterest’s Trust & Safety Tools team is hiring a Senior Software Engineer to build tooling that keeps Pinners safe and inspired. Backing up Pinterest’s promise of being a positive corner of the internet, our team is responsible for supporting operations agents, analysts, and other engineers with content safety efforts with internal tools to aid in scaled content moderation. As part of this role, you will be responsible for maintaining and improving the data systems that Pinterest uses to log business data. What You’ll Do Leverage Python, MySQL, and other data skills to resolve current pain-points and suggest future improvements Provide easy integration points/APIs with web-based tooling that serves thousands of agents and millions of users Partner with T&S Operations, Policy, and Product, and other engineering teams across Pinterest Serve on an on-call rotation (roughly 1 week of every 8) to support our tools What We’re Looking For 5+ years experience with Python, SQL, SparkSQL, Hive and/or other data systems Experience mentoring more junior engineers Comfortable diving into ambiguous technical problems, working closely with Product, Legal, Policy and Operations teams Ability to communicate complex concepts clearly in writing and verbally to many stakeholders Bachelor’s degree in a relevant field such as Computer Science, or equivalent experience Relocation Statement: This position is not eligible for relocation assistance. Visit our PinFlex page to learn more about our working model. In-Office Requirement Statement We let the type of work you do guide the collaboration style. That means we're not always working in an office, but we continue to gather for key moments of collaboration and connection. Our Commitment To Diversity Pinterest is an equal opportunity employer and makes employment decisions on the basis of merit. We want to have the best qualified people in every job. All qualified applicants will receive consideration for employment without regard to race, color, ancestry, national origin, religion or religious creed, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, age, marital status, status as a protected veteran, physical or mental disability, medical condition, genetic information or characteristics (or those of a family member) or any other consideration made unlawful by applicable federal, state or local laws. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you require an accommodation during the job application process, please notify accessibility@pinterest.com for support.",https://mx.linkedin.com/jobs/view/sr-data-engineer-at-pinterest-3994907305,3994907305,"Pinterest's Trust & Safety Tools team is hiring a Senior Software Engineer to build tooling that keeps Pinners safe and inspired by maintaining and improving the data systems that Pinterest uses to log business data. The role involves leveraging Python, MySQL, and other data skills to resolve pain points, providing integration points/APIs with web-based tooling, and supporting operations agents and analysts in content safety efforts.","Python, MySQL, SparkSQL, Hive",5+,Bachelor,True,5.0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,1,0,0
Data Scientist,Seeds,Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Temporary,IT Services and IT Consulting,2024-09-18 07:38:47.568455,42,Analyst,,,"¿Eres Data Scientist ? Entonces… ¿Qué estás esperando para unirte a nuestra comunidad de Seeders? ¡Aplica a nuestra comunidad y accede a trabajo on-demand en las empresas líderes, únete al Present of Work! ¿Quiénes somos? Somos una comunidad que reúne al mejor talento on-demand de Latinoamérica y lo conecta con las empresas líderes de la región. Gestionamos el match perfecto entre las necesidades de las empresas y el talento con las competencias y la experiencia buscada, fomentando flexibilidad y el desarrollo profesional de nuestra comunidad. No somos una plataforma más de freelancers; Seeds lidera un dream team de profesionales altamente calificados que eligen dónde, cómo y para quién trabajar, disfrutando así de contribuir a una misión más grande, definiendo y moldeando la forma en que trabajamos. Estamos buscando Data Scientists para sumar a la comunidad. Responsabilidades usuales del rol: Investigar y desarrollar modelos de aprendizaje estadístico para el análisis de datos. Colaborar con los departamentos de gestión de productos e ingeniería para comprender las necesidades de la empresa y encontrar posibles soluciones. Comunicar resultados e ideas a los principales responsables de la toma de decisiones. Implementar nuevas metodologías estadísticas u otras metodologías matemáticas según sea necesario para modelos o análisis específicos. Optimizar los esfuerzos conjuntos de desarrollo mediante el uso adecuado de la base de datos y el diseño del proyecto. Requisitos: Más de 3 años de experiencia trabajando como Científico de Datos. Haber trabajado en una consultora es un plus. Inglés intermedio/avanzado (deseable). ¿Por qué unirte a nuestra comunidad de Seeders? Elige tus proyectos. Trabaja desde donde tú quieras. Accede a beneficios exclusivos (descuentos en Swiss Medical, espacios de coworking y salas en Benomad, viajes en Cabify, plataforma de aprendizaje de idiomas con Nulinga, soluciones financieras on-demand en Abax, chip internacional con HolaSim y seguros en MeCubro). Eventos de networking. Asesoramiento personalizado. Seeds Academy: Potencia tu desarrollo profesional adquiriendo nuevas habilidades (upskilling & reskilling), participando en webinars, Bootcamps y otras acciones exclusivas para la comunidad. ¡Únete a nuestra comunidad y lleva tus habilidades como Data Scientist al siguiente nivel!",https://mx.linkedin.com/jobs/view/data-scientist-at-seeds-4026020571,4026020571,"Are you a Data Scientist? Then… what are you waiting for to join our community of Seeders? Apply to our community and access on-demand work in leading companies, join the Present of Work! We are a community that brings together the best on-demand talent from Latin America and connects it with the leading companies in the region. We manage the perfect match between the needs of companies and the talent with the skills and experience sought, fostering flexibility and the professional development of our community. We are looking for Data Scientists to join the community. Usual responsibilities of the role include researching and developing statistical learning models for data analysis, collaborating with product management and engineering departments to understand business needs and find potential solutions, communicating results and ideas to key decision-makers, implementing new statistical methodologies or other mathematical methodologies as needed for models or specific analyses, and optimizing development efforts using appropriate database use and project design.","Python, R, SQL, Machine Learning, Statistical Modeling",3+ years,,True,3.0,0,0,0,0,0,1,0,0,0,1,0,0,1,0,1,0,0
AI ML engineer,Tata Consultancy Services,Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-18 07:38:47.568455,25,Consulting,,,"We are seeking new talent! Job Title: AI/ML Engineer Location: Cdmx or Queretaro (candidate must be living in QRO or Cdmx or be able to relocate) English: Advanced Level Work Mode: Hybrid Desired experience: 2+ years What do you need for this challenge? Required technical skill set: AI / ML, Python, R, Vertex AI / TensorFlow · Proven experience as a Subject Matter Expert in AI/ML or a similar role. · In-depth knowledge of Google Cloud Platform (GCP) and its AI/ML tools. · Proficiency in relevant programming languages such as Python, R, or Java. · Familiarity with machine learning frameworks and tools. · Google Cloud Professional Machine Learning Engineer certification. · Experience with deep learning and neural networks. · Knowledge of AI ethics and best practices. We are certified as a Top Employer in Latam, we have benefits such as indefinite contract from the first moment, competitive salary, insurance for major medical expenses for you, spouse and children, dental plan, training portals and certifications to boost your professional development, pantry vouchers, life insurance, excellent work tools, and much more. If you are interested, please send you updated English CV to monica.v-external@tcs.com",https://mx.linkedin.com/jobs/view/ai-ml-engineer-at-tata-consultancy-services-4028766962,4028766962,"We are seeking an AI/ML Engineer to develop and implement AI/ML solutions. This role requires proven experience as a Subject Matter Expert in AI/ML or a similar role, in-depth knowledge of Google Cloud Platform (GCP) and its AI/ML tools, and proficiency in programming languages such as Python, R, or Java. Familiarity with machine learning frameworks and tools, experience with deep learning and neural networks, and knowledge of AI ethics and best practices are also essential. The position requires advanced English proficiency.","AI, ML, Python, R, Java, Vertex AI, TensorFlow, Google Cloud Platform, Machine Learning Frameworks, Deep Learning, Neural Networks",2+,,True,2.0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,1,0,0
Data Analytics,Globant GUT,Mexico City Metropolitan Area,HYBRID,Associate,Full-time,Marketing Services and Advertising Services,2024-09-18 07:38:47.568455,57,Marketing,Advertising,,"¡Hola! En Globant Gut estamos buscando a una persona senior en analítica de datos de Marketing para unirse a nuestro equipo en la posición de Data, analytics & Martech Analyst. Somos una agencia creativa integral con alcance regional y el ingenio que se necesita para triunfar en este mundo digital. Contamos con un equipo de personas atrevidas e inteligentes, decididas a crear comunicación para todo tipo de marcas, llevándolas a donde necesitan estar. Si te apasiona el análisis de datos para convertirlos en información significativa que impulse decisiones estratégicas de marketing, te estamos buscando. Buscamos un analista talentoso y motivado para ser parte del equipo de Data, Analytics & Martech, quien será responsable de recopilar, analizar e interpretar datos relacionados con la operación de retail media y de e-commerce de nuestros clientes para identificar tendencias, oportunidades y recomendaciones que contribuyan directamente en la toma de decisiones estratégicas de los mismos. ¿Qué estaría haciendo esta persona? Trabajar estrechamente con los equipos de retail media e e-commerce para comprender sus prioridades y necesidades analíticas. Crear y administrar soluciones de Bl y análisis que conviertan los datos en conocimiento. Desarrollar dashboards e informes utilizando herramientas como Power BI, Tableau o similares. Rastrear métricas clave del negocio y proporcionar insights accionables a las partes interesadas para apoyar la toma de decisiones ejecutivas. Ayudar a los stakeholders a identificar nuevas oportunidades a través del análisis de datos. Segmentación para personalizar las campañas de marketing. Clasificar, organizar y analizar datos de múltiples fuentes para identificar patrones, tendencias y oportunidades en los datos de ventas, clientes, productos y canales. Realizar análisis de datos ad hoc para proporcionar recomendaciones oportunas y prácticas basadas en los resultados de las acciones ejecutadas. Permanecer al día en las últimas herramientas, técnicas y mejores prácticas en análisis de datos del ecosistema de marketing y de e-commerce. Generación de análisis cuantitativos y cualitativos enfocados en marketing research y diferentes técnicas de investigación. Realizar análisis a profundidad de datos de marketing y ventas, identificando tendencias, competidores, sentimientos e insights del consumidor que sean relevantes para la marca, industria y el público objetivo. Monitoreo de conversaciones online y análisis de sentimientos. Desarrollo de investigaciones cuantitativas para el entendimiento de marca, producto, competencia y audiencias. Combinación de metodologías de reporting, search, listening y estudios de mercado para el desarrollo de estrategias de campañas. Establecer KPIs, benchmarks y objetivos para medir la efectividad y el impacto de las diferentes iniciativas de marketing de nuestros clientes. Colaborar con equipos multidisciplinarios incluyendo stakeholders internos y dentro del cliente para alinear las actividades de análisis de datos y research, con los objetivos estratégicos del cliente. Experiencia. Al menos 1 año de experiencia comprobada en análisis de datos de Marketing Digital, E-commerce, Publicidad, y afines. Comprensión e interés en Marketing Digital, E-commerce, Contenido, Publicidad, el comportamiento de los consumidores en los medios y las tendencias económicas globales. Nivel intermedio de Excel. Experiencia en la construcción de análisis y reportes con herramientas de visualización de datos como PowerBI, Tableau o Looker. Excelentes habilidades de resolución de problemas. Experiencia básica-intermedia de herramientas de análisis web como Google Analytics, Adobe Analytics (Deseable) Consultas básicas de SQL, condiciones y proceso de limpieza de datos (Deseable) Manejo de plataformas de datos orientadas a márketing digital (emplifi, semrush, supermetrics, dataslayer, etc.) (Deseable) Experiencia con Google BigQuery, MySQL, etc. (Deseable) Experiencia con herramientas de escucha social como Sprinklr, Brandwatch, Sprout Social, etc. ¡Anímate y aplica! --------------------------- En Globant Gut fomentamos la inclusión y diversidad, sin importar raza, religión, cultura, género, orientación sexual, identidad de género, expresión de género, condición física, socioeconómica ni capacidades diferentes.",https://mx.linkedin.com/jobs/view/data-analytics-at-globant-gut-4026582885,4026582885,"Globant Gut is looking for a senior Marketing Data Analyst to join the Data, Analytics & Martech team. This position involves collecting, analyzing, and interpreting data related to retail media and e-commerce operations to identify trends and provide strategic recommendations. The analyst will work closely with retail media and e-commerce teams to understand their analytical needs, create BI solutions, develop dashboards and reports using tools like Power BI and Tableau, and help stakeholders identify new opportunities through data analysis.","Power BI, Tableau, Google Analytics, Adobe Analytics, SQL, Excel, Google BigQuery, MySQL, Emplifi, Semrush, Supermetrics, Dataslayer, Sprinklr, Brandwatch, Sprout Social",1+ years,,True,1.0,0,0,1,1,0,0,0,0,1,1,0,0,0,0,0,0,0
Data Engineer,Konfío,Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Full-time,Financial Services and IT Services and IT Consulting,2024-09-18 07:38:47.568455,25,Information Technology,,,"Únete a la revolución Fintech y construye el futuro de las finanzas en México! ¿Quiénes somos? Somos la empresa de tecnología financiera líder en México, impulsando a más de 70.000 clientes a alcanzar sus sueños. Nuestra misión es empoderar a las pequeñas y medianas empresas del país con soluciones innovadoras (financiamiento, tarjeta de crédito y pagos) para superar sus desafíos y convertirlas en los motores del crecimiento económico. Aspiramos a ser el aliado ideal de los emprendedores, contribuyendo al desarrollo de la comunidad, el país y el planeta. Tu reto: Desarrollar e implementar pipelines de datos robustos y escalables para satisfacer las necesidades de análisis y procesamiento de la organización colaborando estrechamente con otros equipos para comprender los requisitos de datos y proporcionar soluciones eficientes. ¿Qué buscamos? Licenciatura o ingeniería en Sistemas de Información o afín. Profundo entendimiento de bases de datos relacionales y no relacionales. Experiencia sólida en herramientas de extracción, transformación y carga (ETL), como AWS Glue o Spark. Habilidades avanzadas de programación en Python, SQL, MySQL, PostgerSQL. Conocimientos especializados en modelado de datos y diseño de arquitecturas. Experiencia práctica en el diseño, construcción y mantenimiento de pipelines de datos para la ingesta, transformación y carga de datos desde diversas fuentes hacia sistemas de almacenamiento y análisis. Amplio conocimiento de arquitecturas de data lakes y data warehouses. Experiencia en el diseño y gestión de procesos de transformación de datos. Dominio de servicios en la nube, especialmente AWS. Experiencia comprensión de modelado de datos, consultas, índices y optimización de rendimiento. Experiencia en herramientas y frameworks de procesamiento de datos distribuidos Conocimientos en prácticas de ingeniería de software, como control de versiones (Git), pruebas unitarias, integración continua (CI/CD), diseño de APIs, y patrones de diseño de software. Comprensión de técnicas y herramientas de ETL (Extract, Transform, Load), así como experiencia en la manipulación y procesamiento de grandes volúmenes de datos. Responsabilidades Liderar la integración de datos procedentes de múltiples fuentes. Encargarse de la preparación y minería de datos. Dirigir la transformación de datos según reglas técnicas y comerciales. Diseñar y desarrollar pipelines de datos para extracción e ingestión de datos. Gestionar el modelado de datos y la creación de ERMs. Gestionar el dimensionamiento y pruebas de rendimiento para capas finales de consumo de datos. Definir procesos y prácticas recomendadas para ingestiones, ETLs, tablas temporales, procedimientos almacenados, almacenes de datos y/o integraciones semánticas. Colaborar estrechamente con analistas y científicos de datos para facilitar procesos de descubrimiento y preparación de datos. Ser responsable de mantener y mejorar los procesos existentes de manera autónoma. Identificar áreas de mejora y desarrollar soluciones innovadoras para aumentar la escalabilidad, la fiabilidad y el rendimiento de los pipelines de datos. Identificar y resolver proactivamente problemas en los procesos de datos, asegurando su eficacia y eficiencia. Colaborar con otros miembros del equipo en la implementación de cambios y actualizaciones en los procesos. ¿Qué ofrecemos? Un ambiente de trabajo dinámico y colaborativo donde podrás desarrollar tu potencial al máximo. Oportunidades para aprender y crecer profesionalmente utilizando tecnologías de vanguardia. Un equipo apasionado y talentoso con el que podrás compartir conocimientos y experiencias. Paquete de compensación competitivo y beneficios atractivos. La oportunidad de impactar positivamente en la vida de miles de personas y contribuir al desarrollo del país.",https://mx.linkedin.com/jobs/view/data-engineer-at-konf%C3%ADo-4026098177,4026098177,"Join the Fintech revolution and build the future of finance in Mexico! Your challenge: Develop and implement robust and scalable data pipelines to meet the organization's analysis and processing needs. Collaborate closely with other teams to understand data requirements and provide efficient solutions. Responsibilities include leading data integration from multiple sources, preparing and mining data, directing data transformation according to technical and business rules, designing and developing data pipelines for data extraction and ingestion, managing data modeling, defining best practices for data handling, and collaborating with analysts and data scientists.","Python, SQL, MySQL, PostgreSQL, AWS Glue, Spark, Data Lakes, Data Warehouses, Git, CI/CD, APIs, ETL",,Bachelor,False,,0,0,1,1,0,0,1,0,0,1,0,1,0,0,1,0,0
Data Analytics,Tata Consultancy Services,Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-18 07:38:47.568455,60,Consulting,,,"We are seeking new talent! Job Title: Data Analytics Location: Cdmx or Queretaro (candidate must be living in QRO or Cdmx or be able to relocate) English: Advanced Level Work Mode: Hybrid Desired experience: 5+ years What do you need for this challenge? Required technical skill set: Data Analytics, BigQuery, Looker, DataVisualization · In-depth knowledge of Google Cloud Platform (GCP) and its data analytics tools, including BigQuery, Data Studio, and Looker. · Strong analytical and problem-solving skills. · Excellent communication and presentation skills. · Proficiency in SQL, Python, and other relevant programming languages. · Familiarity with data visualization tools and techniques. We are certified as a Top Employer in Latam, we have benefits such as indefinite contract from the first moment, competitive salary, insurance for major medical expenses for you, spouse and children, dental plan, training portals and certifications to boost your professional development, pantry vouchers, life insurance, excellent work tools, and much more. If you are interested, please send you updated English CV to monica.v-external@tcs.com",https://mx.linkedin.com/jobs/view/data-analytics-at-tata-consultancy-services-4028761640,4028761640,"We are seeking a Data Analytics professional with a strong technical skill set in Data Analytics, Google Cloud Platform (GCP), and its data analytics tools including BigQuery and Looker. The ideal candidate should have excellent analytical and problem-solving skills, along with proficiency in SQL and Python, and familiarity with data visualization tools.","Data Analytics, BigQuery, Looker, Google Cloud Platform (GCP), SQL, Python, Data Visualization",5+ years,,True,5.0,0,0,1,1,0,1,0,0,1,1,0,0,0,0,1,0,0
Clinical Data Risk Analyst,ICON plc,Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Full-time,Biotechnology Research,2024-09-18 07:38:47.568455,39,Information Technology,,,"Clinical Data Risk Analyst - Mexico, Mexico City - Home or office based ICON plc is a world-leading healthcare intelligence and clinical research organization. We’re proud to foster an inclusive environment driving innovation and excellence, and we welcome you to join us on our mission to shape the future of clinical development. What you will bring: The CDRA role requires both an understanding of how clinical research is conducted and proficiency in data analysis techniques. For this entry-level role, successful candidates will be either life sciences graduates with experience in clinical research and a keen interest in data, or STEM graduates with a strong understanding of human behavior. The Clinical Risk Management team are experts on the prediction, detection, and resolution of data quality issues that could compromise the reliability of clinical trials. During the start-up phase, they use their proficiency in protocol analysis and data review planning to support the team in the identification of potential risks to the trial. Once the study gets underway, they continuously review the data as it comes in to detect new issues as they arise. Through this adaptive approach, the CRM team reduces the time to detection for major issues and lowers the probability of losing critical trial data. The Clinical Data Risk Analysts are functional team leads within the Clinical Data Science group, charged with reviewing the study data as it comes in to identify data quality issues and assigning them to the appropriate member of the study team for resolution. Senior members of the team also act as SMEs for core RBQM topics such as Quality Tolerance Limits and Central Monitoring data platforms (JReview, ICONIK, Cluepoints, Medidata Studio…). Using high level knowledge of the protocol, identifies critical data and processes from protocol review, and supports protocol risk evaluation process. Applies in-depth knowledge of risk-based quality monitoring to guide study team through relevant processes Uses analytic platform to navigate through large volumes of data and identify issues Aggregates and summarizes data for study team Creates data visualizations to explain issues to sponsor Logs and assigns findings for data issues in the Clinical Trial Management System Your profile: Degree in Health Science, Computer Science, Engineering, Statistics, or equivalent 3-4 years of experience with Clinical Data Clinical Trial Experience Advanced English proficiency for speak/read/write Advanced Microsoft Excel skills Experience with relational databases: SQL Exp with clinical data systems: EDC / ePRO / CTMS / IVRS Experience with analytic programming languages: R, Python Experience with analytic software platforms: JReview, Tableau, Spotfire Data Visualization experience What ICON can offer you: Our success depends on the quality of our people. That’s why we’ve made it a priority to build a diverse culture that rewards high performance and nurtures talent. In addition to your competitive salary, ICON offers a range of additional benefits. Our benefits are designed to be competitive within each country and are focused on well-being and work life balance opportunities for you and your family. Our benefits examples include: Various annual leave entitlements A range of health insurance offerings to suit you and your family’s needs. Competitive retirement planning offerings to maximize savings and plan with confidence for the years ahead. Global Employee Assistance Programme, LifeWorks, offering 24-hour access to a global network of over 80,000 independent specialized professionals who are there to support you and your family’s well-being. Life assurance Flexible country-specific optional benefits, including childcare vouchers, bike purchase schemes, discounted gym memberships, subsidized travel passes, health assessments, among others. Visit our careers site to read more about the benefits ICON offers. ICON, including subsidiaries, is an equal opportunity and inclusive employer and is committed to providing a workplace free of discrimination and harassment. All qualified applicants will receive equal consideration for employment without regard to race, colour, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. If, because of a medical condition or disability, you need a reasonable accommodation for any part of the application process, or in order to perform the essential functions of a position, please let us know or submit a request here Interested in the role, but unsure if you meet all of the requirements? We would encourage you to apply regardless – there’s every chance you’re exactly what we’re looking for here at ICON whether it is for this or other roles. Are you a current ICON Employee? Please click here to apply",https://mx.linkedin.com/jobs/view/clinical-data-risk-analyst-at-icon-plc-4009429577,4009429577,"The Clinical Data Risk Analyst role requires an understanding of clinical research and proficiency in data analysis techniques. Successful candidates will be life sciences graduates with clinical research experience or STEM graduates with knowledge of human behavior. The role includes identifying data quality issues, supporting protocol risk evaluation, and using analytic platforms to navigate through large volumes of data.","SQL, R, Python, JReview, Tableau, Spotfire, EDC, ePRO, CTMS, IVRS, Microsoft Excel",3-4 years,,True,3.0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,1,0,0
Data Engineer,Babel,Mexico City Metropolitan Area,HYBRID,Entry level,Full-time,IT Services and IT Consulting,2024-09-18 07:38:47.568455,25,Information Technology,Consulting,,"We are One Team. We make it happen. We are Unstoppable. BABEL es una consultora tecnológica multinacional especializada en aplicar sus servicios y conocimiento tecnológico en los procesos de aceleración digital de sus clientes, grandes empresas y organismos públicos. ¿Cuál es nuestro plan estratégico? En Babel estamos entusiasmados con los progresos de nuestro Plan Marte 2025 . Queremos llegar a 300 millones de euros de facturación y conseguir un EBITDA de 36 millones con una plantilla de 5.000 babelievers en el mundo! El buen hacer y el compromiso del equipo esta dando sus frutos y nos encontramos en buena ruta para alcanzar estas metas, lo cual refleja la solidez y visión de nuestra organización. Mirando hacia el futuro, ya hemos diseñado el nuevo plan estratégico Hyperspace 2029 , un desafío aún mayor, que promete ser un viaje emocionante, lleno de oportunidades para crecer y desarrollarse profesionalmente. Alcanzar 1000 millones de facturación, un reto que estamos seguros de que con la colaboración y el talento de nuestra gente, será otra historia de éxito que escribiremos juntos. ¿Qué buscamos? Al menos 4 años de experiencia en las siguientes herramientas: Lenguajes de programación: JAVA /JavaScript / Python Manejador de Base de Datos: Oracle con conocimientos en desarrollo PL-SQL y fine tunning de Bases de Datos ETL: Python IDE de desarrollo: Eclipse, intelij, Gitlab Conocimientos Deseables: ETL: SSIS, ODI, SPARK, Informática, KAFKA Bases de Datos: SQL Server, DB2, Casandra, etc. Consideraciones de la posición: Asistencia a oficina: Dependiendo la necesidad de interacción con el resto del equipo. Máximo 3 veces a la semana Trabajo en fin de semana: Probablemente el primer mes en el proceso de estabilización del proceso en desarrollo. #babel ¿Qué ofrecemos? Babel, the great way to achieve the success. ¿Quieres formar parte de un equipo en expansión, comprometido e innovador que hace historia cada día? En Babel te acompañamos en tu camino hacia el éxito. Creemos en el talento de las personas y lo queremos potenciar ofreciéndote un gran entorno de trabajo basado en la colaboración y la solidaridad. Trabajar en Babel es mucho más que trabajar en una empresa, es unirse a un equipo de personas con una misión compartida y a un modelo de compañía centrado en valores. Además, Esquema 100% Nomina SGM Mayores, SGM Menores Apoyo de Home Office Beneficios corporativos superiores ¿Aceptas el desafío? ¡Te esperamos! En cumplimiento de la normativa vigente en materia de protección de datos, le informamos que el responsable de sus datos personales es GRUPO BABEL y los utilizará para la realización de procesos internos de selección de personal, basado en su consentimiento, mediante la facilitación de sus datos curriculares y en la aplicación de medidas precontractuales. Los datos podrán ser comunicados a las entidades que conforman el GRUPO BABEL con el fin ofrecerle el puesto de trabajo que se adapte a su perfil profesional y las establecidas legalmente. Puede acceder, rectificar y suprimir los datos, así como otros derechos que le asisten sobre protección de datos a través de data.protection@babelgroup.com. Podrá obtener información adicional, sobre protección de datos, dirigiéndose a nuestra política de privacidad.",https://mx.linkedin.com/jobs/view/data-engineer-at-babel-4026049088,4026049088,"We are looking for a professional with at least 4 years of experience in programming languages such as Java, JavaScript, and Python. The role involves working with Oracle database management with knowledge in PL-SQL development and database fine-tuning. Experience with ETL tools like Python and IDEs such as Eclipse, IntelliJ, and GitLab is required. Desirable knowledge includes ETL tools like SSIS, ODI, SPARK, Informatica, Kafka, as well as familiarity with databases like SQL Server, DB2, and Cassandra.","Java, JavaScript, Python, Oracle, PL-SQL, Eclipse, IntelliJ, GitLab, SSIS, ODI, SPARK, Informatica, Kafka, SQL Server, DB2, Cassandra",4,,True,4.0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,1,0,0
Data Analytics Engineer (SQL Focused) - MX,WITHIN,Mexico City Metropolitan Area,HYBRID,Entry level,Full-time,"Technology, Information and Internet",2024-09-18 07:38:47.568455,25,Information Technology,,,"About Us: WITHIN is the world's first Performance Branding company, partnering with some of the biggest brands in the world to drive business growth through innovative marketing strategies. Our integrated operating model collapses the traditional marketing silos between creative and media, performance and brand, and across media channels. With a full suite of offerings including media, creative, SEO, Lifecycle, Retail Media, Affiliate and Influencer, we're able to work with our brand partners in an integrated fashion, allowing us to align marketing strategies back to core business objectives. Client teams at WITHIN are trained on how to always act as a trusted business partner, acting as a fiduciary to client needs above our own. Teams at WITHIN have the ability to work with iconic brands such as The North Face, Timberland, Movado Watches and Jose Cuervo. Everyone at WITHIN wants to grow and be challenged. It's a collaborative place made up of small, closely knit and versatile teams that are fast and adaptive to solve problems and build systems. About the Role: We are seeking a motivated and experienced Data Analytics Engineer with 2-4 years of experience to join our dynamic and growing team. The ideal candidate will have a strong background in Python, SQL, data warehousing platforms such as Snowflake or Google BigQuery, ETL processes, API integrations, and dbt. Responsibilities include but are not limited to; Design, develop, and maintain scalable and robust ETL pipelines using Python, SQL, and other relevant technologies. Work with data warehousing platforms such as Snowflake or Google BigQuery to manage, optimize, and ensure data integrity and consistency. Utilize dbt for data modeling and transformation to support analytics and data science initiatives. Integrate various data sources, including third-party APIs, into our data ecosystem. Collaborate with data scientists, analysts, and other stakeholders to understand data needs and implement solutions. Monitor and ensure performance, uptime, and scalability of data systems and processes. Document, test, and maintain data workflows and codebase. Participate in code reviews, share knowledge, and mentor junior team members. Stay updated with the latest trends in data engineering and continuously seek opportunities to innovate and optimize current processes. Requirements: Bachelor's degree in Computer Science, Engineering, Business/Finance or a related field. 4-6 years of hands-on experience in data engineering, analytics, or a similar role. Proficiency in Python and SQL. Experience with data warehousing platforms such as Snowflake or Google BigQuery. Familiarity with cloud computing platforms such as AWS, Azure, or Google Cloud Platform. Solid understanding of ETL processes and tools (such as dbt). Familiarity with dbt for data modeling and transformation. Experience in integrating and working with APIs. Strong analytical and problem-solving skills. Effective communication skills, both written and verbal, with the ability to work in cross-functional teams. Strong attention to detail and a commitment to producing high-quality results. Preferred Requirements: Master's degree in a related field. Experience with data visualization tools like Tableau, Power BI or Sigma Computing. Knowledge of other programming languages or tools relevant to the field. Understanding of data science methodologies Our interview process includes, but is not limited to the following: Excel knowledge and Typing Test We offer a competitive salary and benefits based on ability level, including: Base salary DOE Unlimited vacation policy Monthly phone/internet and food stipend Health insurance coverage Professional Development Program Hybrid work (Mexico City)",https://mx.linkedin.com/jobs/view/data-analytics-engineer-sql-focused-mx-at-within-4026530599,4026530599,"We are seeking a motivated and experienced Data Analytics Engineer with 4-6 years of hands-on experience to join our dynamic and growing team. Responsibilities include designing, developing, and maintaining scalable ETL pipelines, managing data integrity using data warehousing platforms like Snowflake or Google BigQuery, utilizing dbt for data modeling, and integrating various data sources. Candidates should possess strong analytical skills, proficiency in Python and SQL, and be familiar with cloud computing platforms and ETL processes.","Python, SQL, Snowflake, Google BigQuery, ETL, API Integrations, dbt, AWS, Azure, Google Cloud Platform, Tableau, Power BI",4-6,Bachelor,True,4.0,0,0,1,1,0,0,1,0,1,1,0,0,0,0,1,0,0
Business Intelligence Analyst,"Solera Holdings, LLC.",Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-18 07:38:47.568455,25,Research,"Analyst,",Information Technology,"BI Analyst Job Summary: We are seeking a detail-oriented and analytical Business Intelligence (BI) Analyst to join our team. The BI Analyst will be responsible for transforming data into insights that drive business decisions. This role involves analyzing complex datasets, creating reports, developing dashboards, and supporting the quality audit process for Supply Chain and Product while working with a cross-functional team. The ideal candidate will have a strong understanding of data analysis, data visualization tools, AI and ML generative models, and the ability to translate business needs into technical requirements. Experience with integrating data from multiple sources via APIs, advanced reporting in Power BI, and working with Salesforce.com and AI/ML models is essential. Key Responsibilities: Data Integration: Connect and integrate data from multiple sources, including APIs and Salesforce.com, into a centralized data model in Power BI. Data Analysis: Collect, analyze, and interpret large datasets to provide actionable insights and recommendations to stakeholders. AI & ML Integration: Leverage AI and ML generative models to enhance data analysis and build predictive analytics capabilities. Experience with prompting language and integrating these models into BI tools is required. Reporting: Develop and maintain comprehensive reports and dashboards using Power BI, ensuring they reflect accurate and up-to-date data from various sources. Data Visualization: Design and implement advanced data visualizations in Power BI that clearly communicate insights to business users. Quality Audits: Participate in the quality audit process for Supply Chain and Product, using data analysis to support audit findings and recommendations. BI Tool Development: Utilize experience with Cognos, QlikView, Looker, Salesforce.com, and other BI tools to develop, enhance, and support BI solutions across different platforms. Database Management: Leverage strong knowledge of SQL, relational databases, data warehousing, and data modeling to manage and analyze data effectively. Advanced Excel Skills: Utilize advanced Excel functions, data analysis tools, and automation techniques to support data-driven decision-making. Collaboration: Work closely with cross-functional teams, including finance, marketing, operations, IT, and quality audit teams, to understand business requirements and provide data-driven solutions. Data Integrity: Ensure the accuracy, quality, and integrity of data by conducting regular audits and troubleshooting discrepancies. Build effective processes to identify inaccuracies. Trend Analysis: Identify trends, patterns, and anomalies in data that can inform strategic decision-making. Process Improvement: Propose and implement improvements to existing BI processes, including data collection methods and analysis techniques. Documentation: Maintain clear and organized documentation of data models, methodologies, and processes. Qualifications: Education: MBA a plus, with a focus on Data Science, Business Analytics, Information Systems, or a related field. Experience: 3+ years of experience in business intelligence, data analysis, or a similar role. Proficiency in BI tools (e.g., Power BI, Cognos, QlikView, Looker, Salesforce.com). Advanced experience in integrating data from multiple sources via APIs. Strong proficiency in SQL and relational database management. Experience with data warehousing platforms such as Snowflake, Amazon Redshift, Google BigQuery, or Microsoft Azure Synapse Analytics. Experience with AI and ML generative models, including prompt engineering and integrating these models with BI tools. Advanced Excel skills, including data analysis, Power Query, and automation techniques. Reporting Skills: Proven ability to generate advanced BI reports in Power BI, connecting and compiling data from various sources. Analytical Skills: Strong analytical and problem-solving abilities with a keen eye for detail. Communication Skills: Excellent verbal and written communication skills, with the ability to present complex data in a clear and concise manner. Time Management: Ability to manage multiple tasks and prioritize effectively in a fast-paced environment. Attention to Detail: High level of accuracy and attention to detail in work products. Business Acumen: Understanding of business processes and how data analysis can impact decision-making.",https://mx.linkedin.com/jobs/view/business-intelligence-analyst-at-solera-holdings-llc-4026073464,4026073464,"We are seeking a detail-oriented and analytical Business Intelligence (BI) Analyst to transform data into insights that drive business decisions. This role involves analyzing complex datasets, creating reports, developing dashboards, and supporting the quality audit process for Supply Chain and Product while working with a cross-functional team. The ideal candidate will have a strong understanding of data analysis, data visualization tools, AI and ML generative models, and the ability to translate business needs into technical requirements.","Power BI, SQL, APIs, Salesforce.com, Cognos, QlikView, Looker, Snowflake, Amazon Redshift, Google BigQuery, Microsoft Azure Synapse Analytics, Excel, AI, ML",3+,,True,3.0,0,0,1,1,0,0,0,0,1,1,0,0,0,0,0,0,0
"Manager, Machine Learning",myGwork - LGBTQ+ Business Community,Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,Pharmaceutical Manufacturing,2024-09-18 07:39:20.647086,25,Engineering,Information Technology,,"This job is with Pfizer, an inclusive employer and a member of myGwork – the largest global platform for the LGBTQ+ business community. Please do not contact the recruiter directly. Role Summary Do you want to make an impact on patient health around the world? Do you thrive in a fast-paced environment that brings together scientific and clinical domains together through data and analytics? Then join Pfizer Digital's AI & Data Analytics (AIDA) organization where you can leverage cutting-edge technology including AI and ML to inform critical business decisions and improve customer experiences for our patients and physicians. Our collection of global teams drives insights to action for some of the most critical business questions for the company. Our analytics professionals are based in over 30 countries around the world and come from diverse backgrounds including: software engineering, data science, digital analytics, finance, investment banking, corporate development, and consulting. Join one of our teams and be at the forefront of Pfizer's digital transformation, driving innovation and bringing advance analytics to change patients' lives. As an AI/ML Engineer, you will be part of a team to develop new capabilities that leverages AI to solve complex problems across the enterprise. In this role, you will be responsible for overseeing the design, implementation, and deployment of AI and machine learning models and algorithms, ensuring their accuracy, scalability, and effectiveness. The ideal candidate will have a strong technical background in machine learning and/or software engineering and a passion for innovation, bridging the gap between data, technology, and people, to deliver the promise of AI/ML to improve patients' lives. Role Responsibilities Design, develop and deploy machine learning products & approaches to solve business problems across multiple domains, including commercial, medical affairs, and R&D. Engage with stakeholders across the enterprise to understand and solve complex problems through AI/ML (including generative AI methods where appropriate) to inform business strategy and decisions Design and execute advanced analytics and predictive modeling projects using rigorous statistical methods and machine learning techniques Design, develop, deploy and maintain reusable assets and custom pipelines to optimize operational efficiencies in analytics execution Research, identify, and apply new algorithms and technologies to solve complex problems and systematize solutions into reusable assets and capabilities Practice Agile-based project management standards (i.e. daily check-in procedures, workload status, and cost overruns/projections) Identify emerging technologies, evaluate their potential impact, and make informed decisions on adopting new tools, frameworks, and methodologies. Basic Qualifications Proven experience (5+ years) as a software engineer, ML engineer, or data scientist and project lead for a diverse range of projects, with a focus on developing and deploying production-grade solutions. Bachelor's degree in STEM (Science, Technology, Engineering, Mathematics) majors with quantitative emphasis - Statistics, Computer Science, Economics, Engineering etc. Strong programming skills in languages such as Python, Java, or C++, and proficiency with AI and machine learning frameworks and libraries (e.g., TensorFlow, PyTorch, scikit-learn). Applied knowledge of statistical analysis, experience with R, Excel, etc. Strong background in computer science: algorithms, data structures, machine learning, and distributed systems. Superior analytical skills required; Strong verbal and written communication skills Demonstrated experience interfacing with other internal and external teams to incorporate their innovations and vice versa Preferred Qualifications Advanced understanding of machine learning algorithms, deep learning architectures, and statistical techniques. Experience with foundation models, LLMs, and generative AI. Proficiency in data preprocessing, feature engineering, and dimensionality reduction. Familiarity with software engineering principles (e.g. version control, testing, and deployment) Experience with cloud platforms (e.g., AWS, Azure, GCP) and distributed computing frameworks is a plus. A passion for staying up-to-date with the latest advancements in AI and machine learning technologies and a commitment to continuous learning. Experience working in Agile processes and practices. EEO (Equal Employment Opportunity) & Employment Eligibility Pfizer is committed to equal opportunity in the terms and conditions of employment for all employees and job applicants without regard to race, color, religion, sex, sexual orientation, age, gender identity or gender expression, national origin, or disability. Information & Business Tech",https://mx.linkedin.com/jobs/view/manager-machine-learning-at-mygwork-lgbtq%2B-business-community-4025785533,4025785533,"The AI/ML Engineer will develop new capabilities leveraging AI to solve complex problems across the enterprise. Responsibilities include designing, implementing, and deploying AI and machine learning models, engaging with stakeholders to solve complex issues, executing advanced analytics and predictive modeling projects, and identifying emerging technologies. The role requires a strong technical background in machine learning and software engineering, with a focus on improving patient health through technology.","Python, Java, C++, TensorFlow, PyTorch, scikit-learn, R, Excel, AWS, Azure, GCP",5+ years,Bachelor,True,5.0,0,0,0,1,0,0,0,0,1,0,0,0,1,0,1,0,0
"Business Intelligence Engineer, Supply Chain Data Science",Amazon,Mexico City Metropolitan Area,ON-SITE,,Full-time,Software Development,2024-09-18 07:39:20.647086,25,Business Development,Sales,,"Description Are you a data enthusiast? Does the world’s most complex logistic systems inspire your curiosity? Is your passion to navigate through hundreds of systems, processes, and data sources to solve the puzzles and identify the next big opportunity? Are you a creative big thinker who is passionate about using data and optimization tools to direct decision making and solve complex and large-scale challenges? Do you feel like your skills uniquely qualify you to bridge communication between teams with competing priorities? If so, then this position is for you! We are looking for a motivated individual with strong analytic and communication skills to join the effort in evolving the network we have today into the network we need tomorrow. Amazon’s extensive logistics system is comprised of thousands of fixed infrastructure nodes, with millions of possible connections between them. Billions of packages flow through this network on a yearly basis, making the impact of optimal improvements unparalleled. This magnificent challenge is a terrific opportunity to analyze Amazon’s data and generate actionable recommendations using optimization and simulation. Come build with us! This role will collaborate with diverse set of stakeholder including product managers, program managers, data scientists, software development engineers and other partner teams to analyze large data sets, prove and disprove hypothesis, automate existing solutions and build self-service dashboards and reports. Key job responsibilities Design and creation of data pipelines reporting and automation using Quicksight tableu or similar. Experience working with AWS resources and data base maintainance (Redshift, Dynamo) Write high quality SQL code to retrieve and analyze data from database tables, and learn and understand a broad range of Amazon’s data resources and know how, when, and which to use and which not to use. Develop queries and visualizations for ad-hoc requests and projects, as well as ongoing reporting. Basic Qualifications 2+ years of analyzing and interpreting data with Redshift, Oracle, NoSQL etc. experience Experience with data visualization using Tableau, Quicksight, or similar tools Experience with one or more industry analytics visualization tools (e.g. Excel, Tableau, QuickSight, MicroStrategy, PowerBI) and statistical methods (e.g. t-test, Chi-squared) Bachelor's degree +3years of experience in data analysis with Python Fluent in Spanish and English (b2+) Preferred Qualifications Knowledge of data modeling and data pipeline design Experience with statistical analysis, co-relation analysis Company - Servicios Comerciales Amazon Mexico S. de R.L. de C.V. Job ID: A2777944",https://mx.linkedin.com/jobs/view/business-intelligence-engineer-supply-chain-data-science-at-amazon-4029113394,4029113394,"We are looking for a motivated individual with strong analytic and communication skills to analyze Amazon’s data and generate actionable recommendations using optimization and simulation. This role collaborates with a diverse set of stakeholders to analyze large data sets, automate existing solutions, and build self-service dashboards and reports. Responsibilities include designing data pipelines, reporting, and automation using tools like Quicksight and Tableau, and working with AWS resources and database maintenance.","AWS, Redshift, DynamoDB, SQL, Python, Tableau, Quicksight, Excel, MicroStrategy, PowerBI",2+,Bachelor,True,2.0,0,0,0,1,0,0,0,0,1,1,0,0,0,0,1,0,0
"Business Intelligence Engineer, Supply Chain Data Science",myGwork - LGBTQ+ Business Community,Mexico City Metropolitan Area,ON-SITE,Entry level,Full-time,"Technology, Information and Internet",2024-09-18 07:39:20.647086,25,Business Development,Sales,,"This job is with Amazon, an inclusive employer and a member of myGwork – the largest global platform for the LGBTQ+ business community. Please do not contact the recruiter directly. Description Are you a data enthusiast? Does the world's most complex logistic systems inspire your curiosity? Is your passion to navigate through hundreds of systems, processes, and data sources to solve the puzzles and identify the next big opportunity? Are you a creative big thinker who is passionate about using data and optimization tools to direct decision making and solve complex and large-scale challenges? Do you feel like your skills uniquely qualify you to bridge communication between teams with competing priorities? If so, then this position is for you! We are looking for a motivated individual with strong analytic and communication skills to join the effort in evolving the network we have today into the network we need tomorrow. Amazon's extensive logistics system is comprised of thousands of fixed infrastructure nodes, with millions of possible connections between them. Billions of packages flow through this network on a yearly basis, making the impact of optimal improvements unparalleled. This magnificent challenge is a terrific opportunity to analyze Amazon's data and generate actionable recommendations using optimization and simulation. Come build with us! This role will collaborate with diverse set of stakeholder including product managers, program managers, data scientists, software development engineers and other partner teams to analyze large data sets, prove and disprove hypothesis, automate existing solutions and build self-service dashboards and reports. Key job responsibilities Design and creation of data pipelines reporting and automation using Quicksight tableu or similar. Experience working with AWS resources and data base maintainance (Redshift, Dynamo) Write high quality SQL code to retrieve and analyze data from database tables, and learn and understand a broad range of Amazon's data resources and know how, when, and which to use and which not to use. Develop queries and visualizations for ad-hoc requests and projects, as well as ongoing reporting. Basic Qualifications 2+ years of analyzing and interpreting data with Redshift, Oracle, NoSQL etc. experience Experience with data visualization using Tableau, Quicksight, or similar tools Experience with one or more industry analytics visualization tools (e.g. Excel, Tableau, QuickSight, MicroStrategy, PowerBI) and statistical methods (e.g. t-test, Chi-squared) Bachelor's degree +3years of experience in data analysis with Python Fluent in Spanish and English (b2+) Preferred Qualifications Knowledge of data modeling and data pipeline design Experience with statistical analysis, co-relation analysis",https://mx.linkedin.com/jobs/view/business-intelligence-engineer-supply-chain-data-science-at-mygwork-lgbtq%2B-business-community-4027166391,4027166391,"We are looking for a motivated individual with strong analytic and communication skills to analyze Amazon's data and generate actionable recommendations using optimization and simulation. This role will collaborate with a diverse set of stakeholders including product managers, program managers, data scientists, and software development engineers to analyze large data sets, automate existing solutions, and build self-service dashboards and reports. The key responsibilities include designing and creating data pipelines, reporting, and automation, as well as writing high-quality SQL code to retrieve and analyze data. Basic qualifications include 2+ years of experience in data analysis with tools like Redshift and Oracle, experience with data visualization using Tableau or similar tools, and a Bachelor's degree with 3 years of experience in data analysis with Python.","SQL, Python, Redshift, Oracle, NoSQL, Tableau, Quicksight, AWS, Excel, Statistical Methods",2+,Bachelor,True,2.0,0,0,0,1,0,1,0,0,1,1,0,0,0,0,1,0,0
BI Developer II,Rackspace Technology,Mexico City Metropolitan Area,REMOTE,,Full-time,IT Services and IT Consulting,2024-09-19 02:12:36.301861,25,Information Technology,,,"We are looking for a BI Developer II with experience in developing and maintaining a business intelligence framework. **Must be fluent in English Responsibilities Works with business requirement team, analysts, and developers to ensure stakeholder requirements are addressed through integration solutions in a manner that aligns with timelines, budgets, and quality expectations Leads the design and development of the Business Intelligence (BI) architecture and continually refines the BI strategy to align with corporate direction Serves as the subject matter expert in the extraction of information from EFD, Star, and Snowflake schemas Builds operational and ad-hoc reports Builds reports that take advantage of OLAP/Dimensional Modeling capabilities Build executive dashboards and corporate scorecards Works with customers to define their requirements and create information delivery solutions that meet their needs utilizing “best practices.” Develops and implements data integration strategy and associated policies as it pertains to lean integration practices Participates in design and development reviews Works with system owners to resolve data transformation issues and to refine transformation Writes software in an open-source setting (number of branches merged) Writes design documents Reviews proposed software branches (number of reviews) Reviews design documents (number of reviews) Participates in project discussions (number of emails etc.) Qualifications Strong skills in Excel and T-SQL recommended Comfort using Qlikview is desirable Advanced level of competence with database structures and design as well as possessing strong SQL development skills with the ability to build reporting tables, stored procedures, and Chron Jobs Basic understanding of relational and columnar database platforms such as MSSQL, My SQL, Oracle, Postgresql, and Cassandra. Working knowledge of CORE and Salesforce Advanced QV skills such as set analysis, variables, actions, triggers, and QVD building Business analysis skills to allow for the creation of report definitions and specifications Basic proficiency in one or more of the following tools: MS Access, .Net, ASP, VB, MongoDB, Hadoop, etc Ability to communicate technical information and ideas so that others will understand Must be able to make appropriate decisions considering the relative costs and benefits of potential actions Must successfully work and promote inclusiveness in small groups Excellent communication skills, both oral and written Ability to develop work plans and follow through on assignments with minimal guidance Ability to work with business and system owners to obtain requirements and manage expectations Requires a Bachelor's degree in Computer Science, MIS, or Business Administration Discover your inner Racker: Racker Life - Fluent, Bi-lingual (Spanish and English) - Role can work remotely in the states of Ciudad de Mexico, Jalisco, Nuevo Leon, Aguascalientes, Queretaro, Estado de Mexico and Puebla - This opportunity is a permanent remote job, but you need to be based in Mexico at one of the above locations. About Rackspace Technology We are the multicloud solutions experts. We combine our expertise with the world’s leading technologies — across applications, data and security — to deliver end-to-end solutions. We have a proven record of advising customers based on their business challenges, designing solutions that scale, building and managing those solutions, and optimizing returns into the future. Named a best place to work, year after year according to Fortune, Forbes and Glassdoor, we attract and develop world-class talent. Join us on our mission to embrace technology, empower customers and deliver the future. More on Rackspace Technology Though we’re all different, Rackers thrive through our connection to a central goal: to be a valued member of a winning team on an inspiring mission. We bring our whole selves to work every day. And we embrace the notion that unique perspectives fuel innovation and enable us to best serve our customers and communities around the globe. We welcome you to apply today and want you to know that we are committed to offering equal employment opportunity without regard to age, color, disability, gender reassignment or identity or expression, genetic information, marital or civil partner status, pregnancy or maternity status, military or veteran status, nationality, ethnic or national origin, race, religion or belief, sexual orientation, or any legally protected characteristic. If you have a disability or special need that requires accommodation, please let us know.",https://mx.linkedin.com/jobs/view/bi-developer-ii-at-rackspace-technology-4027883226,4027883226,"We are looking for a BI Developer II with experience in developing and maintaining a business intelligence framework. Responsibilities include working with business requirement teams to ensure stakeholder requirements are met through integration solutions, leading the design and development of BI architecture, serving as a subject matter expert in data extraction from various schemas, building operational and ad-hoc reports, and creating dashboards. Requires strong skills in Excel and T-SQL, comfort with Qlikview, advanced database design skills, and a bachelor's degree in Computer Science, MIS, or Business Administration. Fluent in English is required.","Excel, T-SQL, Qlikview, MSSQL, MySQL, Oracle, PostgreSQL, Cassandra, .Net, ASP, VB, MongoDB, Hadoop",,Bachelor,True,,0,0,1,0,0,0,0,0,1,1,0,0,0,0,0,0,0
Data Engineer,Accenture México,Mexico City Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Business Consulting and Services,2024-09-19 02:12:36.301861,50,Information Technology,,,"¡ATRÉVETE A SER PARTE DEL DESAFÍO! ¡VEN Y ÚNETE A NUESTRO EQUIPO JUNTOS PODEMOS MARCAR LA DIFERENCIA! ¿Sabías que Accenture está liderando la transformación digital en el mundo? Accenture es una empresa líder mundial de servicios profesionales, que ofrece una amplia gama de servicios y soluciones en estrategia, consultoría, digital, tecnología y operaciones. Nuestro principal propósito es colaborar con nuestros clientes, para que puedan convertirse en negocios de alto rendimiento. Accenture está presente en más de 200 oficinas, 120 ciudades, 56 países y aproximadamente 390.000 empleados en todo el mundo. Oferta Desarrollo profesional de acuerdo a tu perfil e intereses. Trabaja en una de las mejores empresas. Uso de metodologías y herramientas innovadoras. Contacto directo con expertos de todo el mundo. Capacitaciones constantes. Ambiente de trabajo en equipo y colaboración. Participación en Proyectos Internacionales. Descripción del Rol Al menos 3 años de experiencia como Ingeniero de Datos Nube Azure en general y un énfasis en particular con Databricks. ﻿﻿﻿Capacidad de transformar datos en módulos y vistas del lago de datos basados en el framework Delta (DataLakeHouse). ﻿﻿﻿Entendimiento de ingeniería de datos basado en Spark. ﻿﻿﻿Excelente manejo de lenguajes como Python y SQL. Experiencia en la diseño, creación, desarrollo de eventos y manejo de plataformas de streaming de datos Accenture no discrimina por motivos de raza, religión, color, sexo, edad, discapacidad, nacionalidad, orientación sexual, identidad o expresión de género, ni por ninguna otra razón cubierta por la legislación local.",https://mx.linkedin.com/jobs/view/data-engineer-at-accenture-m%C3%A9xico-4007620203,4007620203,"At least 3 years of experience as a Cloud Data Engineer with a focus on Databricks. Ability to transform data into modules and views of the data lake based on the Delta framework (DataLakeHouse). Understanding of data engineering based on Spark. Excellent knowledge of languages such as Python and SQL. Experience in designing, creating, developing events, and managing data streaming platforms.","Azure, Databricks, Spark, Python, SQL, DataLakeHouse",3,,True,3.0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0
Data Engineer ETL Pentaho Spark,Reclutamiento It,Mexico City Metropolitan Area,REMOTE,Associate,Full-time,"Transportation, Logistics, Supply Chain and Storage",2024-09-19 02:12:36.301861,25,Information Technology,Engineering,,"Esta vacante viene de la bolsa de empleo Talenteca.com Vacante para la empresa Reclutamiento IT en Nezahualcóyotl, Estado de México ¿Quiénes somos? Somos una empresa Mexicana especialista en logística y mensajería, tenemos presencia a nivel nacional, latam y EEUU; hemos tenido un crecimiento exponencial y sabemos que la tecnología es parte esencia para ser líderes, por ello, buscamos para nuestras oficinas en CDMX un Ingeniero de Datos Desarrollador ETL con experiencia en diversas plataformas como ETL Pentaho, Cloudera, Spark y apego a buenas prácticas. Con nosotros tendrás la oportunidad de: Proponer, desarrollar y administrar proyectos de análisis y explotación de datos a nivel global. Libertad operativa, innovación y apertura total para ideas disruptivas y únicas, pensar fuera de la caja, para hacer una diferencia. Oportunidad de desarrollo real y estabilidad personal y profesional- Integración con equipos multiculturales en EEUU y Latam. Relacionamiento con proveedores globales. ¿Por qué nosotros? Nos Centramos En Las Personas, La Calidad y Balance De Vida Es Importante Para Nosotros; Contamos Con Programas De Desarrollo, Formación, Dinámicas De Integración, Muy Buen Ambiente De Trabajo y Retos Para Llevar Tu Potencial Al Máximo, Nuestra Propuesta Incluye Ingreso: de 42,000 a 45,000 pesos brutos (nominal directo con nosotros) paquete de beneficios ley, vales, caja y fondo de ahorro, seguro de vida, bonos, 30 días de aguinaldo. Horario: de lunes a viernes de 8:30 a 6:00 p.m. Esquema Híbrido Zona de trabajo: Hipódromo Condesa, Cuauhtémoc (5 minutos del Metro Juan Acatlán Línea 1 Rosa). ¿Qué buscamos? 2 a 3 años de experiencia como: ETL Developer, analista ETL, Programador ETL, Ingeniero ETL, Data engineer ETL, Ingeniero de datos ETL, Ingeniero de datos, especialista de datos. Adecuado conocimiento en análisis de requerimientos, amplio análisis de fuentes de Información, métricas y reglas de negocio. Estimación de esfuerzo y planificación de tareas. 2 a 3 años en desarrollo de ETL con Pentaho, Cloudera o Spark, con apego a buenas prácticas o nociones en gobierno y modelado de datos con framework DAMA. Apego a referencias de DMBOK. Experiencia práctica operativa en proyectos de integración con SAP o SAP HANA en los módulos de BW, BO, BI. Experiencia en gestión de Bases de Datos SQL (MySQL, SQL Server, Oracle) y NoSQL (Mongo, Cassandra, Dynamo) Stored Procedures, Joins, CTEs). Gestión y Modelado de Datos (creación, lectura y conceptos de DWH). Manejo de alguna plataforma de visualización BI como Power BI, Tableau, Qilk View, SAS, etc. Conocimiento básico en al menos un servicio en la nube (GCP, AWS o Azure). Muy deseable experiencia en sector logístico. Nivel De Educación Deseada Superior - trunco Nivel De Experiencia Deseada Nivel Medio Función Departamental Tecnología / Internet Industria Transporte, Logística, Cadena de Suministro y Almacenamiento Habilidades ETL Pentaho DAMA Cloudera Spark Esta Vacante Viene De La Bolsa De Empleo Talenteca.com https://www.talenteca.com/anuncio?j_id=66eb2c0e2900004b0005d652&source=linkedin",https://mx.linkedin.com/jobs/view/data-engineer-etl-pentaho-spark-at-reclutamiento-it-4029706959,4029706959,"This position seeks a Data Engineer ETL with experience in various platforms such as Pentaho ETL, Cloudera, Spark, and adherence to best practices. The role involves proposing, developing, and managing data analysis and exploitation projects globally, with operational freedom, innovation, and openness to unique disruptive ideas. The candidate should have adequate knowledge in requirement analysis, extensive analysis of information sources, metrics, and business rules, along with experience in ETL development with Pentaho, Cloudera, or Spark, and touchpoints with data governance and modeling frameworks like DAMA.","ETL Pentaho, Cloudera, Spark, SAP, SAP HANA, MySQL, SQL Server, Oracle, MongoDB, Cassandra, DynamoDB, Power BI, Tableau, QlikView, SAS, GCP, AWS, Azure",2 to 3,,False,2.0,0,0,1,1,0,0,1,0,1,1,0,0,0,0,0,0,0
Machine Learning Engineer,"Bluetab América, an IBM Company",Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-19 02:13:20.504903,25,Information Technology,Engineering,,"En Bluetab, seguimos en crecimiento y estamos en busca de personas como tú, que comparten nuestra pasión por la tecnología. Nos destacamos por ser diferentes a la consultoría tradicional. Aquí, creemos en contratarte para formar parte de nuestra familia. Valoramos la colaboración, el trabajo en equipo y el aprendizaje constante. Para nosotros, cada miembro es esencial, no sólo un número en una lista. Somos un equipo unido y horizontal, y queremos que así siga siendo. Recuerda, ningún marinero se convirtió en experto en aguas tranquilas. Sí, somos exigentes, pero nuestros desafíos también lo son. Aquí te desarrollarás junto a auténticos expertos, en entornos innovadores y siempre a la vanguardia de la tecnología. Valoramos el talento y nos preocupamos por las personas que, además de ser talentosas, son buenas personas. Si te apasiona el trabajo en equipo, disfrutas aprendiendo y te interesa la innovación, ¡estamos ansiosos por conocerte! Buscamos a un Machine Learning Engineer analítico, proactivo, buena comunicación y adquirir conocimiento de negocio. Habilidades avanzadas de programación en : Python y conocimiento de bibliotecas de ML, como: TensorFlow, PyTorch, Scikit-Learn, etc. SQL ETL (preferentemente DataIku) - Herramientas de flujos analíticos (Alteryx, tableau prep, data fusion, etc) Administración de bases de datos Conexiones ODBC – JDBC Spark. Deseable : Clientes de base de datos (dbeaver, mysql, sqlmanager, etc) Conocimiento en computación en la nube • Hive Experiencia sólida en desarrollo de software y operaciones de ML, con énfasis en MLOps. Responsabilidades: Desarrollar y mantener pipelines de ML altamente automatizados para entrenamiento, validación e implementación de modelos a gran escala. Colaborar estrechamente con los equipos de ingeniería de software para integrar flujos de trabajo de ML en el ciclo de desarrollo de software, aplicando prácticas de DevOps y MLOps. Implementar y gestionar infraestructura de computación distribuida y herramientas de orquestación para soportar flujos de trabajo de ML en entornos de producción. • Desarrollar métricas y herramientas de monitoreo para evaluar el rendimiento y la calidad de los modelos en producción. Automatizar tareas de mantenimiento y monitoreo para garantizar la estabilidad y confiabilidad continua de los sistemas de ML. Identificar las diferentes necesidades de datos e información (Fuentes, Catálogos, Indicadores, Dimensiones), atendiendo a los procesos y fuentes actuales de negocio así como los disponibles dentro de la arquitectura de Data Analytics, mismos que faciliten el dimensionamiento y propuesta de atención del producto. Proponer estrategias de integración de datos a productos/herramientas considerando a las necesidades de negocio para robustecer el valor de los entregables Identificar y proponer mediante la documentación generada, áreas de mejora dentro de la integración de datos con el objetivo de proponer soluciones más eficientes en la transformación de datos. Conocer el significado e interpretación de los datos, y plasmar dicho entendimiento en los documentos entregados que se recogen de los distintos proyectos de integración de Data Analytics con el objetivo de generar insights valiosos para la toma de decisiones que impulse la consistencia de la información a través de los productos. Tu comodidad nos importa. Los /bluetabers trabajamos en un entorno confortable, sin dress-code (A reserva del cliente), agradable y con proyección de carrera. Eso se traduce en: Contrato indefinido con un salario competitivo. El salario se relaciona en función de los conocimientos técnicos detectados en el proceso y rol asignado, procurando respetar el sentido de equidad y siendo susceptible de mejora tras las evaluaciones continuas de desempeño. Formación continua. Plan de carrera individual definido ya sea técnico, funcional o gestión (¡Decide tu camino pero sigue formándote!) Tendrás un Career Coach para que te guíe en tu desarrollo profesional. Beneficios sociales más allá de tu salario: Seguro de gastos médicos menores y de mayores familiar, seguro de vida. Vales de despensa. Vacaciones superiores a la ley. Bolsa de capacitación Días de descanso adicionales a la ley. ¿Qué esperas para sumarte a Bluetab, an IBM Company? En /b promovemos la diversidad de género, origen étnico, nacionalidad, la inclusión de personas con discapacidad y/o habilidades diferentes mediante la igualdad de oportunidades en todos los procesos, y buscamos ampliar las oportunidades de desarrollo profesional.",https://mx.linkedin.com/jobs/view/machine-learning-engineer-at-bluetab-am%C3%A9rica-an-ibm-company-4029462734,4029462734,"At Bluetab, we are looking for an analytical and proactive Machine Learning Engineer with good communication skills and a keen interest in business knowledge. The position requires advanced programming skills in Python and familiarity with ML libraries such as TensorFlow, PyTorch, and Scikit-Learn. Experience with SQL ETL (preferably DataIku), analytical tools (Alteryx, Tableau Prep, Data Fusion), database management, ODBC, JDBC, and Spark is necessary. A solid background in software development and ML operations, especially MLOps, is essential. Responsibilities include developing and maintaining highly automated ML pipelines for training, validation, and deployment of large-scale models, collaborating with software engineering teams, implementing and managing distributed computing infrastructure, developing monitoring metrics for model performance, and identifying data integration strategies to meet business needs.","Python, TensorFlow, PyTorch, Scikit-Learn, SQL, DataIku, Alteryx, Tableau Prep, Data Fusion, ODBC, JDBC, Spark, MLOps",,,True,,0,0,1,0,0,0,0,0,1,1,0,0,1,0,1,0,0
Sr AI Engineer,Aspen Technology,Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Full-time,Software Development,2024-09-19 02:13:20.504903,25,Engineering,Information Technology,,"The driving force behind our success has always been the people of AspenTech. What drives us, is our aspiration, our desire and ambition to keep pushing the envelope, overcoming any hurdle, challenging the status quo to continually find a better way. You will experience these qualities of passion, pride and aspiration in many ways — from a rich set of career development programs to support of community service projects to social events that foster fun and relationship building across our global community. The Role As a Senior Data Scientist in our rapidly growing Technology Group, you will provide technical leadership in developing innovative solutions for the next generation of AspenTech’s Digital Grid Management solutions. We are looking for sharp, disciplined, and highly quantitative individuals who have a passion for playing with complex data and cutting-edge technologies, in all its forms, including data mining, mathematical modeling, cognitive computing and expert systems. You will leverage your skills and passion for Machine Learning, AI and Cognitive Computing to drive AspenTech’s Digital Grid Management suite by developing ground-breaking software. Your Impact Collaborate with data scientists, engineers, and software developers to develop new machine learning applications for the Energy industry in the intersection of AI and Power Systems. Collaborate with customers, product managers and technical staff to develop technology strategies to promote continuous innovation in our Digital Grid Management offerings. Investigate new and developing technologies as they appear in industry and academia and determine how to leverage these new technologies into our software applications. What You'll Need Master’s degree in Computer Science, Electrical Engineering, Engineering with Power Systems Emphasis, or a related major; PhD preferred. 5+ years of experience in data science and software development in the Power System domain. Track record of experience in Python programming, including data science specific packages, such as Pandas, Numpy, TensorFlow, PyTorch, Scikit-Learn etc. Demonstrated experience with machine learning algorithms (regression, semi-supervised learning, deep learning, reinforcement learning, time series analysis, predictive modeling, cognitive computing). Strong expertise required in one of these areas: Generation, Transmission, Distribution, Distributed Energy Resource, SCADA, Contingency Analysis, Power System Optimization. Familiarity with modelling in simulation software eg. PSS/E, PSCAD, PowerFactory, Matlab/Simulink or equivalent and analyzing results. Experience with LLM, generative AI, MLops, Graph Knowledge, and/or cloud technologies is a plus. History of publishing research and results in the ML and Power System field. Participated in the design, development, evaluation, and deployment of scalable data-driven models and analytical solutions for machine learning application. Problem-solving ability and attention to details. Demonstrated ability to use scientific research to deliver value to customers and are motivated to deliver results in a fast-paced environment. Excellent interpersonal, communication, writing, and presentation skills. Demonstrated ability to convey complex information in a clear and concise manner.",https://mx.linkedin.com/jobs/view/sr-ai-engineer-at-aspen-technology-4027434082,4027434082,"As a Senior Data Scientist, you will provide technical leadership in developing innovative solutions for AspenTech’s Digital Grid Management. You will work with complex data and cutting-edge technologies, leveraging skills in Machine Learning, AI, and Cognitive Computing to drive groundbreaking software development. Collaborate with data scientists, engineers, and software developers to create new machine learning applications for the Energy industry, and investigate new technologies to enhance software offerings.","Python, Pandas, Numpy, TensorFlow, PyTorch, Scikit-Learn, PSS/E, PSCAD, PowerFactory, Matlab/Simulink, LLM, MLOps, Cloud Technologies",5+ years,Masters,True,5.0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0
Azure Data Engineer Lead,KI people,Mexico City Metropolitan Area,HYBRID,Mid-Senior level,Full-time,Human Resources Services,2024-09-19 02:13:20.504903,25,,,,"We are looking for a Azure Data Engineer Lead to work on hybrid mode in Mexico City, for a multicultural project with stability and growth in the short, medium and long term. Technical Delivery Skills: Leads meetings with clients to understand business needs. Use business, industry, and technology strategies to map customer requirements to the adoption and optimization of Microsoft technology solutions. Involves other members of the Microsoft team appropriately to understand and define customer requirements. Participates in project planning and develops project documents identifying risks and dependencies. Communicates the business value of planned solutions to the customer. Identifies technical and business risks in programs and proposes mitigations and contingency strategies. Helps project managers and architects prepare for steering committee meetings (for example, developing artifacts, architecture diagrams, and implementation plans or timelines). Manages your agenda and directs communication with project leaders on the client side and with Architects and Project Managers. Generates and delivers Work Breakdown Structure (WBS). Implements solutions designed with the Project Architect and may provide oversight and leadership on workflows to and from all collaborators within the project while adhering to Microsoft Services delivery processes. Aligns solution development and implementation strategies with Microsoft reference architectures for Cloud solutions and validated with the Project Architect, also using reference frameworks, methodologies, patterns and practices for safe and quality development in code and continuous improvement. Proactively manages escalations, analyzes situations and coordinates appropriate resources to resolve issues by following delivery practices, considering cost implications and engaging in discussions with all parties involved in the project both internal and external, e.g., Delivery to Operation, Technical Support, project manager, solutions architect, product group, etc. Proactively manages relationships with clients and all project collaborators at the executive level to identify and contribute to improving satisfaction conditions and reduce or eliminate dissatisfaction conditions, determine the root cause, and establish recovery actions to improve the experience. Work with every Microsoft team to ensure the One Microsoft approach. Share lessons learned with work groups and with the entire community of architects and consultants. Required/Minimum Qualifications: 5 years of experience in leading projects implementing technological solutions in a business environment. Bachelor’s degree in computer science, Engineering, Finance, Business or related field AND 3+ years of leadership experience in the following functional areas: Database administration (preferably with SQL databases like PostgreSQL, SQL Server, Azure SQL): performance tuning, troubleshooting, high availability/disaster recovery, security. Database development (preferably with PostgreSQL, SQL Server, Azure SQL): design and build database solutions (tables/stored procedures/forms/queries/etc.). Business Intelligence: Combines knowledge of Azure Data Factory, Azure Analysis Services, and Power BI technologies with a deep understanding of data structure/data models to design, develop, and tune BI solutions and reports. Advanced Analytics: Design and build solutions using technologies such as Azure Data Factory, Azure Data Lake Store, Azure HD Insights (Hadoop Hive, Hadoop Map Reduce, Hadoop Clusters) and Azure Synapse Implementation of Big Data solutions: using open source and non-SQL technologies such as Databricks, Spark, Spark Streaming, Kafka, Storm, Zeppelin, Scala software development or PySpark Experience in No-SQL databases such as Cosmos DB, MongoDB, Cassandra DB or similar technologies. Build data ingestion and transformation infrastructure. o Management, creation and consumption of static and streaming data for use with batch and online inference. o Work with transactional data and queues. Software development (Desirable) o Strong coding skills for clean, modular, and extensible code. o Strong practices in software development, version control, CI/CD automation. o Strong coding skills to write unit and integration tests. Specific Requirements: Able to Work on Mexico City regular business hours (9-6pm) Technical certifications based on Microsoft technology (Azure Developer Associate, Azure IoT Developer, DevOps Engineer Expert, Azure Solutions Architect Expert, Azure Data Engineer, Azure Enterprise Data Analyst, Azure Customer Data Platform Specialist or similar). Project Management Certification (e.g., PMP, Scrum). Offer: Payroll Superior Benefits Direct hire by client Multicultural teams Perm project If you are looking for a new professional challenge, this is a good opportunity, let's talk about your next professional experience.",https://mx.linkedin.com/jobs/view/azure-data-engineer-lead-at-ki-people-4028008393,4028008393,"We are looking for an Azure Data Engineer Lead to work in a hybrid mode in Mexico City for a multicultural project with opportunities for stability and growth. The role requires leading meetings with clients to understand business needs, mapping customer requirements to Microsoft technology solutions, and participating in project planning. The candidate will generate project documents, manage escalations, analyze situations, and maintain relationships with clients at the executive level. The role demands a bachelor's degree in computer science, engineering, finance, business or related field, and a minimum of 5 years of experience in leading technology implementation projects.","Microsoft Azure, SQL, PostgreSQL, SQL Server, Azure SQL, Azure Data Factory, Azure Analysis Services, Power BI, Azure Data Lake Store, Azure HD Insights, Spark, Kafka, Zeppelin, Scala, PySpark, No-SQL, Cosmos DB, MongoDB, Cassandra DB",5,Bachelor,True,5.0,0,0,1,1,0,0,0,0,1,1,0,0,0,0,0,0,0
Data Analyst,TechProjects,Mexico City Metropolitan Area,HYBRID,Entry level,Full-time,Information Services and Software Development,2024-09-19 02:13:20.504903,25,Information Technology,,,"Techprojects, is one of the fast growing IT Services and staffing company with a mission to provide best value for the time & money invested by our customers. Being the right size and having global operations gives us enough flexibility to pass on cost benefits to our clients and employees. Whether it’s Enterprise Digital transformation, Data Intelligence & Automation, IT Security, or Automation partnering with TechProjects you get a personalized experience and best return on investment. Tech Projects places difficult-to-find highly skilled IT professionals on a contract, contract-to-hire and full-time basis. We provided IT services to commercial customers ranging from small to large corporations in diversified industries such as supply chain & groceries, healthcare and financial services. We served local, state and public sector establishments with a particular emphasis on health and education sector . Techprojects offers full range of IT services from providing high quality professionals for your staffing requirements to implementing large IT projects from design to deployment & maintenance. Our global operations ensure our customers will always get quick response and every aspect of their requirements will be fulfilled fast, at a scale with best value for their time and money. For more details please check our website : http://www.techprojects.com/ TechProjects ( dba name for Dice IT Solutions, LLC ) is a Minority , women owned , GSA schedule 70 and NJ disadvantage certified global IT Projects, Consulting company helping customers from commercial & public sectors and State & local verticals The Role You Will Be Responsible For Defining, developing and maintaining reports to support decision making. Processing & Interpreting data to get actionable insights. Working closely with business users to understand their data analysis needs/requirements. Ideal Profile You possess a degree in Computer Science, Applied Mathematics, Engineering or related field. You have at least 3 years experience, ideally within a Data Analyst role. You have good presentation and communication skills and the ability to present you findings clearly and accessibly in the form of reports and presentations to senior colleagues. You are a strong team player who can manage multiple stakeholders You possess strong analytical skills and are comfortable dealing with numerical data You are adaptable and thrive in changing environments What's on Offer? Flexible working options Work alongside & learn from best in class talent Excellent career development opportunities",https://mx.linkedin.com/jobs/view/data-analyst-at-techprojects-4029272688,4029272688,"You will be responsible for defining, developing, and maintaining reports to support decision making. This includes processing and interpreting data to get actionable insights and working closely with business users to understand their data analysis needs.","Data Analysis, Reporting Tools, SQL, Excel, Presentation Skills",3,Bachelor,True,3.0,0,0,0,0,0,1,0,0,1,1,0,0,0,0,0,0,0
Data Sr Analyst,Connectingology,Mexico City Metropolitan Area,HYBRID,,Full-time,"Technology, Information and Internet",2024-09-19 02:13:20.504903,25,Information Technology,,,"Role’s Mission This position sits within the Analytics team, which is responsible of make data-driven decisions. We work closely with all business units (Growth, Marketing, Credit, Fraud, Sales, Finance, Support, etc), product and data teams to tackle business challenges with data. There's two main functions within the team: Analytics engineering: provide clean datasets to end users, modeling data in a way that empowers end users to answer their own questions. Data Analytics: track overall business performance building critical dashboards and reports, perform deep dives and experiments to solve business problems and identify opportunities. Data stack: BigQuery, dbt, Looker studio Key responsibilities Build and maintain data models to increase the organization's efficiency on data analysis Build and maintain metrics Build and maintain business critical dashboards Perform experiments to prove or disregard hypothesis to improve the business Interact with stakeholders to identify needs Requirements: Requirements Must have Bachelor’s or Master’s degree degree in a quantitatively rigorous discipline like engineering, statistics, math, or economics, or relevant equivalent experience Excellent communication skills to communicate findings and recommendations to both technical and non-technical audiences Superb problem solving skills and analytical mindset Top-notch stakeholder management Advanced SQL Experience with BI tools and building dashboards with high adoption (preferably Looker Studio, but any would suffice) Experience with scripting programming languages such as Python/R Strong time management skills and the ability to manage multiple projects and prioritize Strong business acumen and framing that enable high-impact decision making Nice to have Experience with dbt Experience with data modeling Good understanding of machine learning fundamentals and metrics Experience with forecasting Experience with experimentation (both A/B testing and causal inference when A/B testing is not possible) Experience with ETL/Reverse ETL tools Experience with Cloud-based data warehouses Languages Spanish English (full working proficiency)",https://mx.linkedin.com/jobs/view/data-sr-analyst-at-connectingology-4027710001,4027710001,"This position sits within the Analytics team, responsible for making data-driven decisions and working closely with business units and data teams. It involves building and maintaining data models, metrics, dashboards, and performing experiments to improve the business. The role requires excellent communication skills, superb problem-solving abilities, and advanced SQL along with experience in BI tools and scripting languages like Python or R.","SQL, Python, R, BigQuery, dbt, Looker Studio, ETL, Cloud-based data warehouses",,Bachelor,True,,0,0,1,0,0,0,1,0,1,1,0,0,0,0,1,0,0
Machine Learning Engineer,"Bluetab América, an IBM Company",Mexico City Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-19 02:14:20.161364,25,Information Technology,,,"En /bluetab seguimos con el desarrollo de negocio. Nuestros equipos están en pleno crecimiento Nos alejamos del concepto de consultoría tradicional, ¿Sabes por qué?: Contratamos para nosotros. Somos fieles a nuestra cultura y queremos compartir contigo nuestra filosofía de trabajo cooperativo, en equipo y de formación continua. Siempre podemos aprender más. Confiamos en la gente y que es posible trabajar bajo pasión, y que sientas en nuestro apoyo tanto en lo profesional como en lo personal. Ningún mar en calma hizo experto a un marinero. ¿Somos exigentes? Sí, porque nuestros retos los son, pero te desarrollarás entre cracks, en entornos innovadores y con las últimas tendencias tecnológicas. Esto es lo que te aporta ser /bluetaber… Queremos invitarte a formar parte del equipo como: Machine Learning Engineer ¿Qué buscamos? ¡Que te apasione lo que haces!, ¡Que ames la tecnología, la formación continua y los nuevos retos! Perfil ideal del candidato Experiencia: Historial comprobado en el desarrollo e implementación de modelos de ML, preferiblemente en NLP. Experiencia en integrar modelos de ML con sistemas de ingeniería de producción para la entrega de predicciones en tiempo real. Mentalidad de resolución de problemas, Ciencia de los datos, Ciencia cognitiva, Matemáticas (estadística, probabilidad y álgebra lineal) Amplia experiencia en herramientas de repositorios. Amplia experiencia en GIT (Línea de comandos y CLI) Conocimiento de Gitflow, Github Flow Conocimiento en estrategias de branching Conocimiento en herramientas de Continuous Integration/Continuous delivery (Jenkins, Azure devops) Conocimiento en soluciones de Inteligencia Artificial del mercado Conocimiento en soluciones de Inteligencia Artificial orientada al análisis cognitivo de Datos y Preferencias de los usuarios. Conocimiento de Generative AI Funciones: Desarrollar y mantener los pipelines de machine learning, desplegar los modelos en producción y monitorear su desempeño. Colaborar estrechamente con quants e ingenieros de software, el ingeniero garantizará una integración perfecta de los modelos de machine learning en nuestras aplicaciones. Construir y mejorar nuestro proceso de machine learning (ML) y herramientas relacionadas para respaldar el desarrollo, la experimentación, la integración continua, la entrega continua, la verificación/validación y el monitoreo de modelos de M Habilidades técnicas: Experiencia en construir e implementar modelos de machine learning en organizaciones grandes o pequeñas. Amplia experiencia en machine learning, especialmente en Procesamiento de Lenguaje Natural (NLP, por sus siglas en inglés) y Modelos de Lenguaje Grandes (LLMs, por sus siglas en inglés). Dominio de marcos de trabajo de ML como TensorFlow, PyTorch, Scikit, Keras o similar. Fuertes habilidades de programación en Python (Indispensable) Conocimiento práctico en Cloud, ya sea AWS, GCP, AZURE (Indispensable) Habilidades blandas: Comunicación de resultados Organizado Proactivo Tu comodidad nos importa. Los bluetabers trabajamos en un entorno confortable, agradable y con proyección de carrera. Eso se traduce en: Contrato indefinido con un salario competitivo. El salario se relaciona en función de los conocimientos técnicos detectados en el proceso y rol asignado, procurando respetar el sentido de equidad y siendo susceptible de mejora tras las evaluaciones continuas de desempeño. Formación continua. Plan de carrera individual definido ya sea técnico, funcional o gestión (¡Decide tu camino, pero sigue formándote!). Beneficios sociales más allá de tu salario: Fondo de Ahorro Seguro de gastos médicos menores y de mayores a nivel familiar, seguro de vida. Vales de despensa. Vacaciones superiores a la ley. Bolsa de capacitación Bono de bienestar Tendrás un Career Coach para que te guíe en tu desarrollo profesional. Capacitación constante Días de descanso adicionales a la ley. ""Bluetab"" es una empresa del grupo IBM. Bluetab será la entidad contratante. Al proceder con esta solicitud, usted entiende que Bluetab compartirá su información personal con otras filiales de IBM involucradas en su proceso de reclutamiento, selección y contratación, donde quiera que éstas se encuentren. Encontrará más información sobre cómo IBM protege su información personal, incluidas las medidas en caso de transferencia transfronteriza de datos, aquí: https://www.ibm.com/careers/us-en/privacy-policy/ Si te gusta la tecnología y la resolución de problemas tanto como a nosotros, ¡Nos encantaría conocerte!",https://mx.linkedin.com/jobs/view/machine-learning-engineer-at-bluetab-am%C3%A9rica-an-ibm-company-4029426441,4029426441,"At /bluetab we continue with business development. Our teams are in full growth. We move away from traditional consulting concepts, hiring for ourselves. We are committed to our culture and want to share our philosophy of cooperative work, teamwork, and continuous training. We trust in people and the possibility of working with passion, providing support both professionally and personally. We are looking for a Machine Learning Engineer who is passionate about technology, continuous learning, and new challenges. Ideal candidate profile includes proven experience in developing and implementing ML models, preferably in NLP, integrating ML models with production systems for real-time predictions, problem-solving mindset, extensive experience with repository tools, GIT, and CI/CD tools (Jenkins, Azure DevOps). Responsibilities include developing and maintaining machine learning pipelines, deploying models in production, and monitoring performance. Strong programming skills in Python and knowledge in cloud services (AWS, GCP, AZURE) is required.","Python, Machine Learning, NLP, TensorFlow, PyTorch, Scikit-learn, Keras, AWS, GCP, Azure, Jenkins, Azure DevOps, GIT",,,True,,0,0,0,1,0,0,0,0,0,0,0,0,1,0,1,0,0
Ingeniero de Datos Big Data,APPLY RECRUITERS,Mexico City Metropolitan Area,ON-SITE,Entry level,Full-time,Human Resources Services,2024-09-19 02:14:20.161364,25,Information Technology,,,"Buscamos un Ingeniero de Datos con las capacidades y aptitudes de poder manejar la operación de todo el ciclo de vida del dato utilizando herramientas de Big Data; serás responsable de tareas como ingeniería, modelado, almacenamiento, análisis, procesos de extracción, transformación y carga (ETL) de datos. *REQUISITOS* •	Graduado de Computer Science, Ciencia de los Datos, Ciencia de la Computación y Tecnologías de la Información o carrera afín. •	Dominio de motores de gestión de bases de datos como Oracle, MySQL, SQL, •	⁠Uso de sistemas operativos como Linux y Windows •	Conocimiento de lenguajes de programación como R, Phyton, Scala •	⁠⁠Conocimiento de herramientas de manipulación de datos como Hadoop, spark, hive, yarn ⁠⁠Conocimientos en nube (AWS, Azure, y/o GCP) •	Conocimientos Básicos en sistemas operativos y redes •	Deseable: Experiencia en proyectos de Big Data utilizando herramientas ad-hoc OFRECEMOS •	Salario S22,000 a 25,000 pesos mexicanos •	Prestaciones de ley •	Formación constante •	Estabilidad laboral *OBSERVACIONES* •	El trabajo es para residencia presencial en Santa Fe, Ciudad de México •	Jornadas rotativas de 12 horas (3 días de trabajo - 3 días descanso – 3 días de trabajo, etc.) •	Disponibilidad para estudiar, actualizarse y certificarse, de acuerdo al plan de formación",https://mx.linkedin.com/jobs/view/ingeniero-de-datos-big-data-at-apply-recruiters-4029286415,4029286415,"We are looking for a Data Engineer with the skills to manage the entire data lifecycle using Big Data tools; you will be responsible for tasks such as engineering, modeling, storage, analysis, and ETL (extract, transform, load) processes of data. Requirements include a degree in Computer Science, Data Science, or a related field, proficiency in database management systems such as Oracle, MySQL, SQL, experience with operating systems like Linux and Windows, knowledge of programming languages such as R, Python, and Scala, familiarity with data manipulation tools like Hadoop, Spark, Hive, and Yarn, as well as cloud knowledge (AWS, Azure, and/or GCP). Basic knowledge in operating systems and networks is also required. Desirable: Experience in Big Data projects using ad-hoc tools.","Python, R, Scala, SQL, Oracle, MySQL, Hadoop, Spark, Hive, Yarn, AWS, Azure, GCP, Linux, Windows",,Bachelor,True,,0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0
Data Analytics,Azkait,Mexico City Metropolitan Area,ON-SITE,,Full-time,"Technology, Information and Internet",2024-09-19 02:14:20.161364,25,Research,"Analyst,",Information Technology,"AZKAIT es una empresa Mexicana que busca y conecta el mejor talento IT con empresas Latinoamericanas y de Estados Unidos. Estamos en la búsqueda de tu talento como Data Analytics Requisitos: Ingeniería en Sistemas, Computación, o afín. Inglés avanzado (conversacional) 4+ años de experiencia como Data Analytics Skills : BigQuery Dataflow Composer Data Fusion Looker, Looker Studio Databricks Beneficios : Contratación 100% nómina IMSS, Infonavit y PTU de ley Aguinaldo de 30 días SGMM para el recurso y su familia directa Seguro de Vida (individual) Seguro dental (individual) Cursos y Certificaciones gratuitas Vales de despensa Tarjeta de descuentos en tiendas departamentales y en redes médicas. Trabajo de Lunes a Viernes. Contrato indeterminado, posterior a 3 meses de prueba Lugar y esquema de trabajo : CDMX o Queretaro",https://mx.linkedin.com/jobs/view/data-analytics-at-azkait-4027707593,4027707593,"AZKAIT is seeking talent as a Data Analytics professional. The role requires advanced English (conversational) and 4+ years of experience in Data Analytics. Candidates should have a background in Systems Engineering, Computing, or a related field. Responsibilities include working with various data analytics tools.","BigQuery, Dataflow, Composer, Data Fusion, Looker, Looker Studio, Databricks",4+ years,Bachelor,True,4.0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0
Data Engineer,Ford México,Mexico City Metropolitan Area,ON-SITE,,Full-time,Motor Vehicle Manufacturing,2024-09-19 02:14:20.161364,25,Information Technology,,,"Job Description Creating the future of smart mobility requires the highly intelligent use of data, metrics, and analytics. That’s where you can make an impact as part of our Global Data Insight & Analytics team. We are the trusted advisers that enable Ford to clearly see business conditions, customer needs, and the competitive landscape. With our support, key decision-makers can act in meaningful, positive ways. Join us and use your data expertise and analytical skills to drive evidence-based, timely decision-making. The Global Data Insights and Analytics (GDI&A) department at Ford Motors Company is looking for qualified people who can develop scalable solutions to complex real-world problems using Machine Learning, Big Data, Statistics, Econometrics, and Optimization. The goal of GDI&A is to drive evidence-based decision making by providing insights from data. Applications for GDI&A include, but are not limited to, Connected Vehicle, Smart Mobility, Advanced Operations, Manufacturing, Supply chain, Logistics, and Warranty Analytics. Responsibilities Design, Develop and Implement data engineering solutions using standards, templates, patterns and best practices in the Google Cloud Platform Full stack data engineering solutions utilizing both structured and unstructured data: development, ingestion, curation, implementation, deployment, automation and monitoring Collaborates with the Data Factory Engineering Organization, Data Architecture, PEM, GDIA, Information Technology and Data Consumers to drive data engineering capabilities, product design and proof of concepts, MVPs, to expand understanding, define technical optimization, explore configurations and overcome challenges Create high quality, elegant data engineering solutions that focus on cloud-first, encapsulation, repeatability, automation and auditability Work as an individual contributor and part of a team to build, test, maintain and troubleshoot data solutions Continuously integrates and deploys data solutions via CI/CD Use of Test Driven Development and Code Pairing Practices Qualifications Bachelor’s degree in a Technical Field: Computer Science, Data Science, Computational Finance, Statistics, Economics and/or Mathematics: Masters Preferred 5+ years of experience in data solution, pipeline, mart and/or warehouse development and delivery using agile development methodology Critical thinking skills to propose solutions, test, and make them a reality. 2+ years of experience in a Data Engineering Competency on a public cloud – Google, MS Azure, AWS 2+ years Integration and Configuration Scripting in Tekton and Terraform 3+ years of experience writing complex SQL 3+ years of experience writing data solutions in Python, Java, Scala or Go Deep understanding of data service ecosystems including data warehouses, lakes, metadata, meshes, fabrics and analytical use cases User experience advocacy through empathetic stakeholder relationship Excellent Communication Skills, Verbal and Written, for both internal and external team members Desired Skills 2+ years Extensive knowledge and understanding of GCP offerings, bundled services, especially those associated with data operations Cloud Console, BigQuery, Data Flow, Data Fusion, PubSub / Kafka, Looker Studio and VertexAI Experience with Teradata, Hadoop, Hive, Spark and other on-premise/legacy data solutions Experience optimizing data solutions and data science/analytical workflows: re-coding/re-developing/re-factoring Data Governance concepts including GDPR (General Data Protection Regulation), CCPA (California Consumer Protection Act), PoLP and how these can impact technical architecture Ford Motor Company is an Equal Opportunity Employer, as we are committed with a diverse workforce, and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity and/or expression, status as a veteran and basis of disability.",https://mx.linkedin.com/jobs/view/data-engineer-at-ford-m%C3%A9xico-4029283701,4029283701,"Creating the future of smart mobility requires the highly intelligent use of data, metrics, and analytics. The Global Data Insights and Analytics department at Ford Motors Company is looking for individuals who can develop scalable solutions to complex real-world problems using Machine Learning, Big Data, Statistics, Econometrics, and Optimization. Responsibilities include designing, developing, and implementing data engineering solutions using best practices in the Google Cloud Platform, full stack data engineering solutions utilizing both structured and unstructured data, and collaborating with various teams to enhance data engineering capabilities.","Google Cloud Platform, Machine Learning, Big Data, Statistics, Econometrics, Optimization, SQL, Python, Java, Scala, Go, Terraform, Tekton, Teradata, Hadoop, Hive, Spark",5+,Bachelor,True,5.0,0,0,1,1,0,0,0,0,0,1,0,1,1,0,1,0,0
Business Intelligence Analyst JR,Confidential,Mexico City Metropolitan Area,ON-SITE,Executive,Full-time,"Computers and Electronics Manufacturing, Retail Appliances, Electrical, and Electronic Equipment, and Wholesale",2024-09-19 02:14:20.161364,86,Research,"Analyst,",Information Technology,"Business Intelligence Analyst JR About The role We are looking for a passionate Business Intelligence Specialist to be part of the Retail Team. The ideal candidate will need to turn data into information, information into ideas, and ideas into operational decisions. In this role, you'll be. Interpreting data, analyzing results using statistical techniques, and submitting reports. Developing and implementing databases, data collection systems, data analytics, and other strategies that optimize statistical efficiency and quality. ·Capturing data from primary or secondary sources and maintaining databases and data systems. ldentifying, analyzing, and interpreting trends or patterns in complex data sets. Working with management to prioritize information and business needs. Locating and defining new opportunities for process improvement. We're eager to be in touch because you have. Degree in Administration, Economics, Actuarial Sciences, Engineering, or related field. Proven working experience of 1+ years as a Data/BI Analyst. ·Experience in building data analysis or data reports by creating dashboards. ·Technical expertise in storytelling and data exploration. Experience in conducting root cause analysis and implementing corrective and preventive actions. Advanced Excel skills, including formulas, pivot tables, macros, etc. Intermediate English proficiency.Critical thinking. Strong analytical skills.",https://mx.linkedin.com/jobs/view/business-intelligence-analyst-jr-at-confidential-4029407401,4029407401,"We are looking for a passionate Business Intelligence Specialist to be part of the Retail Team. The ideal candidate will interpret data, analyze results using statistical techniques, and submit reports. Responsibilities include developing and implementing databases, data collection systems, and data analytics strategies that optimize statistical efficiency and quality. The analyst will capture data from primary or secondary sources, maintain databases, and identify trends or patterns in complex data sets. The role also involves working with management to prioritize business needs and locate new opportunities for process improvement.","Excel, SQL, Data Analytics, Dashboard Creation, Statistical Techniques",1+ years,,True,1.0,0,0,0,0,0,1,0,0,1,1,0,0,0,0,0,0,0
