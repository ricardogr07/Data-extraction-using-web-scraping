Title,Company,Location,Remote,SeniorityLevel,EmploymentType,Industries,DatePosted,NumApplicants,JobFunction1,JobFunction2,JobFunction3,Description,Url,JobID,ShortDescription,TechStack,YoE,MinLevelStudies,English,MinYoE,Agile Methodologies,Back-End Development,Big Data Tools,Cloud Platforms,Containerization and Orchestration,Data Analysis,Data Engineering,Data Modeling,Data Visualization,Database Management,Front-End Development,Infrastructure as Code (IaC) and Automation,Machine Learning,Networking,Python,Testing and Quality Assurance,Other
AI/ML and MLOps Field Engineer,Canonical,Monterrey Metropolitan Area,REMOTE,Entry level,Full-time,"Technology, Information and Internet",2024-09-01 11:24:41.937682,25,Engineering,Information Technology,,"Canonical is a leading provider of open source software and operating systems to the global enterprise and technology markets. Our platform, Ubuntu, is very widely used in breakthrough enterprise initiatives such as public cloud, data science, AI, engineering innovation and IoT. Our customers include the world's leading public cloud and silicon providers, and industry leaders in many sectors. The company is a pioneer of global distributed collaboration, with 1000+ colleagues in 70+ countries and very few roles based in offices. Teams meet two to four times yearly in person, in interesting locations around the world, to align on strategy and execution. The company is founder led, profitable and growing. We are hiring an AI/ML and MLOps Field Engineer to help global companies embrace AI in their business, using the latest open source capabilities on public and private cloud infrastructure, Linux and Kubernetes. Our team applies expert insights to real-world customer problems, enabling the enterprise adoption of Ubuntu, Kubeflow, MLFlow, Feast, DVC and related analytics, machine learning and data technologies. We are working to create the world's best open source data platform, covering traditional SQL databases and today's NoSQL data stores, as well as the machinery which turns data into insights and executable models. The people who love this role are software engineers who enjoy customer conversations and solving customer problems during the presales cycle. They are are developers who like to solve customer problems through architecture, presentations and training. Ubuntu is used by pretty much every enterprise in the world, in every industry. This is a fantastic opportunity to learn about the open source technology landscape and develop your business technology insights. You will see first hand in various industries how Linux - and Ubuntu in particular - is shaping innovation and changing the world for the better. This role is particularly suited to candidates with a technical background who are business minded and driven by commercial success. This role is on our global Field Engineering team and will work closely with enterprise sales leads. We are specifically looking for people interested in solving the most difficult problems in modern data architectures. Training LLMs on multiple K8s clusters deployed on a hybrid cloud infrastructure with GPU sharing across multiple teams? Processing 10M events in real time for financial transactions? Object detection on 10k parallel 4K video streams? These are the problems we solve day to day. Location: Most of our colleagues work from home. We are growing teams in EMEA, Americas and APAC time zones, so can accommodate candidates from almost any country. What your day will look like The global Field Engineering team members are Linux and cloud solutions architects for our customers, designing private and public cloud solutions fitting their workload needs. They are the cloud consultants who work hands-on with the technologies by deploying, testing and handing over the solution to our support or managed services team at the end of a project. They are also software engineers who use Python to develop Kubernetes operators and Linux open source infrastructure-as-code. Work across the entire Linux stack, from kernel, networking, storage, to applications Architect cloud infrastructure solutions like Kubernetes, Kubeflow, OpenStack, and Spark Deliver solutions either on-premise or in public cloud (AWS, Azure, Google Cloud) Collect customer business requirements and advise them on Ubuntu and relevant open source applications Grow a healthy, collaborative engineering culture in line with the company values Deliver presentations and demonstrations of Ubuntu Pro and AI/ML capabilities to prospective and current clients Liaise with product teams to give them feedback on requirements to influence roadmap Work collaboratively with your sales team to reach our common targets Global travel up to 25% of time for internal and external events and 25% to customer meetings What we are looking for in you Exceptional academic track record from both high school and university Undergraduate degree in a technical subject or a compelling narrative about your alternative chosen path Experience in data engineering, MLOps, or big data solutions deployment Experience with a relevant programming language, like Python, R, or Rust. Confidence to respectfully speak up, exchange feedback, and share ideas without hesitation Track record of going above-and-beyond expectations to achieve outstanding results Demonstrated personal interest in continuous learning and development Practical knowledge of Linux, virtualisation, containers and networking Business-minded technology thinker and problem solver Knowledge of cloud computing concepts & leaders, such as Kubernetes, AWS, Azure, GCP Interest in large-scale enterprise open source - private clouds, machine learning and AI, data and analytics Intermediate level Python programming skills Passion for technology evidenced by personal projects and initiatives The work ethic and confidence to shine alongside motivated colleagues Professional written and spoken English with excellent presentation skills Experience with Linux (Debian or Ubuntu preferred) Excellent interpersonal skills, curiosity, flexibility, and accountability A dynamic person who loves to jump in new projects and interact with people Appreciative of diversity, polite and effective in a multi-cultural, multi-national organisation Thoughtfulness and self-motivation Result-oriented, with a personal drive to follow up and meet commitments Ability to travel internationally, for company events up to two weeks long, and customer or industry meetings What you'll learn Architect and deploy AI/ML infrastructures, data processing pipelines and multi-cluster distributed training Wide range of open source applications and skills Work directly with customers in a range of different businesses Real-life and hands-on exposure to a wide range of emerging technologies and tools What we offer colleagues We consider geographical location, experience, and performance in shaping compensation worldwide. We revisit compensation annually (and more often for graduates and associates) to ensure we recognise outstanding performance. In addition to base pay, we offer a performance-driven annual bonus or commission. We provide all team members with additional benefits, which reflect our values and ideals. We balance our programs to meet local needs and ensure fairness globally. Distributed work environment with twice-yearly team sprints in person Personal learning and development budget of USD 2,000 per year Annual compensation review Recognition rewards Annual holiday leave Maternity and paternity leave Employee Assistance Programme Opportunity to travel to new locations to meet colleagues Priority Pass, and travel upgrades for long haul company events About Canonical Canonical is a pioneering tech firm at the forefront of the global move to open source. As the company that publishes Ubuntu, one of the most important open source projects and the platform for AI, IoT and the cloud, we are changing the world of software. We recruit on a global basis and set a very high standard for people joining the company. We expect excellence - in order to succeed, we need to be the best at what we do. Most colleagues at Canonical have worked from home since its inception in 2004. Working here is a step into the future, and will challenge you to think differently, work smarter, learn new skills, and raise your game. Canonical is an equal opportunity employer We are proud to foster a workplace free from discrimination. Diversity of experience, perspectives, and background create a better work environment and better products. Whatever your identity, we will give your application fair consideration.",https://mx.linkedin.com/jobs/view/ai-ml-and-mlops-field-engineer-at-canonical-4013780012,4013780012,"We are hiring an AI/ML and MLOps Field Engineer to help global companies embrace AI, using the latest open source capabilities on private and public cloud infrastructure. The role involves designing cloud infrastructure solutions, deploying and testing technologies, and developing Kubernetes operators using Python. It requires experience in data engineering or big data solutions deployment and a strong background in cloud computing concepts such as Kubernetes and AWS.","Python, R, Rust, Kubernetes, AWS, Azure, Google Cloud, Linux, OpenStack, Spark, MLFlow, Feast, DVC, SQL, NoSQL",,Undergraduate Student,True,,0,0,1,1,1,0,0,0,0,1,0,1,1,0,1,0,0
Senior Machine Learning Engineer,Rent-A-Center,Monterrey Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Retail,2024-09-01 11:24:41.937682,28,Engineering,Information Technology,,"Objetivo: Diseñar flujos, automatizar procesos y generar infraestructura sostenible para el manejo, tratamiento, almacenamiento y manipulación general de los datos. Despliegue y mantenimiento continuo de modelos de aprendizaje automático en entornos de producción. Experiencia: Tres años de experiencia en puestos similares. Uso y manejo de Spark. Uso y manejo de Databricks. Uso y manejo de pipelines como Airflow o similares. Uso y manejo de Python. Uso y manejo de Git. Experiencia desarrollando data lakes. Experiencia desarrollando feature stores (actualizables automáticamente y con la menor latencia posible). Uso y manejo de pipelines para deployment, preferentemente con AWS. Experiencia con herramientas generales de AWS. Conocimiento: Trabajo previo con Azure. Líder de proyecto de desarrollo de infraestructura. Uso y manejo de Tensorflow. Uso y manejo de Kafka. Conocimiento de herramientas de Oracle. Conocimiento de Snowflake.",https://mx.linkedin.com/jobs/view/senior-machine-learning-engineer-at-rent-a-center-4009749330,4009749330,"The objective is to design workflows, automate processes, and generate sustainable infrastructure for data management, processing, storage, and general handling. Continuous deployment and maintenance of machine learning models in production environments.","Spark, Databricks, Airflow, Python, Git, AWS, Azure, Tensorflow, Kafka, Oracle, Snowflake",3 years,,False,3.0,0,0,1,1,0,0,0,0,0,1,0,1,0,0,1,0,0
Senior Machine Learning Engineer,Kuona,Monterrey Metropolitan Area,REMOTE,Mid-Senior level,Full-time,"Technology, Information and Internet",2024-08-25 11:24:41.937682,25,Engineering,Information Technology,,"We’re Kuona (kuona.ai), an AI technology company that empowers consumer products and retailers to live up to their revenue goals and empowers our clients to maximize their sales and profitability through the dynamic optimization of prices, promotions, and inventories. Our AI-powered platform helps top brands like Coca-Cola and Oxxo to maximize their profits and optimize inventories. We are looking for people who are world-class, curious, innovative, bright, and work to be better every single day! We are seeking a solution-oriented Senior Machine Learning Engineer to join our product analytics team. This fully remote role offers the opportunity to develop and deploy models that enhance our user experience across all product areas. You will work with large datasets, build models to describe and predict market behavior and generate insights that shape key decisions and investment strategies. In this position, you will face a wide range of problem-solving scenarios, from strategic to real-time, requiring extensive data collection and analysis. We need someone who can apply advanced data science skills and has experience with analytical programming languages, especially Python and the pandas library. The ideal candidate is mature, experienced, and capable of taking on challenges independently with minimal supervision. For the current position, we can only consider candidates living within México, Colombia, Argentina. Key Responsibilities: Develop advanced analytics and predictive models from design through implementation in areas such as pricing, promotion, and inventory management. Collaborate with data and software engineers to deploy scalable models across the company's ecosystem. Build models and algorithms end-to-end, starting from brainstorming and data exploration to implementing production-ready code. Write production-ready code to implement data pipelines and machine learning models. Identify, diagnose, and recommend projects to improve performance. Design product experiments, interpret results to draw detailed and impactful conclusions, and conduct root cause analysis. Work with data infrastructure and product engineering teams to define data collection needs. Provide recommendations to assist quick product ideation and feature launch decisions. Requirements: 5+ years of experience in analytics, data science, or equivalent, applying quantitative, statistical, and machine learning techniques to solve practical product problems. 5+ years of experience building machine learning systems and analyzing large datasets using modern tools. At least 2 advanced years of experience working with the pandas library. Proficiency in Python, SQL, and data visualization tools. Ability to extract business insights and identify stories behind the data. Experience analyzing and conducting hypothesis-driven experimentation and A/B testing. Comfortable translating ambiguous problems and requirements into data-driven analyses. Strong critical thinking and problem-solving skills using analytical and quantitative methodologies. Teamwork and leadership skills. Fluent in spoken and written English. Your experience with Kuona: Creativity: We like that all team members can propose and create new features Self-management: Since we are a very horizontal company, we require that team members can decide for themselves what to work on and define priorities Opportunities to learn: We offer all our employees a wide opportunity to learn things that you probably wouldn't be exposed to in a corporate environment. High Impact: You will be involved in the growth and evolution of the company, all your contributions will be of high impact on the overall results. We value our culture: We are fully committed to prioritizing great results for our clients and an amazing employee experience for our people. Ability to work anywhere / Flexibility: We provide everyone the opportunity to design your day and execute your projects with flexibility and focus on your well-being. Benefits: Competitive base compensation Health insurance Life insurance Flexible time off and 12 holidays Work from home policy including a laptop and support for your home office needs Opportunity to join a diverse, passionate, and fun team Kuona provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.",https://mx.linkedin.com/jobs/view/senior-machine-learning-engineer-at-kuona-4002809612,4002809612,"We are seeking a solution-oriented Senior Machine Learning Engineer to develop and deploy models that enhance user experience across all product areas. The role involves working with large datasets, building predictive models, and generating insights to shape key decisions. You will collaborate with data and software engineers to deploy scalable models, write production-ready code for data pipelines, and design product experiments while interpreting results. The candidate should have experience in analytics, data science, and machine learning techniques, particularly with Python and the pandas library.","Python, Pandas, SQL, Data Visualization Tools, Machine Learning, A/B Testing",5+ years,,True,5.0,0,0,0,0,0,1,0,0,1,1,0,0,1,0,1,0,0
Senior Data Scientist,Axented,Monterrey Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Software Development,2024-08-25 11:24:41.937682,25,Engineering,Information Technology,,"We are seeking a solution-oriented Senior Data Scientist to join our product analytics team. This fully remote role offers the opportunity to develop and deploy models that enhance our user experience across all product areas. You will work with large datasets, build models to describe and predict market behavior and generate insights that shape key decisions and investment strategies. In this position, you will face a wide range of problem-solving scenarios, from strategic to real-time, requiring extensive data collection and analysis. We need someone who can apply advanced data science skills and has experience with analytical programming languages, especially Python and the pandas library. The ideal candidate is mature, experienced, and capable of taking on challenges independently with minimal supervision. For the current position, we can only consider candidates living within México. Requirements 5+ years of experience in analytics, data science, or equivalent, applying quantitative, statistical, and machine learning techniques to solve practical product problems. 5+ years of experience building machine learning systems and analyzing large datasets using modern tools At least 2 advanced years of experience working with the Pandas library. Proficiency in Python, SQL, and data visualization tools. Ability to extract business insights and identify stories behind the data. Experience analyzing and conducting hypothesis-driven experimentation and A/B testing. Comfortable translating ambiguous problems and requirements into data-driven analyses. Strong critical thinking and problem-solving skills using analytical and quantitative methodologies. Teamwork and leadership skills. Fluent in spoken and written English. Responsibilities Develop advanced analytics and predictive models from design through implementation in areas such as pricing, promotion, and inventory management. Collaborate with data and software engineers to deploy scalable models across the company's ecosystem. Build models and algorithms end-to-end, starting from brainstorming and data exploration to implementing production-ready code. Write production-ready code to implement data pipelines and machine learning models. Identify, diagnose, and recommend projects to improve performance. Design product experiments, interpret results to draw detailed and impactful conclusions, and conduct root cause analysis. Work with data infrastructure and product engineering teams to define data collection needs. Provide recommendations to assist quick product ideation and feature launch decisions. Benefits Competitive base compensation Health insurance Life insurance Flexible time off and 12 holidays Work from home policy including a laptop and support for your home office needs Opportunity to join a diverse, passionate, and fun team",https://mx.linkedin.com/jobs/view/senior-data-scientist-at-axented-4024136275,4024136275,"We are seeking a solution-oriented Senior Data Scientist to join our product analytics team. This fully remote role offers the opportunity to develop and deploy models that enhance user experience across all product areas by working with large datasets, building models to describe and predict market behavior, and generating insights. The candidate must apply advanced data science skills, especially in Python and the pandas library, with a focus on machine learning and data analysis. Responsibilities include developing predictive models, collaborating with engineers, and providing data-driven recommendations.","Python, SQL, Pandas, Machine Learning, Data Visualization, A/B Testing, Statistical Analysis",5+ years,,True,5.0,0,0,0,0,0,1,0,0,0,1,0,0,1,0,1,0,0
Senior Machine Learning Engineer,Axented,Monterrey Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Software Development,2024-08-25 11:24:41.937682,25,Engineering,Information Technology,,"We are seeking a solution-oriented Senior Machine Learning Engineer to join our product analytics team. This fully remote role offers the opportunity to develop and deploy models that enhance our user experience across all product areas. You will work with large datasets, build models to describe and predict market behavior and generate insights that shape key decisions and investment strategies. In this position, you will face a wide range of problem-solving scenarios, from strategic to real-time, requiring extensive data collection and analysis. We need someone who can apply advanced data science skills and has experience with analytical programming languages, especially Python and the pandas library. The ideal candidate is mature, experienced, and capable of taking on challenges independently with minimal supervision. For the current position, we can only consider candidates living within México. Requirements 5+ years of experience in analytics, data science, or equivalent, applying quantitative, statistical, and machine learning techniques to solve practical product problems. 5+ years of experience building machine learning systems and analyzing large datasets using modern tools At least 2 advanced years of experience working with the Pandas library. Proficiency in Python, SQL, and data visualization tools. Ability to extract business insights and identify stories behind the data. Experience analyzing and conducting hypothesis-driven experimentation and A/B testing. Comfortable translating ambiguous problems and requirements into data-driven analyses. Strong critical thinking and problem-solving skills using analytical and quantitative methodologies. Teamwork and leadership skills. Fluent in spoken and written English. Responsibilities Develop advanced analytics and predictive models from design through implementation in areas such as pricing, promotion, and inventory management. Collaborate with data and software engineers to deploy scalable models across the company's ecosystem. Build models and algorithms end-to-end, starting from brainstorming and data exploration to implementing production-ready code. Write production-ready code to implement data pipelines and machine learning models. Identify, diagnose, and recommend projects to improve performance. Design product experiments, interpret results to draw detailed and impactful conclusions, and conduct root cause analysis. Work with data infrastructure and product engineering teams to define data collection needs. Provide recommendations to assist quick product ideation and feature launch decisions.",https://mx.linkedin.com/jobs/view/senior-machine-learning-engineer-at-axented-4003533968,4003533968,"We are seeking a solution-oriented Senior Machine Learning Engineer to develop and deploy models that enhance user experience across all product areas. This role involves working with large datasets, building models to describe and predict market behavior, and generating insights for key decisions. The candidate will apply advanced data science skills, including experience with analytical programming languages, especially Python and the pandas library. Responsibilities include developing advanced analytics, collaborating with data and software engineers, writing production-ready code, and conducting product experiments.","Python, Pandas, SQL, Data Visualization Tools, Machine Learning, A/B Testing",5+,,True,5.0,0,0,0,0,0,1,0,0,1,1,0,0,1,0,1,0,0
AI Python Developer Sr,Accenture México,Monterrey Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Business Consulting and Services,2024-09-13 11:24:41.937682,37,Engineering,Information Technology,,"DARE TO BE A PART OF THE CHALLENGE! COME AND JOIN OUR TEAM TOGETHER WE CAN MAKE THE DIFFERENCE! Did you know that Accenture is leading the digital transformation in the World? Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Our main purpose is to collaborate with our clients, so they can become high-performance businesses. Accenture is present in more than 200 cities, 49 countries and approximately 732,000 employees worldwide. We Offer Career development according to your profile and interests. Work in one of the best companies and feel proud. Access to an innovative methodology and tools. Direct contact with experts worldwide. Use of work schemes and cutting-edge technologies. Constant training. Work environment based on teamwork and collaboration. Participation in International Projects Skills: +5 years of experience Python SQL AWS Requirements: Expert proficiency in Machine Learning Expert proficiency in Python Software Development Advanced proficiency in Python Frameworks",https://mx.linkedin.com/jobs/view/ai-python-developer-sr-at-accenture-m%C3%A9xico-4001918826,4001918826,"We are looking for candidates with over 5 years of experience in Python, SQL, and AWS. The requirements include expert proficiency in Machine Learning and software development, as well as advanced proficiency in Python frameworks.","Python, SQL, AWS, Machine Learning, Python Frameworks",5+ years,,True,5.0,0,0,0,1,0,0,0,0,0,1,0,0,1,0,1,0,0
"Python and Kubernetes Software Engineer - Data, AI/ML & Analytics",Canonical,Monterrey Metropolitan Area,REMOTE,Entry level,Full-time,"Technology, Information and Internet",2024-09-01 11:24:41.937682,25,Engineering,Information Technology,,"Canonical is a leading provider of open source software and operating systems to the global enterprise and technology markets. Our platform, Ubuntu, is very widely used in breakthrough enterprise initiatives such as public cloud, data science, AI, engineering innovation and IoT. Our customers include the world's leading public cloud and silicon providers, and industry leaders in many sectors. The company is a pioneer of global distributed collaboration, with 1000+ colleagues in 70+ countries and very few roles based in offices. Teams meet two to four times yearly in person, in interesting locations around the world, to align on strategy and execution. The company is founder led, profitable and growing. We are hiring Python and Kubernetes Specialist Engineers focused on Data, AI/ML and Analytics Solutions to join our teams building open source solutions for public cloud and private infrastructure. As a software engineer on the team, you'll collaborate on an end-to-end data analytics and mlops solution composed of popular, open-source, machine learning tools, such as Kubeflow, MLFlow, DVC, and Feast. You may also work on workflow, ETL, data governance and visualization tools like Apache SuperSet, dbt, and Temporal, or data warehouse solutions such as Apache Trino, or ClickHouse. Your team will own a solution from the analytics and machine learning space, and integrate with the solutions from other teams to build the world's best end-to-end data platform. These solutions may be run on servers or on the cloud, on machines or on Kubernetes, on developer desktops, or as web services. We serve the needs of individuals and community members as much as the needs of our Global 2000 and Fortune 500 customers; we make our primary work available free of charge and our Pro subscriptions are also available to individuals for personal use at no cost. Our goal is to enable more people to enjoy the benefits of open source, regardless of their circumstances. Location: This initiative spans many teams that are home-based in EMEA, Americas and APAC time zones, so we can accommodate candidates in almost any location. We believe in distributed collaboration but we also try to ensure that colleagues have company during their work hourse! Successful candidates will join a team where most members and your manager are broadly in the same time zone so that you have the benefits of constant collaboration and discussion. What your day will look like Develop your understanding of the entire Linux stack, from kernel, networking, and storage, to the application layer Design, build and maintain solutions that will be deployed on public and private clouds and local workstations Master distributed systems concepts such as observability, identity, tracing Work with both Kubernetes and machine-oriented open source applications Collaborate proactively with a distributed team of engineers, designers and product managers Debug issues and interact in public with upstream and Ubuntu communities Generate and discuss ideas, and collaborate on finding good solutions What we are looking for in you Professional or academic software delivery using Python or Golang Exceptional academic track record from both high school and university Undergraduate degree in a technical subject or a compelling narrative about your alternative chosen path Confidence to respectfully speak up, exchange feedback, and share ideas without hesitation Track record of going above-and-beyond expectations to achieve outstanding results Passion for technology evidenced by personal projects and initiatives The work ethic and confidence to shine alongside motivated colleagues Professional written and spoken English with excellent presentation skills Experience with Linux (Debian or Ubuntu preferred) Excellent interpersonal skills, curiosity, flexibility, and accountability Appreciative of diversity, polite and effective in a multi-cultural, multi-national organisation Thoughtfulness and self-motivation Result-oriented, with a personal drive to meet commitments Ability to travel twice a year, for company events up to two weeks long Additional Skills That Would Be Nice To Have The following skills may be helpful to you in the role, but we don't expect everyone to bring all of them. Hands-on experience with machine learning libraries, or tools. Proven track record of building highly automated machine learning solutions for the cloud. Experience with container technologies (Docker, LXD, Kubernetes, etc.) Experience with public clouds (AWS, Azure, Google Cloud) Working knowledge of cloud computing Passionate about software quality and testing Experience working on an open source project What we offer colleagues We consider geographical location, experience, and performance in shaping compensation worldwide. We revisit compensation annually (and more often for graduates and associates) to ensure we recognise outstanding performance. In addition to base pay, we offer a performance-driven annual bonus or commission. We provide all team members with additional benefits, which reflect our values and ideals. We balance our programs to meet local needs and ensure fairness globally. Distributed work environment with twice-yearly team sprints in person Personal learning and development budget of USD 2,000 per year Annual compensation review Recognition rewards Annual holiday leave Maternity and paternity leave Employee Assistance Programme Opportunity to travel to new locations to meet colleagues Priority Pass, and travel upgrades for long haul company events About Canonical Canonical is a pioneering tech firm at the forefront of the global move to open source. As the company that publishes Ubuntu, one of the most important open source projects and the platform for AI, IoT and the cloud, we are changing the world of software. We recruit on a global basis and set a very high standard for people joining the company. We expect excellence - in order to succeed, we need to be the best at what we do. Most colleagues at Canonical have worked from home since its inception in 2004. Working here is a step into the future, and will challenge you to think differently, work smarter, learn new skills, and raise your game. Canonical is an equal opportunity employer We are proud to foster a workplace free from discrimination. Diversity of experience, perspectives, and background create a better work environment and better products. Whatever your identity, we will give your application fair consideration.",https://mx.linkedin.com/jobs/view/python-and-kubernetes-software-engineer-data-ai-ml-analytics-at-canonical-4011644941,4011644941,"We are hiring Python and Kubernetes Specialist Engineers focused on Data, AI/ML, and Analytics Solutions to build open source solutions for public cloud and private infrastructure. As a software engineer, you'll collaborate on an end-to-end data analytics and MLOps solution using popular open-source machine learning tools. You will work on workflow, ETL, data governance, and visualization tools, or data warehouse solutions. Your team will own a solution in the analytics and machine learning space and integrate it with other solutions to build a comprehensive data platform. Candidates should have professional or academic software delivery experience using Python or Golang, a strong academic track record, and an undergraduate degree in a technical subject. Experience with Linux, machine learning libraries, container technologies, and public clouds is preferred.","Python, Golang, Kubernetes, MLFlow, Kubeflow, DVC, Feast, Apache SuperSet, dbt, Temporal, Apache Trino, ClickHouse, Linux",,Undergraduate Student,True,,0,1,1,0,1,0,0,0,0,0,0,0,1,0,1,0,0
Senior Data Scientist,Launch Potato,Monterrey Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Advertising Services,2024-09-08 11:24:41.937682,25,Engineering,Information Technology,,"WHO ARE WE? Launch Potato is a digital media company with a portfolio of brands and technologies. As The Discovery and Conversion Company, Launch Potato is a leading connector of advertisers to customers at all parts of the consumer journey, from awareness to consideration to purchase. The company is headquartered in vibrant downtown Delray Beach, Florida, with a unique international team across over a dozen countries. Launch Potato's success comes from a diverse, energetic culture and high-performing, entrepreneurial team. As a result, the company is always looking for like-minded teammates and partners. (This role will heavily focus on building machine learning models. This is NOT an engineering/data engineering position.) MUST HAVE: Experience within the performance marketing/lead gen industries. Professional experience designing, implementing, optimizing, and testing end-to-end Multi-Armed Bandit (MAB) and recommendation systems. EXPERIENCE: A minimum of 4 years experience in a hands-on, in-the-weeds data science position. YOUR ROLE You will be developing deep personalization models for our users and complex optimization algorithms to bridge our customer experiences with new products/services. Your direct contribution will impact how we connect hundreds of thousands of customers to hundreds of advertisers together daily and will drive significant consumer impact while increasing revenue. You will play a pivotal role in the growth of our data science team and will be an instrumental resource as we continue to build a team of data scientists and machine learning engineers that can increase customer engagement and stickiness on our sites while improving the quality of the leads to our partners. This is an extremely hands-on and in-the-weeds Data Science role where you will be heavily immersed in the data and coding part of the solution implementation. You will design and oversee integrating state-of-the-art machine learning solutions across the company’s products. This role will be responsible for strategic planning of Machine Learning initiatives with the Product, Engineering, Performance and Business Intelligence teams, analysis of potential impact and prioritization of those projects. SUCCESS LOOKS LIKE Innovate, create, and design ML solutions to various business problems such as: Design, implement and continuously improve Multi-Armed Bandit solutions to optimize decisions/options in place of multiple AB-tests. Utilizing Large Language Models in content personalization across various verticals. Recommendation systems to serve ads, offers, questions, etc. Collaborate with stakeholders across the company including but not limited to Analytics, Engineering, Product and Business Leads to improve model infrastructure, tracking and monitoring. Provide data science support at different project stages, including the implementation of ML solutions by collaborating with Data Engineers and MLOps. Being hands-on and in-the-weeds in the data, coding part of the solution implementation. What You Need To Succeed 4+ years of related work experience in the field of Data Science & Machine learning. 2+ years of experience in the Marketing/Advertising Industry. Solid background in Machine Learning and Statistics. Professional experience designing and implementing Multi-Armed Bandit (MAB) solutions and recommendation systems. Proficiency in SQL, Python and working with Data Science tools (e.g., git, kubernetes, Docker, etc.). Structure and clarify any ambiguity for the team, i.e., divide complex projects into sprints and coordinate implementation across multiple teams and individuals. Experience creating ML solutions within cloud services (AWS/GCP). Experience with ML model development lifecycle. Experience with data visualization (preferably Looker). Experience managing a team of data scientists and machine learning researchers (including career development). Ability to communicate clearly, think independently, provide direction, and effectively communicate with technical and non-technical stakeholders. NICE TO HAVES Experience with LLMs and Deep learning models to develop business and data science solutions. Want to make your impact in a profitable, high-growth company? Apply now! Since day one, we've been committed to having a diverse, inclusive team and culture. We are proud to be an Equal Employment Opportunity company. We value diversity, equity, and inclusion. We do not discriminate based on race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",https://mx.linkedin.com/jobs/view/senior-data-scientist-at-launch-potato-4019303841,4019303841,"This role focuses on building machine learning models, requiring expertise in designing, implementing, optimizing, and testing end-to-end Multi-Armed Bandit (MAB) and recommendation systems. The candidate will develop deep personalization models and complex optimization algorithms that bridge customer experiences with products/services. The position involves collaboration with various teams to innovate ML solutions to business problems, improve model infrastructure, and provide data science support at different project stages.","Python, SQL, Machine Learning, Statistics, Git, Kubernetes, Docker, AWS, GCP, Looker",4+,,True,4.0,0,0,0,1,1,0,0,0,1,1,0,1,1,0,1,0,0
"Senior Artificial Intelligence/Machine Learning Engineer - Remote, Latin America",Bluelight Consulting | DevOps & Software Development,Monterrey Metropolitan Area,REMOTE,,Full-time,IT Services and IT Consulting,2024-09-08 11:24:41.937682,25,Engineering,Information Technology,,"Bluelight Consulting is a leading software consultancy dedicated to designing and developing innovative technology that enhances users' lives. With a steadfast commitment to delivering exceptional service to our clients, Bluelight excels in its focus on quality and customer satisfaction. Our mission is not only to create cutting-edge applications but also to foster a collaborative and enriching work environment where each team member can grow and thrive. With a presence across the United States and Central/South America, Bluelight is in an exciting phase of expansion, continually seeking exceptional talent to join its dynamic and diverse community. We are looking for a skilled individual to join our rapidly growing team at Bluelight Consulting. This position is ideal for someone who thrives in a fast-paced, dynamic environment where everyone's opinions and efforts are valued and appreciated. You will have the opportunity to contribute to challenging and meaningful projects, developing high-quality applications that stand out in the market. We value continuous learning, personal growth, and hard work, offering a collaborative environment that promotes professional development. If you are passionate about software development and eager to be part of a growing software consultancy, we invite you to apply and join us on this exciting journey. What we are looking for Strong background in computer science or engineering with 3+ years of experience Knowledge of machine learning, deep learning, and natural language processing Experience with LLMs like GPT and LLama3 Proficient in Python and familiar with TensorFlow or PyTorch Good problem-solving skills and ability to work independently and in a team Experience with AI voice programs/products Proficient in cloud services (AWS, Azure, Google Cloud) and container technologies (Docker, Kubernetes) Strong communication skills for explaining technical ideas to various audiences Ability to manage product specifications from concept to production Understanding of software design principles, including optimization and performance tuning Company Benefits Competitive salary and bonuses, including performance-based salary increases Generous paid-time-off policy Technology / Office stipend Health Coverage Flexible working hours Work remotely Continuing education, training, conferences Company-sponsored coursework, exams, and certifications Being a consultant in our team is a fun, challenging, and rewarding career choice. Your contributions are highly valued by clients, and the work you do often has a direct and significant impact on their business. You will have the opportunity to work on a variety of projects for our incredible clients, which will accelerate your career growth. You’ll collaborate with modern technologies and work alongside some of the best professionals in the industry! If you’re eager to be part of an exciting, challenging, and rapidly growing consultancy, we encourage you to apply.",https://mx.linkedin.com/jobs/view/senior-artificial-intelligence-machine-learning-engineer-remote-latin-america-at-bluelight-consulting-devops-software-development-4018830256,4018830256,"We are looking for a skilled individual with a strong background in computer science or engineering and 3+ years of experience. The role involves knowledge of machine learning, deep learning, and natural language processing, along with experience using large language models like GPT and LLaMA. Proficiency in Python, familiarity with TensorFlow or PyTorch, and experience with AI voice programs/products are required. Candidates should be proficient in cloud services (AWS, Azure, Google Cloud) and container technologies (Docker, Kubernetes). Strong problem-solving skills, communication abilities, and understanding of software design principles are essential.","Python, TensorFlow, PyTorch, AWS, Azure, Google Cloud, Docker, Kubernetes, Machine Learning, Deep Learning, Natural Language Processing",3+ years,Bachelor,True,3.0,0,0,0,1,1,0,0,0,0,0,0,0,1,0,1,0,0
Senior Machine Learning Researcher,Launch Potato,Monterrey Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Advertising Services,2024-09-08 11:24:41.937682,25,Other,,,"WHO ARE WE? Launch Potato is a digital media company with a portfolio of brands and technologies. As The Discovery and Conversion Company, Launch Potato is a leading connector of advertisers to customers at all parts of the consumer journey, from awareness to consideration to purchase. The company is headquartered in vibrant downtown Delray Beach, Florida, with a unique international team across over a dozen countries. Launch Potato's success comes from a diverse, energetic culture and high-performing, entrepreneurial team. As a result, the company is always looking for like-minded teammates and partners. (This role will heavily focus on building machine learning models. This is NOT an engineering/data engineering position.) MUST HAVE: Experience within the performance marketing/lead gen industries. Professional experience designing, implementing, optimizing, and testing end-to-end Multi-Armed Bandit (MAB) and recommendation systems. EXPERIENCE: A minimum of 4 years experience in a hands-on, in-the-weeds data science position. YOUR ROLE You will be developing deep personalization models for our users and complex optimization algorithms to bridge our customer experiences with new products/services. Your direct contribution will impact how we connect hundreds of thousands of customers to hundreds of advertisers together daily and will drive significant consumer impact while increasing revenue. You will play a pivotal role in the growth of our data science team and will be an instrumental resource as we continue to build a team of data scientists and machine learning engineers that can increase customer engagement and stickiness on our sites while improving the quality of the leads to our partners. This is an extremely hands-on and in-the-weeds Data Science role where you will be heavily immersed in the data and coding part of the solution implementation. You will design and oversee integrating state-of-the-art machine learning solutions across the company’s products. This role will be responsible for strategic planning of Machine Learning initiatives with the Product, Engineering, Performance and Business Intelligence teams, analysis of potential impact and prioritization of those projects. SUCCESS LOOKS LIKE Innovate, create, and design ML solutions to various business problems such as: Design, implement and continuously improve Multi-Armed Bandit solutions to optimize decisions/options in place of multiple AB-tests. Utilizing Large Language Models in content personalization across various verticals. Recommendation systems to serve ads, offers, questions, etc. Collaborate with stakeholders across the company including but not limited to Analytics, Engineering, Product and Business Leads to improve model infrastructure, tracking and monitoring. Provide data science support at different project stages, including the implementation of ML solutions by collaborating with Data Engineers and MLOps. Being hands-on and in-the-weeds in the data, coding part of the solution implementation. What You Need To Succeed 4+ years of related work experience in the field of Data Science & Machine learning. 2+ years of experience in the Marketing/Advertising Industry. Solid background in Machine Learning and Statistics. Professional experience designing and implementing Multi-Armed Bandit (MAB) solutions and recommendation systems. Proficiency in SQL, Python and working with Data Science tools (e.g., git, kubernetes, Docker, etc.). Structure and clarify any ambiguity for the team, i.e., divide complex projects into sprints and coordinate implementation across multiple teams and individuals. Experience creating ML solutions within cloud services (AWS/GCP). Experience with ML model development lifecycle. Experience with data visualization (preferably Looker). Experience managing a team of data scientists and machine learning researchers (including career development). Ability to communicate clearly, think independently, provide direction, and effectively communicate with technical and non-technical stakeholders. NICE TO HAVES Experience with LLMs and Deep learning models to develop business and data science solutions. Want to make your impact in a profitable, high-growth company? Apply now! Since day one, we've been committed to having a diverse, inclusive team and culture. We are proud to be an Equal Employment Opportunity company. We value diversity, equity, and inclusion. We do not discriminate based on race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",https://mx.linkedin.com/jobs/view/senior-machine-learning-researcher-at-launch-potato-4019302943,4019302943,"This role will focus on building machine learning models, specifically designing and implementing Multi-Armed Bandit (MAB) and recommendation systems. The candidate will be responsible for developing deep personalization models and complex optimization algorithms to enhance customer experiences. Key responsibilities include innovating machine learning solutions for business problems, collaborating with various stakeholders, providing data science support, and managing a team of data scientists. The position requires a hands-on approach to data and coding in solution implementation.","Python, SQL, Data Science Tools, Git, Kubernetes, Docker, AWS, GCP, Looker",4+ years,,True,4.0,0,0,0,1,1,1,0,0,1,1,0,1,0,0,1,0,0
Data Engineering Intern,Kuona,Monterrey Metropolitan Area,REMOTE,,Internship,"Technology, Information and Internet",2024-09-08 11:24:41.937682,61,Information Technology,,,"We are Kuona ( kuona.a i) , an AI technology company that empowers consumer products and retailers to live up to their revenue goals and empowers our clients to maximize their sales and profitability through the dynamic optimization of prices, promotions, and inventories. Our AI-powered platform helps top brands like Coca-Cola and Oxxo maximize their profits and optimize inventories. We are looking for people who are world-class, curious, innovative, bright, and work to be better every single day! We are currently looking for a Data Engineering Intern. With training, guidance, monitoring, and support from the team and team leader, this role is focused on finding and developing solutions that help Kuona build and maintain complex data pipelines and analytical solutions that deepen relationships with customer-provided information. Responsibilities: Ensure that the quality of presented data is reliable and aligned with its source quality, and be familiar with various data sources and/or flat files for generating solutions. This role collaborates with the data engineering and data science teams to drive and optimize analytical solutions and internal data systems. Contribute to data analysis and integration. Provide support for enhancing and addressing issues with developed and integrated systems, among other related tasks in the area. Required Technical Experience: Desirable experience in data engineering, business intelligence, or engineering. Desirable experience analyzing and integrating data using Python and SQL to extract and transform data according to business rules and requirements. Desirable knowledge in Pandas, Relational and NoSQL databases, and AWS. Desirable knowledge in Airflow and AWS Glue. Desirable experience with large-scale data warehouses, web APIs, and database platforms for integrating internal and external data sources. Your experience with Kuona: Creativity: We like that all team members can propose and create new features Self-management: Since we are a very horizontal company, we require that team members can decide for themselves what to work on and define priorities Opportunities to learn: We offer all our employees a wide opportunity to learn things you probably wouldn't be exposed to in a corporate environment. High Impact: You will be involved in the growth and evolution of the company, and all your contributions will be of high impact on the overall results. We value our culture: We are fully committed to prioritizing great results for our clients and an amazing employee experience for our people. Ability to work anywhere / Flexibility: We provide everyone the opportunity to design your day and execute your projects with flexibility and focus on your well-being. Kuona provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.",https://mx.linkedin.com/jobs/view/data-engineering-intern-at-kuona-4014199772,4014199772,"We are currently looking for a Data Engineering Intern focused on finding and developing solutions that help build and maintain complex data pipelines and analytical solutions. Responsibilities include ensuring data quality, collaborating with data engineering and data science teams, contributing to data analysis and integration, and providing support for enhancing existing systems. Desirable technical experience includes working with Python and SQL for data extraction and transformation, knowledge in Pandas, relational and NoSQL databases, AWS, Airflow, and AWS Glue.","Python, SQL, Pandas, Relational databases, NoSQL, AWS, Airflow, AWS Glue",,,True,,0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0
Tech Support Data Engineer,Boldr,Monterrey Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Non-profit Organizations and Primary and Secondary Education,2024-08-16 11:24:41.937682,44,Engineering,,,"Working hours: US Business hours What Is Your Role This role is part of the team of Customer Engineers in Professional Services, and we're seeking highly talented individuals to join and grow our team. This is the intersection where the product has to meet customer needs and create value. You are a customer-facing data engineer who loves to see technology and data used in ways that ensure our projects' and customers' success. You have great attention to detail and are very proactive in seeking potential roadblocks to success. You have great people skills and know how to manage the trust and expectations of a customer. What Will You Do Customer Engineers are the customer facing technical owners of our existing customer relationships and data driven deliverables on the company's platform You will work hands-on with our technology stack and collaborate with several teams such as Product Engineering and Customer Engagement in order to deliver on all customer technical requests. You will be responsible for regularly interacting with our customers to gather requirements (e.g. weekly meetings, email, etc), and for scoping and prioritizing the incoming work. This can include: Designing Solutions - translate business requirements into technical solutions using SQL, scripting, codebase configurations, etc Setting up ETL pipelines across disparate data sources, and creating a unified Data Model Setting up/enabling new product features & ingest/export integrations Implementing the company's platform and its various components for our new customers Helping answer customer questions, and troubleshooting where necessary Participating in the on-call rotation You will also be: Finding out sustainable ways of addressing repeatable issues, and building tools for automation Contributing with documentation and building our customer specific configuration knowledge base A source of feedback for our product team, full stack and backend engineering teams Requirements BS degree in Computer Science, Engineering, Mathematics, Economics, Statistics, Information Management or similar 2+ years in a technical role that involves managing and manipulating large data sets, such as ETL, Data Warehousing, Analytics, Data Science etc 2+ years in a client-facing role that involves being a point-of-contact for technical and non-technical users Proficient in one programming language and working knowledge of SQL and Unix command line tools Working Knowledge of Github, and AWS infrastructure Excellent problem solving skills Strong Communication skills Improvement mindset, through processes, tools and/ or documentation Strong professionalism & work ethic Nice to have: Working knowledge of Java and/or Scala Marketing technology industry & relevant vendor knowledge Benefits Law Benefits Private Health Insurance Paid Time Off Training Life insurance Mental Health Support Learning and Development Programs",https://mx.linkedin.com/jobs/view/tech-support-data-engineer-at-boldr-3994915995,3994915995,"This role is part of the team of Customer Engineers in Professional Services, seeking highly talented individuals to join and grow the team. As a customer-facing data engineer, you will translate business requirements into technical solutions using SQL and other technologies, set up ETL pipelines, implement the company's platform for new customers, and manage customer relationships. You will also contribute to documentation and provide feedback to product teams.","SQL, Unix, ETL, Data Warehousing, Data Science, GitHub, AWS, Java, Scala",2+ years,Bachelor,True,2.0,0,0,0,1,0,1,1,0,0,1,0,1,0,0,0,0,0
Jr. Data Scientist,Arca Continental,Monterrey Metropolitan Area,HYBRID,Associate,Full-time,Food and Beverage Services,2024-08-25 11:26:01.950696,200,Information Technology,Sales,,"Nuestra compañía Arca Continental es una empresa dedicada a la producción, distribución y venta de bebidas no alcohólicas de las marcas propiedad de The Coca-Cola Company, así como botanas saladas bajo las marcas Bokados en México, Inalecsa en Ecuador y Wise en los Estados Unidos. Con una destacada trayectoria de más de 98 años, Arca Continental es la segunda embotelladora de Coca-Cola más grande de América Latina y una de las más importante del mundo. En su franquicia de Coca-Cola, la empresa atiende a una población de más de 119 millones en la región norte y occidente de México, así como en Ecuador, Perú, la región norte de Argentina y la región suroeste de Estados Unidos. Arca Continental cotiza en la Bolsa Mexicana de Valores bajo el símbolo ""AC"". Misión del puesto Buscamos un Científico de Datos Junior con una sólida base en programación y pasión por los datos. Tu objetivo será utilizar tus habilidades de programación para analizar y extraer insights de bases de datos, desarrollar y dar mantenimiento a modelos de machine learning , y mantener soluciones existentes para varios países de LATAM en conjunto con el equipo de Ciencia de Datos. Responsabilidades clave Desarrollar soluciones analíticas que resuelvan de manera óptima las problemáticas del negocio, para mejorar los procesos actuales y facilitar la toma de decisiones. Presentar insights con equipos técnicos y stakeholders Asegurar la mejora continua y el mantenimiento de los desarrollos, buscando siempre mayor eficiencia en términos de calidad, costo y tiempo. Analizar información sobre el seguimiento continuo del desarrollo productivo y la adopción de los desarrollos para mejorar su interacción con los usuarios finales. Trabajar en conjunto con el equipo de Ciencia de Datos para mejorar los procesos clave de la organización mediante el uso de tecnología y soluciones innovadoras. Cualificaciones y requerimientos Recién egresado en áreas cuantitativas (Ingeniería, Matemáticas, Física). Haber llevado cursos de algoritmos y programación en la carrera profesional. Sólidos conocimientos de programación con Python, pensamiento algorítmico y razonamiento lógico. Conocimiento teórico y práctico de modelos tradicionales de Machine Learning (regresión, clasificación, clustering) y métricas de evaluación. Habilidades de comunicación efectiva, organización de actividades y alta atención al detalle. Idiomas: Inglés Avanzado (tanto conversacional como escrito). Características deseables Experiencia con modelos de forecast o series de tiempo. Conocimiento de procesos de empresas tipo retail. Fundamentos en IA generativa y Deep learning. Nuestro compromiso Arca Continental es una empresa que ofrece igualdad de oportunidades. Las decisiones de contratación se toman sin distinción de raza o etnia, color, religión, nacionalidad, sexo, orientación sexual, identidad de género, edad, discapacidad, estatus de veterano protegido o alguna otra característica protegida por la ley. Nunca solicitaremos ningún tipo de pago para procesar su solicitud de empleo ni en ninguna otra etapa del proceso de selección. Nunca le envíe dinero a nadie que sugiera que puede darle empleo en Arca Continental. Si sospecha que ha recibido una oferta fraudulenta, repórtelo con las autoridades correspondientes.",https://mx.linkedin.com/jobs/view/jr-data-scientist-at-arca-continental-4002846143,4002846143,"We are looking for a Junior Data Scientist with a solid programming foundation and a passion for data. Your objective will be to use your programming skills to analyze and extract insights from databases, develop and maintain machine learning models, and maintain existing solutions for various Latin American countries in collaboration with the Data Science team. Key responsibilities include developing analytical solutions to optimally solve business challenges, presenting insights to technical teams and stakeholders, ensuring continuous improvement and maintenance of developments, and working together with the Data Science team to enhance key organizational processes using technology and innovative solutions.","Python, Machine Learning, Data Analysis, Algorithms, Deep Learning",,Bachelor,True,,0,0,0,0,0,1,0,0,0,0,0,0,1,0,1,0,0
Data Scientist (Consultant),NEORIS,Monterrey Metropolitan Area,HYBRID,Entry level,Full-time,IT Services and IT Consulting,2024-09-08 11:26:01.950696,88,Engineering,Information Technology,,"En NEORIS es un acelerador Digital que ayuda a las compañías a entrar en el futuro, teniendo 20 años de experiencia como Socios Digitales de algunas de las mayores compañías del mundo. Somos más de 4,000 profesionales en 11 países, con nuestra cultura multicultural de startup en donde cultivamos innovación, aprendizaje continuo para crear soluciones de alto valor para nuestros clientes. Estamos En Búsqueda De Data Scientist Consultant Data Scientist Consultant con al menos 2 años de experiencia. El candidato ideal tendrá una sólida comprensión de estadística y matemática, experiencia en el desarrollo con Python y SQL, y una pasión por convertir datos en información procesable. Deseable conocimiento en temas de pricing. Principales Responsabilidades Recopilar, procesar y analizar grandes volúmenes de datos de diversas fuentes. Desarrollar y mantener modelos predictivos y de machine learning. Realizar análisis estadísticos para identificar tendencias, patrones y oportunidades de mejora. Crear visualizaciones de datos efectivas para comunicar hallazgos a equipos no técnicos. Colaborar con equipos multidisciplinarios para definir y resolver problemas de negocio. Documentar procesos, metodologías y resultados de análisis. Contribuir a la mejora continua de los procesos y herramientas de análisis de datos. Monterrey esquema híbrido Requerimientos Egresado de carrera como Ing en matemáticas, estadística, actuaria o afines. Maestría en Computo estadístico (CIMAT) 2 años de experiencia laboral como Data Scientist. Experiencia en programación con Python, incluyendo bibliotecas como pandas, numpy, scikit-learn y matplotlib. Conocimiento sólido de SQL para la consulta y manipulación de bases de datos. Comprensión profunda de conceptos estadísticos y su aplicación en el análisis de datos. Capacidad para comunicar resultados complejos de manera clara y concisa a audiencias técnicas y no técnicas. Fuertes habilidades analíticas y de resolución de problemas. Ser curioso y proactivo, con un fuerte deseo de aprender y explorar nuevas tecnologías y metodologías. Grado en Estadística, Matemáticas, Ciencias de la Computación, Ingeniería o un campo relacionado. Deseable conocimiento en temas de pricing. Inglés conversacional (Avanzado o Intermedio B2). Localización: Monterrey (esquema híbrido) Ofrecemos Esquema 100% Nominal Prestaciones de Ley Paquete de Beneficios Programa Bienestar Plan de desarrollo profesional Colaboración multicultural Te invitamos a conocernos en http://www.neoris.com, Facebook, LinkedIn, Twitter o Instagram: @NEORIS. Hector Antonio Hernandez Sanchez",https://mx.linkedin.com/jobs/view/data-scientist-consultant-at-neoris-3997049604,3997049604,"NEORIS is looking for a Data Scientist Consultant with at least 2 years of experience. The ideal candidate will have a solid understanding of statistics and mathematics, experience in development with Python and SQL, and a passion for turning data into actionable information. Responsibilities include collecting, processing, and analyzing large volumes of data from various sources, developing and maintaining predictive and machine learning models, performing statistical analysis to identify trends and opportunities for improvement, and creating effective data visualizations to communicate findings to non-technical teams.","Python, SQL, pandas, numpy, scikit-learn, matplotlib",2,,True,2.0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0
Data Scientist,Chubb,Monterrey Metropolitan Area,HYBRID,Entry level,Full-time,Insurance,2024-09-10 11:26:01.950696,62,Engineering,Information Technology,,"Job Description Machine Learning Engineer Summary: We are seeking a talented and motivated Machine Learning Engineer to join our team. The ideal candidate will have at least 3 years of experience in the field, with a strong background in machine learning, data science, and software engineering. You will be responsible for designing, developing, and deploying machine learning models to solve complex problems and enhance our products and services. Key Responsibilities: Design, develop, and implement machine learning models and algorithms. Collaborate with cross-functional teams to understand business requirements and translate them into technical solutions. Perform data preprocessing, feature engineering, and model validation. Optimize and scale machine learning models for production. Monitor and maintain deployed models, ensuring their performance and accuracy over time. Conduct experiments to evaluate model performance and identify areas for improvement. Stay up-to-date with the latest developments in machine learning and artificial intelligence. Document processes, models, and methodologies for reproducibility and knowledge sharing. Qualifications: Bachelor’s or Master’s degree in Computer Science, Data Science, Mathematics, Statistics, or a related field. At least 3 years of experience as a Machine Learning Engineer or in a similar role. Proficiency in programming languages such as Python, R, or Java. Experience with machine learning frameworks and libraries (e.g., TensorFlow, PyTorch, scikit-learn). Strong understanding of statistical analysis and data mining techniques. Familiarity with data preprocessing, feature engineering, and model evaluation. Experience with big data technologies (e.g., Hadoop, Spark) is a plus. Knowledge of cloud platforms (e.g., AWS, Azure, GCP) for deploying machine learning models. Excellent problem-solving skills and attention to detail. Strong communication skills, with the ability to explain complex technical concepts to non-technical stakeholders. Preferred Skills: Experience with MLFlow for experiment tracking and model management. Proficiency in using PySpark for big data processing. Strong SQL skills for database querying and manipulation. Knowledge of model serving techniques and tools for deploying machine learning models at scale. Familiarity with DevOps practices and tools for CI/CD in machine learning. Understanding of software development best practices, including version control and testing. Qualifications Machine Learning Engineer Summary: We are seeking a talented and motivated Machine Learning Engineer to join our team. The ideal candidate will have at least 3 years of experience in the field, with a strong background in machine learning, data science, and software engineering. You will be responsible for designing, developing, and deploying machine learning models to solve complex problems and enhance our products and services. Key Responsibilities: Design, develop, and implement machine learning models and algorithms. Collaborate with cross-functional teams to understand business requirements and translate them into technical solutions. Perform data preprocessing, feature engineering, and model validation. Optimize and scale machine learning models for production. Monitor and maintain deployed models, ensuring their performance and accuracy over time. Conduct experiments to evaluate model performance and identify areas for improvement. Stay up-to-date with the latest developments in machine learning and artificial intelligence. Document processes, models, and methodologies for reproducibility and knowledge sharing. Qualifications: Bachelor’s or Master’s degree in Computer Science, Data Science, Mathematics, Statistics, or a related field. At least 3 years of experience as a Machine Learning Engineer or in a similar role. Proficiency in programming languages such as Python, R, or Java. Experience with machine learning frameworks and libraries (e.g., TensorFlow, PyTorch, scikit-learn). Strong understanding of statistical analysis and data mining techniques. Familiarity with data preprocessing, feature engineering, and model evaluation. Experience with big data technologies (e.g., Hadoop, Spark) is a plus. Knowledge of cloud platforms (e.g., AWS, Azure, GCP) for deploying machine learning models. Excellent problem-solving skills and attention to detail. Strong communication skills, with the ability to explain complex technical concepts to non-technical stakeholders. Preferred Skills: Experience with MLFlow for experiment tracking and model management. Proficiency in using PySpark for big data processing. Strong SQL skills for database querying and manipulation. Knowledge of model serving techniques and tools for deploying machine learning models at scale. Familiarity with DevOps practices and tools for CI/CD in machine learning. Understanding of software development best practices, including version control and testing.",https://mx.linkedin.com/jobs/view/data-scientist-at-chubb-3987318831,3987318831,"We are seeking a talented and motivated Machine Learning Engineer to join our team. The ideal candidate will have at least 3 years of experience in the field, with a strong background in machine learning, data science, and software engineering. You will be responsible for designing, developing, and deploying machine learning models to solve complex problems and enhance our products and services. Key responsibilities include designing and implementing machine learning models and algorithms, collaborating with cross-functional teams, performing data preprocessing, optimizing models for production, and monitoring deployed models for performance. The candidate should also stay up-to-date with the latest developments in machine learning and document processes for knowledge sharing.","Python, R, Java, TensorFlow, PyTorch, scikit-learn, Hadoop, Spark, AWS, Azure, GCP, MLFlow, PySpark, SQL",3,Bachelor,True,3.0,0,0,1,1,0,0,0,0,0,1,0,0,1,0,1,0,0
Senior AI Application Engineer,Bain & Company,Monterrey Metropolitan Area,HYBRID,,Full-time,Business Consulting and Services,2024-09-08 11:26:01.950696,25,Engineering,,,"*Applications must be submitted in English* WHAT MAKES US A GREAT PLACE TO WORK We are proud to be consistently recognized as one of the world's best places to work, a champion of diversity and a model of social responsibility. We are currently ranked the #1 consulting firm on Glassdoor’s Best Places to Work list, and we have maintained a spot in the top four on Glassdoor's list for the last 13 years. We believe that diversity, inclusion and collaboration is key to building extraordinary teams. We hire people with exceptional talents, abilities and potential, then create an environment where you can become the best version of yourself and thrive both professionally and personally.  We are publicly recognized by external parties such as Fortune, Vault, Mogul, Working Mother, Glassdoor and the Human Rights Campaign for being a great place to work for diversity and inclusion, women, LGBTQ and parents. WHO YOU’LL WORK WITH As a member of Bain’s Advanced Analytics Group, you’ll join a talented team of diverse and inclusive analytic and engineering professionals who are dedicated to solving complex challenges for our clients. We work closely with our generalist consultants and clients to develop data-driven strategies and innovative solutions. Our collaborative and supportive work environment fosters creativity and continuous learning, enabling us to consistently deliver exceptional results. WHAT YOU’LL DO As a Senior Software Engineer, you will apply technical solutions to cutting-edge problems across various industries. You will be part of a diverse engineering team, participating in the full engineering life cycle. This includes designing, developing, optimizing, and deploying new software engineering solutions and infrastructure for the production scale of the world’s largest companies. Collaborate closely with general consulting teams to identify software solutions to client business problems and execute those solutions Provide technical guidance to external clients and internal stakeholders in Bain Play a key role in delivering technical solutions for client cases (from solution architecture to hands-on development work) Participate in the full software development life cycle including designing, writing documentation and unit/integration tests, and conducting code reviews for engineering solutions Participate in expert client advisory services that require knowledge in software engineering with distributed systems, AI, and application architecture Develop and refine reusable common frameworks, models, and components to solve common software engineering challenges across industries and business functions Implement and promote best practices in software engineering, sharing insights with team members about theoretical and technical advancements Contribute to industry-leading innovations that translate into great impact for our clients in casework Stay current with emerging trends and technologies in cloud computing, data analysis, and software engineering Travel is required (30%) ABOUT YOU Bachelor's degree in Computer Science or a related technical field Master's degree in Computer Science, Engineering, or a related technical field is a plus Relevant academic or industry experience in web development, programming languages, version control, software design pattern, infrastructure and deployment, integration and unit testing implementation 4 years minimum experience Working knowledge (2-3 years) of Python** Experience with server-side frameworks and technologies such as FastAPI, Node.js, Flask. Experience with Cloud platforms and services (AWS, Azure, GCP, etc.) E xperience with administering and managing Kubernetes clusters (EKS, GCP, or AKS) Experience with DevOps, CI/CD, Github Actions Strong computer science fundaments in data structures, algorithms, automated testing, object-oriented programming, performance complexity, and implications of computer architecture on software performance. Knowledge of data architecture, database schema design, database scalability and SQL Knowledge of client-side technologies such as React, Angular, Vue.js, HTML and CSS Awareness of agile development methodologies and principles Strong interpersonal and communication skills, including the ability to explain and discuss technicalities of solutions, algorithms and techniques with colleagues and clients from other disciplines Curiosity, proactivity and critical thinking Ability to collaborate with people at all levels and with multi-office/region teams",https://mx.linkedin.com/jobs/view/senior-ai-application-engineer-at-bain-company-4007871620,4007871620,"As a Senior Software Engineer, you will apply technical solutions to cutting-edge problems across various industries. This includes designing, developing, optimizing, and deploying new software engineering solutions and infrastructure for large-scale production. You will work closely with general consulting teams to identify software solutions to client business problems, provide technical guidance, and participate in all stages of the software development life cycle. Responsibilities include developing reusable frameworks, implementing best practices in software engineering, and staying current with emerging trends and technologies.","Python, FastAPI, Node.js, Flask, AWS, Azure, GCP, Kubernetes, DevOps, CI/CD, Github Actions, React, Angular, Vue.js, HTML, CSS, SQL",4+,Bachelor,True,4.0,0,1,0,1,1,0,0,0,0,1,1,1,0,0,1,0,0
"Principal, AI Application Engineer",Bain & Company,Monterrey Metropolitan Area,HYBRID,,Full-time,Business Consulting and Services,2024-09-08 11:26:01.950696,25,Engineering,,,"*Applications must be submitted in English* WHAT MAKES US A GREAT PLACE TO WORK We are proud to be consistently recognized as one of the world's best places to work, a champion of diversity and a model of social responsibility. We are currently ranked the #1 consulting firm on Glassdoor’s Best Places to Work list, and we have maintained a spot in the top four on Glassdoor's list for the last 13 years. We believe that diversity, inclusion and collaboration is key to building extraordinary teams. We hire people with exceptional talents, abilities and potential, then create an environment where you can become the best version of yourself and thrive both professionally and personally.  We are publicly recognized by external parties such as Fortune, Vault, Mogul, Working Mother, Glassdoor and the Human Rights Campaign for being a great place to work for diversity and inclusion, women, LGBTQ and parents. WHO YOU'LL WORK WITH As a member of Bain’s Advanced Analytics Group, you’ll join a talented team of diverse and inclusive analytic and engineering professionals who are dedicated to solving complex challenges for our clients. We work closely with our generalist consultants and clients to develop data-driven strategies and innovative solutions. Our collaborative and supportive work environment fosters creativity and continuous learning, enabling us to consistently deliver exceptional results. WHAT YOU'LL DO As an Expert Manager, Software Engineering, you will lead the development and application of technical solutions to address complex problems in various industries. You will guide a diverse engineering team through the entire engineering life cycle. Your responsibilities will include designing, developing, optimizing, and deploying cutting-edge software engineering solutions and infrastructure at the production scale required by the world’s largest companies. Collaborate closely with and influence general consulting teams to identify software solutions to client business problems, and to appropriately scope, prioritize and execute those solutions A technical leader responsible for end-to-end technical solution delivery on client cases (from solution architecture to hands-on development work) Lead key parts of the software development life cycle, including architecture design, writing clean code, conducting code reviews, writing documentation, unit/integration tests, identifying issues and resolutions Participate in expert client advisory activities that require deep expertise in software engineering with distributed systems, AI and application architecture Collaborate on (or lead) the development of re-usable common frameworks, model and components that can be highly leveraged to address common software engineering problems across industries and business functions Work with the team and other senior leaders to create a great working environment that attracts other great engineers Coach engineering teams at our clients and partners to raise their capabilities and ensure that our work is successfully deployed to the highest standards Drive best demonstrated practices in software engineering, and share learnings with team members in AAG about theoretical and technical developments in software engineering Drive industry-leading innovations that translate into great impact for our clients in case work Act as PD Advisor as needed Participate in recruiting and onboarding for other team members Travel is required (30%) ABOUT YOU Master's degree in Computer Science, Engineering, or a related technical field Relevant professional hands-on experience in web development, programming languages, version control, software design pattern, infrastructure and deployment, integration and unit testing implementation Commercial acumen and understanding of business models 7 years minimum experience 4 years minimum at Lead or Staff level, or equivalent Track record of leading and collaborating on strategic initiatives Experience in shipping production, applications and data analytics products Expert knowledge (5+ years) of Python** Deep experience with additional server-side frameworks and technologies such as FastAPI, Node.js, Flask. Experience with Cloud platforms and services (AWS, Azure, GCP, etc.) Experience working in accordance with DevSecOps principles, and familiarity with industry deployment best practices using CI/CD tools, MLOps, LLMOps and infrastructure as code (Jenkins, Docker, Kubernetes, and Terraform) Strong computer science fundaments in data structures, algorithms, automated testing, object-oriented programming, performance complexity, and implications of computer architecture on software performance. Experience with data architecture, database schema design, database scalability and SQL Experience with client-side technologies such as React, Angular, Vue.js, HTML and CSS Understanding of data security and privacy regulations, key topics in cybersecurity, authentication and authorization mechanisms (including cloud IAM) Experience working according to agile principles Strong interpersonal and communication skills, including the ability to explain and discuss technicalities of solutions, algorithms and techniques with colleagues and clients from other disciplines Curiosity, proactivity and critical thinking Ability to collaborate with people at all levels and with multi-office/region teams Ability to work independently and juggle priorities to thrive in a fast paced and ambiguous environment, while also collaborating as part of a team in complex situations",https://mx.linkedin.com/jobs/view/principal-ai-application-engineer-at-bain-company-4007146382,4007146382,"As an Expert Manager in Software Engineering, you will lead the development and application of technical solutions to address complex problems across various industries. You will guide a diverse engineering team throughout the entire engineering life cycle, designing, developing, optimizing, and deploying cutting-edge software engineering solutions at the scale required by major companies. Responsibilities include collaborating with consulting teams to identify software solutions, leading the software development life cycle, participating in expert client advisory activities, and driving best practices in software engineering. You will also be involved in recruiting and onboarding new team members, with 30% travel required.","Python, FastAPI, Node.js, Flask, AWS, Azure, GCP, Jenkins, Docker, Kubernetes, Terraform, React, Angular, Vue.js, HTML, CSS, SQL","7 years minimum, 4 years at Lead or Staff level",Masters,True,4.0,0,1,0,1,1,0,0,0,0,1,1,1,0,0,1,0,0
Data Engineer / Visualization,NEORIS,Monterrey Metropolitan Area,HYBRID,Entry level,Full-time,IT Services and IT Consulting,2024-09-14 11:26:01.950696,25,Information Technology,,,"En NEORIS es un acelerador Digital que ayuda a las compañías a entrar en el futuro, teniendo 20 años de experiencia como Socios Digitales de algunas de las mayores compañías del mundo. Somos más de 4,000 profesionales en 11 países, con nuestra cultura multicultural de startup en donde cultivamos innovación, aprendizaje continuo para crear soluciones de alto valor para nuestros clientes. Data Engineer Visualizations con más de 2.5 años de experiencia para unirse a nuestro equipo de tecnología. Responsabilidades Encargado de la ingeniería de datos y visualización para el proyecto de Treceability, con una visión global. Requisitos Ingeniero de Datos para el proyecto de Treceability, Conocimiento en Modelado de Datos, en Ingesta de Datos y visualización. Ingeniero de Datos para el proyecto de Treceability Conocimiento en Modelado de Datos, en Ingesta de Datos y visualización +2-3 años SQL DB +1 año Experiencia en Snowfalake DB, deseable +1 año Experiencias en Ingesta de Datas vis ETLs, o Replicadores Five Tran o Informatica +2 años Experiencia en Power BI. + Ofrecemos 100% Nominal Legal Benefits Benefits Package Wellness Program Professional development plan Multicultural collaboration Come and meet us on: http://www.neoris.com , on Facebook, LinkedIn, Twitter, or Instagram @NEORIS. Hector Antonio Hernandez Sanchez / sanchez.hector@neoris.com",https://mx.linkedin.com/jobs/view/data-engineer-visualization-at-neoris-4025921741,4025921741,"We are looking for a Data Engineer for the Traceability project, responsible for data engineering and visualization with a global perspective. The candidate should have knowledge in Data Modeling, Data Ingestion, and visualization, with over 2-3 years of experience in SQL DB, 1 year of experience in Snowflake DB, and over 2 years of experience in Power BI. Experience with ETL data ingestion or replicators like FiveTran or Informatica is also desired.","SQL, Snowflake, Power BI, ETL, Data Modeling",2-3,,False,2.0,0,0,0,0,0,1,1,1,1,1,0,0,0,0,0,0,0
Data Engineer,Azkait,Monterrey Metropolitan Area,HYBRID,,Full-time,"Technology, Information and Internet",2024-07-17 11:26:01.950696,25,Information Technology,,,"AZKAIT es una empresa Mexicana que busca y conecta el mejor talento IT con empresas Latinoamericanas y de Estados Unidos. Estamos en la búsqueda de tu talento como Data Engineer. Requisitos: Data Engineer Como Data Engineer trabajarás junto a una importante empresa multinacional de soluciones comerciales de consultoría y de servicios de TI. Requisitos: A partir de 4 años de experiencia como Data Engineer Inglés conversacional (se hará evaluación) Licenciatura o Ingeniería concluida Skills: Python Pyspark y Hive SQL Airflow Azure Snowflake (básico) Responsabilidades: Trabajar en soluciones de ingeniería de datos, perfilar datos, desarrollar una ingesta eficiente y construir capas de datos semánticos. Gestión de flujo de trabajo y canalización de datos: Airflow, Azure DataFlow, etc. Servicio DataBricks Servicios en la nube y herramientas de análisis de datos: Databricks, Snowflake, Azure ADLS Gen2, Azure/GCP Beneficios: Esquema de contratación 100% nómina Sueldo competitivo de hasta $90,000 mensuales brutos Modalidad de trabajo híbrido SGMM para el colaborador y su familia directa Seguro de Vida Vales de despensa PTU de ley Aguinaldo de 30 días Vacaciones de ley Certificaciones gratuitas Lugar de trabajo: Modalidad de trabajo híbrido Es importante contar con disponibilidad para presentarse en las oficinas más cercanas ubicadas en: CDMX, Querétaro, Nuevo León, Jalisco",https://mx.linkedin.com/jobs/view/data-engineer-at-azkait-3954350879,3954350879,"As a Data Engineer, you will work with a significant multinational company providing consulting and IT services. The responsibilities include working on data engineering solutions, profiling data, developing efficient ingestions, and building semantic data layers. You will also manage workflows and data pipelines using tools like Airflow and Azure DataFlow.","Python, Pyspark, Hive SQL, Airflow, Azure, Snowflake, Databricks, Azure ADLS Gen2, GCP",4+ years,Bachelor,True,4.0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0
Data Engineer,SEIDOR Analytics,Monterrey Metropolitan Area,HYBRID,Entry level,Full-time,Information Technology & Services,2024-09-13 11:26:01.950696,25,Information Technology,,,"En SEIDOR Analytics buscamos perfiles de Data Engineer para incorporarse a nuestro equipo de México. ¿Qué es lo que necesitas para formar parte de nuestro TEAM? ✔Experiencia comprobable en posición similar ✔Conocimientos de herramientas de base de datos, datawarehousing y ETL ✔Experiencias con alguna de las siguientes tecnologías: SAP (SAP Datawarehouse Cloud, SAP Analytics Cloud, SAP BW, HANA, etc.) / Cloud Analytics (Azure / AWS / Snowflake) ✔Inglés (no excluyente) ✔Comunicación efectiva, orientación al cliente y trabajo en equipo serán competencias valoradas para este perfil ✔Estar ubicados en Monterrey o CDMX. ¿Qué ofrecemos? ✔Formar parte de un gran equipo internacional, con más de 20 años de experiencia en Analytics, orientado al logro y al cliente. ✔Día libre de cumpleaños ✔Obsequios en fechas especiales ✔Clases de inglés in company ✔Capacitación continua y posibilidad de certificarte con nuestros partners. Envíanos tu CV a: talent@seidoranalytics.com para conocerte, contarte sobre la propuesta y nuestros beneficios.",https://mx.linkedin.com/jobs/view/data-engineer-at-seidor-analytics-4025659981,4025659981,"In SEIDOR Analytics, we are looking for Data Engineer profiles to join our team in Mexico. You need proven experience in a similar position, knowledge of database tools, data warehousing, and ETL. Experience with technologies such as SAP (SAP Datawarehouse Cloud, SAP Analytics Cloud, SAP BW, HANA, etc.) / Cloud Analytics (Azure / AWS / Snowflake) is required. English is not mandatory. Effective communication, customer orientation, and teamwork will be valued skills for this profile.","SAP, SAP Datawarehouse Cloud, SAP Analytics Cloud, SAP BW, HANA, Azure, AWS, Snowflake, ETL, Data Warehousing",Proven experience required,,False,,0,0,0,1,0,1,1,0,0,0,0,0,0,0,0,0,0
Data Analyst,Dematic,Monterrey Metropolitan Area,HYBRID,Associate,Full-time,"Transportation, Logistics, Supply Chain and Storage",2024-09-08 11:26:01.950696,116,Purchasing,Analyst,,"Company Overview Dematic is an intralogistics innovator who designs, builds, and supports intelligent, automated solutions for manufacturing, warehouse and distribution environments for customers powering the future of commerce. With engineering centers, manufacturing facilities and service centers located in more than 25 countries, Dematic’s global network of 8,000 employees have helped achieve more than 6,000 worldwide customer installations for some of the world’s leading brands. Headquartered in Atlanta, Georgia, Dematic is a member of KION Group, a global leader in industrial trucks, supply chain solutions and related services, and a leading provider of warehouse automation. Job Summary Dematic member of KION Group is seeking a qualified candidate for the role of Data Analyst, Global Data Management to join our organization to drive consistent, complete, and accurate data and high-quality procurement decision-making. The Analyst’s primary responsibility is to enable improved procurement performance by conducting analysis on procurement data. The candidate will work within the Global Procurement Functions – Governance & Process Excellence group supporting Category Leads as well as other Procurement colleagues to meet the company’s business requirements. In this role, the Analyst will assist Procurement colleagues in multiple KION sites across North America, and Europe, with high-quality procurement master data including supplier information, spend breakdown, procurement saving initiatives primarily. This is What You Will do in This Role: Maintain standard and governance across Business Units on data management Receive and document Business Intelligence and reporting requirements from stakeholders }Provide procurement data and reporting to the Procurement organization to identify synergies between business and operating units and support decision making process Provide accurate, reliable and updated data to obtain category KPIs to support strategy implementation Ensure data availability and readiness to timely support strategic decisions and CTO flight plan implementation Provide good quality and reliable data to analyze KION supplier base to identify opportunities Keep key procurement data up to date in procurement tools Identify and extract relevant data and run analysis Rollout KION Procurement Data Business Intelligence dashboards Define target and actions to measure data in terms of accuracy, completeness, consistency, timeliness, integrity, uniqueness What We are Looking For: Bachelor’s Degree in Engineering, Computer Science, Supply Chain, Accounting, Finance or Statistics , or related. 3+ years’ experience in Procurement, Supply Chain, Finance or Business Familiarity with purchasing and supply chain management and procurement processes Advanced analytical skills with expertise in Microsoft Excel (MS Excel) – Pivot table minimum, Power Point and Business Intelligence (BI) tools like Power BI, Tableau or Qlik Experience with Snowflake or other SQL Database system Experience in working with SAP Module MM, knowledge for FI module (Preferred) Manipulate large data sets through standard analytics software packages and applications Capability with data inquiry / investigation Data consolidation & presentation skills. Ability to analyze, synthesize information from diverse sources, present findings clearly / concisely, and communicate that analysis effectively to business partners Strong communicator and ability to manage/prioritize multiple key activities simultaneously Self-driven individual, able to work with minimal direction to consistently look for opportunities Work cross-functionally in a culturally diverse environment and quickly build strong rapport and relationships with Procurement partners, including interaction with Senior Leaders and working across multiple regions/time",https://mx.linkedin.com/jobs/view/data-analyst-at-dematic-4015082180,4015082180,"Dematic is seeking a qualified candidate for the role of Data Analyst, Global Data Management to drive consistent, complete, and accurate data for high-quality procurement decision-making. The primary responsibility is to enable improved procurement performance by conducting analysis on procurement data. The Analyst will assist Procurement colleagues across multiple KION sites with high-quality procurement master data and provide accurate data and reporting to support decision-making processes.","Microsoft Excel, Power BI, Tableau, Qlik, Snowflake, SQL, SAP MM, SAP FI",3+ years,Bachelor,True,3.0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0
Data Engineer,Chubb,Monterrey Metropolitan Area,HYBRID,Entry level,Full-time,Insurance,2024-09-15 11:26:01.950696,43,Information Technology,,,"Job Description With you, Chubb is better! Are passionate with data infrastructure, metrics and coding? Do you love creating pipelines to support business? Would you like to be a member of a fun working environment where your innovative projects make a real impact? Then, check this outstanding opportunity in our new Technology Hub in Mexico – CBSM (Chubb Business Services Monterrey) as a Data Engineer. If you are a tech lover and are raring to develop your career join our growing, pioneer, diverse team within one of the largest companies in the world, we would love to hear from you! The Opportunity Your Responsibilities for this role may include, but are not limited to: Conceptualize, support, and drive the data architecture for multiple large-scale projects as well as recommend solutions to improve processes. Integrate data from various sources and build robust, multi-functional data assets to support analytics. Responsible for data asset design, development, integration, and optimization. Must love coding – prepare to spend more than 80% of the time on hands-on development with groundbreaking technologies. Gatekeeper of end-to-end applications and frameworks ranging from system programming to micro-services to simple front-end applications Build pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts. Moreover, clean, unify and organize messy and complex data sets for easy access and analysis. Collaborate with others to understand data needs, representing key data insights in a meaningful way. Ability to own complete project or a subject area delivery while leading team members in a scrum setting. Design, build, and launch collections of sophisticated data models and visualizations that support multiple use cases across different products or domains. Solve our most exciting data integration problems, applying optimal ETL patterns, frameworks, query techniques, sourcing from structured and unstructured data sources. Be the point of reference for solving a challenging technical problem Knowledge, Skills, And Abilities At least 4 years of data/software engineering experience including data analysis, design and integration/ETL. Good knowledge of Informatica Intelligent Cloud Services (IICS) Strong knowledge of Python Experience with SQL Bonus points for PySpark Databricks Snowflake NoSQL Data Modelling Our team makes a difference, every time. For this reason, we offer in return! We offer hybrid working model, explicit, structured career development, a competitive salary package, annual bonus, private medical cover, monthly allowance for lunch, continuous learning experiences, work in a fun, lively environment with mentoring from our groundbreaking senior mentors. Integrity. Client Focus. Respect. Excellence. Teamwork Our core values instruct how we live and work. We’re an ethical and honest company that’s wholly committed to its clients. A business that’s engaged in mutual trust and respect for its employees and partners. A place where colleagues perform at the highest levels. And a working environment that’s collaborative and encouraging. Diversity & Inclusion. At Chubb, we consider our people our chief competitive advantage and as such we treat colleagues, candidates, clients, and business partners with equality, fairness, and respect, regardless of their age, disability, race, religion or belief, gender, sexual orientation, marital status or family circumstances. We strive to achieve an environment where all colleagues feel comfortable performing to their full potential and are recognized for their contributions. Many voices, One Chubb!",https://mx.linkedin.com/jobs/view/data-engineer-at-chubb-3897093237,3897093237,"As a Data Engineer, you will conceptualize, support, and drive the data architecture for multiple large-scale projects, recommend solutions to improve processes, integrate data from various sources, and build robust, multi-functional data assets to support analytics. You will spend over 80% of your time on hands-on development with technologies, build pipelines, dashboards, and systems for easier development of data artifacts, and collaborate with others to understand data needs.","Python, SQL, Informatica Intelligent Cloud Services (IICS), PySpark, Databricks, Snowflake, NoSQL, ETL, Data Modelling",4,,True,4.0,0,0,1,0,0,0,1,0,0,1,0,0,0,0,1,0,0
Data Platform Engineer Manager,Accenture México,Monterrey Metropolitan Area,HYBRID,Mid-Senior level,Full-time,Business Consulting and Services,2024-09-13 11:26:01.950696,25,Engineering,Information Technology,,"DARE TO BE A PART OF THE CHALLENGE! COME AND JOIN OUR TEAM TOGETHER WE CAN MAKE THE DIFFERENCE! Did you know that Accenture is leading the digital transformation in the World? Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Our main purpose is to collaborate with our clients, so they can become high-performance businesses. Accenture is present in more than 200 cities, 49 countries and approximately 732,000 employees worldwide. We Offer Career development according to your profile and interests. Work in one of the best companies and feel proud. Access to an innovative methodology and tools. Direct contact with experts worldwide. Use of work schemes and cutting-edge technologies. Constant training. Work environment based on teamwork and collaboration. Participation in International Projects Skills: +12 years of experience Python SQL AWS S3 Data Management background Qlik Replicate Informatica Scala (Spark) Knowledge: Cloud Silicon Firmware Engineering Python Programming Language Data Architecture Principles Platform Engineering",https://mx.linkedin.com/jobs/view/data-platform-engineer-manager-at-accenture-m%C3%A9xico-3990355001,3990355001,"Accenture is leading the digital transformation globally by providing a broad range of services in strategy, consulting, digital, technology, and operations. The role involves working with cutting-edge technologies, participating in international projects, and accessing innovative methodology and tools.","Python, SQL, AWS S3, Qlik Replicate, Informatica, Scala, Spark",12+ years,,True,12.0,0,0,1,1,0,0,0,0,1,1,0,0,0,0,1,0,0
Security Engineer Leader (Data Protection & Identities),The Home Depot México,Monterrey Metropolitan Area,HYBRID,Mid-Senior level,Full-time,Retail,2024-09-10 11:26:01.950696,25,Information Technology,,,"The Home Depot México está en búsqueda de talento para la posición de Security Engineer Leader (Data Protection & Identities) con sede en San Pedro Garza García, N.L. Objetivo del puesto: Asegurar la confidencialidad, integridad y disponibilidad de los activos de información y los sistemas encargados de almacenar, procesar y transmitir estos activos de información. A través de una metodología de robustecimiento y aseguramiento de aplicativos, una estrategia de prevención de fuga de información. Principales Funciones: Responsable de la gestión de identidad y accesos (Identity Access Management). Supervisión, gestión y revisión de controles y políticas de accesos y permisos. Protección de datos y encriptación (Data Protection). Implementar y mantener reglas o controles de protección de datos y asegurar cumplimiento con la regulaciones existentes en México. Herramientas de gestión de password y accesos RSA y CyberArk. Gestión de soluciones de seguridad de accesos así como, soluciones o herramientas de accesos privilegiados (CyberArk). Gestión de soluciones de encripción (voltage), monitoreo de alertas DLP (Data Lost Protection). Gestión de certificados (internos/externos). Gestión de herramientas de protección y encripción de bases de datos. Apoyar el proceso de Auditoría y Certificación de las diversas normas, leyes y regulaciones a las que está sujeto THDM. Requisitos: Carrera profesional terminada en Ing. En Negocios y Tecnología o similares. Inglés avanzado. Experiencia en puesto similares de 3 a 5 años. Conocimiento en ciclo de vida de las identidades (IAM). Conocimiento en gestión de accesos privilegiados (CyberArk, RSA). Práctica de protección y fuga de información (DLP). Herramientas de encriptación (Voltage). Si cumples con el perfil y esta oportunidad es de tu interés, ¡postúlate por este medio! Todos nuestros procesos de reclutamiento y selección son incluyentes y libres de discriminación; sin importar género, edad, nacionalidad, raza, cultura, religión, estado civil, creencias, discapacidad, orientación sexual, identidad y expresión de género.",https://mx.linkedin.com/jobs/view/security-engineer-leader-data-protection-identities-at-the-home-depot-m%C3%A9xico-4020466138,4020466138,"The Home Depot México is seeking a Security Engineer Leader (Data Protection & Identities) to ensure the confidentiality, integrity, and availability of information assets and systems responsible for storing, processing, and transmitting this information. This includes managing identity and access (Identity Access Management), overseeing controls and access policies, protecting data and encryption (Data Protection), and ensuring compliance with regulations in Mexico.","Identity Access Management, Data Protection, RSA, CyberArk, DLP, Voltage",3 to 5 years,Bachelor,True,3.0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
Data Analyst,Chubb,Monterrey Metropolitan Area,HYBRID,Entry level,Full-time,Insurance,2024-09-08 11:26:01.950696,25,Information Technology,,,"Job Description Overview: Chubb's North America data delivery team provides business insights, data management, and business and data analysis to North America. As a Data Analyst, you will be responsible for conducting a detailed analysis of various data sources to identify trends, patterns, and insights that will support strategic decision-making. Additionally, you will perform quality assurance tasks to ensure data accuracy and integrity across our systems. The ideal candidate will possess strong analytical skills, advanced knowledge of querying languages, and a keen eye for detail. Role Summary: Partner with business teams to analyze requirements and identify data sources needed for analytics/reporting applications with medium level complexity Establish open data standards, metadata management policies and data classifications. Conduct full data lifecycle analysis to develop new insights for analytics and reporting dashboards Partner with business and tech teams to develop testing requirements, procedures and corrective actions to ensure data products meet quality standards Provide recommendations to address data quality issues with source systems. Communicate approaches with cross functional teams Establish open data standards, metadata management policies and data classifications Responsibilities: Comprehend and adhere to all data security policies and procedures Create data tools for analytics and data scientist team members Build analytical tools to provide actionable insights into key business KPIs, etc Work with data engineers to optimize pipelines for scalability and data delivery Qualifications Functional Competencies Working knowledge with data and analytics framework supporting data lakes, warehouses, marts, reporting, etc Experience with data tools for visualizations, analytics and reporting Knowledge of testing policies, procedures and the role testing performs within the software development lifecycle Strong analytical skills with ability to research, assess and develop observations/findings Ability to communicate findings, approaches to cross functional teams and stakeholders. Technical competencies 3+ years' hands-on experience with a data science background Some programming skills in Java, Python and SQL Clear hands-on experience with database systems - Cloud technologies (e.g. AWS, Azure, Google), in-memory database systems (e.g. HANA, Hazel cast, etc) and other database systems - traditional RDBMS (e.g. Teradata, SQL Server, Oracle), and NoSQL databases (e.g. Cassandra, MongoDB, DynamoDB) Education, Knowledge, Experience: Background in SQL, databases and/or data science OR BS/MS in software engineering, computer science, mathematics Experience working with global teams is a must. English proficiency is a must.",https://mx.linkedin.com/jobs/view/data-analyst-at-chubb-4018776894,4018776894,"As a Data Analyst, you will be responsible for conducting a detailed analysis of various data sources to identify trends and insights that support strategic decision-making. Additionally, you will ensure data accuracy and integrity across systems. This role involves partnering with business teams to analyze requirements, establishing data standards and classifications, and developing testing requirements to ensure quality standards of data products. Responsibilities include creating data tools, building analytical tools, and working with data engineers to optimize pipelines for scalability and delivery.","Java, Python, SQL, AWS, Azure, Google Cloud, HANA, Hazelcast, Teradata, SQL Server, Oracle, Cassandra, MongoDB, DynamoDB",3+ years,Bachelor,True,3.0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0
Data Engineer Analyst,NEORIS,Monterrey Metropolitan Area,HYBRID,Entry level,Full-time,IT Services and IT Consulting,2024-09-14 11:26:01.950696,25,Information Technology,,,"NEORIS is a Digital accelerator that helps companies enter the future, having 20 years of experience as Digital Partners of some of the largest companies in the world. We are more than 4,000 professionals in 11 countries, with our multicultural startup culture where we cultivate innovation and continuous learning to create high-value solutions for our clients. We are looking for a Data Engineer Analyst: (Hybrid position in Monterrey) Controls and coordinates the approved commercial data process with rules, information, data, KPIs, times and actions to improve. Advise and manage all commercial efforts aimed at improving the experience of our clients in the Business processes. Main Responsibilities Reporting systematic errors and other data issues related to the data and information under governance Making corrections to data or data systems Identifying root causes of recurring errors and reporting these for potential remediation Reporting incidents of non-compliance to approved data governance policies and procedures Recommending new data governance policies and procedures or modifications to existing data governance policies and procedures based on new or emerging business practices that impact the data and information under governance Actively promote and communicate data governance to all USA Data Community members Provide necessary data-related training Design and implement procedures and standards as to ensure conformance with the data governance policies Collect and organize data specifications and metadata, such as: Business glossary, Data dictionaries, Data quality rules, Business rules including regulatory compliance, Reference data management, Data Issue tracking Promote Data Culture and Data Sharing Behavior across business units. Enforce Safe and Responsible Behaviors in the Data Mgmt. Processes Enforce Data Sharing practices. Review and ensure proper Data Assets Mgmt. Supervise proper practices to make sure Data Completeness and Integrity in the Data creation., Data processing and Data archiving. Observe and enforce local (global and legal normative and Information Security policies Requirements Fluent English and Spanish Academic Background: Analytics master’s degree or similar, 2 - 3 years in data management areas or similar Areas of expertise: Business / Operation, Process & IT, Analytics, adoption of digital tools Technical Skills required by role: Software skills for data collection and presentation, Advanced Excel, Statistical programming knowledge, Ability to articulate data-driven decisions, ability to summarize and present data, well versed in the latest innovations and trends in the market related to data manipulation product and services. Programming languages: SQL and Python or similar. Soft Skills: Self-motivated, highly engaged, problem solving, motivated for digital technology, managing uncertainty, critical thinking, time management of projects and relationships We Offer 100% nominal scheme. Professional Growth Dynamic work environment Benefits plan. Legal benefits Development Opportunities We invite you to get to know us at http://www.neoris.com, Facebook, LinkedIn, Twitter or Instagram: @NEORIS. Arantza Cervantes",https://mx.linkedin.com/jobs/view/data-engineer-analyst-at-neoris-4025921745,4025921745,"We are looking for a Data Engineer Analyst who controls and coordinates the approved commercial data process with rules, information, KPIs, and actions to improve the client experience in business processes. Responsibilities include reporting errors, managing data governance, and promoting data culture.","SQL, Python, Advanced Excel, Statistical programming",2 - 3,Masters,True,2.0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,1,0,0
Data Platform Engineer Senior Analyst,Accenture México,Monterrey Metropolitan Area,HYBRID,Mid-Senior level,Full-time,Business Consulting and Services,2024-09-13 11:26:01.950696,55,Engineering,Information Technology,,"DARE TO BE A PART OF THE CHALLENGE! COME AND JOIN OUR TEAM TOGETHER WE CAN MAKE THE DIFFERENCE! Did you know that Accenture is leading the digital transformation in the World? Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Our main purpose is to collaborate with our clients, so they can become high-performance businesses. Accenture is present in more than 200 cities, 49 countries and approximately 743,000 employees worldwide. Offer Career development according to your profile and interests. Work in one of the best companies and feel proud. Access to an innovative methodology and tools. Direct contact with experts worldwide. Use of work schemes and cutting-edge technologies. Constant training. Work environment based on teamwork and collaboration. Participation in International Projects Mandatory Skills: +4 years of experience Your primary skill in Python will be utilized to develop and maintain the platform. Utilize AWS development skills to optimize the performance of the data platform. Activities: As a Mid Level Data Platform Engineer, you will be responsible for designing, building, and maintaining clients data platform. You will work closely with the data science and machine learning teams to ensure the platform meets their needs.",https://mx.linkedin.com/jobs/view/data-platform-engineer-senior-analyst-at-accenture-m%C3%A9xico-3875043968,3875043968,"As a Mid Level Data Platform Engineer, you will be responsible for designing, building, and maintaining clients' data platform, working closely with data science and machine learning teams to ensure the platform meets their needs.","Python, AWS, Data Platform, Machine Learning",4+ years,,True,4.0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,1,0,0
Azure Data Engineer,Sequoia Connect,Monterrey Metropolitan Area,HYBRID,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-08 11:26:01.950696,25,Information Technology,,,"Our client is a global leader in next-generation digital services and consulting. They enable clients in more than 50 countries to navigate their digital transformation. With over four decades of experience in managing the systems and workings of global enterprises, they expertly steer their clients through their digital journey. They do it by enabling the enterprise with an AI-powered core that helps prioritize the execution of change. They also empower the business with agile digital at scale to deliver unprecedented levels of performance and customer delight. Their always-on learning agenda drives their continuous improvement through building and transferring digital skills, expertise, and ideas from their innovation ecosystem. We are currently searching for an Azure Data Engineer: Responsibilities: Work on a hybrid model in any of our client’s locations (Mexico City, Guadalajara, or Monterrey). Provide production support and development in a data engineering environment. Design, implement, and maintain robust and scalable data pipelines on Azure. Troubleshoot performance issues, identify root causes and apply fixes. Implement and manage CI/CD pipelines for data engineering projects using Azure DevOps. Requirements: 3+ years of experience designing, implementing, and maintaining data pipelines on Azure with services such as Azure Data Factory, Azure SQL Data Warehouse, Azure Analysis Services, or Azure Databricks/Synapse/Fabric. 2+ years of experience in data platform design/architecture with a multi-layered approach. 2+ years of experience in troubleshooting performance issues. 3+ years of experience in SQL. Ability to implement CI/CD pipelines for data engineering projects. Languages Advanced Oral English. Native Spanish. Note: Hybrid (Guadalajara, Mexico City, Monterrey) If you meet these qualifications and are pursuing new challenges, Start your application to join an award-winning employer. Explore all our job openings | Sequoia Career’s Page: https://www.sequoia-connect.com/careers/.",https://mx.linkedin.com/jobs/view/azure-data-engineer-at-sequoia-connect-4017678551,4017678551,"We are currently searching for an Azure Data Engineer responsible for providing production support and development in a data engineering environment. The role includes designing, implementing, and maintaining robust and scalable data pipelines on Azure, troubleshooting performance issues, and implementing CI/CD pipelines for data engineering projects using Azure DevOps.","Azure Data Factory, Azure SQL Data Warehouse, Azure Analysis Services, Azure Databricks, Azure Synapse, SQL, Azure DevOps, CI/CD",3+ years,,True,3.0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,0,0,0
Senior Data Engineer,Endava,Monterrey Metropolitan Area,HYBRID,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-08-16 11:26:01.950696,25,Information Technology,,,"Company Description Technology is our how. And people are our why. For over two decades, we have been harnessing technology to drive meaningful change. By combining world-class engineering, industry expertise and a people-centric mindset, we consult and partner with leading brands from various industries to create dynamic platforms and intelligent digital experiences that drive innovation and transform businesses. From prototype to real-world impact - be part of a global shift by doing work that matters. Job Description Our data team has expertise across engineering, analysis, architecture, modeling, machine learning, artificial intelligence, and data science. This discipline is responsible for transforming raw data into actionable insights, building robust data infrastructures, and enabling data-driven decision-making and innovation through advanced analytics and predictive modeling. As a Data Engineer at Endava you will be responsible for designing, implementing, and managing the data infrastructure of the projects. You will be work closely with data scientists, software engineers, and other stakeholders to ensure the availability, usability, and integrity of data. Responsibilities: Designing, building, and deploying solutions that increase product reliability and organizational efficiency Motivating and guiding the creation of effective CI/CD pipelines Providing mentorship and insight into DevSecOps best-practices Working with product teams to expose their requirements and support the above Improving reliability via root cause analyses, post-mortems, and using code to prevent recurrence Implementing effective monitoring and security scanning Assisting support teams in resolving issues Demonstrating and evangelizing state of the art technologies and practices that can be used to build and improve better workflows Discovering and implementing automation to reduce manual support requirements Providing emergency after-hours support if needed Qualifications Degree or diploma in Computer Sciences or related fields, or equivalent work experience 8-10 years of experience as a software engineer and writing Infrastructure-and Configuration-as-Code Excellent English written and verbal communication skills Highly proficient in AWS design and architecture Professional level AWS Certification a significant asset Highly experienced with Terraform and or AWS CloudFormation Experience with Infrastructure- and Configuration-as-Code Experience with CI/CD pipeline systems such as Jenkins and GitLab Experience with Git in a multi-team environment Some experience with containers and containers-as-a-service systems, such as EKS Experience with log aggregation systems such as Splunk, Datadog, or Sumo Logic Experience with APM solutions and infrastructure monitoring solutions an asset Desire to push themselves and learn new things Additional Information Discover some of the global benefits that empower our people to become the best version of themselves: Finance: Competitive salary package, share plan, company performance bonuses, value-based recognition awards, referral bonus; Career Development: Career coaching, global career opportunities, non-linear career paths, internal development programmes for management and technical leadership; Learning Opportunities: Complex projects, rotations, internal tech communities, training, certifications, coaching, online learning platforms subscriptions, pass-it-on sessions, workshops, conferences; Work-Life Balance: Hybrid work and flexible working hours, employee assistance programme; Health: Global internal wellbeing programme, access to wellbeing apps; Community: Global internal tech communities, hobby clubs and interest groups, inclusion and diversity programmes, events and celebrations.",https://mx.linkedin.com/jobs/view/senior-data-engineer-at-endava-3977692343,3977692343,"As a Data Engineer, you will be responsible for designing, implementing, and managing the data infrastructure of projects, collaborating with data scientists and software engineers to ensure data availability, usability, and integrity. You will design and deploy solutions to enhance product reliability and efficiency, create effective CI/CD pipelines, and mentor best practices in DevSecOps. Your role includes improving reliability through root cause analyses, implementing monitoring and security scanning, and supporting teams in issue resolution.","AWS, Terraform, AWS CloudFormation, CI/CD, Jenkins, GitLab, Git, EKS, Splunk, Datadog, Sumo Logic",8-10 years,,True,8.0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0
Data Platform Engineer Senior,Accenture México,Monterrey Metropolitan Area,HYBRID,Mid-Senior level,Full-time,Business Consulting and Services,2024-09-13 11:26:01.950696,33,Engineering,Information Technology,,"DARE TO BE A PART OF THE CHALLENGE! COME AND JOIN OUR TEAM TOGETHER WE CAN MAKE THE DIFFERENCE! Did you know that Accenture is leading the digital transformation in the World? Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Our main purpose is to collaborate with our clients, so they can become high-performance businesses. Accenture is present in more than 200 cities, 49 countries and approximately 732,000 employees worldwide. We Offer Career development according to your profile and interests. Work in one of the best companies and feel proud. Access to an innovative methodology and tools. Direct contact with experts worldwide. Use of work schemes and cutting-edge technologies. Constant training. Work environment based on teamwork and collaboration. Participation in International Projects Mandatory Skills: +4 years of experience Your primary skill in Python will be utilized to develop and maintain the platform. Utilize AWS development skills to optimize the performance of the data platform Activities: Responsibilities As a Mid Level Data Platform Engineer, you will be responsible for designing, building, and maintaining clients data platform. You will work closely with the data science and machine learning teams to ensure the platform meets their needs.",https://mx.linkedin.com/jobs/view/data-platform-engineer-senior-at-accenture-m%C3%A9xico-3875043971,3875043971,"As a Mid Level Data Platform Engineer, you will be responsible for designing, building, and maintaining clients' data platforms. You will utilize your primary skill in Python to develop and maintain the platform, while also applying AWS development skills to optimize performance. You will work closely with data science and machine learning teams to ensure the platform meets their needs.","Python, AWS, Data Platforms, Machine Learning",4+,,True,4.0,0,0,0,1,0,1,1,0,0,0,0,0,1,0,1,0,0
Data Governance and Management Engineer,Arca Continental,Monterrey Metropolitan Area,HYBRID,Associate,Full-time,Food and Beverage Services,2024-09-12 11:26:01.950696,25,Information Technology,,,"Nuestra compañía Arca Continental es una empresa dedicada a la producción, distribución y venta de bebidas no alcohólicas de las marcas propiedad de The Coca-Cola Company, así como botanas saladas bajo las marcas Bokados en México, Inalecsa en Ecuador y Wise en los Estados Unidos. Con una destacada trayectoria de más de 98 años, Arca Continental es la segunda embotelladora de Coca-Cola más grande de América Latina y una de las más importante del mundo. En su franquicia de Coca-Cola, la empresa atiende a una población de más de 119 millones en la región norte y occidente de México, así como en Ecuador, Perú, la región norte de Argentina y la región suroeste de Estados Unidos. Arca Continental cotiza en la Bolsa Mexicana de Valores bajo el símbolo ""AC"". Misión del puesto Diseñar, implementar y gestionar soluciones de Administración de Datos (Maestros, Transaccionales, de Referencia y Metadata) desde la perspectiva Técnica como de Gobierno de Datos, atendiendo los requerimientos de negocio y garantizando el ciclo de vida de los mismos en los diferentes dominios de AC (Clientes, Productos, etc.), para que la información requerida pueda ser utilizada para decisiones basadas en hechos, asegurando calidad, disponibilidad e integridad. Responsabilidades clave Implementar y Asegurar, Mejoras técnicas en los procesos para asegurar el correcto funcionamiento del Gobierno de Datos Diseñar y Documentar, Estándares y Reglas para el correcto funcionamiento del Ciclo de vida de los datos, considerando particularidades de cada una de las unidades de negocio dentro de AC Asegurar y mantener, La efectiva operación de las soluciones de calidad y administración para los procesos de datos maestros con la finalidad de garantizar el mantenimiento de la información de acuerdo con los estándares establecidos siempre impulsando la cultura Data Driven. Implementar y Desarrollar, Herramientas que permitan implementar el Gobierno de Datos dentro de AC, ya sean Data Catalog, MDM, Data Quality en todas las Unidades de Negocio de AC. Cualificaciones y requerimientos Título Universitario es requerido, preferentemente carreras de sistemas o afines Idiomas: Inglés Avanzado (Lectura, Escritura y Conversacional) Conocimiento avanzado en herramientas de Gestión de Datos e Información, como Administración de Datos Maestros / MDM, Calidad de Datos, Catalogo de Datos, Gobierno de Datos, etc. Conocimiento técnico avanzado en fuentes de datos de SAP (ECC, S/4, CRM, etc) Capacidad para modelar y comunicar ideas complejas a diferentes audiencias (interacción con equipos multidisciplinarios). Habilidad para administrar problemas de alta complejidad y analizarlos desde diferentes puntos de vista. Trabajo en equipo, planeación y gestión de proyectos. Características deseables Conocimiento de los procesos de negocio (Comercial, Cadena de Suministro, Finanzas) es un plus. Experiencia en la industria de Fast-Moving Consumer Goods Experiencia en proyectos globales. Nuestro compromiso Arca Continental es una empresa que ofrece igualdad de oportunidades. Las decisiones de contratación se toman sin distinción de raza o etnia, color, religión, nacionalidad, sexo, orientación sexual, identidad de género, edad, discapacidad, estatus de veterano protegido o alguna otra característica protegida por la ley. Nunca solicitaremos ningún tipo de pago para procesar su solicitud de empleo ni en ninguna otra etapa del proceso de selección. Nunca le envíe dinero a nadie que sugiera que puede darle empleo en Arca Continental. Si sospecha que ha recibido una oferta fraudulenta, repórtelo con las autoridades correspondientes.",https://mx.linkedin.com/jobs/view/data-governance-and-management-engineer-at-arca-continental-4022944549,4022944549,"The mission of the position is to design, implement, and manage Data Management solutions (Master, Transactional, Reference, and Metadata) from both a Technical and Data Governance perspective, addressing business requirements and ensuring their lifecycle across different domains. Key responsibilities include implementing technical improvements for effective Data Governance, designing and documenting standards and rules for data lifecycle management, ensuring the operation of data quality solutions, and developing tools for Data Governance across AC's business units.","Data Management, MDM, Data Quality, Data Governance, SAP (ECC, S/4, CRM), Data Catalog",,Masters,True,,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0
Data Engineer,NEORIS,Monterrey Metropolitan Area,HYBRID,Entry level,Full-time,IT Services and IT Consulting,2024-09-01 11:26:01.950696,62,Information Technology,,,"NEORIS es una aceleradora Digital que ayuda a las empresas a entrar al futuro, contando con 20 años de experiencia como Digital Partners de algunas de las empresas más grandes del mundo. Contamos con más de 4.000 profesionales en 11 países, con nuestra cultura startup multicultural donde cultivamos la innovación, el aprendizaje continuo para crear soluciones de alto valor para nuestros clientes. Estamos buscando Data Engineer Sr Descripción General Carreras de Ingeniería (Computación, Electrónica, Mecatrónica, etc.), Matemáticas Aplicadas, Actuaría, Física, Matemáticas, o carreras afines. Monterrey Nuevo León, México. Posición híbrida. Inglés intermedio avanzado Conocimiento en Modelado de Datos, en Ingesta de Datos, Deseable conocimiento en temas Logistica y SAP Requerimientos +3 Años SQL DB +1 Año Experiencia en Snowflake DB +2 Años Experiencias en Ingesta de Datas vis ETLs, o Replicadores Five Tran o Informatica +2 años Experiencia en Power BI. + SAP deseable Deseable conocimiento en temas Logistica y SAP Responsable de +2 personas Fivetran ETL, Power Bi, Snowflake Data Warehouse, Sql (Importante) Ofrecemos Esquema 100% Nominal Prestaciones de Ley Paquete de Beneficios Programa Bienestar Plan de desarrollo profesional Colaboración multicultural Te invitamos a conocernos en http://www.neoris.com, Facebook, LinkedIn, Twitter o Instagram: @NEORIS. Andrea Arantza Cervantes Romero",https://mx.linkedin.com/jobs/view/data-engineer-at-neoris-3977451215,3977451215,"We are looking for a Senior Data Engineer with a background in Engineering (Computer, Electronics, Mechatronics, etc.), Applied Mathematics, Actuarial Science, Physics, Mathematics, or related fields. The role is hybrid based in Monterrey, Nuevo León, Mexico. The ideal candidate should have intermediate to advanced English skills, experience in Data Modeling, Data Ingestion, and preferably knowledge in Logistics and SAP.","SQL, Snowflake, ETL, Fivetran, Informatica, Power BI, SAP",3+ years,,True,3.0,0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,0,0
Data Engineer Senior,NEORIS,Monterrey Metropolitan Area,HYBRID,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-08 11:26:01.950696,47,Information Technology,,,"NEORIS es un acelerador Digital que ayuda a las compañías a entrar en el futuro, teniendo 20 años de experiencia como Socios Digitales de algunas de las mayores compañías del mundo. Somos más de 4,000 profesionales en 11 países, con nuestra cultura multicultural de startup en donde cultivamos innovación, aprendizaje continuo para crear soluciones de alto valor para nuestros clientes. Principales Responsabilidades Estamos en búsqueda de Data Engineer Senior: Ingeniero de Datos SR para Modelado de Datos, Ingesta de Datos, Visualización de Datos Requerimientos +3 Años SQL DB +1 Año Experiencia en Snowflake DB +2 Años Experiencias en Ingesta de Datas vis ETLs, o Replicadores Five Tran o Informatica +2 años Experiencia en Power BI Posición híbrida en MTY Inglés intermedio B2, fluido. Deseable: Deseable conocimiento en temas Financieros, contables, y SAP Ofrecemos Esquema 100% Nominal Prestaciones de Ley Paquete de Beneficios Programa Bienestar Plan de desarrollo professional Colaboración multicultural Te invitamos a conocernos en http://www.neoris.com, Facebook, LinkedIn, Twitter o Instagram: @NEORIS. Andrea Arantza Cervantes Romero",https://mx.linkedin.com/jobs/view/data-engineer-senior-at-neoris-3931873676,3931873676,"We are looking for a Senior Data Engineer for Data Modeling, Data Ingestion, and Data Visualization.","SQL, Snowflake, ETL, Five Tran, Informatica, Power BI",3+ years,,True,3.0,0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,0,0
Data Scientist Intern,Siemens,Monterrey Metropolitan Area,ON-SITE,Internship,Full-time,Automation Machinery Manufacturing,2024-09-11 11:27:40.933821,193,Other,,,"We are looking for dedicated and talented people who tackle ever-changing challenges, customer needs, and questions from colleagues with clever concepts and creativity. We embrace change and work with curious minds re-inventing the future of work. Join us and let us focus together on what’s truly important: making lives better with new ideas and the latest technology around the world. Why you’ll love working for Siemens! Freedom and a healthy work- life balance– Embrace our flexible work environment with flex hours, telecommuting and digital workspaces. Solve the world’s most significant problems – Be part of exciting and innovative projects. Engaging, challenging, and fast evolving, cutting edge technological environment. Opportunities to advance your career and mentorship programs on a local and global scale. Contribute to our social responsibility initiatives focused on access to education, access to technology and sustaining communities and make a positive impact on the community. Participate in our celebrations, social events and offsite business events. Opportunities to contribute your innovative ideas and get rewards for them! Diversity and inclusivity focused. We are looking for a highly motivated and talented Data Scientist to join our team. The ideal candidate will be passionate about data analysis, statistical modeling, and creating data-driven solutions that drive the success of our company. What will you do? Perform complex data analysis to identify trends, patterns, and opportunities for improvement. Develop machine learning models for business decision making. Collaborate with other teams to understand and define data analysis requirements. Prepare and clean data for analysis. Communicate analysis results effectively through reports and presentations. Stay abreast of the latest trends in data science and related technologies. What will you need to succeed? Current student in Data Science, Statistics, Mathematics, Computer Engineering, or related field. Previous experience in data analysis and statistical modeling. Solid knowledge of data analysis tools such as Python, R, Pandas, Numpy, SciPy, Scikit-learn, Matplotlib and TensorFlow or similar tools. Experience using machine learning libraries and frameworks. Ability to effectively communicate technical results to non-technical audiences. Strong problem-solving skills and attention to detail. Ability to work as a team and adapt to a constantly changing business environment. Equal Employment Opportunity Statement Siemens is an Equal Opportunity and Affirmative Action Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to their race, color, creed, religion, national origin, citizenship status, ancestry, sex, age, physical or mental disability, marital status, family responsibilities, pregnancy, genetic information, sexual orientation, gender expression, gender identity, transgender, sex stereotyping, protected veteran or military status, and other categories protected by federal, state or local law. Location: Santa Catarina, Nuevo Leon",https://mx.linkedin.com/jobs/view/data-scientist-intern-at-siemens-4005909465,4005909465,"We are looking for a highly motivated and talented Data Scientist to join our team. The ideal candidate will be passionate about data analysis, statistical modeling, and creating data-driven solutions. Responsibilities include performing complex data analysis, developing machine learning models, collaborating with teams to define data requirements, preparing data for analysis, and effectively communicating results.","Python, R, Pandas, Numpy, SciPy, Scikit-learn, Matplotlib, TensorFlow, Machine Learning",,Undergraduate Student,True,,0,0,0,0,0,0,0,0,1,0,0,0,1,0,1,0,0
ML Engineer (Engineer Software Development),NEORIS,Monterrey Metropolitan Area,ON-SITE,Entry level,Full-time,IT Services and IT Consulting,2024-09-10 11:27:40.933821,42,Engineering,Information Technology,,"En NEORIS es un acelerador Digital que ayuda a las compañías a entrar en el futuro, teniendo 20 años de experiencia como Socios Digitales de algunas de las mayores compañías del mundo. Somos más de 4,000 profesionales en 11 países, con nuestra cultura multicultural de startup en donde cultivamos innovación, aprendizaje continuo para crear soluciones de alto valor para nuestros clientes. Principales Responsabilidades Estamos en búsqueda de ML Engineer: Soporte de Despliegue de los Modelos que construye el equipo de Ciencia de Datos. Mantenimiento y monitoreo de las aplicaciones en producción, seguimiento a troubleshooting. Requerimientos Graduados en Informática / Ingeniería en sistemas / Masters o especialización en Data Mining / Data Science / Machine Learning / AI / Computer Vision (deseable) +4 años background Desarrollo (Python) +4 años en tecnologías de almacenamiento ( Snowflake, SQL ) +3 años Web services technologies (Creación Microservicios con FastAPI, Django, Flask) Preferably FastAPI +2 años usando herramientas en la nube (Azure, AWS, GCP) / Tecnologías de orquestración o Deploy de modelos (+2 modelos) Docker Contexto de Tecnologías en la Nube (Azure, AWS, GCP) +2 años CI/CD (Pruebas Unitarias, Automatización de Deploy) +2 años aplicando modelos predictivos/prescriptivos (Machine Learning) Mantenimiento y Monitoreo aplicaciones en producción Participación en definición de Arquitecturas de Soluciones / Conocimiento de Mejores Prácticas Ingles conversacional (B2 / C1) Experiencia lidereando equipos remotos multiculturales / Experiencia en Logistics Maestrías, Certificaciones y Cursos sugeridos: IA, Machine Learning, Deep Learning, Cursos Programación, Python / R Soft skills: Solución Problemas (Inteligencia Lógica & Matemática), Atención al detalle, Proactividad, Autoaprendizaje & Autoinvestigación, Trabajo en Equipo, Articulado (buena comunicación oral, escrita), Analítico, Autoadministrado, Perfil Técnico, Innovador, Creativo, Enfocado a resultados y soluciones. Monterrey esquema híbrido, / Otros estados remoto Ofrecemos Esquema 100% Nominal Prestaciones de Ley Paquete de Beneficios Programa Bienestar Plan de desarrollo professional Colaboración multicultural Te invitamos a conocernos en http://www.neoris.com, Facebook, LinkedIn, Twitter o Instagram: @NEORIS. Andrea Arantza Cervantes Romero",https://mx.linkedin.com/jobs/view/ml-engineer-engineer-software-development-at-neoris-4002146229,4002146229,"We are seeking a Machine Learning Engineer to support the deployment of models built by the Data Science team. Responsibilities include maintaining and monitoring applications in production and troubleshooting issues. Candidates should have a background in Python development, experience with storage technologies like Snowflake and SQL, and familiarity with web service technologies such as FastAPI, Django, and Flask. Knowledge of cloud tools (Azure, AWS, GCP) is preferred, along with CI/CD experience.","Python, Snowflake, SQL, FastAPI, Django, Flask, Azure, AWS, GCP, Docker","4+ years in development, 4+ years in storage technologies, 3+ years in web services, 2+ years in cloud tools, 2+ years in CI/CD, 2+ years applying predictive/prescriptive models",Bachelor,True,2.0,0,1,0,1,1,0,0,0,0,1,0,0,0,0,1,0,0
AI Engineer,NEORIS,Monterrey Metropolitan Area,ON-SITE,Entry level,Full-time,IT Services and IT Consulting,2024-09-08 11:27:40.933821,106,Engineering,Information Technology,,"En NEORIS es un acelerador Digital que ayuda a las compañías a entrar en el futuro, teniendo 20 años de experiencia como Socios Digitales de algunas de las mayores compañías del mundo. Somos más de 4,000 profesionales en 11 países, con nuestra cultura multicultural de startup en donde cultivamos innovación, aprendizaje continuo para crear soluciones de alto valor para nuestros clientes. Estamos en búsqueda de AI Engineer: Monterrey híbrido/otros estados remoto Requerimientos Licenciatura o maestría en ciencias de la computación, ingeniería de software, inteligencia artificial, aprendizaje automático o un campo relacionado Experiencia en programación con lenguajes como Python o similares. Conocimiento profundo de las bibliotecas y marcos de trabajo de IA y aprendizaje automático como Scikit Learn, TensorFlow, PyTorch, Keras, etc. Experiencia en el desarrollo y la implementación de modelos de IA generativa Uso de langchain Uso de Bases de datos vectorizadas como Redis, Search AI. Familiaridad con las técnicas de procesamiento de datos y los algoritmos de aprendizaje automático. Familiaridad con herramientas de cloud (AWS, GCP o Azure), preferentemente Azure Manejo de colas (PUB/SUB, Queues ) Web apps (app services o azure/ lambda functions) Experiencia o al menos entendimiento de cómo funciona Docker para realizar paquetes de aplicaciones Experiencia con las bases de datos SQL y NoSQL. (SQL server, CosmosDB. MongoDB) Experiencia en llevar un proyecto end to end ( analisis hasta producción) Fluidez en inglés, tanto escrito como hablado. Deseable: Azure Bots (deseable) Re-entrenamiento de modelos de Generative AI (deseable) Certificaciones (opcional): Certificaciones en inteligencia artificial, aprendizaje automático o ciencia de datos de instituciones reconocidas pueden ser beneficiosas."" Ofrecemos Esquema 100% nómina. Crecimiento Profesional Ambiente laboral dinámimico Plan de beneficios. Prestaciones de ley Oportunidades de Desarrollo Te invitamos a conocernos en http://www.neoris.com, Facebook, LinkedIn, Twitter o Instagram: @NEORIS. Arantza Cervantes",https://mx.linkedin.com/jobs/view/ai-engineer-at-neoris-3984233060,3984233060,"We are looking for an AI Engineer in Monterrey, with hybrid or remote work options. Requirements include a bachelor's or master's degree in computer science, software engineering, artificial intelligence, machine learning, or a related field. Experience in programming with languages like Python or similar, deep knowledge of AI and machine learning libraries and frameworks such as Scikit Learn, TensorFlow, PyTorch, Keras, etc. Experience in the development and implementation of generative AI models. Use of langchain and vectorized databases like Redis, Search AI. Familiarity with data processing techniques and machine learning algorithms. Familiarity with cloud tools (AWS, GCP, or Azure), preferably Azure. Knowledge of queue management (PUB/SUB, Queues) and web apps (app services or Azure/lambda functions). Experience or at least understanding of how Docker works for application packaging. Experience with SQL and NoSQL databases (SQL Server, CosmosDB, MongoDB). Experience in carrying out an end-to-end project (from analysis to production). Fluency in English, both written and spoken.","Python, Scikit Learn, TensorFlow, PyTorch, Keras, Redis, Search AI, AWS, GCP, Azure, Docker, SQL, NoSQL",,Bachelor,True,,0,0,0,1,1,0,0,0,0,1,0,0,1,0,1,0,0
Sr. Data Scientist,Arca Continental,Monterrey Metropolitan Area,ON-SITE,Associate,Full-time,Food and Beverage Services,2024-08-25 11:27:40.933821,79,Information Technology,Sales,,"Sr Data Scientist - Forecast and Segmentation Team Arca Continental is the second largest Coca-Cola bottler in Latin America, with presence in 5 countries. We are looking for a Sr Data Scientist willing to take their skills to the next level. In this position you will be responsible for supporting, improving and creating next generation solutions across the organization. Please apply if you are a Data Scientist with a passion for crunching data, finding insights, taking models to production and have a business/product sense. Responsibilities You will be part of our success by: Design, deliver and iterate highly scalable code in close collaboration with the data engineering team, adhering to established standards of quality for documentation and coding. Apply statistical and machine learning techniques to problems related to forecasting and customer segmentation/classification to add value to our products. Take into production trained models and modeling pipelines in an agile framework. Serve as a mentor to Jr Data Scientists on your team. Design experiments, analyze results and produce trustworthy conclusions from them; present findings to stakeholders. Required Qualifications Bachelor’s degree in Computer Science, Mathematics, Engineering or related field, or a proven track of projects/courses for at least 1 year. At least 12 months of experience working with business centered, applied data science projects. Advanced coding skills for production-ready code in Python and SQL. Advanced experience in machine learning libraries like scikit-learn and Spark ML. Demonstrated knowledge of the theory behind traditional machine learning algorithms. Experience in or desire to learn big data technologies like Spark. Professional written and spoken English. Preferred Qualifications Experience in application deployment in cloud-based infrastructure (e.g. AWS, Azure, GCP). Experience in sale/demand forecasting. Knowledge of agile project development techniques (e.g. Scrum). Experience with deep learning models and frameworks. Passion for data-driven decision making. Employment Type Full-time, hybrid. Location Monterrey Area, Nuevo Leon, Mexico Contact Brissa Romero, brissa.romero@arcacontal.com",https://mx.linkedin.com/jobs/view/sr-data-scientist-at-arca-continental-4002829402,4002829402,"We are looking for a Sr Data Scientist willing to improve and create next generation solutions across the organization. Responsibilities include designing highly scalable code in collaboration with the data engineering team, applying statistical and machine learning techniques for forecasting and customer segmentation, and mentoring Jr Data Scientists. You will also design experiments, analyze results, and present findings to stakeholders.","Python, SQL, scikit-learn, Spark ML, AWS, Azure, GCP, Agile Methodologies, Scrum",1,Bachelor,True,1.0,1,0,1,1,0,0,0,0,0,1,0,0,1,0,1,0,0
Data Scientist Sr,NEORIS,Monterrey Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-01 11:27:40.933821,25,Engineering,Information Technology,,"NEORIS is a Digital accelerator that helps companies enter the future, having 20 years of experience as Digital Partners of some of the largest companies in the world. We have more than 4,000 professionals in 11 countries, with our multicultural startup culture where we cultivate innovation, continuous learning to create high-value solutions for our clients. We Are Looking For a Data Scientist Sr We are seeking a highly skilled and experienced Senior Data Scientist to join our dynamic team. The ideal candidate will lead core data-based projects to provide cutting-edge solutions to our business supply chain, support and mentor junior and experienced talent, and translate business needs into technical requirements or solutions. If you are passionate about data science and have a proven track record of delivering impactful results, we would love to hear from you. Main Responsibilities Project Leadership: Lead and manage core data-based projects aimed at optimizing and innovating our business supply chain processes. Mentorship: Support and mentor junior and experienced data scientists, fostering a collaborative and growth-oriented environment. Business Translation: Understand business needs and translate them into technical requirements or solutions, ensuring alignment with organizational goals. Data Analysis: Perform data manipulation, cleaning, and wrangling to prepare datasets for analysis. Machine Learning: Develop, implement, and evaluate machine learning models to solve complex business problems. Collaboration: Work closely with cross-functional teams to integrate data-driven solutions into business operations. Reporting: Communicate findings and insights to stakeholders through reports, dashboards, and presentations. Hybrid manner Monterrey, other locations remote (México) Requirements Educational Background: Bachelor's degree in a scientific or engineering field is required. A Master's or PhD is desirable. Experience: Minimum of 5+ years of work experience in data science. Technical Skills: Proficiency in Python for data analysis and machine learning. Strong experience querying SQL and NoSQL databases. Expertise in data manipulation, cleaning, and wrangling. Solid background in probability and statistics. Experience with machine learning models’ development and evaluation. Experience deploying data-based products as a solution to business needs. Familiarity with version control systems, particularly Git. Relevant exposure to libraries such as Pandas, NumPy, SciPy, Scikit-Learn, FastAPI, Streamlit. Familiarity with cloud services Azure/AWS/GCP. Analytical Skills: Strong problem-solving skills and the ability to think critically and analytically. Communication: Excellent verbal and written communication skills in english, with the ability to convey complex technical concepts to non-technical stakeholders. Desirable: Advanced Degrees: A Master's or PhD in a relevant field is highly desirable. Industry Experience: Previous experience in supply chain analytics or a related field. Tools & Technologies: Familiarity with additional data science tools and technologies such as R, Hadoop, Spark, or cloud platforms (AWS, Azure, GCP). Certifications: Relevant certifications in data science, machine learning, or related areas. Publications & Contributions: Contributions to the data science community through publications, open-source projects, or conference presentations. We Offer 100% Nominal Scheme Legal Benefits Benefits Package Wellness Program Professional development plan Multicultural collaboration Come and meet us on: http://www.neoris.com, on Facebook, LinkedIn, Twitter, or Instagram @NEORIS. Andrea Arantza Cervantes Romero",https://mx.linkedin.com/jobs/view/data-scientist-sr-at-neoris-3997051344,3997051344,"We are seeking a highly skilled and experienced Senior Data Scientist to lead core data-based projects, support and mentor junior talent, and translate business needs into technical requirements. Responsibilities include performing data analysis, developing and evaluating machine learning models, and collaborating with cross-functional teams to integrate data-driven solutions into business operations.","Python, SQL, NoSQL, Pandas, NumPy, SciPy, Scikit-Learn, FastAPI, Streamlit, Azure, AWS, GCP, Git",5+ years,Bachelor,True,5.0,0,1,0,1,0,0,0,0,0,1,0,1,1,0,1,0,0
Computer Vision Software Developer,SICK Sensor Intelligence,Monterrey Metropolitan Area,ON-SITE,Associate,Full-time,Automation Machinery Manufacturing,2024-09-12 11:27:40.933821,25,Information Technology,Engineering,,"***This position is in our SICK, Monterrey MX office. Located in the Valle Oriente area. The person will work in office Monday through Friday. ABOUT SICK: SICK is a leading global provider of intelligent sensors, systems and services for factory, logistics and process automation applications. With more than 1,000 patents, innovation and technology are at its core. This focus on innovation and “Sensor Intelligence” have allowed SICK to develop products and solutions for every phase of production in the automotive, packaging, electronics, food and beverage, consumer goods, storage and conveyor, robotics, material handling, oil and gas, chemical, power, maritime industries and more. In addition, SICK’s focus on Sensor Intelligence allows us to make Industry 4.0, or the Industrial Internet of Things, a reality for their customers. POSITION SUMMARY: As a Computer Vision software developer with SICK, you will be part of the Americas Engineering Hub team to develop and implement machine vision algorithms and solutions to proactively address a target industry or reactively on request to support a customer’s quality control project. You will collaborate closely with the sales and technical staffs in the North and South America region throughout the project life cycle. The computer vision technology stack that you will be working with consists of multiple platforms including OpenCV, Halcon, Python Machine Learning, convolutional neural network, tensor flow, C#, C++, .NET, Lua, ROS, ROS2. RESPONSIBILITIES: Implement 2D & 3D image processing such as extracting features, patterns, OCR, image stitching, point cloud analysis and tools development. Develop algorithm for quality inspection, anomaly detection and robot guidance. Sensor fusion: integration and calibration of different sensors (Mono/Stereo cameras, IMUs, depth cameras, time of flight camera, LiDAR, Laser Triangulation camera etc.) Integration of hardware - sensors, integration machine and software algorithms into a high-throughput low-latency pipeline. Write efficient, modular and easy to read code, review code from others. Support on-site project commissioning and deployment. Create technical documentations for internal and external use. QUALIFICATIONS: Bachelor’s degree in computer science, data science, engineering, or a related field. 2 years of experience in computer vision software development in an industrial automation environment. Work experience in OpenCV, TensorFlow, .NET, ROS, ROS2 or other computer vision platforms. Work experience in computer vision algorithms for OCR, Patten Matching, Point Cloud and Image rectification. Proficiency with C#, C++ and Python. Knowledge of computer vision frameworks, libraries, data structures, data modelling, and software development. Experience with AI technologies including Machine Learning and Deep Learning. Experience in working with 2D & 3D industrial cameras and devices. Writing and communicate in English fluently. Knowledge of DevOps methodologies and CI/CD principles and automation tools is a big plus. CORE COMPETENCIES: Ethics and Integrity Personal Growth and Learning, Customer Focus, Personal Accountable, Building Effective Relationships. How to Apply: ***While we commit to reviewing all applications. Only those selected for the next steps in the employment process will be contacted by a Recruiter. Thank you for the time you have invested in applying at SICK. Please email the following to matt.vanahn@sick.com English and Spanish version of your resume. Cover letter if desired. Salary expectations.",https://mx.linkedin.com/jobs/view/computer-vision-software-developer-at-sick-sensor-intelligence-4023705078,4023705078,"As a Computer Vision software developer, you will develop and implement machine vision algorithms and solutions to support quality control projects. Your responsibilities include implementing 2D & 3D image processing, developing algorithms for quality inspection, and integrating various sensors into a high-throughput pipeline. You will collaborate closely with sales and technical teams throughout the project lifecycle.","OpenCV, Halcon, Python, C#, C++, .NET, Lua, ROS, ROS2, TensorFlow, Machine Learning, Deep Learning",2,Bachelor,True,2.0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0
Prompt Engineer AI Data Engineer,Innova Solutions,Monterrey Metropolitan Area,ON-SITE,Entry level,Full-time,IT Services and IT Consulting,2024-09-09 11:27:40.933821,25,Engineering,Information Technology,,"As a AI Data Engineer, you will be: We are seeking a highly skilled Senior AI Data Engineer with specialized expertise in Generative AI models, particularly in configuring and optimizing LLMs such as Azure's ChatGPT, Llama, Mistral, and others. The ideal candidate will excel in prompt engineering, configuring contexts, and working with vector databases. This role will involve deploying and managing AI models within Azure Functions and containerized environments. Configure, deploy, and optimize generative AI models, focusing on LLMs like Azure's ChatGPT, Llama, Mistral, etc. Develop and refine prompt engineering strategies to enhance AI model performance and accuracy. Customize and configure AI model contexts to align with specific business requirements and objectives. Manage and integrate vector databases, ensuring seamless data flow and accessibility for AI models. Utilize Azure Functions and containerization techniques to deploy and maintain AI solutions. Work closely with cross-functional teams to integrate AI solutions into broader business processes. Stay updated on the latest advancements in generative AI and LLM technologies to continually enhance our AI capabilities. Candidate Must have skills: 5+ years of experience in a data engineering role. Extensive experience with LLMs such as OpenAI, Llama, Mistral, and others. Proven track record in deploying and configuring generative AI models, specifically within Azure environments. Strong ability to design and implement effective prompt engineering strategies. Experience with vector databases and their integration into AI systems. Proficiency in deploying AI solutions using Azure Functions and containerization (Docker, Kubernetes). Familiarity with various AI tools and frameworks, along with a solid understanding of software development best practices. Advanced English proficiency Good to have skills: Experience with machine learning models beyond generative AI, including traditional predictive models. Familiarity with DevOps tools and practices for continuous integration and deployment. Additional experience with other cloud platforms like AWS or Google Cloud Soft Skills: Excellent analytical and problem-solving abilities. Strong communication skills, with the ability to convey complex technical concepts to non-technical stakeholders. Proven ability to work effectively in a collaborative team environment. Flexibility to adapt to new challenges and evolving technologies Qualified candidates should APPLY NOW for immediate consideration! Please hit APPLY to provide the required information, and we will be back in touch as soon as possible.",https://mx.linkedin.com/jobs/view/prompt-engineer-ai-data-engineer-at-innova-solutions-4021571528,4021571528,"As a Senior AI Data Engineer, you will be responsible for configuring and optimizing generative AI models, particularly LLMs such as Azure's ChatGPT, Llama, and Mistral. You will develop and refine prompt engineering strategies, manage and integrate vector databases, utilize Azure Functions and containerization techniques, work closely with cross-functional teams, and stay updated on advancements in generative AI and LLM technologies.","Generative AI, LLMs, Azure Functions, Docker, Kubernetes, Vector Databases, OpenAI, Mistral, Llama",5+ years,,True,5.0,0,0,0,1,1,0,0,0,0,1,0,0,0,0,0,0,0
Data Monitoring Engineer (Mexico),MSIGHTS,Monterrey Metropolitan Area,ON-SITE,Entry level,Full-time,Internet Publishing,2023-12-20 11:27:40.933821,26,Engineering,Information Technology,,"Company Overview Founded in 2004, MSIGHTS (msights.com) provides cloud-based marketing data integration services to some of the world’s most sophisticated global advertisers. As marketing channels proliferate, so do the data sources marketers must examine in order to quantify results and guide strategy. MSIGHTS services make marketers more efficient and successful by providing a single view of overall marketing performance with actionable insights on what works and what doesn’t. The MSIGHTS Platform automatically collects and reconciles disparate data, making it immediately available to fuel a wide variety of analytical and visualization tools. Job Summary Monitor all daily operations throught the data value chain QA data based on boards and daily data intake Interest in data (Trending, rules, behavior) As part of the MSIGHTS Technology team, this position requires a great capacity to innovate, take initiative, an ability to consistently deliver above expectation, a passion for continuous improvement, and a willingness to work hard and be rewarded Responsibilities And Duties Will need to work perform daily data operations at specific times (early morning shift or late night shift) Monitor daily intake of data throughits various channels (API, Email, FTP) and solve problems as they arise Daily QA of data to spot inconsistencies, unusual, trending or errors and communicate findings The candidate is required to document, generate ideas, follow established work porcedures and methodologies Qualifications And Skills 1+ years of IT related experience SQL Serverknowledge is a necessity Postgre SQL, SSIS, or AWS Services (Athena, Spectrum, GLUE) are desirable Must be a self-starter, willing to take the initiative and propose innovation in MSIGHTS products and/or processes Strong communications skills — both written and verbal — and the ability to work well with an internal team Must be detail-oriented, committed to quality, responsable, punctual, and client-focused, all while being flexible and entrepreneurial in a fast-paced international work environment Analytical and problem-solving skills, and experience applying these skills to resolve potential issues Bachelor’s Degree or equivalent Powered by JazzHR TcfYc39JO1",https://mx.linkedin.com/jobs/view/data-monitoring-engineer-mexico-at-msights-3787755081,3787755081,"Monitor daily operations through the data value chain, QA data based on boards and daily data intake. This position requires a great capacity to innovate, take initiative, and deliver above expectations while being committed to continuous improvement.","SQL, PostgreSQL, SSIS, AWS Services (Athena, Spectrum, GLUE), API, Email, FTP",1+ years,Bachelor,True,1.0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0
ESPECIALISTA EN BI,EnviaFlores.com,Monterrey Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,"Internet Marketplace Platforms and Technology, Information and Internet",2024-09-01 11:27:40.933821,163,Analyst,"Administrative,",Research,"Estamos en el negocio de construir la marca más confiable de envío de regalos que inspire a nuestros clientes a festejar y conectarse en México y países afines. Nuestros clientes confían en nosotros porque ofrecemos una experiencia memorable donde cada detalle cuenta, desde la realización del pedido hasta la entrega. Buscamos Especialista en BI Responsabilidades: Desarrollo de KPIs hacia otras áreas para eficientizar y reducir gastos que ayuden a alcanzar el business plan. Transformación de datos crudos a bases de datos estructuradas, utilizando diversas técnicas (Python, SQL, Macros) para modelos o tableros para su seguimiento continuo . Colaboración con el área de Data Arquitect para la homologación y limpieza de todos los datos de la compañía Proveer soluciones digitales a problemas que surgen en el día a día (tickets) del negocio para la toma de decisiones. Identificar y eliminar el uso de tableros obsoletos o KPIs duplicados para reducir la memoria diaria de extracción y evitar riesgos operativos. Control de las altas/bajas/permisos de los usuarios que se tienen en Tableau Creación de alertas automáticas cuando ciertas métricas estén alcanzando su límite permitido. Colaboración con todas las áreas de la compañía para desarrollar dashboards interactivos que mejoren la eficiencia del usuario. Análisis y evaluación de casos de negocio con datos cuantitativos. Utilizar herramientas externas para la automatización de procesos/archivos de diversos clientes. Requisitos: Licenciatura concluida en Actuaría, Transformación digital, Tecnología de la información. 2 a 4 años en experiencia de análisis e inteligencia de datos. conocimientos en: Excel, SQL, python, Power Bi, tableau. 1 a 2 años de conocimiento en fiananzas e IT (deseable).",https://mx.linkedin.com/jobs/view/especialista-en-bi-at-enviaflores-com-4010270253,4010270253,"We are looking for a BI Specialist. Responsibilities include developing KPIs to optimize and reduce costs that help achieve the business plan, transforming raw data into structured databases using various techniques (Python, SQL, Macros) for models or dashboards for continuous monitoring. Collaborating with the Data Architect area to standardize and clean all company data, providing digital solutions to daily business problems for decision-making. Identifying and eliminating the use of obsolete dashboards or duplicate KPIs to reduce daily extraction memory and avoid operational risks. Managing user permissions in Tableau, creating automatic alerts when certain metrics reach their allowed limits, and collaborating with all company areas to develop interactive dashboards that enhance user efficiency. Analyzing and evaluating business cases with quantitative data and using external tools for process/file automation for various clients.","Python, SQL, Excel, Power BI, Tableau, Macros",2-4,Bachelor,False,2.0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,1,0,0
Data Engineering Intern,Kuona,Monterrey Metropolitan Area,ON-SITE,Internship,Internship,"Technology, Information and Internet",2024-09-08 11:27:40.933821,25,Information Technology,,,"We are Kuona ( kuona.a i) , an AI technology company that empowers consumer products and retailers to live up to their revenue goals and empowers our clients to maximize their sales and profitability through the dynamic optimization of prices, promotions, and inventories. Our AI-powered platform helps top brands like Coca-Cola and Oxxo maximize their profits and optimize inventories. We are looking for people who are world-class, curious, innovative, bright, and work to be better every single day! We are currently looking for a Data Engineering Intern. With training, guidance, monitoring, and support from the team and team leader, this role is focused on finding and developing solutions that help Kuona build and maintain complex data pipelines and analytical solutions that deepen relationships with customer-provided information. Responsibilities Ensure that the quality of presented data is reliable and aligned with its source quality, and be familiar with various data sources and/or flat files for generating solutions. This role collaborates with the data engineering and data science teams to drive and optimize analytical solutions and internal data systems. Contribute to data analysis and integration. Provide support for enhancing and addressing issues with developed and integrated systems, among other related tasks in the area. Required Technical Experience Desirable experience in data engineering, business intelligence, or engineering. Desirable experience analyzing and integrating data using Python and SQL to extract and transform data according to business rules and requirements. Desirable knowledge in Pandas, Relational and NoSQL databases, and AWS. Desirable knowledge in Airflow and AWS Glue. Desirable experience with large-scale data warehouses, web APIs, and database platforms for integrating internal and external data sources. Your Experience With Kuona Creativity: We like that all team members can propose and create new features Self-management: Since we are a very horizontal company, we require that team members can decide for themselves what to work on and define priorities Opportunities to learn: We offer all our employees a wide opportunity to learn things you probably wouldn't be exposed to in a corporate environment. High Impact: You will be involved in the growth and evolution of the company, and all your contributions will be of high impact on the overall results. We value our culture: We are fully committed to prioritizing great results for our clients and an amazing employee experience for our people. Ability to work anywhere / Flexibility: We provide everyone the opportunity to design your day and execute your projects with flexibility and focus on your well-being. Kuona provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.",https://mx.linkedin.com/jobs/view/data-engineering-intern-at-kuona-4016149298,4016149298,"We are currently looking for a Data Engineering Intern. This role is focused on finding and developing solutions that help build and maintain complex data pipelines and analytical solutions. Responsibilities include ensuring data quality, collaborating with data engineering and data science teams, contributing to data analysis and integration, and providing support for enhancing and addressing issues with integrated systems.","Python, SQL, Pandas, Relational Databases, NoSQL, AWS, Airflow, AWS Glue","Desirable experience in data engineering, business intelligence, or engineering.",,True,,0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0
Data Engineer (Monterrey),i-Consulting,Monterrey Metropolitan Area,ON-SITE,Entry level,Full-time,Information Technology & Services,2024-09-01 11:27:40.933821,25,Information Technology,,,"Overview.- The Resource Description role is focused on ensuring that technical systems and equipment operate optimally for end users. This includes diagnosing and resolving technical issues, implementing new technology solutions, and upgrading systems to enhance efficiency and functionality. The role also involves creating documentation, training users, and generating reports on system usage, status, and incidents. Requirements.- Experience in creating reports, dashboards, and data queries. Proficiency in script creation, testing, and quality assurance for global end-user configurations. Ability to create end-user guides and training materials for Global Service Centers (GSC) and Field Service Operations (FSO). Strong documentation skills for processes and presentation generation. Expertise in analyzing and resolving issues in end-user environments (Windows 11, O365, System Center Client, Intune). Qualifications.- Proven ability to present project progress and make informed decisions based on technical requirements. Strong troubleshooting skills for resolving technical incidents in end-user environments. Experience running pilot tests for end-user solutions. Competence in training support groups on the use of tools and technologies in end-user environments. Education.- Bachelor's degree in Information Technology, Computer Science, or a related field. Additional certifications in relevant technologies (e.g., Microsoft Certified: Modern Desktop Administrator Associate) are a plus. #DATA #Queries #DataEngineers #TechSupport #ITSolutions #EndUserExperience #TechTroubleshooting #SystemImplementation #ITTraining #TechDocumentation #Windows11 #O365 #Intune #ITCareer #TechJobs #SystemUpgrades",https://mx.linkedin.com/jobs/view/data-engineer-monterrey-at-i-consulting-4013716973,4013716973,"The Resource Description role is focused on ensuring that technical systems and equipment operate optimally for end users. This includes diagnosing and resolving technical issues, implementing new technology solutions, and upgrading systems to enhance efficiency and functionality. The role also involves creating documentation, training users, and generating reports on system usage, status, and incidents.","Windows 11, O365, System Center Client, Intune, Data Queries, Scripting, Quality Assurance, Documentation",,Bachelor,True,,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0
Data Engineers Python,"GSPANN Technologies, Inc",Monterrey Metropolitan Area,ON-SITE,Entry level,Full-time,Information Technology & Services,2024-07-17 11:27:40.933821,25,Information Technology,,,"SQL, Python, PySpark, Databricks, AWS Description GSPANN seeks seasoned Data Engineers to join our team in Mexico. As we march ahead on a tremendous growth trajectory, we seek passionate and talented professionals to join our growing family. Who We Are GSPANN has been in business for over a decade, with over 2000 employees worldwide, and servicing some of the largest retail, high technology, and manufacturing clients in North America. We provide an environment that enables career growth while still interacting with company leadership. Visit Why GSPANN for more information. Location: Monterrey or Remote in Mexico Role Type: Full Time Published On: 26 June 2024 Experience: 7+ Years Share this job Description GSPANN seeks seasoned Data Engineers to join our team in Mexico. As we march ahead on a tremendous growth trajectory, we seek passionate and talented professionals to join our growing family. Role and Responsibilities Analyze, code, test, build, release, and maintain data pipelines or ETL-related systems. Participate in the design of the above-mentioned system with the principal engineer and Architect. Work with multiple sourcing teams when it comes to data ingest. Implement processes to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it. Select and implement the right technical tools and processes within the boundary defined by the client. Perform data analysis required to troubleshoot data-related issues and assist in the resolution of data issues. Collaborate with Product Analysts and Visualization Engineers during solution implementation. Write documentation and tutorials, as well as provide guidance. Be part of the support process with the rest of the squad. Coach and mentor more junior colleagues from the squad. Participate actively in the relative community of practice, helping shape Nike’s engineering culture, standards, and best practices, advocating for engineering excellence and innovation. Work with product owner and scrum master to understand requirements. Collaborate with the Lead Engineer to understand requirements, define scope, and estimate the level of effort. Ensure that your peers in the team have the full context and understanding of requirements and create valuable solutions. Establish trust and build strong and effective partnerships with technical leaders and architects in various functions across regions/global locations. Partner effectively with your peers to ensure delivery and positive results. Skills And Experience A degree in Computer Science, Information Systems, or other relevant subject area related to information technology. 3+ years of hands-on experience in technical architecture, design, development, and testing of data warehouse and big data solutions 3+ years of experience in implementing, testing, deploying, and troubleshooting data pipelines using any of these: PySpark, Apache Spark, Databricks, and Data Lake in cloud environments such as AWS or Microsoft Azure. 3+ years of experience in a complex matrix organization within a global IT environment, having a diverse and complex landscape. 3+ years of experience in developing CI/CD pipelines using Git, Terraform, and Jenkins. Prior experience working on multiple projects using Agile Methodologies (SAFE). Hands-on with applying pattern-based architecture, governance, security, and global process standards to system changes and deployments. Expertise in practicing DevOps principles for observability, reliability, and scalability. Diverse experience in databases, designs, constructs, and utilities. Comfortable working in a multi-tasking, fast-paced, results-oriented environment. Excellent verbal and written communication and collaboration skills to effectively communicate with both business and technical IT teams across global locations. Passion for building trust, coaching, teaching, mentoring, and learning.",https://mx.linkedin.com/jobs/view/data-engineers-python-at-gspann-technologies-inc-3967872045,3967872045,"GSPANN seeks seasoned Data Engineers to analyze, code, test, build, release, and maintain data pipelines or ETL-related systems. Responsibilities include collaborating with teams on data ingest, monitoring data quality, troubleshooting data-related issues, and ensuring effective communication with stakeholders. The position involves implementing CI/CD pipelines, applying DevOps principles, and mentoring junior colleagues while participating in agile methodologies.","SQL, Python, PySpark, Databricks, AWS, Microsoft Azure, Git, Terraform, Jenkins",7+ Years,Masters,True,7.0,0,0,1,1,0,0,0,0,0,1,0,1,0,0,1,0,0
Test Engineer - Lenovo Data Center Group,Lenovo,Monterrey Metropolitan Area,ON-SITE,Entry level,Full-time,IT Services and IT Consulting,2024-09-12 11:27:40.933821,25,Engineering,Information Technology,,"We are Lenovo. We do what we say. We own what we do. We WOW our customers. Lenovo is a US$57 billion revenue global technology powerhouse, ranked #248 in the Fortune Global 500, and serving millions of customers every day in 180 markets. Focused on a bold vision to deliver Smarter Technology for All, Lenovo has built on its success as the world’s largest PC company with a full-stack portfolio of AI-enabled, AI-ready, and AI-optimized devices (PCs, workstations, smartphones, tablets), infrastructure (server, storage, edge, high performance computing and software defined infrastructure), software, solutions, and services. Lenovo’s continued investment in world-changing innovation is building a more equitable, trustworthy, and smarter future for everyone, everywhere. Lenovo is listed on the Hong Kong stock exchange under Lenovo Group Limited (HKSE: 992) (ADR: LNVGY). This transformation together with Lenovo’s world-changing innovation is building a more inclusive, trustworthy, and smarter future for everyone, everywhere. To find out more visitwww.lenovo.com, and read about the latest news via ourStoryHub. Job Title: Test Engineer - Lenovo Data Center Group General Description: We are looking for Test engineer with a background in functional testing for a position in Lenovo’s ISG Product Assurance team. The role will require experience with new feature validation on servers, options, enterprise software and server OS’s. Testing will include error injection, using test scripts and automation, data capture, and assisting with debug efforts. This role will be responsible for execution test plans and test cases indented to ensure quality delivery of new Lenovo ThinkSystem servers and FW functions. Applicants must have a background in one or more of the following: UEFI, systems management features, networking or storage. The applicants should have some experience in several of the following areas: error injection, testing and validation. The role requires the ability to apply this knowledge to execute test plans, find defects and document them. Job Responsibilities: Execution of test plans on Lenovo servers Defect documentation / discover Server configuration and installation Network / SAN setup Identify automation opportunities and drive automation development activities Working with development on defect debug efforts Skills / Qualifications: Strong English is required Experience in any of the following: Working knowledge of server OS’s (RedHat, SuSE, Windows, VMWare) Understanding of servers basics Understanding on network basics Additional skills a plus: Basics on networking IPv6 / V4, Virtualization, InfiniBand, etc. Basics on Intel and AMD architecture Fault injection Server architecture Programming / scripting Automation development Test Case / plan development VMWare virtualization NetAPP Storage We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, religion, sexual orientation, gender identity, national origin, status as a veteran, and basis of disability or any federal, state, or local protected class. WD00070705 https://lenovo.avature.net/en_US/careers/JobDetail?jobId=60173 Skills / Qualifications: Strong English is required Experience in any of the following: Working knowledge of server OS’s (RedHat, SuSE, Windows, VMWare) Understanding of servers basics Understanding on network basics Additional skills a plus: Basics on networking IPv6 / V4, Virtualization, InfiniBand, etc. Basics on Intel and AMD architecture Fault injection Server architecture Programming / scripting Automation development Test Case / plan development VMWare virtualization NetAPP Storage We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, religion, sexual orientation, gender identity, national origin, status as a veteran, and basis of disability or any federal, state, or local protected class. WD00070705 https://lenovo.avature.net/en_US/careers/JobDetail?jobId=60173 We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, religion, sexual orientation, gender identity, national origin, status as a veteran, and basis of disability or any federal, state, or local protected class.",https://mx.linkedin.com/jobs/view/test-engineer-lenovo-data-center-group-at-lenovo-4022882442,4022882442,"We are looking for a Test Engineer with a background in functional testing for a position in Lenovo’s ISG Product Assurance team. The role will require experience with new feature validation on servers, options, enterprise software, and server OS’s. Responsibilities include executing test plans, defect documentation, server configuration and installation, network/SAN setup, and identifying automation opportunities. Applicants must have experience in UEFI, systems management features, networking, or storage, and the ability to apply this knowledge to execute test plans and find defects.","RedHat, SuSE, Windows, VMWare, IPv4, IPv6, InfiniBand, Intel architecture, AMD architecture, Automation development, Test Case development",,,True,,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
Data Engineer,Dexian México,Monterrey Metropolitan Area,ON-SITE,Mid-Senior level,Contract,IT Services and IT Consulting,2024-09-11 11:27:40.933821,25,Information Technology,,,"Responsibilities Create and maintain optimal data pipeline architecture, Assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS �big data� technologies. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Work with data and analytics experts to strive for greater functionality in our data systems. Qualifications for Data Engineer Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Experience building and optimizing �big data� data pipelines, architectures and data sets. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Strong analytic skills related to working with unstructured datasets. Build processes supporting data transformation, data structures, metadata, dependency and workload management. A successful history of manipulating, processing and extracting value from large disconnected datasets. Working knowledge of message queuing, stream processing, and highly scalable �big data� data stores. Strong project management and organizational skills. Experience supporting and working with cross-functional teams in a dynamic environment. Leverage data and software engineering techniques, data science to create business value through data accessibility (includes data ingestion, data preparation and analytics processing) Identifying, acquiring, cleansing/preparing, storing data and developing reusable data products aligned with defined architecture patterns Enabling data scientists, making data available for advanced analytics models, and contributing to advanced analytics models Working with data analysts and architects to scale and deploy solutions including models, documentation, training, integration Required Technical Skills Proficiency in building out scalable and reliable ETL pipelines and processes to ingest data from variety of data sources including but not limited to SharePoint, REST API, Blob Storage . Proficiency in Azure PaaS offerings and data engineering target architecture, including but not limited to Azure SQL database, Azure Data Factory, Azure Synapse, Azure Databrick, Azure Functions, Data lake, Azure Log Analytics. Proficiency in large dataset transformation using Python Proficiency in relational databases and SQL, including but not limited to stored procedures, indexes, functions and triggers. Proficiency in Azure DevOps CI/CD and Git Repository. Deep understanding in data model design and relational database normalization Familiarity with Non SQL databases. E.g Cosmos DB INTERESADOS Si cumples con los requisitos, compartir CV en inglés Desarrollo de proyecto remoto para empresa basada en US Puesto remoto para profesionales viviendo en México Puedes compartir el CV por este medio o a la siguiente cuenta de correo: cesar.montufar@dexian.com Prestaciones superiores",https://mx.linkedin.com/jobs/view/data-engineer-at-dexian-m%C3%A9xico-4021369240,4021369240,"The responsibilities include creating and maintaining optimal data pipeline architecture, assembling large and complex data sets, identifying and implementing internal process improvements, and building the infrastructure for data extraction, transformation, and loading from various data sources. You will also build analytics tools to provide actionable insights, work with stakeholders to assist with technical data issues, and create data tools for analytics and data scientists. Qualifications include advanced SQL knowledge, experience with big data pipelines, strong analytic skills, and proficiency in Azure PaaS offerings and data engineering architecture.","SQL, AWS, Python, Azure SQL Database, Azure Data Factory, Azure Synapse, Azure Databricks, Azure Functions, Data Lake, Azure Log Analytics, Azure DevOps, Git, Cosmos DB",,,True,,0,0,1,1,0,0,0,0,0,1,0,1,0,0,1,0,0
Data Engineer,Dematic,Monterrey Metropolitan Area,ON-SITE,Entry level,Full-time,"Transportation, Logistics, Supply Chain and Storage",2024-09-14 11:27:40.933821,25,Information Technology,,,"What We Offer: Career Development Competitive Compensation and Benefits Pay Transparency Global Opportunities Learn More Here: https://www.dematic.com/es-mx/about/careers/ Dematic provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training. What we offer: Company Overview Dematic Corporation is a leading supplier of integrated automated technology, software, and services to optimize the supply chain. Dematic belongs to the KION Group. The KION Group is among the world's leading suppliers of industrial trucks and supply chain solutions. We currently have more than 41,000 employees and approximately €11,100 million in revenue. Our portfolio encompasses industrial trucks, such as forklift trucks and warehouse trucks, as well as integrated automation technology and software solutions for the optimization of supply chains, including all related services. Across more than 100 countries worldwide, the KION Group's solutions improve the flow of material and information within factories, warehouses, and distribution centers. Tasks and Qualifications: The Role KION is expanding its global Big Data Analytics & AI Platform that supports a large variety of different use cases from explorative Data Analytics through Machine Learning Projects or Power BI dashboards. This position is meant to be the IT counterpart for those projects. We are looking for a highly skilled and experienced Data Engineer as an extension to the Analytics Team. The KION Analytics Platform is KION’s cloud data platform for analytics, data science and AI use cases. It holds data from various source systems and provides services and infrastructure for data analysts and data scientists to kickstart their projects. Among others, the platform comprises of following services: Azure DataLake Azure Data Factory Azure Databricks Dremio GCP VertexAI Power BI We are making sure all projects have the adequate data and tools they need to provide further insights to grow and optimize KION’s Business. Responsibilities To be successful in this demanding role, your proven track record will enable you to deliver against the following key performance areas: Design, develop and operate robust data pipelines in Azure Data Factory and Databricks Build data transformations in Databricks and Dremio based on business needs Develop and implement data quality and data governance frameworks Support and advise a variety of projects on big data Collaborate with data analysts and scientists to ensure data availability, accuracy, and quality Advice and consult business partners to use data efficiently Develop and maintain scalable and efficient ETL processes User support, incident and change management for applications and services Operate and support KION Analytics Platform architecture and corresponding toolset Monitor and analyze data and metrics of the platform Create and maintain documentation and training materials for platform users Qualifications Minimum of 2 years’ experience in data engineering, data management, or related field Good understanding of data, databases, and data lakes in general Experience with cloud-based data storage and processing platforms (e.g., AWS, Azure, Google Cloud Platform) Strong proficiency in a programming language (preferably Python, SQL, Powershell, Bash) Experience with IoT Data and related technologies (e.g., Kafka) Proficiency in professional software development (testing, Git, CI/CD) Experience with creating solutions within a collaborative, cross-functional team environment Good problem-solving skills and the ability to troubleshoot complex data issues Motivation to think out of the box coupled with a hands-on mentality Proven track record of delivering value from data Strong communication skills (English required C1/C2) Self-starter, detail oriented, excellent time-management/schedule skills, ability to meet deadlines, desire to learn Resume/CV must be submitted in English Willingness to travel up to 10% internationally",https://mx.linkedin.com/jobs/view/data-engineer-at-dematic-4024622626,4024622626,"The role is focused on expanding the global Big Data Analytics & AI Platform, which supports various use cases from explorative Data Analytics to Machine Learning Projects and Power BI dashboards. The Data Engineer will design, develop, and operate robust data pipelines, implement data quality frameworks, collaborate with data analysts, and manage cloud data architecture. The position requires a strong track record in data engineering and experience with various cloud-based data storage platforms.","Azure DataLake, Azure Data Factory, Azure Databricks, Dremio, GCP VertexAI, Power BI, Python, SQL, Powershell, Bash, Kafka",2,,True,2.0,0,0,1,1,0,0,0,0,1,1,0,0,0,0,1,0,0
Data Engineer,"GSPANN Technologies, Inc",Monterrey Metropolitan Area,ON-SITE,Entry level,Full-time,Information Technology & Services,2024-07-17 11:27:40.933821,25,Information Technology,,,"Java, Databricks, ETL, Data Lake, Database Design, Big Data Description We are looking for a Data Engineer to join our global workforce. Our dynamic team offers valuable opportunities and a tangible career support system for your professional and personal development. Who We Are GSPANN has been in business for over a decade, with over 2000 employees worldwide, and servicing some of the largest retail, high technology, and manufacturing clients in North America. We provide an environment that enables career growth while still interacting with company leadership. Visit Why GSPANN for more information. Location: Monterrey or Remote in Mexico Role Type: Full Time Published On: 25 June 2024 Experience: 7+ Years Share this job Description We are looking for a Data Engineer to join our global workforce. Our dynamic team offers valuable opportunities and a tangible career support system for your professional and personal development. Role and Responsibilities Lead the design, development, and maintenance of scalable customer data platform architectures. Collaborate with engineers, marketers, and product managers to ensure seamless integration and alignment of the CDP with business objectives. Implement robust data pipelines, APIs, and reverse ETL for real-time and batch data processing. Identify data sources, build data mappings, and conduct transformational logic between systems to enable data migration. Ensure high data quality and adherence to data privacy and security guidelines. Evaluate and incorporate new technologies and tools to enhance the capabilities of the CDP, building efficient integration to consume and provide data to third-party platforms. Skills And Experience Bachelor’s or Master’s degree in Computer Science, Information Technology, or a related field. Minimum of 7 years of experience in software development, focusing on backend engineering and data-intensive applications. Strong programming skills in Java. 1-2 years of experience implementing any Customer Data Platforms (CDP) such as Segment, RudderStack, Hightouch, or mParticle. Proficient in SQL and NoSQL databases. Hands-on experience with AWS cloud platforms. Ability to collaborate efficiently with cross-functional teams, including product owners, technology teams, and marketing partners. Excellent written and oral communication skills. Experience with big data technologies such as Kafka, Hadoop, or Spark is desirable.",https://mx.linkedin.com/jobs/view/data-engineer-at-gspann-technologies-inc-3967865934,3967865934,"We are looking for a Data Engineer to lead the design, development, and maintenance of scalable customer data platform architectures, collaborating with various teams to ensure alignment with business objectives, implementing robust data pipelines, and ensuring high data quality and security.","Java, SQL, NoSQL, AWS, Kafka, Hadoop, Spark, ETL, Data Lake, APIs",7+,Bachelor,True,7.0,0,0,1,1,0,0,1,0,0,1,0,0,0,0,0,0,0
Senior Engineer - Data Engineering (MONTERREY),Slalom Build,Monterrey Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,Information Technology & Services,2024-09-08 11:27:40.933821,25,Engineering,Information Technology,,"Who You’ll Work With At Slalom Build we co-create custom software, data and cloud products with clients who are ready to accelerate their digital transformation. We're passionate about technology, compelled by its potential as we help create the digital products, experiences, and technology-driven organizations that drive true change. We’re thrilled by the opportunity to build the future we want to see, with anyone willing to join us. Slalom Build’s Data Engineering Capability Is Focused On Injecting Intelligence Into Products, Engineering Systems That Support Learning And Insight And Creating Innovative Data Products. Within Data Engineering We Help Customers Build World-class Products Through Effective Use Of Data Engineering consisting of streaming / real-time data solutions, modern data platforms, and data systems within products (e.g.., database systems, graph databases, key-value stores, document databases and transactional systems) Data visualization Machine learning and artificial intelligence What You’ll Do Slalom Build’s Data Engineering capability is comprised of passionate, flexible technologists who love to practice and hone their craft. As tools evolve and technologies emerge, we work to stay in front of innovations in data platform development and delivery. As a Senior Data Engineer for Slalom Build, you will work in teams with minimal oversight and direction to deliver innovative solutions on Amazon Web Services, Microsoft Azure, and Google Cloud Platform using core cloud data warehouse tools, distributed processing engines, event streaming platforms, and other modern data related technologies. In addition to building the next generation of data platforms, you will be working with some of the most forward-thinking organizations in data and analytics. You will typically work under the direction of a Solution Architect to help design and implement components of our clients’ data platform solution. You’ll also participate in design sessions, be experienced at breaking down complex development tasks, and be responsible for the timely and quality completion of development items assigned to you and the data engineers reporting to you. We are looking for candidates who are interested in working in a hybrid environment as we build the foundation and grow our team in Mexico. We offer a flexible working environment to balance the need to work independently, with days that may require in-person collaboration at our office. What You’ll Bring As a Senior Engineer in the Data Engineering capability, you will bring a curious mindset to your client’s engagement, a thirst for knowledge and a hunger for fearless experimentation in new and interesting ways to meet our clients’ most pressing data challenges. You are self-starter, effective in breaking down large problems into smaller ones, and eager to regularly share what you learn with others within your projects and in the broader Builder community. You Will Have An Insatiable Need For Becoming The Best At What You Do And Have Hands-on Experience With Data Platforms And Programming Languages As You Explore The Range Of Technologies We Help Our Clients With, Including Big Data Platforms (Apache Spark, Presto, Amazon EMR) Cloud Data Warehouses (Amazon Redshift, Snowflake, Google BigQuery) Object Oriented Coding (Java, Python) NoSQL Databases (DynamoDB, Cosmos DB, MongoDB) Container Management Systems (Kubernetes, Amazon ECS) Artificial Intelligence / Machine Learning (Amazon Sagemaker, Azure ML Studio) Streaming Data Ingestion and Analytics (Amazon Kinesis, Apache Kafka) Visual Analytics (Tableau, PowerBI) Modern Data Workflows (Apache Airflow, dbt, Dagster) About Us Slalom Build is a highly scalable, high-velocity Build as a Service firm. We work with clients in a flexible, collaborative, and repeatable methodology to create custom technology solutions for their most impactful initiatives and to accelerate their digital transformation journey. Over 1500 Builders strong, distributed across the globe, our innovation hubs attract the type of people who contribute to thriving teams. By placing builders in close proximity to clients – as well as their cultural and technology cohorts – we can assure the quality, versatility, and speed that product delivery demands, along with the elasticity and scale to tailor to individual client needs. Slalom Build leverages a foundation of innovation inherited from Slalom, a Seattle based firm that set out in 2001 to disrupt and redefine management consulting. Now 13,000+ professionals strong around the globe, Slalom is deeply engaged with some of the world’s most influential, change-making enterprises. Learn more at slalombuild.com or slalom.com",https://mx.linkedin.com/jobs/view/senior-engineer-data-engineering-monterrey-at-slalom-build-4018794281,4018794281,"As a Senior Data Engineer for Slalom Build, you will work with minimal oversight to deliver innovative solutions on cloud platforms, using core cloud data warehouse tools and modern data technologies. You will participate in design sessions, break down complex development tasks, and ensure timely and quality completion of assigned items. You will bring a curious mindset, hands-on experience with data platforms, and be eager to experiment with new technologies to solve data challenges.","Amazon Web Services, Microsoft Azure, Google Cloud Platform, Apache Spark, Presto, Amazon EMR, Amazon Redshift, Snowflake, Google BigQuery, Java, Python, DynamoDB, Cosmos DB, MongoDB, Kubernetes, Amazon ECS, Amazon Sagemaker, Azure ML Studio, Amazon Kinesis, Apache Kafka, Tableau, PowerBI, Apache Airflow, dbt, Dagster",,,True,,0,0,1,1,1,0,0,0,1,1,0,0,0,0,1,0,0
Azure Data Engineer,Infosys,Monterrey Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-13 11:27:40.933821,25,Information Technology,,,"We are looking for an Azure Data Eng to work on hybrid model on any of Infosys Locations (Mexico City, Guadalajara and Monterry) in a Production Support + Development project with one of the top companies in Silicon Valley . Expertise Required: Very good communication skills + English Level. At least 3 years of experience in designing, implementing, and maintaining robust and scalable data pipelines on Azure using services such as Azure Data Factory, Azure SQL Data Warehouse, Azure Analysis Services or any of the Azure Databricks/Synapse/Fabric. At least 2 years of experience in data platforms – with multi layered approach, Design/Architecture setup is needed. At least 2 years of experience in troubleshooting performance issues, identifying root cause and applying fixes. At least 3 years of experience in SQL. Ability to implement and manage CI/CD pipelines for data engineering projects, leveraging tools like Azure DevOps. EEO/About Us : About Us Infosys is a global leader in next-generation digital services and consulting. We enable clients in more than 50 countries to navigate their digital transformation. With over four decades of experience in managing the systems and workings of global enterprises, we expertly steer our clients through their digital journey. We do it by enabling the enterprise with an AI-powered core that helps prioritize the execution of change. We also empower the business with agile digital at scale to deliver unprecedented levels of performance and customer delight. Our always-on learning agenda drives their continuous improvement through building and transferring digital skills, expertise, and ideas from our innovation ecosystem. Infosys provides equal employment opportunities to applicants and employees without regard to race; color; sex; gender identity; sexual orientation; religious practices and observances; national origin; pregnancy, childbirth, or related medical conditions; status as a protected veteran or spouse/family member of a protected veteran; or disability.",https://mx.linkedin.com/jobs/view/azure-data-engineer-at-infosys-4020124696,4020124696,"We are looking for an Azure Data Engineer to work in a hybrid model in any of Infosys Locations (Mexico City, Guadalajara, and Monterrey) in a Production Support + Development project with a top Silicon Valley company. The role requires excellent communication skills and proficiency in English. The candidate should have at least 3 years of experience in designing, implementing, and maintaining robust and scalable data pipelines on Azure, using services such as Azure Data Factory, Azure SQL Data Warehouse, and Azure Analysis Services or any of Azure Databricks/Synapse/Fabric. Additionally, 2 years of experience in data platforms with a multi-layered approach is needed, along with design/architecture setup experience. The candidate should also have 2 years of experience in troubleshooting performance issues. Proficiency in SQL for at least 3 years, as well as the ability to implement and manage CI/CD pipelines for data engineering projects using tools like Azure DevOps, is required.","Azure Data Factory, Azure SQL Data Warehouse, Azure Analysis Services, Azure Databricks, Azure Synapse, Azure DevOps, SQL",3+,,True,3.0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,0,0,0
"Senior, Data Engineer",Schneider Electric,Monterrey Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,Automation Machinery Manufacturing,2024-09-08 11:27:40.933821,25,Information Technology,,,"Schneider Electric has an opportunity for a Senior Data Engineer in our Monterrey, MX location. The Data Engineer will develop, maintain, and improve data delivery through North America (NAM) Data Excellence platform. The right person in this role will support improvements in data architecture, metric definition, and processes to support business data and analytical initiatives. Our Data Engineers provide guidance and support to team members in the Data Services team and our business partners. About Us Schneider Electric creates connected technologies that reshape industries, transform cities, and enrich lives. Our 135,000+ employees thrive in more than 100 countries. From the simplest of switches to complex operational systems, our technology, software, and services improve how our customers manage and automate their operations. Help us deliver solutions that ensure Life Is On everywhere, for everyone, and at every moment. http://www.youtube.com/watch?v=YtExntUe89c Great People Make Schneider Electric a Great Company. Key responsibilities include: Collaborate with team members to conceptualize, design, and deliver enterprise and departmental data solutions to support business intelligence, data warehousing, reporting, and machine learning requirements. Implement reliable and scalable solutions to meet the service levels associated with mission-critical solutions. Participate in and enhance our DevOps practice to ensure highly available solutions and quick issue resolution. Translate business requirements into data pipelines and data stores to support business requirements. Perform assessments (Proof of Concepts) of the latest tools and technologies. Work with Data and Solution Architects to define and implement migration strategies from legacy systems to cloud architecture and technologies. Provide team feedback to optimize the delivery of our solutions. Education Bachelor’s degree related to Computer Science or Information Technology or equivalent Benefits Competitive salary Comprehensive health benefits Retirement savings plan Professional development opportunities We know skills and competencies show up in many ways and can be based on your life experience. If you do not necessarily meet all the requirements that are listed, we still encourage you to apply for the position. Qualifications Required qualifications: 5+ years of experience with modern programming languages such as Python, Scala, or Java. 3+ years of experience developing data-related solutions on cloud platforms such as Amazon Web Services (AWS). Demonstrated experience with primary AWS services such as EC2, Lambda, EMR, S3, IAM policies, CloudWatch, Cloud Formation, SES Demonstrated experience with Cloud Services for data handling and database technologies (DMS, Kafka, Spark, Redshift, Athena, Hadoop, Airflow, etc.). Knowledge of Data Management, Integration, and Data Quality tools, such as Alteryx, Trifecta, Informatica Power Center, Informatica Cloud, and Oracle Data Integrator. Command of advanced SQL queries and programming. Experience contributing to and following best practices for architecture, design, and implementation. Have an eye for operational transparency and resiliency at every application layer. Proven analytical and problem-solving abilities. Ability to assimilate information, quickly discern the most relevant facts, and recommend creative, practical design solutions. Ability to think outside the box is a real asset. Experience with DevOps tools and processes and CI/CD are an asset. Excellent communication, presentation, influencing, and reasoning capabilities. Solid understanding of data modeling, ETL processes, and data warehousing concepts. We know skills and competencies show up in many ways and can be based on your life experience. If you do not necessarily meet all the requirements that are listed, we still encourage you to apply for the position. Schedule: Full-time Req: 00922Q",https://mx.linkedin.com/jobs/view/senior-data-engineer-at-schneider-electric-4015117029,4015117029,"The Data Engineer will develop, maintain, and improve data delivery through the North America Data Excellence platform, support improvements in data architecture and processes, and collaborate to deliver data solutions for business intelligence and machine learning. Responsibilities include implementing scalable solutions, enhancing DevOps practices, translating business requirements into data pipelines, and working on migration strategies to cloud technologies. Required qualifications include experience with modern programming languages, cloud platforms, data handling tools, and advanced SQL queries.","Python, Scala, Java, AWS, EC2, Lambda, EMR, S3, IAM policies, CloudWatch, Cloud Formation, SES, Kafka, Spark, Redshift, Athena, Hadoop, Airflow, Alteryx, Informatica Power Center, Informatica Cloud, Oracle Data Integrator, SQL",5+,Bachelor,True,5.0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0
Data Engineer (SQL),BAT,Monterrey Metropolitan Area,ON-SITE,Associate,Full-time,Data Infrastructure and Analytics,2024-09-10 11:27:40.933821,54,Information Technology,,,"BAT is evolving at pace - truly like no other organization. To achieve the ambition, we have set for ourselves, we are looking for colleagues who are ready to live our ethos every day. Come be a part of this journey! BAT MEXICO IS LOOKING FOR A DATA ENGINEER (SQL) SENIORITY LEVEL: Junior Level FUNCTION: Digital Business Solutions (DBS) LOCATION: Monterrey ROLE POSITIONING AND OBJECTIVES This role is part of the DBS function. The role is responsible for support the US team in data integration, data architecture and process optimization tasks. Reports to: Data Engineer Lead Reporting Level: Managerial Geographic Scope: US WHAT YOU WILL BE ACCOUNTABLE FOR Integrates end to end data pipelines to take data from data source to target data repositories ensuring the quality and consistency of data. Understand Data Architecture concepts. Drive performance analysis and optimization tasks over SQL database objects like Store Procedures and Views. Coordinates issue resolution with multi-functional teams and vendors. Serves as a productive project team member delivering high quality results for work you are doing. Assists the project manager by assisting sharing work plans, effort estimates and delivery timelines for work you're leading. Drive collaborative reviews of design, code, data, features implementation performed by other data engineers in support of maintaining data engineering standards. CAN THIS BE YOUR FUTURE ROLE? Are you willing to develop your career in a fast paced global company? ESSENTIAL EXPERIENCE, SKILLS AND KNOWLEDGE Bachelor's Degree or equivalent experience in Computer Science/Engineering or related. +2 years working experience preferred. Experience with partners and requirements gathering/implementation. Intermediate knowledge (as minimum) over SQL (CTEs, Historical data management, Store Procs, Views, Functions, Logs, etc). Experience developing extract, transform, load (ETL) pipelines using Databricks, PySpark and Cloud Storage. Experience with Python. Extensive experience with data engineering tools, languages, frameworks to mine, cleanse and explore data. Experience Control-Versioning coding such as Git. Experience with Cloud technologies (ex. Azure, AWS, GCP, Teradata, Snowflake). Advance English proficiency written and verbal. BENEFICIAL Experience with Databricks: MachineLearning (MLFlow); SQL Warehousing / Delta tables; Unity Catalog; Event/Driver Logs analysis. PySpark RDDs (Resilient Distributed Dataset) and MLOPS (Azure DevOps). AWS Redshift, Teradata, Snowflake and Knowledge over Programming Object-Oriented concepts. Productionalize the full pipeline including and ETL workflows (e.g., training/test pipeline). Experience with orchestration toolsets (e.g. Airflow, Tidal). Experience with software development applying best-practice methodologies and frameworks such as Agile, Scrum, etc. WE ARE BAT At BAT we are committed to our Purpose of creating A Better Tomorrow. This is what drives our people and our passion for innovation. See what is possible for you at BAT. Global Top Employer with 53,000 BAT people across more than 180 markets Brands sold in over 200 markets, made in 44 factories in 42 countries Newly established Tech Hubs building world-class capabilities for innovation in 4 strategic locations Diversity leader in the Financial Times and International Women’s Day Best Practice winner Seal Award winner – one of 50 most sustainable companies BELONGING, ACHIEVING, TOGETHER Collaboration, diversity and teamwork underpin everything we do here at BAT. We know that collaborating with colleagues from different backgrounds is what makes us stronger and best prepared to meet our business goals. Come bring your difference!",https://mx.linkedin.com/jobs/view/data-engineer-sql-at-bat-4020485728,4020485728,"This role is responsible for supporting the US team in data integration, data architecture, and process optimization tasks. The Data Engineer will integrate end-to-end data pipelines, ensure data quality and consistency, and perform performance analysis and optimization tasks over SQL database objects. Additionally, the role requires collaboration with multi-functional teams and delivering high-quality results while assisting in project management tasks.","SQL, Databricks, PySpark, Cloud Storage, Python, Git, Azure, AWS, GCP, Teradata, Snowflake, Airflow",2+ years,Bachelor,True,2.0,0,0,1,1,0,0,0,0,0,1,0,1,0,0,1,0,0
Procurement Data Engineer III,Johnson Controls,Monterrey Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,Industrial Machinery Manufacturing,2024-09-14 11:27:40.933821,25,Information Technology,,,"Johnson Controls is a global diversified technology and multi industrial leader serving a wide range of customers in more than 150 countries. Our 130,000 employees create intelligent buildings, efficient energy solutions, integrated infrastructure and next generation transportation systems that work seamlessly together to deliver on the promise of smart cities and communities. Our commitment to sustainability dates back to our roots in 1885, with the invention of the first electric room thermostat. We are committed to helping our customers win and creating greater value for all of our stakeholders through strategic focus on our buildings and energy growth platforms. For additional information, please visit www.johnsoncontrols.com or follow us @johnsoncontrols on Twitter. What you will do? Join us in the Procurement Execution Center (PEC) as a Data Engineer as part of a is a diverse team of data and procurement individuals. In this role, you will be responsible for deploying supporting the E2E management of our data, including: ETL/ELT, DW/DL, data staging, data governance, and manage the different layers of data required to ensure a successful BI & Reporting for the PEC. This role will work with multiple types of data, spreading across multiple functional areas of expertise, including Fleet, MRO & Energy, Travel, Professional Services, among others. How you will do it? Serve as the main technical resource for any data-related requirement Demonstrate an ability to communicate technical knowledge through project management and contributions to product strategy Deploy data ingestion processes through Azure Data Factory to load data models as required into Azure Synapse. Build and design complex ETL/ELT processes with Azure Data Factory (ADF) and/or Python, which once deployed, will require to be executed daily and weekly. Assemble large, complex data sets that meet functional / non-functional business requirements. Build the infrastructure required for optimal ETL/ELT of data from a wide variety of data sources using Azure SQL and ADF. Develop data models that enable DataViz, Reporting and Advanced Data Analytics, striving for optimal performance across all data models. Maintain conceptual, logical, and physical data models along with corresponding metadata. Manages the DevOps pipeline deployment model, including automated testing procedures Deploys data stewardship and data governance across our data warehouse, to cleanse and enhance our data, using knowledge bases and business rules. Ensure compliance to system architecture, methods, standards, practices and participate in their creation Clearly articulate and effectively influence both business and technical teams Performs the necessary data ingestion, cleansing, transformation, and coding of business rules to support annual Procurement bidding activities. Support the deployment of a global data standard for Logistics. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Support Rate Repository management as required (including Rate Card uploads to our DW). Other Procurement duties as assigned. What are we looking for? Bachelor’s degree in related field (Engineering, Computer Science, Data Science or similar) 4+ years of relevant experience in BI Engineering, data modeling, data engineering, software engineering or other relevant roles. Advanced working SQL knowledge and experience working with relational databases. Knowledge in DW/DL concepts, data marts, data modeling, ETL/ELT, data quality/stewardship, distributed systems and metadata management. Experience building and optimizing data pipelines, architectures, and data sets. Azure Data Engineering certification preferred (DP-203) ETL/ELT development experience (3+ years). SSIS or ADF are preferred. Ability to resolve ETL/ELT problems by proposing and implementing tactical/Strategic solutions. Strong project management and organizational skills. Experience with object-oriented function scripting languages: Python, Scala, C#, etc. Experience with NoSQL databases is a plus to support the transition from On-Prem to Cloud. Excellent problem solving, critical thinking, and communication skills Relevant experience with Azure DevOps (CI/CD, git/repo management) Due to the global nature of the role, proficiency in English language is a must. Johnson Controls does not request pregnancy or HIV testing as a requirement for admission, permanence or promotion.",https://mx.linkedin.com/jobs/view/procurement-data-engineer-iii-at-johnson-controls-4024652565,4024652565,"Join the Procurement Execution Center as a Data Engineer responsible for managing the end-to-end data process including ETL/ELT, data staging, and governance. You will deploy data ingestion processes using Azure Data Factory, build complex ETL/ELT processes, and create data models for analytics. Your role includes maintaining data models, managing DevOps pipeline deployment, and supporting global data standards.","Azure Data Factory, Azure Synapse, Azure SQL, Python, SQL, ETL, ELT, SSIS, NoSQL, Azure DevOps",4+,Bachelor,True,4.0,0,0,0,1,0,0,1,0,0,1,0,0,0,0,1,0,0
"Senior, Data Engineer",Oil and Gas Job Search Ltd,Monterrey Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,Oil and Gas,2024-09-08 11:27:40.933821,25,Information Technology,,,"Schneider Electric has an opportunity for a Senior Data Engineer in our Monterrey, MX location. The Data Engineer will develop, maintain, and improve data delivery through North America (NAM) Data Excellence platform. The right person in this role will support improvements in data architecture, metric definition, and processes to support business data and analytical initiatives. Our Data Engineers provide guidance and support to team members in the Data Services team and our business partners. About Us Schneider Electric creates connected technologies that reshape industries, transform cities, and enrich lives. Our 135,000+ employees thrive in more than 100 countries. From the simplest of switches to complex operational systems, our technology, software, and services improve how our customers manage and automate their operations. Help us deliver solutions that ensure Life Is On everywhere, for everyone, and at every moment. http://www.youtube.com/watch?v=YtExntUe89c Key Responsibilities Include Great people make Schneider Electric a great company. Collaborate with team members to conceptualize, design, and deliver enterprise and departmental data solutions to support business intelligence, data warehousing, reporting, and machine learning requirements. Implement reliable and scalable solutions to meet the service levels associated with mission-critical solutions. Participate in and enhance our DevOps practice to ensure highly available solutions and quick issue resolution. Translate business requirements into data pipelines and data stores to support business requirements. Perform assessments (Proof of Concepts) of the latest tools and technologies. Work with Data and Solution Architects to define and implement migration strategies from legacy systems to cloud architecture and technologies. Provide team feedback to optimize the delivery of our solutions. Education Bachelor's degree related to Computer Science or Information Technology or equivalent Benefits Competitive salary Comprehensive health benefits Retirement savings plan Professional development opportunities We know skills and competencies show up in many ways and can be based on your life experience. If you do not necessarily meet all the requirements that are listed, we still encourage you to apply for the position. Qualifications Required qualifications: 5+ years of experience with modern programming languages such as Python, Scala, or Java. 3+ years of experience developing data-related solutions on cloud platforms such as Amazon Web Services (AWS). Demonstrated experience with primary AWS services such as EC2, Lambda, EMR, S3, IAM policies, CloudWatch, Cloud Formation, SES Demonstrated experience with Cloud Services for data handling and database technologies (DMS, Kafka, Spark, Redshift, Athena, Hadoop, Airflow, etc.). Knowledge of Data Management, Integration, and Data Quality tools, such as Alteryx, Trifecta, Informatica Power Center, Informatica Cloud, and Oracle Data Integrator. Command of advanced SQL queries and programming. Experience contributing to and following best practices for architecture, design, and implementation. Have an eye for operational transparency and resiliency at every application layer. Proven analytical and problem-solving abilities. Ability to assimilate information, quickly discern the most relevant facts, and recommend creative, practical design solutions. Ability to think outside the box is a real asset. Experience with DevOps tools and processes and CI/CD are an asset. Excellent communication, presentation, influencing, and reasoning capabilities. Solid understanding of data modeling, ETL processes, and data warehousing concepts. We know skills and competencies show up in many ways and can be based on your life experience. If you do not necessarily meet all the requirements that are listed, we still encourage you to apply for the position. Schedule: Full-time Req: 00922Q",https://mx.linkedin.com/jobs/view/senior-data-engineer-at-oil-and-gas-job-search-ltd-4017867467,4017867467,"The Data Engineer will develop, maintain, and improve data delivery through the North America Data Excellence platform, supporting improvements in data architecture, metric definition, and processes necessary for business data and analytical initiatives. Responsibilities include collaborating to conceptualize and deliver data solutions, implementing reliable solutions for mission-critical systems, participating in DevOps practices, translating business requirements into data pipelines, and assessing tools and technologies.","Python, Scala, Java, Amazon Web Services (AWS), EC2, Lambda, EMR, S3, IAM, CloudWatch, CloudFormation, SES, DMS, Kafka, Spark, Redshift, Athena, Hadoop, Airflow, SQL, Alteryx, Trifecta, Informatica Power Center, Informatica Cloud, Oracle Data Integrator",5+ years,Bachelor,True,5.0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0
Procurement Data Engineer II,Johnson Controls,Monterrey Metropolitan Area,ON-SITE,Entry level,Full-time,Industrial Machinery Manufacturing,2024-09-01 11:27:40.933821,25,Information Technology,,,"Johnson Controls is a global diversified technology and multi industrial leader serving a wide range of customers in more than 150 countries. Our 130,000 employees create intelligent buildings, efficient energy solutions, integrated infrastructure and next generation transportation systems that work seamlessly together to deliver on the promise of smart cities and communities. Our commitment to sustainability dates back to our roots in 1885, with the invention of the first electric room thermostat. We are committed to helping our customers win and creating greater value for all of our stakeholders through strategic focus on our buildings and energy growth platforms. For additional information, please visit www.johnsoncontrols.com or follow us @johnsoncontrols on Twitter. What you will do? Join us in the Procurement Execution Center (PEC) as a Data Engineer as part of a is a diverse team of data and procurement individuals. In this role, you will be responsible for deploying supporting the E2E management of our data, including: ETL/ELT, DW/DL, data staging, data governance, and manage the different layers of data required to ensure a successful BI & Reporting for the PEC. This role will work with multiple types of data, spreading across multiple functional areas of expertise, including Logistics, MRO & Energy, Travel, Professional Services, among others. How you will do it? Deploy data ingestion processes through Azure Data Factory to load data models as required into Azure Synapse. Build and design ETL/ELT processes with Azure Data Factory (ADF) and/or Python, which once deployed, will require to be executed daily and weekly. Assemble large, complex data sets that meet functional / non-functional business requirements. Build the infrastructure required for optimal ETL/ELT of data from a wide variety of data sources using Azure SQL and ADF. Develop data models that enable DataViz, Reporting and Advanced Data Analytics, striving for optimal performance across all data models. Maintain conceptual, logical, and physical data models along with corresponding metadata. Manages the DevOps pipeline deployment model, including automated testing procedures Deploys data stewardship and data governance across our data warehouse, to cleanse and enhance our data, using knowledge bases and business rules. Performs the necessary data ingestion, cleansing, transformation, and coding of business rules to support annual Procurement bidding activities. Support the deployment of a global data standard for Logistics. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Support Rate Repository management as required (including Rate Card uploads to our DW). Other Procurement duties as assigned. What are we looking for? Bachelor’s degree in related field (Engineering, Computer Science, Data Science or similar) 3+ years of relevant experience in BI Engineering, data modeling, data engineering, software engineering or other relevant roles. Strong SQL knowledge and experience working with relational databases. Knowledge in DW/DL concepts, data marts, data modeling, ETL/ELT, data quality/stewardship, distributed systems and metadata management. Experience building and optimizing data pipelines, architectures, and data sets. Azure Data Engineering certification preferred (DP-203) ETL/ELT development experience (3+ years). SSIS or ADF are preferred. Ability to resolve ETL/ELT problems by proposing and implementing tactical/Strategic solutions. Strong project management and Organizational skills. Experience with object-oriented function scripting languages: Python, Scala, C#, etc. Experience with NoSQL databases is a plus to support the transition from On-Prem to Cloud. Excellent problem solving, critical thinking, and communication skills Relevant experience with Azure DevOps (CI/CD, git/repo management) is a plus Due to the global nature of the role, proficiency in English language is a must Johnson Controls does not request pregnancy or HIV testing as a requirement for admission, permanence or promotion.",https://mx.linkedin.com/jobs/view/procurement-data-engineer-ii-at-johnson-controls-4008470721,4008470721,"Join us in the Procurement Execution Center as a Data Engineer responsible for end-to-end management of our data, including ETL/ELT, data warehousing, data governance, and business intelligence. You will deploy data ingestion processes through Azure Data Factory, design and build ETL/ELT processes, manage complex data sets, and develop data models for reporting and analytics. A Bachelor’s degree in a related field and 3+ years of experience in BI Engineering or related roles are required.","Azure Data Factory, Azure Synapse, SQL, Python, ETL, ELT, Data Warehousing, Data Modeling, DevOps, SSIS, NoSQL",3+ years,Bachelor,True,3.0,0,0,0,1,0,1,1,1,0,1,0,0,0,0,1,0,0
Sr. Data Engineer,Uber Freight,Monterrey Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,"Transportation, Logistics, Supply Chain and Storage",2024-08-16 11:27:40.933821,25,Information Technology,,,"About The Team The Uber Freight team is building a better future for logistics. We believe that when shippers and carriers have the freedom to move together, the entire industry moves ahead. Our teams design and build innovative applications, infrastructure, and models to power Uber Freight. Utilizing Uber Freight's foundational elements, these include the mobile app for Carriers, the portals and integrations that give Shippers access to the platform, tools for our Operations teams, and all the underlying pricing, matching, and forecasting algorithms that evolve the freight industry forward. About The Role We are seeking a talented and experienced Data Engineer to contribute to our technical efforts in modernizing and replacing legacy reporting solutions. This role involves collaborating closely with Data Analysts and Business SMEs to perform detailed requirement analysis for enhancing and creating new reporting and analytics solutions. The ideal candidate will have a knack for imagining and implementing creative, innovative reporting solution designs while adhering to architectural requirements of maintainability and scalability. What You'll Do Build scalable highly performant dashboards for delivering clear business insights from a variety of raw data sources Understanding of Web concepts (HTML, CSS, URLS, frames) to the level appropriate to develop Tableau reports in HTML according to UX designs EXPERIENCE in working with Tableau Reporting system an Power BI Develop batch and real-time analytical solutions, prototypes and proof of concept for selected solutions. Collaborate with cross functional team to resolve data quality and operational issues. Basic Qualifications EXPERIENCE with Tableau EXPERIENCE with Power BI Advanced Microsoft Office EXPERIENCE with SQL server reporting services (SSRS); SQL; queries EXPERIENCE with Oracle",https://mx.linkedin.com/jobs/view/sr-data-engineer-at-uber-freight-3976383188,3976383188,"We are seeking a talented and experienced Data Engineer to contribute to modernizing and replacing legacy reporting solutions. This role involves collaborating closely with Data Analysts and Business SMEs to perform detailed requirement analysis for enhancing and creating new reporting and analytics solutions. The ideal candidate will develop scalable dashboards for delivering business insights, understand web concepts to develop Tableau reports, and collaborate with cross-functional teams to resolve data quality issues.","Tableau, Power BI, SQL, Microsoft Office, SQL Server Reporting Services (SSRS), Oracle, HTML, CSS",,,True,,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
Data Insights & Visualization Specialist,Accenture México,Monterrey Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Business Consulting and Services,2024-09-16 15:10:44.080834,158,Information Technology,,,"DARE TO BE A PART OF THE CHALLENGE! COME AND JOIN OUR TEAM TOGETHER WE CAN MAKE THE DIFFERENCE! Did you know that Accenture is leading the digital transformation in the World? Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Our main purpose is to collaborate with our clients, so they can become high-performance businesses. Accenture is present in more than 200 cities, 49 countries and approximately 732,000 employees worldwide. We Offer Career development according to your profile and interests. Work in one of the best companies and feel proud. Access to an innovative methodology and tools. Direct contact with experts worldwide. Use of work schemes and cutting-edge technologies. Constant training. Work environment based on teamwork and collaboration. Participation in International Projects Skills: +7 years of experience Microsoft Power BI Responsibilities: As a Mid Level Data Insights Visualization Practitioner, you use your Microsoft Power BI PBI expertise to develop and implement effective data visualization solutions. You should have expert proficiency in PBI and advanced proficiency in BI Reporting Tools, Data Analysis Interpretation, and Data Visualization. Develop and implement effective data visualization solutions using PBI. Create interactive dashboards and custom reports to provide insights to business stakeholders. Analyze data to identify trends and patterns, and provide recommendations for business improvement. Collaborate with cross functional teams to ensure seamless integration of data visualization solutions. Provide technical guidance and support to project teams throughout the implementation lifecycle.",https://mx.linkedin.com/jobs/view/data-insights-visualization-specialist-at-accenture-m%C3%A9xico-4004418995,4004418995,"As a Mid Level Data Insights Visualization Practitioner, you will use your Microsoft Power BI expertise to develop and implement effective data visualization solutions, create interactive dashboards, analyze data for trends and patterns, and collaborate with cross-functional teams to ensure seamless integration of solutions.","Microsoft Power BI, BI Reporting Tools, Data Analysis, Data Visualization",7+ years,,True,7.0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0
Data Engineer,Chubb,Monterrey Metropolitan Area,HYBRID,Entry level,Full-time,Insurance,2024-09-16 15:10:53.434211,34,Information Technology,,,"Job Description With you, Chubb is better! Are passionate with data infrastructure, metrics and coding? Do you love creating pipelines to support business? Would you like to be a member of a fun working environment where your innovative projects make a real impact? Then, check this outstanding opportunity in our new Technology Hub in Mexico – CBSM ( Chubb Business Services Monterrey ) as a Data Engineer. If you are a tech lover and are raring to develop your career join our growing, pioneer, diverse team within one of the largest companies in the world, we would love to hear from you! The Opportunity Your Responsibilities for this role may include, but are not limited to: Conceptualize, support, and drive the data architecture for multiple large-scale projects as well as recommend solutions to improve processes. Integrate data from various sources and build robust, multi-functional data assets to support analytics. Responsible for data asset design, development, integration, and optimization. Must love coding – prepare to spend more than 80% of the time on hands-on development with groundbreaking technologies. Gatekeeper of end-to-end applications and frameworks ranging from system programming to micro-services to simple front-end applications Build pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts. Moreover, clean, unify and organize messy and complex data sets for easy access and analysis. Collaborate with others to understand data needs, representing key data insights in a meaningful way. Ability to own complete project or a subject area delivery while leading team members in a scrum setting. Design, build, and launch collections of sophisticated data models and visualizations that support multiple use cases across different products or domains. Solve our most exciting data integration problems, applying optimal ETL patterns, frameworks, query techniques, sourcing from structured and unstructured data sources. Be the point of reference for solving a challenging technical problem Knowledge, Skills, And Abilities At least 4 years of data/software engineering experience including data analysis, design and integration/ETL. Good knowledge of Informatica Intelligent Cloud Services (IICS) Strong knowledge of Python Experience with SQL Bonus points for PySpark Databricks Snowflake NoSQL Data Modelling Our team makes a difference, every time. For this reason, we offer in return! We offer hybrid working model, explicit, structured career development, a competitive salary package, annual bonus, private medical cover, monthly allowance for lunch, continuous learning experiences, work in a fun, lively environment with mentoring from our groundbreaking senior mentors. Integrity. Client Focus. Respect. Excellence. Teamwork Our core values instruct how we live and work. We’re an ethical and honest company that’s wholly committed to its clients. A business that’s engaged in mutual trust and respect for its employees and partners. A place where colleagues perform at the highest levels. And a working environment that’s collaborative and encouraging. Diversity & Inclusion. At Chubb, we consider our people our chief competitive advantage and as such we treat colleagues, candidates, clients, and business partners with equality, fairness, and respect, regardless of their age, disability, race, religion or belief, gender, sexual orientation, marital status or family circumstances. We strive to achieve an environment where all colleagues feel comfortable performing to their full potential and are recognized for their contributions. Many voices, One Chubb!",https://mx.linkedin.com/jobs/view/data-engineer-at-chubb-3870861602,3870861602,"In the Data Engineer role, the responsibilities include conceptualizing, supporting, and driving data architecture for large-scale projects, integrating data from various sources, and building multi-functional data assets to support analytics. The role involves hands-on development with technologies, ensuring the design, development, integration, and optimization of data assets. The engineer will be responsible for developing pipelines, dashboards, and systems, as well as cleaning and organizing complex data sets. Collaboration with others to understand data needs and delivering impactful data models and visualizations across different products is key. The role also requires solving data integration problems with optimal ETL patterns and serving as a technical reference.","Python, SQL, Informatica Intelligent Cloud Services (IICS), PySpark, Databricks, Snowflake, NoSQL",4,,True,4.0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,1,0,0
Power BI Consultant,Accenture México,Monterrey Metropolitan Area,HYBRID,Mid-Senior level,Full-time,Business Consulting and Services,2024-09-16 15:10:53.434211,200,Information Technology,,,"DARE TO BE A PART OF THE CHALLENGE! COME AND JOIN OUR TEAM TOGETHER WE CAN MAKE THE DIFFERENCE! Did you know that Accenture is leading the digital transformation in the World? Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Our main purpose is to collaborate with our clients, so they can become high-performance businesses. Accenture is present in more than 200 cities, 49 countries and approximately 732,000 employees worldwide. We Offer Career development according to your profile and interests. Work in one of the best companies and feel proud. Access to an innovative methodology and tools. Direct contact with experts worldwide. Use of work schemes and cutting-edge technologies. Constant training. Work environment based on teamwork and collaboration. Participation in International Projects Requirements: 1-3 years of experience working with reporting and data visualization tools, particularly Power BI. Professional background in data analysis. Practical experience using SQL and DAX. Ability to rapidly transform data into robust reporting and analytical solutions. Understanding of the principles and methodologies of database modeling. Familiarity with Power BI Service. Strong written and verbal communication skills in English. Knowledge of Azure Modern Data Platform (Azure Data Lake, Synapse, Data Factory, Databricks) is a plus. Knowledge or training in Microsoft Fabric is a plus.",https://mx.linkedin.com/jobs/view/power-bi-consultant-at-accenture-m%C3%A9xico-3931982607,3931982607,"The position requires 1-3 years of experience working with reporting and data visualization tools, particularly Power BI. A professional background in data analysis is necessary, along with practical experience using SQL and DAX. The candidate should be able to rapidly transform data into robust reporting and analytical solutions, understand database modeling principles, and be familiar with Power BI Service. Strong written and verbal communication skills in English are required, and knowledge of Azure Modern Data Platform and Microsoft Fabric is a plus.","Power BI, SQL, DAX, Azure Data Lake, Azure Synapse, Azure Data Factory, Databricks, Microsoft Fabric",1-3,,True,1.0,0,0,1,1,0,0,0,0,1,1,0,0,0,0,0,0,0
Workday Data Sr. Analyst,Accenture México,Monterrey Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,Business Consulting and Services,2024-09-16 15:11:11.469289,25,Information Technology,Engineering,,"DARE TO BE A PART OF THE CHALLENGE! COME AND JOIN OUR TEAM TOGETHER WE CAN MAKE THE DIFFERENCE! Did you know that Accenture is leading the digital transformation in the World? Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Our main purpose is to collaborate with our clients, so they can become high-performance businesses. Accenture is present in more than 200 cities, 49 countries and approximately 743,000 employees worldwide. Offer Career development according to your profile and interests. Work in one of the best companies and feel proud. Access to an innovative methodology and tools. Direct contact with experts worldwide. Use of work schemes and cutting-edge technologies. Constant training. Work environment based on teamwork and collaboration. Participation in International Projects Basic Qualifications: 1+ years’ previous consulting experience or congruent professional experience either as an internal consultant or with a consulting/software company 1+ years of experience in HRIS field with Workday related experience in data migration from SAP, Oracle, PeopleSoft, or similar applications Experience with XML, XSD, XSLT or XPath Formula and macro experience in Microsoft Excel Experience with at least 1 full life cycle ERP implementations in a Data Conversion role 1+ years project workstream experience Ability and willingness to travel up to 80% Preferred Skills: Four-year college degree in a computer related or engineering field or equivalent work experience Developed understanding and demonstration of the Software Development Lifecycle (SDLC) Developed experience in Reporting/Analytics Self-starter with proven ability to work within a team-oriented environment Ability to work in a fast-paced environment and to adapt to frequent change Demonstrated ability to work creatively and analytically in a problem-solving environment Demonstrated experience with Excel, Visio, MS Project (or equivalent) and PowerPoint Solid communication (both written and oral) effectiveness with project leadership Accenture does not discriminate based on race, religion, color, sex, age, disability, nationality, sexual orientation, gender identity or expression, or for any other reason covered by local law.",https://mx.linkedin.com/jobs/view/workday-data-sr-analyst-at-accenture-m%C3%A9xico-4004420828,4004420828,"Join our team to make a difference! The position requires 1+ years of previous consulting experience and 1+ years in the HRIS field with Workday. Responsibilities include data migration from SAP, Oracle, PeopleSoft, or similar applications, and experience with XML, XSD, XSLT, or XPath. Experience in Microsoft Excel with formulas and macros, as well as at least 1 full life cycle ERP implementation in a Data Conversion role is necessary. Ability and willingness to travel up to 80% is required.","Workday, SAP, Oracle, PeopleSoft, XML, XSD, XSLT, XPath, Microsoft Excel, Visio, MS Project, PowerPoint",1+,,True,1.0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0
Sr. Data Engineering,Accenture México,Monterrey Metropolitan Area,REMOTE,Mid-Senior level,Full-time,Business Consulting and Services,2024-09-18 07:36:23.414069,25,Information Technology,N/A,N/A,"DARE TO BE A PART OF THE CHALLENGE! COME AND JOIN OUR TEAM TOGETHER WE CAN MAKE THE DIFFERENCE! Did you know that Accenture is leading the digital transformation in the World? Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Our main purpose is to collaborate with our clients, so they can become high-performance businesses. Accenture is present in more than 200 cities, 49 countries and approximately 732,000 employees worldwide. We Offer Career development according to your profile and interests. Work in one of the best companies and feel proud. Access to an innovative methodology and tools. Direct contact with experts worldwide. Use of work schemes and cutting-edge technologies. Constant training. Work environment based on teamwork and collaboration. Participation in International Projects Skills: +5 years of experience Microsoft Azure Microsoft SQL Microsoft Azure Databricks Microsoft Data Factory SSIS ETL Responsibilities As a Data Engineer: You will be responsible for designing, developing, and maintaining data solutions for data generation, collection, and processing. Your main tasks will include creating data pipelines, ensuring data quality, and implementing ETL extract, transform, and load processes to migrate and deploy data across systems. You will be expected to perform independently and become a subject matter expert, actively participating and contributing in team discussions, as well as providing solutions to work related problems. Intermediate proficiency in Microsoft Azure Data Factory is required. Additionally, intermediate proficiency in Microsoft Azure Synapse Analytics, Microsoft Azure Databricks, and beginner proficiency in Microsoft SQL Server Integration Services SSIS are recommended. Develop innovative data solutions to optimize data generation, collection, and processing. Collaborate with cross functional teams to ensure data quality and integrity. Implement efficient ETL processes to migrate and deploy data across systems. Stay updated with the latest industry trends and technologies in data engineering. Identify and resolve data related issues to ensure smooth data operations.",https://mx.linkedin.com/jobs/view/sr-data-engineering-at-accenture-m%C3%A9xico-4026774506,4026774506,"As a Data Engineer, you will be responsible for designing, developing, and maintaining data solutions for data generation, collection, and processing. Your main tasks will include creating data pipelines, ensuring data quality, and implementing ETL processes to migrate and deploy data across systems. You will perform independently, become a subject matter expert, and actively contribute in team discussions.","Microsoft Azure, Microsoft SQL, Microsoft Azure Databricks, Microsoft Data Factory, SSIS, ETL",5+ years,N/A,True,5,0,0,1,1,0,0,1,0,0,1,0,0,0,0,0,0,0
AI Data Engineer,Recruiters Worldwide,Monterrey Metropolitan Area,HYBRID,Entry level,Full-time,IT Services and IT Consulting,2024-09-18 07:36:40.941057,25,Information Technology,N/A,N/A,"Buscamos un AI Data Engineer Senior Resource Description • Ingeniero de datos, especialista en Inteligencia Artificial Generativa (Específicamente en modelos CHATGPT de Azure u otros, que pueda configurarlos, configurar contexto, prompting engineering) Requirements • Ingeniero de datos, especialista en Inteligencia Artificial Generativa LLMs (Open AI,  Llama, Mistral, etc.). • Específicamente en modelos CHATGPT de Azure u otros, vector DataBase, configurar contexto, prompting engineering • Azure functions • Containers. Consideraciones Importantes: • La persona requiere dominar muy bien el inglés. • La persona seleccionada debe residir en Nuevo León., porque el puesto es un  80% presencial. ¿Qué ofrecemos? • Contrato por tiempo determinado de 9 meses (posibilidad de extensión). • Vacaciones conforme a la ley. (Al cumplir un año tienes derecho a 12 días, el siguiente 14 días, después 16 y así sucesivamente). • Aguinaldo conforme a la ley. (15 días por año trabajado). • Prima vacacional del 25%. • Seguro de gastos médicos mayores para el colaborador. • Tarjeta de beneficios MedicallHom o Doctor en línea 24/7 o Ambulancia (1 envío gratis, subsecuentes con precio preferencial) o Médico a domicilio desde $450 pesos. o Chequera de la salud digital (promociones y descuentos a través de la  app) o Consultas con médicos especialistas desde $350 o Descuentos en laboratorios, clínicas, hospitales. o Descuentos comerciales en restaurantes, tiendas departamentales, spas,  tiendas para mascotas, etc. o Servicios oftalmológicos y odontológicos con costos preferenciales o seguro de protección ante accidentes (seguro por muerte accidental,  reembolso de gastos funerarios por accidente, entre otros) o Servicio funerario o Farmacia en línea (Envío de medicamentos a domicilio) o asesoría médica, nutricional y emocional. o Check up médico gratis.",https://mx.linkedin.com/jobs/view/ai-data-engineer-at-recruiters-worldwide-4026715137,4026715137,"We are looking for a Senior AI Data Engineer, a data engineer specializing in Generative Artificial Intelligence (specifically in Azure CHATGPT models or others, capable of configuring them, configuring context, prompting engineering).","Generative AI, OpenAI, Llama, Mistral, Azure, Vector Database, Azure Functions, Containers",N/A,N/A,True,N/A,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0
Data Engineer,Chubb,Monterrey Metropolitan Area,HYBRID,Entry level,Full-time,Insurance,2024-09-18 07:36:40.941057,25,Information Technology,N/A,N/A,"Job Description Data Engineer Job Description: We are seeking an experienced Data Engineer with expertise in ETLs (Extract, Transform, Load), Data Modeling, and Databricks to join our dynamic team. The ideal candidate must possess excellent knowledge and skills in SQL and Python, as they will play a crucial role in managing, optimizing, and enhancing our data infrastructure. Responsibilities: Develop and maintain robust, efficient, and scalable ETL processes for data extraction, transformation, and loading tasks. Design, implement, and optimize data models to meet business requirements and ensure data integrity and accuracy. Collaborate with cross-functional teams, including Data Scientists, Software Engineers, and Business Analysts, to understand data needs and provide data-related solutions. Perform data analysis to identify and resolve data quality issues, inconsistencies, and performance bottlenecks. Build and maintain the data pipeline architecture to enable data ingestion from various sources into the data warehouse or data lake. Work closely with stakeholders to understand business objectives, identify data-related opportunities, and provide actionable insights. Develop and maintain documentation related to data processes, data models, and system architecture. Collaborate with the Data Governance team to ensure compliance with data privacy regulations and implement appropriate security measures. Skills and Qualifications: Bachelor’s or Master’s degree in Computer Science, Information Systems, or a related field. Proven work experience as a Data Engineer or in a similar role. English Fluent Strong knowledge and experience with ETL processes, data modeling, and data warehousing concepts. Proficient in SQL, with the ability to write complex queries and optimize their performance. Expertise in Python programming language and its associated data libraries (e.g., Pandas, NumPy) for data manipulation and analysis. In-depth understanding of relational database systems (e.g., PostgreSQL, MySQL) and experience in query optimization techniques. Hands-on experience with Databricks for data engineering, including building and managing data pipelines, and optimizing data processing workflows. Strong problem-solving and analytical skills, with the ability to troubleshoot and resolve data-related issues. Excellent communication skills and the ability to effectively collaborate with cross-functional teams. Knowledge of data governance and data security principles. Attention to detail and ability to adhere to project timelines and deadlines. Nice to Have Skills: Experience with Informatica Intelligent Cloud Services (IICS) or similar cloud-based integration platforms. Experience designing and developing data integration workflows using IICS or similar tools. Experience with data integration performance tuning and optimization. Familiarity with cloud platform Azure and experience with its data services (e.g., Azure Data Factory). Experience with big data technologies (e.g., Hadoop, Spark) and distributed computing frameworks.",https://mx.linkedin.com/jobs/view/data-engineer-at-chubb-4028793012,4028793012,"We are seeking an experienced Data Engineer with expertise in ETLs, Data Modeling, and Databricks to manage, optimize, and enhance our data infrastructure. Responsibilities include developing and maintaining ETL processes, designing data models, collaborating with cross-functional teams, performing data analysis, building data pipeline architecture, and ensuring compliance with data privacy regulations. The ideal candidate must have a Bachelor’s or Master’s degree in Computer Science or related field and proven work experience in a similar role.","SQL, Python, ETL, Databricks, PostgreSQL, MySQL, Pandas, NumPy, Azure Data Factory, Hadoop, Spark",N/A,Bachelor,True,N/A,0,0,1,1,0,0,1,0,0,1,0,0,0,0,1,0,0
Master Data Analyst,Steelcase,Monterrey Metropolitan Area,HYBRID,Associate,Full-time,Furniture and Home Furnishings Manufacturing,2024-09-18 07:36:40.941057,27,Manufacturing,N/A,N/A,"We are hiring a Master Data Analyst - Associate who will be responsible for the creation and maintenance of Master Data for: customers (Sold-to and Ship-tos), Business partner (site IDs) and other type of data that are fundamental to business processes that influence the customer experience. About the role: The role involves ensuring the integrity, quality, and reliability of master data to support business processes and decision-making. This includes overseeing the creation, modification, and deletion of master data elements to ensure accuracy, completeness, and consistency. The role also involves collaboration with various departments such as IT, Credit, Sales-Channel and other stakeholders to understand data requirements, implement data governance policies, and support business processes. Responsibilities will include: Execute and monitor customer, business partners and product data management and maintenance activities while following global master data policies and practices. Responsibility to manage and communicate directly with Dealers, Customers and Business Partners. Create, update, and maintain master data records in SAP, ensuring data accuracy and consistency. Possible evolution to other systems CRM´s. Implement and enforce data governance policies and standards to guarantee high-quality master data. Conduct regular audits of master data to identify and resolve discrepancies or inconsistencies. Implement data quality checks and validations to prevent errors in master data creation or modification. Identify opportunities for process optimization and automation to enhance efficiency in master data management. Contribute to the development and implementation of best practices for master data processes. Provide training to end-users on SAP master data processes and best practices. Create and maintain documentation related to master data processes, procedures, and standards. Works with relevant partners and appropriate team members to resolve Master Data issues in an efficient and timely manner. Manage customer data and customer data integrity across systems Ensure Replication of data is conducted in a timely manner. Investigate and resolve master data-related issues or errors, working with cross-functional teams to implement corrective actions. Be an active member of assigned integration projects that involve Customer Master Data changes. Who you are Required Skills and Competencies Bachelor’s degree in Business or related. At least 1 year of experience in Master Data or System Administration. Advanced written and spoken English. Intermediate to advanced level of MS Excel. Preferred Skills and Competencies SAP knowledge is a plus. Strong organization skills and able to prioritizes tasks and complete it efficiently. Strong attention to detail with ability to research and resolve complex problems. Demonstrated customer service passion and a willingness to go extra mile. Ability to communicate effectively through a variety of channels with customers and working across matrix organizations (cross functional teams). Continuous improvement mindset. Excellent analytical and problem-solving skills. Why people choose to work with us: At Steelcase, we put people at the center of everything we do. We understand the role of work and believe that it can bring meaning and purpose to the lives of our customers and our employees. We prioritize supporting our employees both in and out of work, in all aspects of their lives. When we bring our talents together, we make a positive lasting impact through our work and communities. Who we are: Organizations around the world trust Steelcase to help them create places that help people work better, be inspired, and accomplish more. We design, manufacture, and partner with other leading organizations to provide architecture, furniture, and technology solutions- accessible through a network of channels, including over 800 Steelcase dealer locations. Steelcase is a global, industry-leading, publicly traded company with fiscal year 2021 revenue of $2.6 billion. What Matters to Us: More than qualifications, we’re looking for talent and potential. We are proud to have a diverse and inclusive workforce, and we're always looking to improve our global community. We value applicants who are comfortable interacting with people different from themselves, building mutual respect and positive relationships. We invite people from all backgrounds and genders to apply. Steelcase provides employment opportunities to all qualified employees and applicants without regard to race, color, creed, genetic information, religion, national origin, gender, sexual orientation, gender identity and expression, age, disability, or veteran status and bases all employment decisions only on valid job requirements. We are proud to be recognized for our inclusive workforce by the Corporate Equality Index for the past nine years.",https://mx.linkedin.com/jobs/view/master-data-analyst-at-steelcase-4028860670,4028860670,"We are hiring a Master Data Analyst - Associate who will be responsible for the creation and maintenance of Master Data for customers, business partners, and other types of data that are fundamental to business processes that influence the customer experience. The role involves ensuring the integrity, quality, and reliability of master data to support business processes and decision-making. Responsibilities include managing data governance policies, conducting audits, implementing quality checks, and optimizing processes. The candidate will create and maintain master data records in SAP, with an emphasis on data accuracy and consistency. Collaboration with various departments is required, along with providing training to end-users.","SAP, MS Excel",1+,Bachelor,True,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
Senior Data Analyst,Chubb,Monterrey Metropolitan Area,HYBRID,Mid-Senior level,Full-time,Insurance,2024-09-18 07:36:40.941057,25,Information Technology,N/A,N/A,"Job Description Senior Data Analyst By joining Chubb as a Senior Data Analyst, you will analyze and certify data, troubleshoot data issues, promote data quality, work directly with the business and developers to document requirements and technical specifications and lead the delivery of key projects in support of North America Statutory Reporting from the enterprise data warehouse. Our data warehouse platform is a strategic application within the business, feeding into multiple systems and applications both up and downstream with data that directly supports business decisions being made each and every day. With us, you’ll leverage your knowledge of SQL and database tables to analyze data, identify gaps or discrepancies, and partner with applications teams, IT teams across the business, our stakeholders, and our Data Architect to drive solutions that directly impacts how data is used throughout the business. You will lead reporting initiatives, delivering solutions from inception to reporting submission while working within budget and timelines. Through it all, we’ll also look to you to share your ideas and manage data related projects end to end that influence how we incorporate, validate, and distribute data enterprise-wide. In this role, you will: Lead all phases of the development, testing, and implementation life cycle, defining, documenting and reviewing all requirements, creating test scenarios, developing test plans, analyzing results and testing/validating data Work with business partners, project management, architecture, development and leadership to deliver reporting solutions on-time, within budget and with data accuracy. Document requirements, technical specifications and implementation documentation on all reporting solutions. Reconcile multiple data sources and identify the root cause of discrepancies in expected output; distinguish between multiple root causes and/or multiple trends in a given data set and articulate results to various stakeholders, management, and technical resources Analyze and test relational databases and investigate any data load failures or data retrieval issues Monitor data warehousing systems based on assigned tasks to ensure reliability and accuracy of information loaded into the databases Generate reports, dashboards, and ad hoc extracts for business and/or leadership Ensure data integrity by implementing quality assurance practices, gathering, and entering missing data, and resolving any anomalies Qualifications 7+ years of experience in a Data Analysis, Business Analysis, Data Quality Assurance (or similar) role as part of a data warehouse team and supporting data-driven projects Experience working with DBMS platforms, including a demonstrated understanding of table structures, hierarchies, joins, etc. Advanced knowledge of SQL, with the ability to write and troubleshoot medium to advanced SQL queries Knowledge of data warehousing methodologies and tools including their connection to systems both up and down stream Bachelor’s degree in Mathematics, Engineering, Computer Science, or a related discipline preferred Prior experience within the insurance industry or related to regulatory reporting is preferred Previous experience with Azure Synapse, Informatica Intelligent Cloud Services (IICS), a plus Our team makes a difference, every time. For this reason, we offer in return! We offer hybrid working model, explicit, structured career development, a competitive salary package, annual bonus, private medical cover, monthly allowance for lunch, continuous learning experiences, work in a fun, lively environment with mentoring from our groundbreaking senior mentors. Integrity. Client Focus. Respect. Excellence. Teamwork Our core values instruct how we live and work. We’re an ethical and honest company that’s wholly committed to its clients. A business that’s engaged in mutual trust and respect for its employees and partners. A place where colleagues perform at the highest levels. And a working environment that’s collaborative and encouraging. Diversity & Inclusion. At Chubb, we consider our people our chief competitive advantage and as such we treat colleagues, candidates, clients, and business partners with equality, fairness, and respect, regardless of their age, disability, race, religion or belief, gender, sexual orientation, marital status or family circumstances. We strive to achieve an environment where all colleagues feel comfortable performing to their full potential and are recognized for their contributions. Many voices, One Chubb!",https://mx.linkedin.com/jobs/view/senior-data-analyst-at-chubb-3992774351,3992774351,"As a Senior Data Analyst, you will analyze and certify data, troubleshoot data issues, promote data quality, and lead the delivery of key projects in support of North America Statutory Reporting from the enterprise data warehouse. Your role involves using SQL to analyze data, identify discrepancies, document requirements, and collaborate with various teams to drive data solutions. You will manage reporting initiatives, ensure data integrity, reconcile data sources, and generate reports while adhering to budget and timelines.","SQL, Data Warehousing, DBMS, Azure Synapse, Informatica Intelligent Cloud Services",7+,Bachelor,True,7,0,0,0,1,0,1,1,0,0,1,0,0,0,0,0,0,0
Business Intelligence Specialist,ABB,Monterrey Metropolitan Area,ON-SITE,N/A,Full-time,"Appliances, Electrical, and Electronics Manufacturing",2024-09-18 07:37:03.680629,25,Sales,N/A,N/A,"At ABB, we are dedicated to addressing global challenges. Our core values: care, courage, curiosity, and collaboration - combined with a focus on diversity, inclusion, and equal opportunities - are key drivers in our aim to empower everyone to create sustainable solutions. Write the next chapter of your ABB story. This position reports to EL Customer Operations Manager Your role and responsibilities In this role, you will have the opportunity to facilitate the development of the marketing strategy for existing and potential products, systems, and/or services. Each day, you will support the definition of the assigned market footprint (market presence, execution standards, and delivery model). You will also showcase your expertise by performing various market analyses. The work model for the role is: #L-Hybrid This role is contributing to the ELECTRIFICATION team and stakeholders. You will be mainly accountable for: Collecting data and providing sound business and competitor intelligence analyses of internal sales, technical and financial data, and external market data and trends. Interpreting resulting data and supports the Business Intelligence Manager in providing recommendations to Marketing and Sales management teams. Supporting the definition of business intelligence strategic plans in collaboration with management and driving relevant implementation. Building comprehensive sales analyses regarding channels, segments, geographic areas, customers, products, systems, and services to provide valuable insights for strategic decision-making. Qualifications For The Role Bachelor’s degree in Electrical, Mechatronics or Automation Engineering. Experience with Electrification Projects and Medium Voltage Products. Previous experience working with Infrastructure projects. 2+ years of experience in similar roles working as leadership. Available to relocation and travel. Advanced English level. Benefits Retirement plan Life insurance Accident insurance Paid Parental leave (gender neutral) Wellbeing program",https://mx.linkedin.com/jobs/view/business-intelligence-specialist-at-abb-4026437275,4026437275,"In this role, you will facilitate the development of the marketing strategy for existing and potential products, perform various market analyses, and support the definition of market presence and execution standards. You will collect data and provide business and competitor intelligence analyses, interpret data for marketing and sales management recommendations, and build comprehensive sales analyses for strategic decision-making.","Data Analysis, Business Intelligence, Market Analysis, Sales Analysis, Electrical Engineering",2+ years,Bachelor,True,2,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
Data Analyst,Epicor,Monterrey Metropolitan Area,ON-SITE,Entry level,Full-time,"IT Services and IT Consulting, Software Development, and Technology, Information and Internet",2024-09-18 07:37:03.680629,57,Information Technology,N/A,N/A,"Requirements Description & Requirements The Job: The Data Quality Analyst is responsible for ensuring the accuracy, integrity, and reliability of data across the organization. What you will be doing: Performing statistical tests on large datasets to determine data quality and integrity. Evaluating system performance and design, as well as its effect on data quality. Collaborating with database developers to improve data collection and storage processes. Running data queries to identify coding issues and data exceptions, as well as cleaning data. Gathering data from primary or secondary data sources to identify and interpret trends. Reporting data analysis findings to management to inform business decisions and prioritize information system needs. Documenting processes and maintaining data records. Adhering to best practices in data analysis and collection. Keeping abreast of developments and trends in data quality analysis. Working with functional operational teams to institute new processes to mitigate impacts to data integrity Perform corrections within source systems to adhere to overall data integrity guidelines. You bring (most) of this!: Bachelor's degree in statistics, mathematics, computer science, information management, or similar. At least 3-5 years of experience in data quality analysis. Proficiency in programming languages, including Structured Query Language (SQL) and JavaScript is preferred. In-depth knowledge of statistical methods and tests. Extensive experience with statistical packages, such as MS Excel, SAS, and SPSS Exceptional analytical skills. Advanced problem-solving skills. Knowledge of best practices in data analysis. Excellent interpersonal and communication skills. The Finance Team You’ll find a strong sense of community, collaboration, and cross-functional partnering within the Epicor Finance and Accounting organization. With Epicor being an eager company, you will play a key role in supporting mergers and acquisitions and strategic financial activity globally. We are rapidly expanding and looking for exceptional talent to join our team in all of our Epicor offices. About Epicor At Epicor we know that success comes from working together. Everyone has a role to play, and it’s the essential partnerships across our company that are crucial to our customers’ success and our growth as a business. We’re truly a team. Working in close partnership, we bring wide-ranging talents together in powerful collaborations. We think innovatively, share our knowledge generously, and constantly learn from our colleagues. We’re proud of the success we achieve every day, but we never stop challenging ourselves and encouraging each other. Together, we go further and imagine an even brighter future. Whatever your career journey, we’ll help you find the right path. Through our training courses, mentorship, and continuous support, you’ll get everything you need to thrive. At Epicor, your success is our success. And that success really matters, because we’re the essential partners for the world’s most essential businesses—the hardworking companies who make, move, and sell the things the world needs. Equal Opportunities and Accommodations Statement Epicor is committed to creating a workplace and global community where inclusion is valued; where you bring the whole and real you—that’s who we’re interested in. If you have interest in this or any role- but your experience doesn’t match every qualification of the job description, that’s okay- consider applying regardless. We are an equal-opportunity employer.",https://mx.linkedin.com/jobs/view/data-analyst-at-epicor-3994990217,3994990217,"The Data Quality Analyst is responsible for ensuring the accuracy, integrity, and reliability of data across the organization, performing statistical tests on large datasets, collaborating with database developers, running data queries, interpreting trends, and reporting findings to management.","SQL, JavaScript, MS Excel, SAS, SPSS, Statistical Methods",3-5,Bachelor,True,3,0,0,0,0,0,1,0,0,1,1,0,0,0,0,0,0,0
Master Data Analyst,Clarios,Monterrey Metropolitan Area,ON-SITE,Mid-Senior level,Full-time,Motor Vehicle Parts Manufacturing,2024-09-18 07:37:03.680629,64,Information Technology,N/A,N/A,"Responsibilities Master Data Management using knowledge of/experience with SAP master data and concepts across Materials Management (MM), Production Planning (PP) modules, with emphasis on plant-specific material masters, BOMs, Work centers, Routings, and production versions. Master Data Management using the SAP Business Workplace and workflow-enabled processes and coordinating with Cost Accounting following Engineering Change Order release to extend materials and BOMs to plants, create/update routings, and production versions, and verify that all master data objects are complete for the business operations. Conduct Material Master Data updates as needed by the business using mass update tools including Winshuttle, LSMW, and MM17/MASS. Develop and maintain mass maintenance scripts using Winshuttle (10.7x or 11.x) including script and Excel template development, file management / version control, and general technical support (utilizing Winshuttle Support, as necessary). Coordinate with domain data stewards and data quality lead to ensure master data integrity and data quality in key systems is aligned to approved data standards and business rules. Active monitoring of material data quality audit reports. Identifying Root cause, documenting and resolving data quality issues. Support day-to-day data related issues for US/CA/MX plants in SAP, BES and QAD. About Clarios: Clarios is the global leader in advanced, low-voltage battery technologies for mobility. We power progress through ever-smarter solutions for virtually every kind of vehicle. With 16,000 employees in over 140 countries, we bring deep expertise to our Aftermarket and OEM partners, and reliability, safety and comfort to everyday lives. We answer to the planet with a rigorous ESG focus – advancing best-in-class sustainability practices and advocating for them across our industry. We recover, recycle and reuse up to 99% of our battery materials. Clarios is a Brookfield portfolio company. To all recruitment agencies: Clarios does not accept unsolicited agency resumes/CVs. Please do not forward resumes/CVs to our careers email addresses, Clarios employees or any other company location. Clarios is not responsible for any fees related to unsolicited resumes/CVs. Clarios, LLC is an equal employment opportunity and affirmative action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, protected veteran status, status as a qualified individual with a disability, or any other characteristic protected by law. For more information, please view EEO is the Law, EEO is the Law (supplement), and Pay Transparency Non-discrimination. If you are an individual with a disability and you require an accommodation during the application process, please email Special.Accommodations@Clarios.com. A Note to Job Applicants : please be aware of scams being perpetrated through the Internet and social media platforms. Clarios will never require a job applicant to pay money as part of the application or hiring process.",https://mx.linkedin.com/jobs/view/master-data-analyst-at-clarios-3992226351,3992226351,"The responsibilities include Master Data Management using SAP master data within Materials Management (MM) and Production Planning (PP) modules. The position emphasizes plant-specific material masters, BOMs, work centers, routings, and production versions. You will conduct updates using mass tools like Winshuttle, LSMW, and MM17/MASS, and develop maintenance scripts with technical support. Coordination with data stewards and auditing for data quality are also crucial components of the role.","SAP, Winshuttle, LSMW, MM17/MASS, Excel",N/A,N/A,True,N/A,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
