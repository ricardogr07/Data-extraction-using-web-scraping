Title,Company,Location,Remote,SeniorityLevel,EmploymentType,Industries,DatePosted,NumApplicants,JobFunction1,JobFunction2,JobFunction3,Description,Url,JobID,ShortDescription,TechStack,YoE,MinLevelStudies,English,MinYoE,Agile Methodologies,Back-End Development,Big Data Tools,Cloud Platforms,Containerization and Orchestration,Data Analysis,Data Engineering,Data Modeling,Data Visualization,Database Management,Front-End Development,Infrastructure as Code (IaC) and Automation,Machine Learning,Networking,Python,Testing and Quality Assurance,Other
Machine Learning Engineer,Grid Dynamics,Guadalajara,REMOTE,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-08-16 11:29:34.794464,41,Engineering,Information Technology,,"We are seeking a Senior Machine Learning Engineer with proven expertise in developing Machine Learning models, including tabular data and NLP models. The ideal candidate will have experience with product recommendation systems and the ability to innovate beyond traditional approaches. This role requires strong programming skills in Python, extensive experience with AWS cloud services (particularly SageMaker, EC2, S3, and Redshift), and a solid understanding of the full ML lifecycle and MLOps principles. Responsibilities Collaborate closely with the engineering and product team to design and implement Machine Learning models that support product recommendations and other business needs Develop and manage the Machine Learning lifecycle, from initial prototyping to full-scale production deployment Interpret and integrate complex data sets from various sources, including structured and unstructured data Apply expert knowledge in Machine Learning and Artificial Intelligence to diverse datasets and use cases, ensuring scalability and adaptability of solutions based on volume and requirements Build and maintain a robust MLOps workflow, including model prototyping, deployment, and monitoring. Requirements Proven expertise in developing Machine Learning models, including tabular data and NLP models Experience with product recommendation systems and the ability to innovate beyond traditional approaches. Experience with AWS cloud services, particularly SageMaker, EC2, S3, and Redshift. Strong programming skills in Python Experience in deploying Machine Learning models into production environments, particularly using CI/CD frameworks Solid understanding of the full ML lifecycle and MLOps principles Demonstrated ability to work collaboratively in cross-functional teams and communicate complex technical information to non-expert stakeholders. We offer 100% payroll scheme, benefits by law (IMSS, INFONAVIT, 12+ vacation days) Benefits above the law: Vacation premium 50%, 5 PTOs, 3 sick days, 10 guaranteed public holidays per year Major medical insurance, Dental and Vision plan for an employee and direct family members Minor Medical Insurance (Multiservicios Médicos Santander) for an employee and direct family members Life Insurance and funeral expenses 5% savings fund, uncapped (matched by the company in the end of the year) Grocery cards/vouchers (Vales de Despensa) 30 days End of the Year Bonus (Aguinaldo) Opportunity to work on bleeding-edge projects with a highly motivated and dedicated team all over the world Individual career development plan and support from the best experts Professional development opportunities (Linkedin Learning, Cloud certification programs, access to corporate LMS integrated with other learning platforms) Well-equipped office in a business area of Guadalajara (quiet room, games room, air hockey, PS5, Nintendo Switch and Xbox Series X, pool table, ping pong, snacks, smoothies, and much more) Corporate social events (yoga, massages, sport tournaments, discussion panels, technical talks, lunch & learns) Flexible working hours Opportunity to relocate to another country where the company's offices are present. About Us Grid Dynamics (NASDAQ: GDYN) is a leading provider of technology consulting, platform and product engineering, AI, and advanced analytics services. Fusing technical vision with business acumen, we solve the most pressing technical challenges and enable positive business outcomes for enterprise companies undergoing business transformation. A key differentiator for Grid Dynamics is our 8 years of experience and leadership in enterprise AI, supported by profound expertise and ongoing investment in data, analytics, cloud & DevOps, application modernization, and customer experience. Founded in 2006, Grid Dynamics is headquartered in Silicon Valley with offices across the Americas, Europe, and India.",https://mx.linkedin.com/jobs/view/machine-learning-engineer-at-grid-dynamics-3990273246,3990273246,"We are seeking a Senior Machine Learning Engineer with proven expertise in developing Machine Learning models, including tabular data and NLP models. The ideal candidate will have experience with product recommendation systems and the ability to innovate beyond traditional approaches. This role requires strong programming skills in Python, extensive experience with AWS cloud services, and a solid understanding of the full ML lifecycle and MLOps principles. Responsibilities include collaborating closely with engineering and product teams to design and implement Machine Learning models, managing the Machine Learning lifecycle, interpreting complex data sets, and building and maintaining a robust MLOps workflow.","Python, AWS (SageMaker, EC2, S3, Redshift), Machine Learning, NLP, CI/CD, MLOps",,,True,,0,0,0,1,0,0,0,0,0,0,0,0,1,0,1,0,0
Data Scientist with Azure Machine Learning Engineer - Fulltime,"Cliecon Solutions, Inc.",Guadalajara,REMOTE,Entry level,Full-time,IT Services and IT Consulting,2024-09-12 11:29:34.794464,26,Engineering,Information Technology,,"Hello Professional, Greetings from Cliecon Solutions Inc., I am Musham Goutham, part of Cliecon Recruiting team. Please check/review the below requirements and forward your/Consultant resume, and contact details if you are interested and comfortable with the below job description feel free to call/mail me at goutham@cliecon.com or O: 732-626-9717 Ext 107 *Please make sure consultant should be in Mexico only and Mexican Citizen, because need to visit the Client location based on the Client need. Role - Azure Machine Learning – Technical Support Engineer Location – Guadalajara, MX (Remote) Job description: Skills: Knowledge with Azure Machine Learning and how it works with associated Azure services. Strong Python coding skills preferably SDK Ver2 Knowledge of AML workspace Provisioning and model Deployment Knowledge in AML Studio, Azure Key Vault, Azure Kubernetes Services, Azure cloud Storage, Azure Container Registry Knowledge of scenario-based Inferencing, how to deploy, how to provision on a compute and get the inferencing results Knowledge of Networking, DNS, Troubleshooting will be added advantage Familiarity with machine learning algorithms, model development, and deployment. Experience in troubleshooting and resolving technical issues related to machine learning frameworks and tools. Responsible for providing technical support and expertise to customers utilizing the Azure Machine Learning platform. Respond to inquiries, troubleshoot technical issues and provide solutions. Debugging, and problem-solving skills Investigate and resolve customer-reported problems related to Azure Machine Learning services (Ex:ML job failures). Understand API errors, browser compatibility issues, image processing, face recognition. Azure, AWS cloud development experience Effective communication and interpersonal skills to interact with customers and cross-functional teams. About us: Cliecon Solutions Inc.,( headquartered in central NJ ) is one of the fastest-growing and leading consulting and management firms with 16 years of experience in Staff Augmentation. We handle a complete recruiting cycle for fortune 500 clients, major implementing partners, and tier -1 vendors. We specialized in recruiting for Application development, Bigdata, Databases, Infrastructure, Cloud, Mobile, and ERP-based solutions projects. Thanks & Regards, Musham Goutham, Technical Lead, Cliecon Solutions Inc., (Client + Consultants) O: 732-626-9717 Ext 107 Direct: 609-901-9002 E: goutham@cliecon.com || http://www.cliecon.com Contact me on LinkedIn: https://www.linkedin.com/in/goutham-m-640035a2/",https://mx.linkedin.com/jobs/view/data-scientist-with-azure-machine-learning-engineer-fulltime-at-cliecon-solutions-inc-4022936511,4022936511,"The role of Azure Machine Learning Technical Support Engineer involves providing technical support and expertise to customers utilizing the Azure Machine Learning platform, troubleshooting and resolving technical issues related to machine learning frameworks, and deploying models on Azure services. Responsibilities include responding to inquiries, debugging, and investigating customer-reported problems, with a strong emphasis on Python coding and machine learning algorithms.","Azure Machine Learning, Azure Services, Python, Azure Key Vault, Azure Kubernetes Services, Azure Cloud Storage, Azure Container Registry, Machine Learning Algorithms",,,True,,0,0,0,1,1,0,0,0,0,0,0,0,1,0,1,0,0
AI/ML and MLOps Field Engineer,Canonical,Guadalajara,REMOTE,Entry level,Full-time,"Technology, Information and Internet",2024-09-01 11:29:34.794464,25,Engineering,Information Technology,,"Canonical is a leading provider of open source software and operating systems to the global enterprise and technology markets. Our platform, Ubuntu, is very widely used in breakthrough enterprise initiatives such as public cloud, data science, AI, engineering innovation and IoT. Our customers include the world's leading public cloud and silicon providers, and industry leaders in many sectors. The company is a pioneer of global distributed collaboration, with 1000+ colleagues in 70+ countries and very few roles based in offices. Teams meet two to four times yearly in person, in interesting locations around the world, to align on strategy and execution. The company is founder led, profitable and growing. We are hiring an AI/ML and MLOps Field Engineer to help global companies embrace AI in their business, using the latest open source capabilities on public and private cloud infrastructure, Linux and Kubernetes. Our team applies expert insights to real-world customer problems, enabling the enterprise adoption of Ubuntu, Kubeflow, MLFlow, Feast, DVC and related analytics, machine learning and data technologies. We are working to create the world's best open source data platform, covering traditional SQL databases and today's NoSQL data stores, as well as the machinery which turns data into insights and executable models. The people who love this role are software engineers who enjoy customer conversations and solving customer problems during the presales cycle. They are are developers who like to solve customer problems through architecture, presentations and training. Ubuntu is used by pretty much every enterprise in the world, in every industry. This is a fantastic opportunity to learn about the open source technology landscape and develop your business technology insights. You will see first hand in various industries how Linux - and Ubuntu in particular - is shaping innovation and changing the world for the better. This role is particularly suited to candidates with a technical background who are business minded and driven by commercial success. This role is on our global Field Engineering team and will work closely with enterprise sales leads. We are specifically looking for people interested in solving the most difficult problems in modern data architectures. Training LLMs on multiple K8s clusters deployed on a hybrid cloud infrastructure with GPU sharing across multiple teams? Processing 10M events in real time for financial transactions? Object detection on 10k parallel 4K video streams? These are the problems we solve day to day. Location: Most of our colleagues work from home. We are growing teams in EMEA, Americas and APAC time zones, so can accommodate candidates from almost any country. What your day will look like The global Field Engineering team members are Linux and cloud solutions architects for our customers, designing private and public cloud solutions fitting their workload needs. They are the cloud consultants who work hands-on with the technologies by deploying, testing and handing over the solution to our support or managed services team at the end of a project. They are also software engineers who use Python to develop Kubernetes operators and Linux open source infrastructure-as-code. Work across the entire Linux stack, from kernel, networking, storage, to applications Architect cloud infrastructure solutions like Kubernetes, Kubeflow, OpenStack, and Spark Deliver solutions either on-premise or in public cloud (AWS, Azure, Google Cloud) Collect customer business requirements and advise them on Ubuntu and relevant open source applications Grow a healthy, collaborative engineering culture in line with the company values Deliver presentations and demonstrations of Ubuntu Pro and AI/ML capabilities to prospective and current clients Liaise with product teams to give them feedback on requirements to influence roadmap Work collaboratively with your sales team to reach our common targets Global travel up to 25% of time for internal and external events and 25% to customer meetings What we are looking for in you Exceptional academic track record from both high school and university Undergraduate degree in a technical subject or a compelling narrative about your alternative chosen path Experience in data engineering, MLOps, or big data solutions deployment Experience with a relevant programming language, like Python, R, or Rust. Confidence to respectfully speak up, exchange feedback, and share ideas without hesitation Track record of going above-and-beyond expectations to achieve outstanding results Demonstrated personal interest in continuous learning and development Practical knowledge of Linux, virtualisation, containers and networking Business-minded technology thinker and problem solver Knowledge of cloud computing concepts & leaders, such as Kubernetes, AWS, Azure, GCP Interest in large-scale enterprise open source - private clouds, machine learning and AI, data and analytics Intermediate level Python programming skills Passion for technology evidenced by personal projects and initiatives The work ethic and confidence to shine alongside motivated colleagues Professional written and spoken English with excellent presentation skills Experience with Linux (Debian or Ubuntu preferred) Excellent interpersonal skills, curiosity, flexibility, and accountability A dynamic person who loves to jump in new projects and interact with people Appreciative of diversity, polite and effective in a multi-cultural, multi-national organisation Thoughtfulness and self-motivation Result-oriented, with a personal drive to follow up and meet commitments Ability to travel internationally, for company events up to two weeks long, and customer or industry meetings What you'll learn Architect and deploy AI/ML infrastructures, data processing pipelines and multi-cluster distributed training Wide range of open source applications and skills Work directly with customers in a range of different businesses Real-life and hands-on exposure to a wide range of emerging technologies and tools What we offer colleagues We consider geographical location, experience, and performance in shaping compensation worldwide. We revisit compensation annually (and more often for graduates and associates) to ensure we recognise outstanding performance. In addition to base pay, we offer a performance-driven annual bonus or commission. We provide all team members with additional benefits, which reflect our values and ideals. We balance our programs to meet local needs and ensure fairness globally. Distributed work environment with twice-yearly team sprints in person Personal learning and development budget of USD 2,000 per year Annual compensation review Recognition rewards Annual holiday leave Maternity and paternity leave Employee Assistance Programme Opportunity to travel to new locations to meet colleagues Priority Pass, and travel upgrades for long haul company events About Canonical Canonical is a pioneering tech firm at the forefront of the global move to open source. As the company that publishes Ubuntu, one of the most important open source projects and the platform for AI, IoT and the cloud, we are changing the world of software. We recruit on a global basis and set a very high standard for people joining the company. We expect excellence - in order to succeed, we need to be the best at what we do. Most colleagues at Canonical have worked from home since its inception in 2004. Working here is a step into the future, and will challenge you to think differently, work smarter, learn new skills, and raise your game. Canonical is an equal opportunity employer We are proud to foster a workplace free from discrimination. Diversity of experience, perspectives, and background create a better work environment and better products. Whatever your identity, we will give your application fair consideration.",https://mx.linkedin.com/jobs/view/ai-ml-and-mlops-field-engineer-at-canonical-4013777275,4013777275,"We are hiring an AI/ML and MLOps Field Engineer to help global companies embrace AI in their business, using the latest open source capabilities on public and private cloud infrastructure, Linux, and Kubernetes. The role involves designing cloud infrastructure solutions, developing Kubernetes operators using Python, and working with various open source applications to solve customer problems in modern data architectures.","Python, Kubernetes, Linux, OpenStack, Spark, AWS, Azure, Google Cloud, Kubeflow, MLFlow, Feast, DVC",,Undergraduate Student,True,,0,0,1,1,1,0,0,0,0,0,0,1,1,0,1,0,0
Python Software Engineer for AI,Oowlish,Guadalajara,REMOTE,Entry level,Full-time,IT Services and IT Consulting,2024-09-01 11:29:34.794464,93,Engineering,Information Technology,,"Join Our Team Oowlish, one of Latin America's rapidly expanding software development companies, is seeking experienced technology professionals to enhance our diverse and vibrant team. As a valued member of Oowlish, you will collaborate with premier clients from the United States and Europe, contributing to pioneering digital solutions. Our commitment to creating a nurturing work environment is recognized by our certification as a Great Place to Work, where you will have opportunities for professional development, growth, and a chance to make a significant international impact. We offer the convenience of remote work, allowing you to craft a work-life balance that suits your personal and professional needs. We're looking for candidates who are passionate about technology, proficient in English, and excited to engage in remote collaboration for a worldwide presence. We are seeking a highly skilled Senior Python Developer with experience in Machine Learning and Artificial Intelligence. The ideal candidate will have recent hands-on experience in these areas and a proven track record of delivering high-quality technical projects. Must Have Advanced English skills, both written and verbal. Over 5 years of experience in Python development. Hands-on experience with Generative AI technologies (Langchain, Bedrock, prompt engineering, RAG, etc.). Proven experience in designing and implementing AI-driven solutions. Strong problem-solving skills and attention to detail. Excellent communication and collaboration skills. Ability to work independently and as part of a team. Benefits & Perks Home office; Flexible Hours Competitive compensation based on experience; Career plans to allow for extensive growth in the company; International Projects; Oowlish English Program (Technical and Conversational); Oowlish Fitness with Total Pass; Connecting You (Internet allowance); Anniversary bonus; Wedding gift; Pet adoption incentive; New baby Oowl bonus; Back to School bonus; Streaming Subscription; PTO Bonus; Games and Competitions; Enjoy your national Holidays. You Can Also Apply Here Website: https://www.oowlish.com/work-with-us/ LinkedIn: https://www.linkedin.com/company/oowlish/jobs/ Instagram: https://www.instagram.com/oowlishtechnology/",https://mx.linkedin.com/jobs/view/python-software-engineer-for-ai-at-oowlish-4010711405,4010711405,"We are seeking a highly skilled Senior Python Developer with experience in Machine Learning and Artificial Intelligence. The ideal candidate will have recent hands-on experience in these areas and a proven track record of delivering high-quality technical projects. Must have advanced English skills, both written and verbal. Candidates will engage in delivering AI-driven solutions and have strong problem-solving skills and attention to detail.","Python, Machine Learning, Artificial Intelligence, Langchain, Bedrock, Prompt Engineering, RAG",5+ years,,True,5.0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0
"Python and Kubernetes Software Engineer - Data, AI/ML & Analytics",Canonical,Guadalajara,REMOTE,Entry level,Full-time,"Technology, Information and Internet",2024-09-01 11:29:34.794464,25,Engineering,Information Technology,,"Canonical is a leading provider of open source software and operating systems to the global enterprise and technology markets. Our platform, Ubuntu, is very widely used in breakthrough enterprise initiatives such as public cloud, data science, AI, engineering innovation and IoT. Our customers include the world's leading public cloud and silicon providers, and industry leaders in many sectors. The company is a pioneer of global distributed collaboration, with 1000+ colleagues in 70+ countries and very few roles based in offices. Teams meet two to four times yearly in person, in interesting locations around the world, to align on strategy and execution. The company is founder led, profitable and growing. We are hiring Python and Kubernetes Specialist Engineers focused on Data, AI/ML and Analytics Solutions to join our teams building open source solutions for public cloud and private infrastructure. As a software engineer on the team, you'll collaborate on an end-to-end data analytics and mlops solution composed of popular, open-source, machine learning tools, such as Kubeflow, MLFlow, DVC, and Feast. You may also work on workflow, ETL, data governance and visualization tools like Apache SuperSet, dbt, and Temporal, or data warehouse solutions such as Apache Trino, or ClickHouse. Your team will own a solution from the analytics and machine learning space, and integrate with the solutions from other teams to build the world's best end-to-end data platform. These solutions may be run on servers or on the cloud, on machines or on Kubernetes, on developer desktops, or as web services. We serve the needs of individuals and community members as much as the needs of our Global 2000 and Fortune 500 customers; we make our primary work available free of charge and our Pro subscriptions are also available to individuals for personal use at no cost. Our goal is to enable more people to enjoy the benefits of open source, regardless of their circumstances. Location: This initiative spans many teams that are home-based in EMEA, Americas and APAC time zones, so we can accommodate candidates in almost any location. We believe in distributed collaboration but we also try to ensure that colleagues have company during their work hourse! Successful candidates will join a team where most members and your manager are broadly in the same time zone so that you have the benefits of constant collaboration and discussion. What your day will look like Develop your understanding of the entire Linux stack, from kernel, networking, and storage, to the application layer Design, build and maintain solutions that will be deployed on public and private clouds and local workstations Master distributed systems concepts such as observability, identity, tracing Work with both Kubernetes and machine-oriented open source applications Collaborate proactively with a distributed team of engineers, designers and product managers Debug issues and interact in public with upstream and Ubuntu communities Generate and discuss ideas, and collaborate on finding good solutions What we are looking for in you Professional or academic software delivery using Python or Golang Exceptional academic track record from both high school and university Undergraduate degree in a technical subject or a compelling narrative about your alternative chosen path Confidence to respectfully speak up, exchange feedback, and share ideas without hesitation Track record of going above-and-beyond expectations to achieve outstanding results Passion for technology evidenced by personal projects and initiatives The work ethic and confidence to shine alongside motivated colleagues Professional written and spoken English with excellent presentation skills Experience with Linux (Debian or Ubuntu preferred) Excellent interpersonal skills, curiosity, flexibility, and accountability Appreciative of diversity, polite and effective in a multi-cultural, multi-national organisation Thoughtfulness and self-motivation Result-oriented, with a personal drive to meet commitments Ability to travel twice a year, for company events up to two weeks long Additional Skills That Would Be Nice To Have The following skills may be helpful to you in the role, but we don't expect everyone to bring all of them. Hands-on experience with machine learning libraries, or tools. Proven track record of building highly automated machine learning solutions for the cloud. Experience with container technologies (Docker, LXD, Kubernetes, etc.) Experience with public clouds (AWS, Azure, Google Cloud) Working knowledge of cloud computing Passionate about software quality and testing Experience working on an open source project What we offer colleagues We consider geographical location, experience, and performance in shaping compensation worldwide. We revisit compensation annually (and more often for graduates and associates) to ensure we recognise outstanding performance. In addition to base pay, we offer a performance-driven annual bonus or commission. We provide all team members with additional benefits, which reflect our values and ideals. We balance our programs to meet local needs and ensure fairness globally. Distributed work environment with twice-yearly team sprints in person Personal learning and development budget of USD 2,000 per year Annual compensation review Recognition rewards Annual holiday leave Maternity and paternity leave Employee Assistance Programme Opportunity to travel to new locations to meet colleagues Priority Pass, and travel upgrades for long haul company events About Canonical Canonical is a pioneering tech firm at the forefront of the global move to open source. As the company that publishes Ubuntu, one of the most important open source projects and the platform for AI, IoT and the cloud, we are changing the world of software. We recruit on a global basis and set a very high standard for people joining the company. We expect excellence - in order to succeed, we need to be the best at what we do. Most colleagues at Canonical have worked from home since its inception in 2004. Working here is a step into the future, and will challenge you to think differently, work smarter, learn new skills, and raise your game. Canonical is an equal opportunity employer We are proud to foster a workplace free from discrimination. Diversity of experience, perspectives, and background create a better work environment and better products. Whatever your identity, we will give your application fair consideration.",https://mx.linkedin.com/jobs/view/python-and-kubernetes-software-engineer-data-ai-ml-analytics-at-canonical-4011644944,4011644944,"Canonical is hiring Python and Kubernetes Specialist Engineers focused on Data, AI/ML, and Analytics Solutions to build open source solutions for public cloud and private infrastructure. Responsibilities include developing an understanding of the entire Linux stack, designing, building, and maintaining solutions for public and private clouds, and collaborating with a distributed team. Candidates should have experience in software delivery using Python or Golang, exceptional academic track record, and the ability to communicate effectively in English.","Python, Golang, Kubernetes, Kubeflow, MLFlow, DVC, Feast, Apache SuperSet, dbt, Temporal, Apache Trino, ClickHouse, Linux, Docker, AWS, Azure, Google Cloud",,Undergraduate Student,True,,0,1,1,1,1,0,0,0,0,0,0,0,1,0,1,0,0
Senior Data Scientist,Launch Potato,Guadalajara,REMOTE,Mid-Senior level,Full-time,Advertising Services,2024-09-08 11:29:34.794464,25,Engineering,Information Technology,,"WHO ARE WE? Launch Potato is a digital media company with a portfolio of brands and technologies. As The Discovery and Conversion Company, Launch Potato is a leading connector of advertisers to customers at all parts of the consumer journey, from awareness to consideration to purchase. The company is headquartered in vibrant downtown Delray Beach, Florida, with a unique international team across over a dozen countries. Launch Potato's success comes from a diverse, energetic culture and high-performing, entrepreneurial team. As a result, the company is always looking for like-minded teammates and partners. (This role will heavily focus on building machine learning models. This is NOT an engineering/data engineering position.) MUST HAVE: Experience within the performance marketing/lead gen industries. Professional experience designing, implementing, optimizing, and testing end-to-end Multi-Armed Bandit (MAB) and recommendation systems. EXPERIENCE: A minimum of 4 years experience in a hands-on, in-the-weeds data science position. YOUR ROLE You will be developing deep personalization models for our users and complex optimization algorithms to bridge our customer experiences with new products/services. Your direct contribution will impact how we connect hundreds of thousands of customers to hundreds of advertisers together daily and will drive significant consumer impact while increasing revenue. You will play a pivotal role in the growth of our data science team and will be an instrumental resource as we continue to build a team of data scientists and machine learning engineers that can increase customer engagement and stickiness on our sites while improving the quality of the leads to our partners. This is an extremely hands-on and in-the-weeds Data Science role where you will be heavily immersed in the data and coding part of the solution implementation. You will design and oversee integrating state-of-the-art machine learning solutions across the company’s products. This role will be responsible for strategic planning of Machine Learning initiatives with the Product, Engineering, Performance and Business Intelligence teams, analysis of potential impact and prioritization of those projects. SUCCESS LOOKS LIKE Innovate, create, and design ML solutions to various business problems such as: Design, implement and continuously improve Multi-Armed Bandit solutions to optimize decisions/options in place of multiple AB-tests. Utilizing Large Language Models in content personalization across various verticals. Recommendation systems to serve ads, offers, questions, etc. Collaborate with stakeholders across the company including but not limited to Analytics, Engineering, Product and Business Leads to improve model infrastructure, tracking and monitoring. Provide data science support at different project stages, including the implementation of ML solutions by collaborating with Data Engineers and MLOps. Being hands-on and in-the-weeds in the data, coding part of the solution implementation. What You Need To Succeed 4+ years of related work experience in the field of Data Science & Machine learning. 2+ years of experience in the Marketing/Advertising Industry. Solid background in Machine Learning and Statistics. Professional experience designing and implementing Multi-Armed Bandit (MAB) solutions and recommendation systems. Proficiency in SQL, Python and working with Data Science tools (e.g., git, kubernetes, Docker, etc.). Structure and clarify any ambiguity for the team, i.e., divide complex projects into sprints and coordinate implementation across multiple teams and individuals. Experience creating ML solutions within cloud services (AWS/GCP). Experience with ML model development lifecycle. Experience with data visualization (preferably Looker). Experience managing a team of data scientists and machine learning researchers (including career development). Ability to communicate clearly, think independently, provide direction, and effectively communicate with technical and non-technical stakeholders. NICE TO HAVES Experience with LLMs and Deep learning models to develop business and data science solutions. Want to make your impact in a profitable, high-growth company? Apply now! Since day one, we've been committed to having a diverse, inclusive team and culture. We are proud to be an Equal Employment Opportunity company. We value diversity, equity, and inclusion. We do not discriminate based on race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",https://mx.linkedin.com/jobs/view/senior-data-scientist-at-launch-potato-4019304707,4019304707,"This role heavily focuses on building machine learning models and is not an engineering/data engineering position. You will be developing deep personalization models and complex optimization algorithms. Your contribution will impact how customers connect with advertisers and drive significant consumer impact while increasing revenue. The position requires designing and overseeing integrating state-of-the-art machine learning solutions, strategic planning of initiatives with various teams, and providing data science support at different project stages. You will need to innovate and create ML solutions for various business problems and collaborate with stakeholders across the company.","Python, SQL, Machine Learning, Multi-Armed Bandit Systems, Recommendation Systems, Statistics, Docker, Kubernetes, AWS, GCP",4+ years,,True,4.0,0,0,0,1,1,0,0,0,0,1,0,0,1,0,1,0,0
Big Data Developer,Grid Dynamics,Guadalajara,REMOTE,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-01 11:29:34.794464,25,Engineering,Information Technology,,"We are seeking a highly skilled Data Engineer to join our team and lead the development and management of our data feeds for digital eCommerce. In this role, you will act as a critical liaison between the digital and data teams, ensuring seamless data integration and flow across our platforms. Your expertise will drive the success of our data initiatives and support our mission to provide top-notch digital services to our customers. Responsibilities Develop, manage, and optimize data feeds for digital eCommerce data. Serve as a liaison between the digital and data teams, ensuring effective communication and collaboration. Design and implement scalable data pipelines using the Databricks platform. Work with cloud platforms, primarily GCP, but also adapt to Azure or AWS as needed. Ensure data integrity, quality, and availability across all systems. Collaborate with stakeholders to understand data requirements and deliver solutions that meet business needs. Monitor and troubleshoot data processes to maintain seamless operations. Implement best practices in data management, security, and governance. Requirements 5+ years of experience in data engineering, with a focus on digital eCommerce. Proven expertise with the Databricks platform. Strong knowledge of cloud platforms, particularly GCP. Experience with Azure or AWS is a plus. Strong understanding of data warehousing concepts and big data technologies. Hands-on experience with SQL Ability to work in a fast-paced, dynamic environment. Strong problem-solving skills and attention to detail. Nice to have Familiarity with data visualization tools and techniques. Knowledge of data governance and security best practices. We offer 100% payroll scheme, benefits by law (IMSS, INFONAVIT, 12+ vacation days) Benefits above the law: Vacation premium 50%, 5 PTOs, 3 sick days, 10 guaranteed public holidays per year Major medical insurance, Dental and Vision plan for an employee and direct family members Minor Medical Insurance (Multiservicios Médicos Santander) for an employee and direct family members Life Insurance and funeral expenses 5% savings fund, uncapped (matched by the company in the end of the year) Grocery cards/vouchers (Vales de Despensa) 30 days End of the Year Bonus (Aguinaldo) Opportunity to work on bleeding-edge projects with a highly motivated and dedicated team all over the world Individual career development plan and support from the best experts Professional development opportunities (Linkedin Learning, Cloud certification programs, access to corporate LMS integrated with other learning platforms) Well-equipped office in a business area of Guadalajara (quiet room, games room, air hockey, PS5, Nintendo Switch and Xbox Series X, pool table, ping pong, snacks, smoothies, and much more) Corporate social events (yoga, massages, sport tournaments, discussion panels, technical talks, lunch & learns) Flexible working hours Opportunity to relocate to another country where the company's offices are present. About Us Grid Dynamics (NASDAQ: GDYN) is a leading provider of technology consulting, platform and product engineering, AI, and advanced analytics services. Fusing technical vision with business acumen, we solve the most pressing technical challenges and enable positive business outcomes for enterprise companies undergoing business transformation. A key differentiator for Grid Dynamics is our 8 years of experience and leadership in enterprise AI, supported by profound expertise and ongoing investment in data, analytics, cloud & DevOps, application modernization and customer experience. Founded in 2006, Grid Dynamics is headquartered in Silicon Valley with offices across the Americas, Europe, and India.",https://mx.linkedin.com/jobs/view/big-data-developer-at-grid-dynamics-4013792922,4013792922,"We are seeking a highly skilled Data Engineer to lead the development and management of data feeds for digital eCommerce. In this role, you will ensure seamless data integration and flow across our platforms, driving the success of our data initiatives. Responsibilities include optimizing data feeds, collaborating between digital and data teams, designing scalable data pipelines using the Databricks platform, and ensuring data integrity and availability. Additionally, you will monitor data processes and implement best practices in data management and security.","Databricks, GCP, Azure, AWS, SQL, Data Warehousing, Big Data Technologies",5+ years,,True,5.0,0,0,1,1,0,1,1,0,0,1,0,0,0,0,0,0,0
Senior Applied Scientist,Launch Potato,Guadalajara,REMOTE,Mid-Senior level,Full-time,Advertising Services,2024-09-08 11:29:34.794464,25,Research,"Analyst,",Information Technology,"WHO ARE WE? Launch Potato is a digital media company with a portfolio of brands and technologies. As The Discovery and Conversion Company, Launch Potato is a leading connector of advertisers to customers at all parts of the consumer journey, from awareness to consideration to purchase. The company is headquartered in vibrant downtown Delray Beach, Florida, with a unique international team across over a dozen countries. Launch Potato's success comes from a diverse, energetic culture and high-performing, entrepreneurial team. As a result, the company is always looking for like-minded teammates and partners. (This role will heavily focus on building machine learning models. This is NOT an engineering/data engineering position.) MUST HAVE: Experience within the performance marketing/lead gen industries. Professional experience designing, implementing, optimizing, and testing end-to-end Multi-Armed Bandit (MAB) and recommendation systems. EXPERIENCE: A minimum of 4 years experience in a hands-on, in-the-weeds data science position. YOUR ROLE You will be developing deep personalization models for our users and complex optimization algorithms to bridge our customer experiences with new products/services. Your direct contribution will impact how we connect hundreds of thousands of customers to hundreds of advertisers together daily and will drive significant consumer impact while increasing revenue. You will play a pivotal role in the growth of our data science team and will be an instrumental resource as we continue to build a team of data scientists and machine learning engineers that can increase customer engagement and stickiness on our sites while improving the quality of the leads to our partners. This is an extremely hands-on and in-the-weeds Data Science role where you will be heavily immersed in the data and coding part of the solution implementation. You will design and oversee integrating state-of-the-art machine learning solutions across the company’s products. This role will be responsible for strategic planning of Machine Learning initiatives with the Product, Engineering, Performance and Business Intelligence teams, analysis of potential impact and prioritization of those projects. SUCCESS LOOKS LIKE Innovate, create, and design ML solutions to various business problems such as: Design, implement and continuously improve Multi-Armed Bandit solutions to optimize decisions/options in place of multiple AB-tests. Utilizing Large Language Models in content personalization across various verticals. Recommendation systems to serve ads, offers, questions, etc. Collaborate with stakeholders across the company including but not limited to Analytics, Engineering, Product and Business Leads to improve model infrastructure, tracking and monitoring. Provide data science support at different project stages, including the implementation of ML solutions by collaborating with Data Engineers and MLOps. Being hands-on and in-the-weeds in the data, coding part of the solution implementation. What You Need To Succeed 4+ years of related work experience in the field of Data Science & Machine learning. 2+ years of experience in the Marketing/Advertising Industry. Solid background in Machine Learning and Statistics. Professional experience designing and implementing Multi-Armed Bandit (MAB) solutions and recommendation systems. Proficiency in SQL, Python and working with Data Science tools (e.g., git, kubernetes, Docker, etc.). Structure and clarify any ambiguity for the team, i.e., divide complex projects into sprints and coordinate implementation across multiple teams and individuals. Experience creating ML solutions within cloud services (AWS/GCP). Experience with ML model development lifecycle. Experience with data visualization (preferably Looker). Experience managing a team of data scientists and machine learning researchers (including career development). Ability to communicate clearly, think independently, provide direction, and effectively communicate with technical and non-technical stakeholders. NICE TO HAVES Experience with LLMs and Deep learning models to develop business and data science solutions. Want to make your impact in a profitable, high-growth company? Apply now! Since day one, we've been committed to having a diverse, inclusive team and culture. We are proud to be an Equal Employment Opportunity company. We value diversity, equity, and inclusion. We do not discriminate based on race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",https://mx.linkedin.com/jobs/view/senior-applied-scientist-at-launch-potato-4019305670,4019305670,"The role focuses on building machine learning models with specific emphasis on developing deep personalization models, complex optimization algorithms, and designing Multi-Armed Bandit (MAB) and recommendation systems. The position requires collaboration with various teams to innovate and implement ML solutions that enhance customer experiences and increase revenue.","Python, SQL, Machine Learning, Statistics, Large Language Models, Data Science tools, Git, Kubernetes, Docker, AWS, GCP, Looker",4+ years,,True,4.0,0,0,0,1,1,1,0,0,1,1,0,1,1,0,1,0,0
"Senior Artificial Intelligence/Machine Learning Engineer - Remote, Latin America",Bluelight Consulting | DevOps & Software Development,Guadalajara,REMOTE,,Full-time,IT Services and IT Consulting,2024-09-08 11:29:34.794464,25,Engineering,Information Technology,,"Bluelight Consulting is a leading software consultancy dedicated to designing and developing innovative technology that enhances users' lives. With a steadfast commitment to delivering exceptional service to our clients, Bluelight excels in its focus on quality and customer satisfaction. Our mission is not only to create cutting-edge applications but also to foster a collaborative and enriching work environment where each team member can grow and thrive. With a presence across the United States and Central/South America, Bluelight is in an exciting phase of expansion, continually seeking exceptional talent to join its dynamic and diverse community. We are looking for a skilled individual to join our rapidly growing team at Bluelight Consulting. This position is ideal for someone who thrives in a fast-paced, dynamic environment where everyone's opinions and efforts are valued and appreciated. You will have the opportunity to contribute to challenging and meaningful projects, developing high-quality applications that stand out in the market. We value continuous learning, personal growth, and hard work, offering a collaborative environment that promotes professional development. If you are passionate about software development and eager to be part of a growing software consultancy, we invite you to apply and join us on this exciting journey. What we are looking for Strong background in computer science or engineering with 3+ years of experience Knowledge of machine learning, deep learning, and natural language processing Experience with LLMs like GPT and LLama3 Proficient in Python and familiar with TensorFlow or PyTorch Good problem-solving skills and ability to work independently and in a team Experience with AI voice programs/products Proficient in cloud services (AWS, Azure, Google Cloud) and container technologies (Docker, Kubernetes) Strong communication skills for explaining technical ideas to various audiences Ability to manage product specifications from concept to production Understanding of software design principles, including optimization and performance tuning Company Benefits Competitive salary and bonuses, including performance-based salary increases Generous paid-time-off policy Technology / Office stipend Health Coverage Flexible working hours Work remotely Continuing education, training, conferences Company-sponsored coursework, exams, and certifications Being a consultant in our team is a fun, challenging, and rewarding career choice. Your contributions are highly valued by clients, and the work you do often has a direct and significant impact on their business. You will have the opportunity to work on a variety of projects for our incredible clients, which will accelerate your career growth. You’ll collaborate with modern technologies and work alongside some of the best professionals in the industry! If you’re eager to be part of an exciting, challenging, and rapidly growing consultancy, we encourage you to apply.",https://mx.linkedin.com/jobs/view/senior-artificial-intelligence-machine-learning-engineer-remote-latin-america-at-bluelight-consulting-devops-software-development-4018827405,4018827405,"We are looking for a skilled individual with a strong background in computer science or engineering and 3+ years of experience. You should have knowledge of machine learning, deep learning, and natural language processing, with experience using LLMs like GPT and LLama3. Proficiency in Python and familiarity with TensorFlow or PyTorch are required. Good problem-solving skills and the ability to work both independently and in a team are essential. Experience with AI voice programs/products and proficiency in cloud services (AWS, Azure, Google Cloud) and container technologies (Docker, Kubernetes) is also needed. Strong communication skills for explaining technical ideas to various audiences are important, along with the ability to manage product specifications from concept to production and an understanding of software design principles, including optimization and performance tuning.","Python, TensorFlow, PyTorch, AWS, Azure, Google Cloud, Docker, Kubernetes, Machine Learning, Deep Learning, Natural Language Processing",3+,,True,3.0,0,0,0,1,1,0,0,0,0,0,0,0,1,0,1,0,0
Senior Machine Learning Researcher,Launch Potato,Guadalajara,REMOTE,Mid-Senior level,Full-time,Advertising Services,2024-09-08 11:29:34.794464,25,Other,,,"WHO ARE WE? Launch Potato is a digital media company with a portfolio of brands and technologies. As The Discovery and Conversion Company, Launch Potato is a leading connector of advertisers to customers at all parts of the consumer journey, from awareness to consideration to purchase. The company is headquartered in vibrant downtown Delray Beach, Florida, with a unique international team across over a dozen countries. Launch Potato's success comes from a diverse, energetic culture and high-performing, entrepreneurial team. As a result, the company is always looking for like-minded teammates and partners. (This role will heavily focus on building machine learning models. This is NOT an engineering/data engineering position.) MUST HAVE: Experience within the performance marketing/lead gen industries. Professional experience designing, implementing, optimizing, and testing end-to-end Multi-Armed Bandit (MAB) and recommendation systems. EXPERIENCE: A minimum of 4 years experience in a hands-on, in-the-weeds data science position. YOUR ROLE You will be developing deep personalization models for our users and complex optimization algorithms to bridge our customer experiences with new products/services. Your direct contribution will impact how we connect hundreds of thousands of customers to hundreds of advertisers together daily and will drive significant consumer impact while increasing revenue. You will play a pivotal role in the growth of our data science team and will be an instrumental resource as we continue to build a team of data scientists and machine learning engineers that can increase customer engagement and stickiness on our sites while improving the quality of the leads to our partners. This is an extremely hands-on and in-the-weeds Data Science role where you will be heavily immersed in the data and coding part of the solution implementation. You will design and oversee integrating state-of-the-art machine learning solutions across the company’s products. This role will be responsible for strategic planning of Machine Learning initiatives with the Product, Engineering, Performance and Business Intelligence teams, analysis of potential impact and prioritization of those projects. SUCCESS LOOKS LIKE Innovate, create, and design ML solutions to various business problems such as: Design, implement and continuously improve Multi-Armed Bandit solutions to optimize decisions/options in place of multiple AB-tests. Utilizing Large Language Models in content personalization across various verticals. Recommendation systems to serve ads, offers, questions, etc. Collaborate with stakeholders across the company including but not limited to Analytics, Engineering, Product and Business Leads to improve model infrastructure, tracking and monitoring. Provide data science support at different project stages, including the implementation of ML solutions by collaborating with Data Engineers and MLOps. Being hands-on and in-the-weeds in the data, coding part of the solution implementation. What You Need To Succeed 4+ years of related work experience in the field of Data Science & Machine learning. 2+ years of experience in the Marketing/Advertising Industry. Solid background in Machine Learning and Statistics. Professional experience designing and implementing Multi-Armed Bandit (MAB) solutions and recommendation systems. Proficiency in SQL, Python and working with Data Science tools (e.g., git, kubernetes, Docker, etc.). Structure and clarify any ambiguity for the team, i.e., divide complex projects into sprints and coordinate implementation across multiple teams and individuals. Experience creating ML solutions within cloud services (AWS/GCP). Experience with ML model development lifecycle. Experience with data visualization (preferably Looker). Experience managing a team of data scientists and machine learning researchers (including career development). Ability to communicate clearly, think independently, provide direction, and effectively communicate with technical and non-technical stakeholders. NICE TO HAVES Experience with LLMs and Deep learning models to develop business and data science solutions. Want to make your impact in a profitable, high-growth company? Apply now! Since day one, we've been committed to having a diverse, inclusive team and culture. We are proud to be an Equal Employment Opportunity company. We value diversity, equity, and inclusion. We do not discriminate based on race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",https://mx.linkedin.com/jobs/view/senior-machine-learning-researcher-at-launch-potato-4019305690,4019305690,"The role will heavily focus on building machine learning models, requiring experience in the performance marketing and lead generation industries. You will develop deep personalization models and complex optimization algorithms, significantly impacting consumer connections and driving revenue. The position involves designing and implementing Multi-Armed Bandit solutions, utilizing Large Language Models for content personalization, and collaborating across teams to improve model infrastructure. Success in the role entails innovating ML solutions, analyzing impact, and integrating machine learning across the company’s products.","Python, SQL, Machine Learning, Statistics, Multi-Armed Bandit, Recommendation Systems, Git, Kubernetes, Docker, AWS, GCP, Looker",4+ years,,True,4.0,0,0,0,1,1,0,0,0,1,1,0,1,1,0,1,0,0
Tech Support Data Engineer,Boldr,Guadalajara,REMOTE,Mid-Senior level,Full-time,Non-profit Organizations and Primary and Secondary Education,2024-08-16 11:29:34.794464,44,Engineering,,,"Working hours: US Business hours What Is Your Role This role is part of the team of Customer Engineers in Professional Services, and we're seeking highly talented individuals to join and grow our team. This is the intersection where the product has to meet customer needs and create value. You are a customer-facing data engineer who loves to see technology and data used in ways that ensure our projects' and customers' success. You have great attention to detail and are very proactive in seeking potential roadblocks to success. You have great people skills and know how to manage the trust and expectations of a customer. What Will You Do Customer Engineers are the customer facing technical owners of our existing customer relationships and data driven deliverables on the company's platform You will work hands-on with our technology stack and collaborate with several teams such as Product Engineering and Customer Engagement in order to deliver on all customer technical requests. You will be responsible for regularly interacting with our customers to gather requirements (e.g. weekly meetings, email, etc), and for scoping and prioritizing the incoming work. This can include: Designing Solutions - translate business requirements into technical solutions using SQL, scripting, codebase configurations, etc Setting up ETL pipelines across disparate data sources, and creating a unified Data Model Setting up/enabling new product features & ingest/export integrations Implementing the company's platform and its various components for our new customers Helping answer customer questions, and troubleshooting where necessary Participating in the on-call rotation You will also be: Finding out sustainable ways of addressing repeatable issues, and building tools for automation Contributing with documentation and building our customer specific configuration knowledge base A source of feedback for our product team, full stack and backend engineering teams Requirements BS degree in Computer Science, Engineering, Mathematics, Economics, Statistics, Information Management or similar 2+ years in a technical role that involves managing and manipulating large data sets, such as ETL, Data Warehousing, Analytics, Data Science etc 2+ years in a client-facing role that involves being a point-of-contact for technical and non-technical users Proficient in one programming language and working knowledge of SQL and Unix command line tools Working Knowledge of Github, and AWS infrastructure Excellent problem solving skills Strong Communication skills Improvement mindset, through processes, tools and/ or documentation Strong professionalism & work ethic Nice to have: Working knowledge of Java and/or Scala Marketing technology industry & relevant vendor knowledge Benefits Law Benefits Private Health Insurance Paid Time Off Training Life insurance Mental Health Support Learning and Development Programs",https://mx.linkedin.com/jobs/view/tech-support-data-engineer-at-boldr-3994917960,3994917960,"This role is part of the Customer Engineers team in Professional Services, where you will serve as a customer-facing data engineer, responsible for ensuring project and customer success. You'll interact regularly with customers to gather requirements, design solutions based on business needs using SQL, and set up ETL pipelines. You will also implement product features, troubleshoot issues, and contribute documentation to support customer-specific configurations.","SQL, Unix, ETL, Data Warehousing, Data Analytics, AWS, Java, Scala, Github",2+ years,Bachelor,True,2.0,0,0,0,1,0,1,1,0,0,1,0,1,0,0,0,0,0
AI Machine Learning Engineer,Scale Up Recruiting Partners,Guadalajara,REMOTE,Associate,Full-time,Software Development,2024-09-13 11:29:34.794464,25,Information Technology,,,"Hi there! We are Scale Up and our client is looking for a AI Machine Learning Engineer! The Machine Learning Engineer role is responsible for the design, development and implementation of machine learning solutions to serve our organization. This includes ownership or oversight of projects from conception to deployment with appropriate AWS services, Docker, MLFlow, and others. The role also includes responsibility for following best practices with which to optimize and measure the performance of our models and algorithms against business goals. Responsibilities Design and develop machine learning models and algorithms for various aspects of the localization and business workflow processes, including machine translation, LLM fine tuning, and quality assurance. Take ownership of key projects from definition to deployment, ensuring that they meet technical requirements and maintain momentum and direction until delivery. Evaluate and select appropriate machine learning techniques and algorithms to solve specific problems. Implement and optimize machine learning models and technologies using Python, TensorFlow, and other relevant tools and frameworks. Perform statistical analysis and fine-tuning using test results. Deploy machine learning models and algorithms using appropriate techniques and technologies, such as containerization using Docker and deployment to cloud infrastructure. Use AWS technologies (including but not limited to Sagemaker, EC2, S3) to deploy and monitor production environments. Keep abreast of developments in the field, with a dedication to learning in the role. Document diligently and communicate thoughtfully about ML experimentation, design, and deployment. Project scope: Define and design solutions to machine learning problems. Integration with larger systems done with guidance from more senior colleagues. Requirements Effective model development: success is evident when the models developed are accurate, efficient, and align with project requirements. Positive team collaboration: demonstrated ability to collaborate effectively with various teams and stakeholders, contributing positively to project outcomes. Continuous learning and improvement: a commitment to continuous learning and applying new techniques to improve existing models and processes. Clear communication: ability to articulate findings, challenges, and insights to a range of stakeholders, ensuring understanding and appropriateness. Skills And Knowledge Ability to write robust, production-grade code in Python. Excellent communication and documentation skills. Strong knowledge of machine learning techniques and algorithms, including supervised and unsupervised learning, deep learning, and reinforcement learning. Hands-on, high proficiency experience with machine learning frameworks such as TensorFlow, PyTorch, and Scikit-learn. Experience with natural language processing (NLP) techniques and tools. Strong communication and collaboration skills, with the ability to explain complex technical concepts to non-technical stakeholders. Experience taking ownership of projects from conception to deployment, and mentoring more junior team members. Hands-on experience with AWS technologies including EC2, S3, and other deployment strategies. Experience with SNS, Sagemaker a plus. Experience with ML management technologies and deployment techniques, such as AWS ML offerings, Docker, GPU deployments, etc. Education And Experience BSc in computer science, mathematics or similar field. Master’s Degree is a plus. 3+ years’ experience as a Machine Learning Engineer or similar role. Benefits National public holidays. Vacations: 3 weeks per year. Work laptop provided. If this opportunity sounds good to you, send us your resume!",https://mx.linkedin.com/jobs/view/ai-machine-learning-engineer-at-scale-up-recruiting-partners-4023312409,4023312409,"The Machine Learning Engineer role is responsible for the design, development, and implementation of machine learning solutions to serve the organization, including ownership of projects from conception to deployment with appropriate AWS services, Docker, and MLFlow. Responsibilities include designing and developing machine learning models and algorithms, optimizing performance against business goals, deploying models using cloud infrastructure, and documenting processes.","Python, TensorFlow, PyTorch, Scikit-learn, AWS (EC2, S3, Sagemaker), Docker, MLFlow",3+ years,Bachelor,True,3.0,0,0,0,1,1,0,0,0,0,0,0,0,1,0,1,0,0
Data Scientist ll,O'Reilly Autopartes México,Guadalajara,HYBRID,Mid-Senior level,Full-time,"Motor Vehicle Parts Manufacturing, IT System Data Services, and Data Infrastructure and Analytics",2024-09-08 11:30:57.007212,55,Information Technology,,,"¡Únete a nuestro equipo como Data Scientist ll! ¿Te apasiona resolver problemas empresariales complejos a través del análisis de datos y la aplicación de técnicas avanzadas de modelado estadístico y aprendizaje automático? Si es así, esta es tu oportunidad para ser parte de un equipo innovador y contribuir a la toma de decisiones estratégicas dentro de nuestra organización. Resumen General: Como Data Scientist ll , serás responsable de modelar problemas empresariales complejos, descubrir insights y detectar oportunidades mediante el uso de técnicas estadísticas, algoritmos, minería de datos y visualización. Trabajarás estrechamente con clientes, administradores de datos, gerentes de proyectos/programas y otros equipos de TI para transformar los datos en información crítica y conocimiento que apoye la toma de decisiones organizacionales. Funciones Esenciales del Puesto: Colaboración con Stakeholders: Trabajarás con diversas partes interesadas en la organización para identificar oportunidades de aprovechamiento de datos que impulsen soluciones empresariales efectivas. Análisis Complejo: Sintetizarás hechos, teorías, tendencias e inferencias en situaciones complejas y variables, reconociendo patrones abstractos y relaciones entre entidades o situaciones aparentemente no relacionadas. Desarrollo de Soluciones: Aplicarás conceptos y teorías apropiadas en el desarrollo de principios, prácticas, técnicas, herramientas y soluciones innovadoras. Investigación y Mejora Continua: Recogerás y analizarás información sobre las tendencias actuales y futuras en las mejores prácticas, mejorando el rendimiento organizacional mediante la aplicación de ideas originales a métodos, procesos, productos y servicios existentes y emergentes. Otras Funciones del Puesto: Implementación de Innovaciones: Utilizarás un juicio sólido para determinar cómo se implementarán las innovaciones que produzcan un retorno de la inversión positivo. Mejora del Rendimiento: Traducirás la información más actualizada en actividades de mejora continua que optimicen el rendimiento. Resolución de Problemas: Anticiparás, identificarás y definirás problemas, buscando causas raíces y desarrollando soluciones prácticas y oportunas. Experiencia en Machine Learning: Tendrás un conocimiento profundo de varias técnicas de aprendizaje automático (como clustering, árboles de decisión, redes neuronales artificiales, etc.) y sus ventajas/desventajas en el mundo real. Técnicas Estadísticas Avanzadas: Contarás con conocimientos avanzados en técnicas y conceptos estadísticos (regresión, propiedades de distribuciones, pruebas estadísticas y su uso adecuado, etc.) y experiencia en su aplicación práctica. Requisitos: Licenciatura. 5+ años de experiencia práctica en ETL, procesamiento de datos, programación de bases de datos y análisis de datos. Experiencia extensiva con Python y bibliotecas como Pandas, Numpy, SciKit-Learn, y Jupyter notebooks. Experiencia extensiva en aprendizaje automático y modelado estadístico. Maestría en SQL junto con conocimientos en diseño y optimización de bases de datos. Excelentes habilidades de comunicación y deseo de trabajar en un entorno dinámico y colaborativo. Capacidad demostrable para desarrollar e implementar soluciones matemáticas a problemas de datos. Ingles avanzado conversacional",https://mx.linkedin.com/jobs/view/data-scientist-ll-at-o-reilly-autopartes-m%C3%A9xico-4017387486,4017387486,"Join our team as a Data Scientist II! The role involves solving complex business problems through data analysis and the application of advanced statistical modeling and machine learning techniques. As a Data Scientist II, you will be responsible for modeling complex business problems, discovering insights, and detecting opportunities using statistical techniques, algorithms, data mining, and visualization. You will work closely with clients, data managers, project/program managers, and other IT teams to transform data into critical information and knowledge to support organizational decision-making.","Python, Pandas, Numpy, SciKit-Learn, Jupyter Notebooks, SQL, ETL, Data Analysis, Machine Learning, Statistical Modeling",5+ years,Bachelor,True,5.0,0,0,0,0,0,1,1,0,0,1,0,0,1,0,1,0,0
AI Graduate,Cognizant,Guadalajara,HYBRID,Entry level,Full-time,IT Services and IT Consulting,2024-06-17 11:30:57.007212,60,Research,"Analyst,",Information Technology,"Cognizant is an America IT consultancy with a presence in more than 40 countries. A Great Place to Work where we look for people who contribute new ideas, experiencing a dynamic and growing environment. At Cognizant we promote an inclusive culture, where we value different perspectives providing career growth and development opportunities. This is an opportunity with the aim of training students or nearly graduated in the field of technology so that can develop their careers. All program participants undergo training in specific technologies so that they can later perform their roles in the projects. Why choose this program? Training: Participants will be able to receive behavioral and technical training for a period of time to later put into practice in the project. This makes theoretical + practical knowledge possible in a short time! Career: You will start your career as an analyst in the technology field. From them on, contact with technology will be constant. Collaboration : Here you will know that no ones is alone at the beginning of their career. All associates receive constant support from Cognizant’s leadership and stakeholders, charting the way forward. Position Overview By joining Cognizant as an entry-level in AI, you will be analyzing, designing, programming, and testing software programs and applications across all industries. Kick-start your software engineering career in our new hire training program to learn the latest technical skills! Responsibilities: Develop auxiliar functions on Python language. Testing AI applications developed by the team, looking for and analyzing possible errors. Label new documents to be analyzed by AI models. Generate project documentation. Basic Qualifications: Bachelor’s degree or equivalent in IT related field Basic knowledge with Python Advanced English level Self-motivated individuals with strong analytical, troubleshooting, and problem-solving skills with the passion and appetite to learn newer technologies. Excellent interpersonal & communication skills Ability to work collaboratively with global project teams. Location Guadalajara Start Date May 2024 Why choose us? Cognizant delivers that draw upon the full power and scale of our associates. You will be supported by high-caliber experts and employ some of the most advanced and patented capabilities. Our associate’s diverse backgrounds offer varied perspectives and fuel new ways of thinking. We encourage lively discussions which inspire better results for our clients. If you’re comfortable with ambiguity excited by change, and excel through autonomy, we’d love to hear from you. Benefits : Cognizant offers upper law benefits We are committed to respecting human rights and build a better future by helping your minds and the environment We invest in people and their wellbeing. We create conditions for everyone to thrive. We do not discriminate based on race, religion, color, sex, age, disability, nationality, sexual orientation, gender identity or expression, or for any other reason covered. Employee Status : Full Time Employee Shift : Day Job Travel : No Job Posting : Apr 05 2024 About Cognizant Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @Cognizant. 00058405301",https://mx.linkedin.com/jobs/view/ai-graduate-at-cognizant-3970607635,3970607635,"By joining Cognizant as an entry-level in AI, you will be analyzing, designing, programming, and testing software programs and applications across all industries. You will develop auxiliary functions in Python, test AI applications developed by the team, label new documents for AI models, and generate project documentation.",Python,,Bachelor,True,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
Principal Data Scientist,HP,Guadalajara,HYBRID,,Full-time,"Computer Hardware Manufacturing, Software Development, and IT Services and IT Consulting",2024-09-11 11:30:57.007212,25,Engineering,Information Technology,,"Position Overview We are seeking a talented and visionary Principal Data Scientist to join our Supply Chain Planning Analytics team. As a Principal Data Scientist, you will play a key role in shaping our long-term strategic direction by providing data-driven insights, conducting in-depth analysis, and developing innovative solutions to drive business growth and competitiveness while communicating business value and innovation potential through effective insights and visualizations. You will collaborate closely with senior leadership, business stakeholders, and cross-functional teams to identify strategic opportunities, assess market trends, and drive strategic initiatives across the organization. Key Responsibilities Forecasting Models: Develop predictive models and analytical frameworks to forecast market demand, assess competitive dynamics, predict demand, optimize inventory levels, and inform strategic decision-making. Utilize time series analysis, machine learning, and statistical techniques to improve forecast accuracy. Analyze large datasets to identify trends, patterns, and opportunities for improvement in supply planning. Build and validate predictive models to forecast inventory needs and minimize stockouts and overstock situations. Continuously monitor and refine models to ensure accuracy and reliability. Inventory Optimization Utilize methods such as linear programming, queuing theory, and simulation to optimize inventory and production workflows. Develop optimization models to improve supply planning and logistics. Work with the supply chain team to implement inventory optimization strategies. Conduct scenario analysis to support decision-making processes. Component Classification and Segmentation Conduct in-depth analysis of internal and external data sources to identify market trends, customer behaviors, and strategic opportunities. Collaborate with cross-functional teams to define strategic priorities, establish performance metrics, and track progress against strategic goals. Utilize deep learning models such as Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Transformer models for complex product classification and segmentation tasks. Implement prescriptive analytics techniques to recommend actionable insights for product categorization and segmentation, enabling targeted marketing and inventory management strategies. Supply Planning Optimization Lead strategic data science initiatives to support key business objectives in Inventory Optimization / Planning area. Develop optimization models to improve supply planning and logistics. Work with the supply chain team to implement inventory optimization strategies. Conduct scenario analysis and simulation to support decision-making processes. Mentor and coach junior team members and contribute to the development of a high-performing and collaborative data science team. Qualifications Master's degree or related work experience Data Science, Mathematics, Statistics, Operations Research, Computer Science or a related field. PhD a Plus 10 -15 years of experience in strategic planning within Supply Chain, business analytics, or a similar role, with a strong focus on data-driven decision-making. Proficiency in programming languages such as Python, R, or Scala, and experience with data analysis libraries and frameworks (e.g., pandas, scikit-learn, TensorFlow, PyTorch, PuLP, SciPy, SimPy). Experience in advanced forecasting techniques (e.g., ARIMA, Prophet, LSTM) Strong analytical and problem-solving skills, with the ability to translate complex data into actionable insights and strategic recommendations. In-depth supply chain knowledge. Fluent in structured and unstructured data, its management, and modern data transformation methodologies Excellent communication and presentation skills, with the ability to convey technical concepts to non-technical stakeholders. Proven track record of leading strategic initiatives, driving organizational change, and delivering measurable business results. Ability to thrive in a fast-paced, dynamic environment, and manage multiple priorities effectively. Strong leadership and collaboration skills, with the ability to build consensus and drive alignment across diverse stakeholders. Experience in strategic consulting, management consulting, or corporate strategy is a plus. The base pay range for this role is $137,000 to $211,000 annually with additional opportunities for pay in the form of bonus and/or equity (applies to US candidates only). Pay varies by work location, job-related knowledge, skills, and experience. Benefits HP offers a comprehensive benefits package for this position, including: Health insurance Dental insurance Vision insurance Long term/short term disability insurance Employee assistance program Flexible spending account Life insurance Generous time off policies, including; 4-12 weeks fully paid parental leave based on tenure 11 paid holidays Additional flexible paid vacation and sick leave (US benefits overview) The compensation and benefits information is accurate as of the date of this posting. The Company reserves the right to modify this information at any time, with or without notice, subject to applicable law.",https://mx.linkedin.com/jobs/view/principal-data-scientist-at-hp-4017034443,4017034443,"We are seeking a talented and visionary Principal Data Scientist to join our Supply Chain Planning Analytics team. You will develop predictive models, analyze large datasets, and optimize inventory and production workflows. Responsibilities include forecasting market demand, conducting scenario analysis, and utilizing machine learning models for classification tasks. A Master's degree or related work experience is required, along with 10-15 years of experience in strategic planning within Supply Chain and proficiency in programming languages.","Python, R, Scala, pandas, scikit-learn, TensorFlow, PyTorch, PuLP, SciPy, SimPy, ARIMA, Prophet, LSTM",10-15,Masters,True,10.0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0
AI/ML Engineer - Azure,Synechron,Guadalajara,HYBRID,Entry level,Full-time,Software Development and IT Services and IT Consulting,2024-09-12 11:30:57.007212,25,Engineering,Information Technology,,"We are At Synechron, we believe in the power of digital to transform businesses for the better. Our global consulting firm combines creativity and innovative technology to deliver industry-leading digital solutions. Synechron’s progressive technologies and optimization strategies span end-to-end Artificial Intelligence, Consulting, Digital, Cloud & DevOps, Data, and Software Engineering, servicing an array of noteworthy financial services and technology firms. Through research and development initiatives in our FinLabs we develop solutions for modernization, from Artificial Intelligence and Blockchain to Data Science models, Digital Underwriting, mobile-first applications and more. Over the last 20+ years, our company has been honored with multiple employer awards, recognizing our commitment to our talented teams. With top clients to boast about, Synechron has a global workforce of 14,000+, and has 55 offices in 20 countries within key global markets. Our challenge We are seeking a skilled and motivated AI/ML Engineer with Azure to join our team. Candidate will collaborate, analyze, design, develop, test, maintain and implement premier software while working with cross-functional teams such as product and architecture. The Role Responsibilities : Experience in CMS as major subsystem and FAS or TRAMS as minor sub-Collaboration: Work closely with cross-functional teams, including IT, business, operations, and business stakeholders, to align AI support with objectives. Work with business users to understand their needs and document them using various tools Anticipate user needs and propose solutions and alternatives Understand functional and non-functional requirements Work with development teams in building and testing the solutions Maintain active communication channels with all stakeholders on deliverables and report status Track all outstanding issues and manage them from initiation to production deployment Ability to multitask and work with multiple teams Manage enhancement requests and production issues. Able to prioritize and allocate resources effectively Requirements: You are: Python and AI/ML Develop and deploy GenAI applications on Azure with focuses on: Azure OpenAI Azure Functions Azure Cosmos Azure Blob Storage Azure API Management Infrastructure as Code experience with Terraform with Azure CI/CD experiences with Jenkins Experience with Azure cloud, Python, Angular (applications are built today with azure cloud, using python & angular as backend & front end, and other azure services) Support in Regression Testing & Patch Releases for new & existing applications We can offer you: A highly competitive compensation and benefits package A multinational organization with 55 offices in 20 countries and the possibility to work abroad Laptop/equipment 12 days of paid annual leave (plus sick leave and national holidays) Maternity & Paternity leave plans A comprehensive insurance plan including: medical, dental, vision, and long-/short-term disability (plans vary by region) Retirement savings plans A higher education certification policy Extensive training opportunities, focused on skills, substantive knowledge, and personal development On-demand Udemy for Business for all Synechron employees with free access to more than 5000 curated courses Coaching opportunities with experienced colleagues from our Financial Innovation Labs (FinLabs) and Center of Excellences (CoE) groups Cutting edge projects at the world’s leading tier-one banks, financial institutions and insurance firms A flat and approachable organization A truly diverse, fun-loving and global work culture Saving funds plan for Mexico S YNECHRON’S DIVERSITY & INCLUSION STATEMENT Diversity & Inclusion are fundamental to our culture, and Synechron is proud to be an equal opportunity workplace and is an affirmative action employer. Our Diversity, Equity, and Inclusion (DEI) initiative ‘Same Difference’ is committed to fostering an inclusive culture – promoting equality, diversity and an environment that is respectful to all. We strongly believe that a diverse workforce helps build stronger, successful businesses as a global company. We encourage applicants from across diverse backgrounds, race, ethnicities, religion, age, marital status, gender, sexual orientations, or disabilities to apply. We empower our global workforce by offering flexible workplace arrangements, mentoring, internal mobility, learning and development programs, and more. All employment decisions at Synechron are based on business needs, job requirements and individual qualifications, without regard to the applicant’s gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law. Candidate Application Notice",https://mx.linkedin.com/jobs/view/ai-ml-engineer-azure-at-synechron-4021940326,4021940326,"We are seeking a skilled and motivated AI/ML Engineer with Azure to join our team. The candidate will collaborate, analyze, design, develop, test, maintain, and implement software while working with cross-functional teams. Responsibilities include understanding user needs, working with development teams, managing enhancement requests and production issues, and maintaining communication with stakeholders.","Python, AI/ML, Azure, Azure OpenAI, Azure Functions, Azure Cosmos, Azure Blob Storage, Azure API Management, Terraform, Jenkins, Angular",,,True,,0,0,0,1,0,0,0,0,0,0,1,1,0,0,1,0,0
Python Data Engineer,Deloitte,Guadalajara,HYBRID,Associate,Full-time,Business Consulting and Services,2024-08-25 11:30:57.007212,200,Information Technology,,,"Learn more about our great opportunities and don't miss the opportunity to be part of the evolution with this incredible team. We have this vacancy: Python Data Engineer It is hybrid, showing up twice a week at offices. Required: Strong proficiency in Python for data engineering tasks Experience with Kafka for real-time data streaming and processing Experience with SQL Preferred: Hands-on experience with Azure Cloud services for data solution Proficient with Kubernetes and Docker for container management Knowledge of CI/CD pipelines using Jenkins for automated deployment Experience with monitoring tools and techniques for data pipeline health Experience with MongoDB for NoSQL database management Familiarity with Apache Airflow for workflow orchestration Experience with version control systems, specifically Git",https://mx.linkedin.com/jobs/view/python-data-engineer-at-deloitte-4006452223,4006452223,"We have a vacancy for a Python Data Engineer, which is a hybrid role requiring attendance at the office twice a week. The position requires strong proficiency in Python for data engineering tasks, experience with Kafka for real-time data streaming and processing, and experience with SQL. Preferred qualifications include hands-on experience with Azure Cloud services, proficiency with Kubernetes and Docker, knowledge of CI/CD pipelines using Jenkins, experience with monitoring tools for data pipeline health, experience with MongoDB for NoSQL database management, familiarity with Apache Airflow, and experience with version control systems like Git.","Python, Kafka, SQL, Azure Cloud, Kubernetes, Docker, Jenkins, MongoDB, Apache Airflow, Git",,,True,,0,0,1,1,1,0,0,0,0,1,0,1,0,0,1,0,0
Data Engineer,MezTal,Guadalajara,HYBRID,Associate,Full-time,Non-profit Organizations and Primary and Secondary Education,2024-09-10 11:30:57.007212,25,Information Technology,,,"Meztal is looking for a talented and motivated Data Engineer to join our growing team. As a Data Engineer, you will be working closely with cross-functional teams, including product managers, data scientists, and software engineers, to design, build, and maintain scalable data pipelines and infrastructure. You will play a critical role in ensuring data integrity, availability, and accessibility to help drive business decisions and support our mission of delivering innovative solutions. Key Responsibilities: Design, develop, and maintain scalable ETL (Extract, Transform, Load) pipelines to process large volumes of structured and unstructured data from various sources Collaborate with data scientists and analysts to understand data requirements and ensure optimal data delivery architecture Implement data validation and cleansing processes to ensure data quality and consistency Develop and optimize data storage solutions (such as data lakes, warehouses, and databases) to support analytics and reporting needs Work with cloud-based data platforms and services (e.g., AWS, Azure, GCP) to deploy and manage data infrastructure Participate in code reviews, and maintain comprehensive documentation for data pipelines and processes Monitor and troubleshoot data workflows to ensure reliability, efficiency, and scalability Collaborate with team members to drive the overall data strategy and provide input on data governance and best practices Contribute to the development and deployment of machine learning models and algorithms in collaboration with data scientists Requirements Professional English Proficiency: Strong verbal and written communication skills in English are a must, as you will be collaborating with international teams Location Requirement: Must be based in Guadalajara, Jalisco, Mexico, and be willing to work in a hybrid model (combination of remote and in-office work) Experience: 3+ years of experience in a data engineering role or similar Technical Skills: Strong programming skills in Python, SQL, and familiarity with other languages such as Java or Scala Experience with data pipeline orchestration tools such as Apache Airflow, Prefect, or similar Hands-on experience with cloud-based data storage and processing services (AWS S3, Redshift, Glue, Azure Data Lake, GCP BigQuery, etc.) Familiarity with big data technologies such as Apache Spark, Hadoop, Kafka, or Flink Experience with database management systems (e.g., MySQL, PostgreSQL, NoSQL databases) Data Modeling and Warehousing: Strong understanding of data modeling, schema design, and building data warehouses Data Tools: Experience with data visualization and BI tools (Tableau, Power BI, Looker) is a plus Problem-Solving Mindset: Ability to work independently and collaboratively in a fast-paced environment, with a proactive approach to solving complex problems Attention to Detail: Strong analytical skills and attention to detail to ensure data quality and reliability Adaptability: Comfortable working in a dynamic and unstructured startup environment, with a willingness to learn and adapt to new tools and technologies Benefits Awesome Benefits for Our Team! Christmas Bonus: 30 days, to be paid in December Major Medical Expense Insurance: Coverage up to $20,000,000.00 MXN Minor Medical Insurance: VRIM membership with special discounts on doctor's appointments and accident reimbursements Dental Insurance: Always smile with confidence! Life Insurance: (Death and MXN Disability) Vacation Days: 12 vacation days in accordance with Federal Labor Law, with prior approval from your manager. + Floating Holidays: 3 floating holidays in addition to the 7 official holidays in Mexico Cell Phone Reimbursement & Transportation Subsidy. Hybrid Scheme: Enjoy the best of both worlds, remote and in-office work. Multicultural Exposure: Work with operations within Mexico and United Satates MezTal Internal Events: Strike a healthy balance between your professional and personal goals Exclusive Discounts: Benefits with different companies for being part of MezTal Academic Agreements: Access to national universities and language schools",https://mx.linkedin.com/jobs/view/data-engineer-at-meztal-4021666245,4021666245,"Meztal is looking for a talented and motivated Data Engineer to design, build, and maintain scalable data pipelines and infrastructure while ensuring data integrity, availability, and accessibility. You will collaborate with cross-functional teams to process large volumes of structured and unstructured data, implement data validation and cleansing processes, and develop data storage solutions. You will also work with cloud-based data platforms, monitor data workflows, and contribute to machine learning model development.","Python, SQL, Java, Scala, Apache Airflow, Prefect, AWS S3, Redshift, Glue, Azure Data Lake, GCP BigQuery, Apache Spark, Hadoop, Kafka, Flink, MySQL, PostgreSQL, NoSQL databases, Tableau, Power BI, Looker",3+ years,,True,3.0,0,0,1,1,0,0,0,0,1,1,0,0,0,0,1,0,0
Machine Learning Engineer - USA (TN Visa),Openwave Computing,Guadalajara,ON-SITE,Entry level,Full-time,IT Services and IT Consulting and Software Development,2024-09-08 11:32:47.028901,40,Engineering,Information Technology,,"Company Description Openwave Computing LLC is a global information technology company that provides comprehensive web and mobile app development services, catering to clients from diverse verticals. We have been in the industry for over two decades, gaining vast expertise and winning Company Description Openwave Computing LLC is a global information technology company that provides comprehensive web and mobile app development services, catering to clients from diverse verticals. We have been in the industry for over two decades, gaining vast expertise and winning the trust of our clients. We are a customer-centric company committed to quality, innovation, and security. At Openwave, we celebrate ideas and welcome breakthroughs from anyone. We are looking for someone who is passionate about their craft, committed to excellence, and wants to be part of a dynamic team. We offer TN visas for Mexican engineers. Job overview: We are seeking a highly skilled and motivated Machine Learning/AI Engineer to join our innovative team. The ideal candidate will have a strong background in machine learning and artificial intelligence, with experience developing and deploying ML/AI models. As a Machine Learning/AI Engineer for our clients projects, you will play a key role in designing, developing, and implementing ML/AI models to solve complex business problems for our clients. You will work closely with stakeholders to understand business needs and translate them into technical solutions, and collaborate with cross-functional teams to integrate ML/AI solutions into products. This role requires a strong understanding of machine learning algorithms, proficiency in Python and libraries like TensorFlow, PyTorch, and scikit-learn, and the ability to work independently and collaboratively in a fast-paced environment. Responsibilites: Design, develop, and implement machine learning, deep learning, and artificial intelligence models to solve complex business problems for our clients. Work closely with stakeholders to understand business needs and translate them into technical solutions. Collect, clean, and preprocess data for use in ML/DL/AI models. Train, test, and evaluate models to ensure accuracy and reliability. Deploy models into production environments and monitor their performance. Collaborate with cross-functional teams to integrate ML/DL/AI solutions into products. Stay up-to-date with the latest developments in the fields of machine learning, deep learning, and artificial intelligence. Qualifications Bachelor's degree in Computer Science, Engineering, or related field. Minimum of 5 years of experience in machine learning, deep learning, and artificial intelligence. Proficiency in Python and libraries like TensorFlow, PyTorch, and scikit-learn. Strong understanding of machine learning and deep learning algorithms. Experience with data preprocessing techniques and feature engineering. Familiarity with cloud platforms such as AWS, Google Cloud, or Azure. Excellent communication and problem-solving skills. Ability to work independently and collaboratively in a fast-paced environment. We offer: -TN Visa -Starting salary range $65,000 - 85,000 USD annual -Health insurance -More benefits will be discussed in the interview -Relocation help (Housing, transportation, and food)",https://mx.linkedin.com/jobs/view/machine-learning-engineer-usa-tn-visa-at-openwave-computing-4014109994,4014109994,"We are seeking a highly skilled and motivated Machine Learning/AI Engineer to join our innovative team. The ideal candidate will have a strong background in machine learning and artificial intelligence, with experience in developing and deploying ML/AI models. You will design, develop, and implement machine learning, deep learning, and AI models to solve complex business problems, work closely with stakeholders to translate business needs into technical solutions, collect and preprocess data, train and evaluate models, deploy them into production, and collaborate with cross-functional teams. The role requires a strong understanding of machine learning algorithms and proficiency in Python and libraries such as TensorFlow, PyTorch, and scikit-learn.","Python, TensorFlow, PyTorch, scikit-learn, AWS, Google Cloud, Azure",5,Bachelor,True,5.0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,1,0,0
Data Scientist,Cognizant,Guadalajara,ON-SITE,Entry level,Full-time,IT Services and IT Consulting,2024-08-16 11:32:47.028901,25,Engineering,Information Technology,,"Cognizant is always looking for top talent. We are searching for candidates to fill future needs within the business. This job posting represents potential future employment opportunities with Cognizant. Although the position is not currently available, we want to provide you with the opportunity to express your interest in future employment opportunities with Cognizant. If a job opportunity that you may be qualified for becomes available in the future, we will notify you. At that time you can determine whether you would like to apply for the specific open position. Thank you for your interest in Cognizant career opportunities. We’re hiring! At Cognizant we have an ideal opportunity for you to be part of one of the largest companies in the digital sector worldwide. A Great Place To Work where we look for people who contribute new ideas, experiencing a dynamic and growing environment. At Cognizant we promote an inclusive culture, where we value different perspectives providing career growth and development opportunities. #WelcomeToCognizant! We have an exciting opportunity for an exceptional individual to work supporting one of our clients as a IT Engineer What you’ll be able to do: Big Data Technologies: GCP Azure Data Lake GCP Big Query Databricks Spark Hadoop Kafka SQL and NO-SQL Data Visulaization tools: Qlickview Qlicksense Tableau PowerBI AI/ML technologies Statistical Methods application: ANOVA Principal Component analysis Correspondence Analysis K-means clustering Factor analysis Mutli-variate analysis, Neural Networks, causal inference, Gaussian Regression Others. Open source Data science technologies: Python R Why Cognizant? Improve your career in one of the largest and fastest growing IT services providers worldwide Receive ongoing support and funding with training and development plans Have a highly competitive benefits and salary package Get the opportunity to work for leading global companies We are committed to respecting human rights and build a better future by helping your minds and the environment We invest in people and their wellbeing. We create conditions for everyone to thrive. We do not discriminate based on race, religion, color, sex, age, disability, nationality, sexual orientation, gender identity or expression, or for any other reason covered. At Cognizant we believe than our culture make us stronger! Join us now! #BeCognizant #IntuitionEngineered Igualdad de Empleo y Política de Acción Afirmativa: Cognizant es un empleador que ofrece igualdad de oportunidades. Todos los solicitantes calificados recibirán consideración para el empleo sin distinción de sexo, identidad de género, orientación sexual, raza, color, religión, origen nacional, discapacidad, estado de veterano protegido, edad o cualquier otra característica protegida por la ley. Employee Status : Full Time Employee Shift : Day Job Job Posting : Apr 23 2024 About Cognizant Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @Cognizant. 44080",https://mx.linkedin.com/jobs/view/data-scientist-at-cognizant-4006276504,4006276504,"We have an exciting opportunity for an exceptional individual to work supporting one of our clients as an IT Engineer. The position involves working with Big Data technologies such as GCP, Azure Data Lake, GCP Big Query, Databricks, Spark, Hadoop, Kafka, SQL, and NoSQL. Additionally, candidates will utilize data visualization tools like QlikView, QlikSense, Tableau, and PowerBI. AI/ML technologies and statistical methods such as ANOVA, Principal Component Analysis, Correspondence Analysis, K-means Clustering, Factor Analysis, Multivariate Analysis, Neural Networks, Causal Inference, and Gaussian Regression will also be required. Open source data science technologies like Python and R are essential.","GCP, Azure Data Lake, GCP Big Query, Databricks, Spark, Hadoop, Kafka, SQL, NoSQL, QlikView, QlikSense, Tableau, PowerBI, Python, R",,,True,,0,0,1,1,0,0,0,0,1,1,0,0,0,0,1,0,0
AI Software Engineer,Plexus Corp.,Guadalajara,ON-SITE,,Full-time,"Defense and Space Manufacturing, Appliances, Electrical, and Electronics Manufacturing, and Medical Equipment Manufacturing",2024-09-10 11:32:47.028901,25,Engineering,Information Technology,,"Purpose Statement: The AI Software Engineer II is responsible for designing, developing, and implementing new or modified software products for ongoing AI/decision technology projects. They collaborate closely with various teams and stakeholders, including Data Scientists, Architects, Analysts, Project Managers, and other developers, to ensure software projects meet requirements. A key focus of this role will be supporting the AI/Decision Technology Team and their respective applications. This position will work on integrating different AI algorithms to create user and data friendly solutions. Key Job Accountabilities: Collaboration: Actively collaborate with cross-functional teams to conceptualize and develop or enhance software applications, ensuring adherence to project requirements, best practices, and business objectives. Software Development: Research, design, write, test, and implement high-performing code for software applications, ensuring they meet project requirements, coding standards and best practices. Integrate AI models into production systems and monitor their performance. Documentation: Prepare and maintain project documentation, including design and unit test documents, with a preference for UML proficiency. Testing and Quality Assurance: Participate in testing and quality assurance activities, including code reviews, unit testing, and bug identification. Help ensure software meets quality standards. Innovation and Research: Stay updated on emerging software development technologies and best practices, actively seeking opportunities and contributing ideas to improve development processes and efficiency. Creation of functional and friendly user and data interfaces. Education/Experience Qualifications: Typically requires a Bachelor’s degree and a minimum of 2 years of related experience; or equivalent work experience. Minimum of 1 year of AI/decision technology integration and development experience. Other Qualifications: English Proficiency Experience with cloud platforms such as AWS, Google Cloud, or Azure for AI model deployment. Agile and Lean Six Sigma certifications are desirable JDE / DSI .NET / C# - Design and setup development framework with n-tier environment (C#/.NET). Python, Machine Learning, IoT and Big Data analysis User Interface (UI) / User Design (UX ) Action oriented Ability to escalate issues appropriately Present information for decision making purposes with little to no direction Strong time management skills Ability to multi-task i.e. managing multiple projects A strong passion for software development and willingness to learn and grow. Strong problem-solving and analytical abilities. Ability to work effectively in a team. Excellent communication and teamwork skills. Physical Requirements: Professional office environment with suitable lighting, comfortable temperatures, and low noise level. May require prolonged periods of sitting at a desk, using a computer, and other office equipment. Minimal physical activity is generally involved, emphasizing the importance of good posture and ergonomic workplace arrangements. Travel Requirements: N/A This document does not represent a contract of employment and is not intended to capture every possible assignment the incumbent could be asked to perform.",https://mx.linkedin.com/jobs/view/ai-software-engineer-at-plexus-corp-4021817862,4021817862,"The AI Software Engineer II is responsible for designing, developing, and implementing new or modified software products for AI and decision technology projects. This includes collaborating with various teams to ensure software projects meet requirements, integrating AI algorithms, and creating user-friendly solutions. The role involves researching, writing, testing, and implementing code that meets project requirements and coding standards, as well as preparing project documentation. The engineer will also participate in testing and quality assurance activities, stay updated on software development technologies, and seek opportunities to improve processes.","C#, .NET, Python, Machine Learning, IoT, Big Data, AWS, Google Cloud, Azure, UML, Agile Methodologies, Lean Six Sigma",2,Bachelor,True,2.0,1,1,1,1,0,0,0,0,0,0,0,0,1,0,1,0,0
Senior Data Scientist,AdventInfotech,Guadalajara,ON-SITE,Mid-Senior level,Full-time,"IT Services and IT Consulting, IT System Data Services, and Software Development",2024-09-13 11:32:47.028901,25,Consulting,"Analyst,",Engineering,"Data Scientist: We are seeking a highly motivated and skilled Data Scientist to join our dynamic team. The Data Scientist will play a crucial role in turning complex data into actionable insights that drive business decisions and innovation. This position involves analyzing large datasets, developing models, and delivering strategic recommendations to enhance our products and services. Skills Requirements: Bachelor's or Master's degree in Data Science, Statistics, Computer Science, Mathematics, or a related field. 6plus years experience in data analysis, machine learning, and predictive modeling. Proficiency in programming languages such as Python or R. Strong knowledge of machine learning frameworks and libraries (e.g., TensorFlow, scikit-learn, PyTorch). Experience with data visualization tools (e.g., Tableau, Power BI, Matplotlib, Seaborn). Excellent problem-solving skills and attention to detail. Effective communication and presentation skills. Ability to work in a collaborative team environment and independently. Experience with big data technologies and platforms (e.g., Hadoop, Spark, SQL, NoSQL). Knowledge of natural language processing (NLP) and deep learning. Familiarity with cloud computing platforms (e.g., AWS, Azure, Google Cloud). Previous industry experience in a data scientist or analytics role. What do we expect from you? Masters or Bachelor in CIS/ Engineering / Science / Mathematics / Statistics/ Design …etc Should have Cedula /Titulo Should have hands-on years of experience in any one of the above technology Advance English Speaking Ability to work independently Competitive Salary NOTE: We sponsor TN visas for qualified Mexican citizens. If you are interested in pursuing this opportunity then forward an updated Word copy of your resume in English. Our company runs on referrals and your referrals are always appreciated. If you can forward these emails to any of your friends that would be great. About Advent Infotech: Advent Infotech is a multinational IT services company with offices in 7 countries, including Mexico. Our clients mainly come from the United States. Our head office is located in New Jersey, USA Our delivery centers are located in six countries: India, Indonesia, Australia, Poland, Canada, and Mexico. Advent is led by great leadership with more than twenty years in the business. Our directors are highly ethical and come with a Harvard Business School education, serial entrepreneurs, and angel investors with long-standing business ethics. Advent's motto has always been to provide profitable technology solutions for our clients while creating value for our clients.",https://mx.linkedin.com/jobs/view/senior-data-scientist-at-adventinfotech-4025686300,4025686300,"We are seeking a highly motivated and skilled Data Scientist to join our dynamic team. The Data Scientist will play a crucial role in turning complex data into actionable insights that drive business decisions and innovation. This position involves analyzing large datasets, developing models, and delivering strategic recommendations to enhance our products and services.","Python, R, TensorFlow, scikit-learn, PyTorch, Tableau, Power BI, Matplotlib, Seaborn, Hadoop, Spark, SQL, NoSQL, AWS, Azure, Google Cloud",6+,Bachelor,True,6.0,0,0,1,1,0,0,0,0,1,1,0,0,1,0,1,0,0
QA Machine Learning Engineer,C3 AI,Guadalajara,ON-SITE,Entry level,Full-time,Software Development,2024-09-15 11:32:47.028901,200,Engineering,Information Technology,,"C3.ai, Inc. (NYSE:AI) is a leading Enterprise AI software provider for accelerating digital transformation. The proven C3 AI Platform provides comprehensive services to build enterprise-scale AI applications more efficiently and cost-effectively than alternative approaches. The C3 AI Platform supports the value chain in any industry with prebuilt, configurable, high-value AI applications for reliability, fraud detection, sensor network health, supply network optimization, energy management, anti-money laundering, and customer engagement. Learn more at: C3 AI C3 AI is seeking for a QA Machine Learning Engineer to work with Platform Engineering, Product Development, QA, and Operations, to drive the software quality automation solutions for our existing Machine learning Infrastructure. You will be part of a team of highly skilled dedicated engineers to ensure that we are shipping the highest quality software possible. This is a great opportunity to work with cutting-edge artificial intelligence and machine learning technologies. Responsibilities Improve software tooling and operational procedures for standing-up, monitoring and troubleshooting the Model Inference Service. Take ownership of the operational aspects of such a service for internal use in C3 AI. Help disseminate operations knowledge to customers who wish to stand up the Model Inference Service. Write and maintain playbooks and runbooks for customer Site Reliability Engineers (SREs). Contribute to existing (or develop new) dashboards and tooling to monitor Quality-of-Service (QoS) of the Model Inference Service. Become a C3 AI Suite and C3 AI SaaS application expert to thoroughly understand all use case scenarios. Design and develop automated test suites for new C3 AI products and features. Automate and maintain test execution flow via Continuous Integration in Jenkins. Work with performance engineers to build automation for performance, scalability, and reliability tests. Perform analysis to identify root cause for defects identified during the release validation process. Qualifications Bachelor’s degree in a Science, Technology, Engineering or Math (STEM) field. Good understanding of software development lifecycle, and automation testing solutions. Advanced programming and troubleshooting skills. Clear understanding of Agile software development methodology. Outstanding team player with excellent interpersonal skills. Preferred Qualifications Strong understanding of common machine learning techniques, Python programming, and quality assurance methodologies. Proficiency with Linux command line tools, shell scripting, Node.js, Python, and JavaScript. Proficiency working with web applications and cloud deployments (AWS, Azure, GCP). Experience with container orchestration technologies (Kubernetes). Experience with cloud infrastructure technologies. Experience with logging and monitoring tools such as OpenSearch, Graphana, and Glowroot. Great verbal and written communication skills to collaborate multi-functionally. C3 AI provides a competitive compensation package and excellent benefits. Employee Testimonial - Juan Castaneda from C3 on Vimeo. C3 AI is proud to be an Equal Opportunity and Affirmative Action Employer. We do not discriminate on the basis of any legally protected characteristics, including disabled and veteran status.",https://mx.linkedin.com/jobs/view/qa-machine-learning-engineer-at-c3-ai-3853531535,3853531535,"C3 AI is seeking a QA Machine Learning Engineer to work with Platform Engineering, Product Development, QA, and Operations to drive software quality automation solutions for existing Machine Learning Infrastructure. Responsibilities include improving software tooling, taking ownership of operational aspects, writing and maintaining playbooks, contributing to dashboards and tooling, designing and developing automated test suites, and automating test execution flow via Continuous Integration. The role requires a good understanding of the software development lifecycle, automation testing solutions, and Agile methodologies.","Python, JavaScript, Node.js, Linux, AWS, Azure, GCP, Kubernetes, OpenSearch, Grafana, Glowroot, Jenkins",,Bachelor,True,,0,1,0,1,1,0,0,0,0,0,0,0,0,0,1,0,0
AI ML Engineer- Azure,Synechron,Guadalajara,ON-SITE,Mid-Senior level,Full-time,Financial Services and Investment Banking,2024-09-13 11:32:47.028901,25,Information Technology,,,"Our challenge We are seeking a skilled and motivated AI/ML Engineer with Azure to join our team. Candidate will collaborate, analyze, design, develop, test, maintain and implement premier software while working with cross-functional teams such as product and architecture. The Role Responsibilities: Experience in CMS as major subsystem and FAS or TRAMS as minor sub-Collaboration: Work closely with cross-functional teams, including IT, business, operations, and business stakeholders, to align AI support with objectives. Work with business users to understand their needs and document them using various tools Anticipate user needs and propose solutions and alternatives Understand functional and non-functional requirements Work with development teams in building and testing the solutions Maintain active communication channels with all stakeholders on deliverables and report status Track all outstanding issues and manage them from initiation to production deployment Ability to multitask and work with multiple teams Manage enhancement requests and production issues. Able to prioritize and allocate resources effectively Requirements: You are: Python and AI/ML Develop and deploy GenAI applications on Azure with focuses on: Azure OpenAI Azure Functions Azure Cosmos Azure Blob Storage Azure API Management Infrastructure as Code experience with Terraform with Azure CI/CD experiences with Jenkins Experience with Azure cloud, Python, Angular (applications are built today with azure cloud, using python & angular as backend & front end, and other azure services) Support in Regression Testing & Patch Releases for new & existing applications We can offer you: A highly competitive compensation and benefits package A multinational organization with 55 offices in 20 countries and the possibility to work abroad Laptop/equipment 12 days of paid annual leave (plus sick leave and national holidays) Maternity & Paternity leave plans A comprehensive insurance plan including: medical, dental, vision, and long-/short-term disability (plans vary by region) Retirement savings plans A higher education certification policy Extensive training opportunities, focused on skills, substantive knowledge, and personal development On-demand Udemy for Business for all Synechron employees with free access to more than 5000 curated courses Coaching opportunities with experienced colleagues from our Financial Innovation Labs (FinLabs) and Center of Excellences (CoE) groups Cutting edge projects at the world’s leading tier-one banks, financial institutions and insurance firms A flat and approachable organization A truly diverse, fun-loving and global work culture Saving funds plan for Mexico S​YNECHRON’S DIVERSITY & INCLUSION STATEMENT Diversity & Inclusion are fundamental to our culture, and Synechron is proud to be an equal opportunity workplace and is an affirmative action employer. Our Diversity, Equity, and Inclusion (DEI) initiative ‘Same Difference’ is committed to fostering an inclusive culture – promoting equality, diversity and an environment that is respectful to all. We strongly believe that a diverse workforce helps build stronger, successful businesses as a global company. We encourage applicants from across diverse backgrounds, race, ethnicities, religion, age, marital status, gender, sexual orientations, or disabilities to apply. We empower our global workforce by offering flexible workplace arrangements, mentoring, internal mobility, learning and development programs, and more. All employment decisions at Synechron are based on business needs, job requirements and individual qualifications, without regard to the applicant’s gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law.",https://mx.linkedin.com/jobs/view/ai-ml-engineer-azure-at-synechron-4014991273,4014991273,"We are seeking a skilled and motivated AI/ML Engineer with Azure to develop, test, maintain, and implement software while collaborating with cross-functional teams. The role involves understanding user needs, proposing solutions, and managing enhancement requests. Responsibilities include developing and deploying GenAI applications on Azure with a focus on Azure OpenAI, Azure Functions, Azure Cosmos, Azure Blob Storage, and Azure API Management, and utilizing Infrastructure as Code with Terraform and CI/CD with Jenkins.","Python, Azure, AI, ML, Azure OpenAI, Azure Functions, Azure Cosmos, Azure Blob Storage, Azure API Management, Terraform, Jenkins, Angular",,,True,,0,0,0,1,0,0,0,0,0,0,1,1,0,0,1,0,0
Senior Data Scientist - Support Global Supply Chain,AstraZeneca,Guadalajara,ON-SITE,Associate,Full-time,Pharmaceutical Manufacturing,2024-09-01 11:32:47.028901,165,Engineering,Information Technology,,"Sr. Data Scientist 📌Positions are open to Mexican Citizens and official residents of Mexico. 📍Location: Guadalajara (hybrid) 📌Strong English Communication Skills Required. Join our diverse team , where we ensure our partners have access to the data, insights, and innovations required to deliver against our Supply Chain Digital Strategy. We are seeking Data Scientists who can help advance the field within the Supply Chain Organization and deliver substantial solutions that strive to solve our biggest challenges. This is your chance to thrive with standardised ways of working driven by Lean. Embrace our standardised approach to drive efficiencies through our processes and focus us on the essentials. Accountabilities: As a Sr. Data Scientist, you will lead analytics projects and work with our Supply Chain Customers to take on significant challenges, resulting in breakthroughs in understanding our business and driving results, impacting Customer Service, Efficiency, Cost, and Sustainability. You will advance the development of internal capability for Data Science within supply chain, including Artificial Intelligence (AI), and Machine Learning (ML). You will play a significant role in crafting the future of analytics in the supply chain organization. You will engage with key stakeholders in operations and IT to advance the quality of analysis and data science capabilities. Essential Skills/Experience: - 8+ yr. proven experience in Statistical Modeling, Machine Learning, Data Mining, Unstructured Data Analytics, incorporate and/or Academic Research environments- 8+ yr. experience with Data Science tools, including Dataiku, SAS, AWS Sagemaker, and Machine Learning methods (Clustering, Regression, Optimization, Recommendation, Neural Networks) Desirable experience in Supply Chain Projects (Demand planning & forecasting Inventory Optimization, Logistics, Network Design, Segmentation, and S&OP) Bachelor's degree in Applied Mathematics, Computer Science, Physics, Economics, Engineering, Statistics, Operations Research, Quantitative Social Science, etc.) Desirable Skills/Experience: Master’s degree in a quantitative field, Engineering, Computer Science, Physics, Applied Mathematics, Statistics, Economics or related field. When we put unexpected teams in the same room, we unleash bold thinking with the power to inspire life-changing medicines. In-person working gives us the platform we need to connect, work at pace and challenge perceptions. That’s why we work, on average, a minimum of three days per week from the office. But that doesn't mean we’re not flexible. We balance the expectation of being in the office while respecting individual flexibility. Join us in our outstanding and ambitious world. Why AstraZeneca? With constant new products and launches, there's never been a better time to join Supply Chain and craft our future with a big contribution to life-changing medicines. Our resilience helps us to thrive as we innovate and evolve. Ours is a safe and positive space where ideas are encouraged and rewarded. As part of an agile team it's crucial we speak up to offer innovative approaches for process improvements and faster execution. It's our patient focus that drives us. If you want to make a big impact, this is the place for you. Our contribution to life changing medicines is why people have been here for decades. We do it for the patients. Are you ready to join our team and make a difference? Apply now and let's craft the future together!",https://mx.linkedin.com/jobs/view/senior-data-scientist-support-global-supply-chain-at-astrazeneca-3920041308,3920041308,"Join our diverse team as a Senior Data Scientist to lead analytics projects within the Supply Chain Organization, implementing substantial solutions to improve customer service, efficiency, cost, and sustainability. You will develop internal data science capabilities, applying artificial intelligence (AI) and machine learning (ML) techniques while engaging with key stakeholders to enhance analysis quality.","Statistical Modeling, Machine Learning, Data Mining, Unstructured Data Analytics, Dataiku, SAS, AWS Sagemaker, Clustering, Regression, Optimization, Recommendation, Neural Networks",8+ years,Bachelor,True,8.0,0,0,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0
"Sr. Applied Scientist, Devices, Device Science and Data Technology",myGwork - LGBTQ+ Business Community,Guadalajara,ON-SITE,Entry level,Full-time,"Technology, Information and Internet",2024-09-08 11:32:47.028901,25,Research,"Analyst,",Information Technology,"This job is with Amazon, an inclusive employer and a member of myGwork – the largest global platform for the LGBTQ+ business community. Please do not contact the recruiter directly. Description The Amazon Devices team designs and engineers high-profile consumer electronics, including the best-selling Kindle family of products. We have also produced groundbreaking devices like Fire tablets, Fire TV, Amazon Dash, and Amazon Echo. What will you help us create? The Team: How often have you had an opportunity to be a founding member of a team that is solving a significant problem through innovative technology? Would you like to know more about how we are envisioning the use of machine learning and GenAI to solve these problems? If this sounds intriguing, then we'd like to talk to you about a role on our team that's tackling a set of problems requiring significant innovation and scaling. As a Sr. Applied Scientist, you will design, evangelize, and implement state-of-the-art solutions for never-before-solved problems, helping Amazon Device to provide customer great products. This role will be a key member of a Science and Data technology team based in Guadalajara, Mexico. You will work closely with other scientists, machine learning experts, engineers to design and run experiments, research new algorithms, and find new ways to improve Amazon Device Services & Software products. You will partner with technology and product leaders to solve business and technology problems using scientific approaches to build new services that surprise and delight our customers. Our scientists work closely with software engineers to put algorithms into practice. They also work on cross-disciplinary efforts with other scientists within Amazon. The Key Responsibility For This Role Include Define proper output business Metrics, and build input models to identify patterns and drivers of the output. Drive actions at scale using scientifically-based methods and decision making. Design and develop complex mathematical, statistical, Machine Learning, GenAI models and apply them to define strategic and tactical needs and drive the appropriate business and technical solutions Design experiments, test hypotheses, and build actionable models Prototype these models by using modeling languages such as R or in software languages such as Python. Work with software engineering teams to drive scalable, real-time implementations Utilizing Amazon systems and tools to effectively work with terabytes of data We are open to hiring candidates to work out of one of the following locations: Zapopan, MEX Basic Qualifications 5+ years of building machine learning models for business application experience PhD, or Master's degree and 6+ years of applied research experience Experience programming in Java, C++, Python or related language Experience with neural deep learning methods and machine learning Preferred Qualifications Experience with modeling tools such as R, scikit-learn, Spark MLLib, MxNet, Tensorflow, numpy, scipy etc. Experience with large scale distributed systems such as Hadoop, Spark etc.",https://mx.linkedin.com/jobs/view/sr-applied-scientist-devices-device-science-and-data-technology-at-mygwork-lgbtq%2B-business-community-4018420774,4018420774,"As a Sr. Applied Scientist, you will design, evangelize, and implement state-of-the-art solutions for innovative problems, working closely with other scientists and engineers to run experiments, research new algorithms, and improve Amazon Device Services & Software products. You will define business metrics, build input models, design and develop complex mathematical models, and drive scalable implementations using Amazon systems and tools.","Python, R, Java, C++, scikit-learn, Spark MLLib, MxNet, Tensorflow, numpy, scipy, Hadoop, Machine Learning, GenAI",5+ years,Masters,True,5.0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,1,0,0
"Sr. Applied Scientist, Amazon Devices, Device Science and Data Technology",Amazon,Guadalajara,ON-SITE,Mid-Senior level,Full-time,Software Development,2024-09-01 11:32:47.028901,58,Research,"Science,",Engineering,"Description The Amazon Devices team designs and engineers high-profile consumer electronics, including the best-selling Kindle family of products. We have also produced groundbreaking devices like Fire tablets, Fire TV, Amazon Dash, and Amazon Echo. What will you help us create? The Team: How often have you had an opportunity to be a founding member of a team that is solving a significant problem through innovative technology? Would you like to know more about how we are envisioning the use of machine learning and GenAI to solve these problems? If this sounds intriguing, then we’d like to talk to you about a role on our team that's tackling a set of problems requiring significant innovation and scaling. As a Sr. Applied Scientist, you will design, evangelize, and implement state-of-the-art solutions for never-before-solved problems, helping Amazon Device to provide customer great products. This role will be a key member of a Science and Data technology team based in Guadalajara, Mexico. You will work closely with other scientists, machine learning experts, engineers to design and run experiments, research new algorithms, and find new ways to improve Amazon Device Services & Software products. You will partner with technology and product leaders to solve business and technology problems using scientific approaches to build new services that surprise and delight our customers. Our scientists work closely with software engineers to put algorithms into practice. They also work on cross-disciplinary efforts with other scientists within Amazon. The Key Responsibility For This Role Include Define proper output business Metrics, and build input models to identify patterns and drivers of the output. Drive actions at scale using scientifically-based methods and decision making. Design and develop complex mathematical, statistical, Machine Learning, GenAI models and apply them to define strategic and tactical needs and drive the appropriate business and technical solutions Design experiments, test hypotheses, and build actionable models Prototype these models by using modeling languages such as R or in software languages such as Python. Work with software engineering teams to drive scalable, real-time implementations Utilizing Amazon systems and tools to effectively work with terabytes of data We are open to hiring candidates to work out of one of the following locations: Zapopan, MEX Basic Qualifications 5+ years of building machine learning models for business application experience PhD, or Master's degree and 6+ years of applied research experience Experience programming in Java, C++, Python or related language Experience with neural deep learning methods and machine learning Preferred Qualifications Experience with modeling tools such as R, scikit-learn, Spark MLLib, MxNet, Tensorflow, numpy, scipy etc. Experience with large scale distributed systems such as Hadoop, Spark etc. Company - Servicios Comerciales Amazon Mexico S. de R.L. de C.V. Job ID: A2641396",https://mx.linkedin.com/jobs/view/sr-applied-scientist-amazon-devices-device-science-and-data-technology-at-amazon-3924984506,3924984506,"As a Sr. Applied Scientist, you will design, evangelize, and implement state-of-the-art solutions for complex problems, helping Amazon Devices provide great products. You will work closely with scientists, machine learning experts, and engineers to design and run experiments, research new algorithms, and improve services and software products. Your responsibilities will include defining business metrics, building input models, driving actions using scientific methods, designing experiments, and prototyping models using various programming languages.","Python, Java, C++, R, scikit-learn, Spark MLLib, MxNet, TensorFlow, numpy, scipy, Hadoop, Spark",5+ years,Masters,True,5.0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,1,0,0
"Data Engineer, Science & Data Technology team",Amazon,Guadalajara,ON-SITE,,Full-time,Software Development,2024-09-13 11:32:47.028901,196,Strategy/Planning,"Analyst,",Information Technology,"Description The Amazon Devices team designs and engineers high-profile consumer electronics, including the best-selling Kindle family of products. We have also produced groundbreaking devices like Fire tablets, Fire TV, Amazon Dash, and Amazon Echo. What will you help us create? The Team: How often have you had an opportunity to be a founding member of a team that is solving a significant problem through innovative technology? Would you like to know more about how we are envisioning the use of data analytics, machine learning, AI and linear programming to solve these problems? If this sounds intriguing, then we’d like to talk to you about a role on a new Amazon team that's tackling a set of problems requiring significant innovation and scaling. We are seeking a Data Engineer with strong analytical, communication and project management skills to join our team. This role will be a key member of a Science and Data technology team based in Guadalajara,MX. Working closely with business stakeholders, software development engineers and scientist colleagues, you will design, evangelize, and implement state-of-the-art solutions for never-before-solved problems, helping Amazon Device to provide customer great products and keep the data secure. You will work with the most complicated data environment, employ right architecture to handle big data and support various analytics use cases, including business reporting, production data pipeline, machine learning, optimization models, statistical models, simulation, etc. Your work will have a direct impact on the day-to-day decision making in the Amazon Devices Sales & Operations Technology, and end customers. You are an individual with outstanding analytical abilities, excellent communication skills, good business understanding, and technically savvy. The successful candidate will be an analytical problem solver who enjoys diving into data, is excited about solving ambiguity problems, can multi-task, and can credibly interface between technical teams and business stakeholders. We are open to hiring candidates to work out of one of the following locations: Zapopan, MEX Basic Qualifications 3+ years of data engineering experience Experience with data modeling, warehousing and building ETL pipelines Preferred Qualifications Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases) Company - Servicios Comerciales Amazon Mexico S. de R.L. de C.V. - D44 Job ID: A2564109",https://mx.linkedin.com/jobs/view/data-engineer-science-data-technology-team-at-amazon-3877282509,3877282509,"We are seeking a Data Engineer with strong analytical, communication, and project management skills to join our team. You will design, evangelize, and implement state-of-the-art solutions for complex problems, helping Amazon Device provide great products and keep the data secure. You will work with a complicated data environment, employing the right architecture to handle big data and support various analytics use cases, including business reporting, production data pipelines, machine learning, optimization models, statistical models, and simulation. Your work will impact the decision-making in Amazon Devices Sales & Operations Technology and end customers.","AWS Redshift, AWS S3, AWS Glue, AWS EMR, AWS Kinesis, AWS FireHose, AWS Lambda, Data Modeling, ETL Pipelines, Non-relational Databases",3+ years,,True,3.0,0,0,1,1,0,1,1,1,0,1,0,0,0,0,0,0,0
Big Data Engineer,Infosys,Guadalajara,ON-SITE,Entry level,Full-time,IT Services and IT Consulting,2024-09-01 11:32:47.028901,25,Engineering,Information Technology,,"Job Description Looking for a BigData Eng At least 1 year of experience in Big Data projects, with experience in Hadoop -Spark/Scala Must have experience in AWS Experience with Python Good English communication skills Can be located in MTY, CDMX or GDL About Us Infosys is a global leader in next-generation digital services and consulting. We enable clients in more than 50 countries to navigate their digital transformation. With over four decades of experience in managing the systems and workings of global enterprises, we expertly steer our clients through their digital journey. We do it by enabling the enterprise with an AI-powered core that helps prioritize the execution of change. We also empower the business with agile digital at scale to deliver unprecedented levels of performance and customer delight. Our always-on learning agenda drives their continuous improvement through building and transferring digital skills, expertise, and ideas from our innovation ecosystem.",https://mx.linkedin.com/jobs/view/big-data-engineer-at-infosys-4012245318,4012245318,"Looking for a Big Data Engineer with at least 1 year of experience in Big Data projects, with experience in Hadoop and Spark/Scala. Must have experience in AWS and proficiency in Python. Good English communication skills are required.","Hadoop, Spark, Scala, AWS, Python",1,,True,1.0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,1,0,0
"Data Engineer, Science & Data Technology team",myGwork - LGBTQ+ Business Community,Guadalajara,ON-SITE,Entry level,Full-time,"Technology, Information and Internet",2024-09-08 11:32:47.028901,25,Information Technology,,,"This job is with Amazon, an inclusive employer and a member of myGwork – the largest global platform for the LGBTQ+ business community. Please do not contact the recruiter directly. Description The Amazon Devices team designs and engineers high-profile consumer electronics, including the best-selling Kindle family of products. We have also produced groundbreaking devices like Fire tablets, Fire TV, Amazon Dash, and Amazon Echo. What will you help us create? The Team: How often have you had an opportunity to be a founding member of a team that is solving a significant problem through innovative technology? Would you like to know more about how we are envisioning the use of data analytics, machine learning, AI and linear programming to solve these problems? If this sounds intriguing, then we'd like to talk to you about a role on a new Amazon team that's tackling a set of problems requiring significant innovation and scaling. We are seeking a Data Engineer with strong analytical, communication and project management skills to join our team. This role will be a key member of a Science and Data technology team based in Guadalajara,MX. Working closely with business stakeholders, software development engineers and scientist colleagues, you will design, evangelize, and implement state-of-the-art solutions for never-before-solved problems, helping Amazon Device to provide customer great products and keep the data secure. You will work with the most complicated data environment, employ right architecture to handle big data and support various analytics use cases, including business reporting, production data pipeline, machine learning, optimization models, statistical models, simulation, etc. Your work will have a direct impact on the day-to-day decision making in the Amazon Devices Sales & Operations Technology, and end customers. You are an individual with outstanding analytical abilities, excellent communication skills, good business understanding, and technically savvy. The successful candidate will be an analytical problem solver who enjoys diving into data, is excited about solving ambiguity problems, can multi-task, and can credibly interface between technical teams and business stakeholders. We are open to hiring candidates to work out of one of the following locations: Zapopan, MEX Basic Qualifications 3+ years of data engineering experience Experience with data modeling, warehousing and building ETL pipelines Preferred Qualifications Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases)",https://mx.linkedin.com/jobs/view/data-engineer-science-data-technology-team-at-mygwork-lgbtq%2B-business-community-4018426579,4018426579,"We are seeking a Data Engineer with strong analytical, communication, and project management skills to join a Science and Data technology team. You will design, implement state-of-the-art solutions for complex problems, helping Amazon Devices to provide great products and keep data secure. Your work will involve handling big data and supporting various analytics use cases, including machine learning, optimization models, and business reporting.","AWS Redshift, AWS S3, AWS Glue, AWS EMR, AWS Kinesis, AWS FireHose, AWS Lambda, non-relational databases, data modeling, ETL pipelines",3+ years,,True,3.0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0
Data Cloud Engineer,DB Schenker,Guadalajara,ON-SITE,Entry level,Full-time,"Transportation, Logistics, Supply Chain and Storage",2024-09-12 11:32:47.028901,25,Engineering,Information Technology,,"At DB Schenker, you are part of a global logistics network that connects the world. A network that allows you to shape your career by encouraging you to contribute and truly make a difference. With more than 76,000 colleagues worldwide, we welcome diversity and thrive on individual backgrounds, perspectives, and skills. Together as one team, we are Here to move. Job Overview At Schenker International S.A. de C.V. we are looking for a Data Cloud Engineer to be part of our IT team, for our office in Guadalajara, Mexico. This role contributes to turning DB Schenker into a data-driven company. Our Data Engineering team focuses on designing advanced analytics solutions to solve potential business use cases in logistics using Machine Learning, AI techniques, Data Visualization tools and Big Data technologies in cooperation with our Software Engineering team, internal business units and global IT. We are looking for a talented Data Engineer who can contribute to our projects with solid data intuition, hands-on problem-solving skills, engineering mindset and eagerness to learn about our logistics business data. What will be your challenges? Analyze data and design, code, test, debug, automate, document, and maintain data solutions Support building, improving, and maintaining a cloud native data lake platform Integrate machine learning and operations research solutions into the DB Schenker system landscape Support and interact with data scientist, operations research specialists and business consultants in all their data-related activities What you need to succeed? Experience working with distributed computing tools especially Spark using Databricks and streaming technologies (Kafka, Spark Structured Streaming, etc.) Knowledge of cloud platforms (ideally Azure, alternatively AWS or GCP) and respective Data and Machine Learning related service associated models Fluency in at least one programming language such as Python or Scala Experience with relational databases (Oracle, PostgreSQL) and good knowledge of SQL Fluency in POSIX systems (e.g., Linux, MacOS X) and the command-line terminal Experience with orchestration / data pipelining tools like Argo, Azure Data Factory, Airflow etc. Experience in delivering software and of the software development life cycle: source code repositories (Git) and versioning/branching/peer reviewing, continuous integration (e.g., GitLab CI, Azure DevOps), deployment/release (e.g., artifact building and repositories), maintenance Competences Proficient English skills in reading, writing and speaking for clear communication with global teams Customer and service orientation Ability to work effectively across diverse organizations, groups and functions Flexible thinker able to operate in a changing environment Why you will love DB Schenker Many of our jobs come with great benefits and career path opportunities: Generous and additional vacation and yearly bonus schemes Financial savings and various insurance options Grocery & restaurant vouchers Flexible & hybrid working models Global & multicultural environment: Collaborate with colleagues all around the world. Language courses Mentorship, career program & development opportunities Learning & education programs Mental health & support initiatives How To Get Started You can begin by applying above or visit us at https://dbschenker.com/global/careers Stay Connected With Us Web Page: http://www.dbschenker.com DB Schenker is committed to a diverse and inclusive workplace. DB Schenker is an equal opportunity employer and does not discriminate based on race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.",https://mx.linkedin.com/jobs/view/data-cloud-engineer-at-db-schenker-4022966273,4022966273,"We are looking for a Data Cloud Engineer to contribute to turning DB Schenker into a data-driven company by designing advanced analytics solutions in logistics using Machine Learning, AI, Data Visualization tools, and Big Data technologies. The role involves analyzing data, designing and maintaining data solutions, integrating machine learning into systems, and supporting data-related activities with various specialists.","Python, Scala, SQL, Oracle, PostgreSQL, Spark, Databricks, Kafka, Azure, AWS, GCP, Linux, MacOS X, Argo, Azure Data Factory, Airflow, Git, GitLab CI, Azure DevOps",,,True,,0,0,1,1,0,0,0,0,0,1,0,1,0,0,1,0,0
AWS Data Engineer,Cognizant,Guadalajara,ON-SITE,Entry level,Full-time,IT Services and IT Consulting,2024-08-16 11:32:47.028901,25,Information Technology,,,"Cognizant is always looking for top talent. We are searching for candidates to fill future needs within the business. This job posting represents potential future employment opportunities with Cognizant. Although the position is not currently available, we want to provide you with the opportunity to express your interest in future employment opportunities with Cognizant. If a job opportunity that you may be qualified for becomes available in the future, we will notify you. At that time you can determine whether you would like to apply for the specific open position. Thank you for your interest in Cognizant career opportunities. We’re hiring! At Cognizant we have an ideal opportunity for you to be part of one of the largest companies in the digital sector worldwide. A Great Place To Work where we look for people who contribute new ideas, experiencing a dynamic and growing environment. At Cognizant we promote an inclusive culture, where we value different perspectives providing career growth and development opportunities. #WelcomeToCognizant! We have an exciting opportunity for an exceptional individual to work supporting one of our clients as AWS Data Engineer What you’ll do: Data Extraction from On-Prem Hadoop system and Ingestion to AWS S3. Tech stack -AWS CLI. Data Validation, Compression and Processing. Tech stack – AWS Lambda, Glue. Orchestration of the end-to-end pipeline for Machine Learning Models (Train/Score). Tech stack – Step Function, SageMaker, Lambda, ECR. Creating partitioned tables and maintaining ML model output data in the tables. Tech stack – Athena, Redshift Spectrum, Glue. Creating and Maintaining Data warehouse solutions for Analytical Model Output and Intermediate Files. Tech stack – Redshift. Loading Incremental/Full Data to Quicksight for Visualization. Tech stack - Lambda. Building the Interactive Reporting Dashboards in AWS. Tech stack – Quicksight. Implementation of Error Handling and Logging mechanism. Tech stack – CloudWatch, SNS. Part of various phases such as Requirements Gathering, Software development, unit & integration testing, deployment preparation, Go-Live phase involve in Project handover and post implementation support. Preferred experience: Amazon Web Services: S3, Lambda, Glue, Redshift, Athena, Step Function, SNS. Programming Languages: Python. Collaboration Tools: Jira, Confluence. Why Cognizant? Improve your career in one of the largest and fastest growing IT services providers worldwide Receive ongoing support and funding with training and development plans Have a highly competitive benefits and salary package Get the opportunity to work for leading global companies We are committed to respecting human rights and build a better future by helping your minds and the environment We invest in people and their wellbeing. We create conditions for everyone to thrive. We do not discriminate based on race, religion, color, sex, age, disability, nationality, sexual orientation, gender identity or expression, or for any other reason covered. At Cognizant we believe than our culture make us stronger! Join us now! #BeCognizant #IntuitionEngineered Employee Status : Full Time Employee Shift : Day Job Job Posting : Jan 03 2024 About Cognizant Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @Cognizant. 43483",https://mx.linkedin.com/jobs/view/aws-data-engineer-at-cognizant-4006646151,4006646151,"We have an exciting opportunity for an exceptional individual to work supporting one of our clients as an AWS Data Engineer. Responsibilities include data extraction from an on-prem Hadoop system and ingestion to AWS S3, data validation, compression, processing, and the orchestration of end-to-end pipelines for machine learning models. This role involves creating and maintaining data warehouse solutions for analytical model output and intermediate files, loading data to Quicksight for visualization, building interactive reporting dashboards, and implementing error handling and logging mechanisms.","AWS S3, AWS Lambda, AWS Glue, AWS Redshift, AWS Athena, AWS Step Function, AWS SNS, Python, Jira, Confluence, AWS Quicksight, AWS CloudWatch",,,True,,0,0,1,1,0,0,0,0,0,0,0,0,0,0,1,0,0
Data Engineer,In All Media,Guadalajara,ON-SITE,Entry level,Full-time,Information Technology & Services,2024-05-18 11:32:47.028901,25,Information Technology,,,"Data Analyst Engineer The objective of this project and role is to focus on delivering the solution your business partners need to grow the business, e.g. an application, an API, a rules engine, or a Data Pipeline. You know what it takes to deliver the best possible, within the given deadline Deliverables Tool called conversion, delivering recommendations on this tool , solving technical debt updates and maintaining add net new recommendations, we can directly measure these recommendations by count and impact (example - how many more features were adopted) CS - simplify data on active points and deliver the best recommendations, more net new Requirements Technologies Backend * Python * Flask * SQLAlchemy * PyMySQL * MongoDB * Internal SOA libraries * Healthcheck tools * Tracing tools DevOps * GitLab CI/CD * Docker * Kubernetes * AWS We're seeking a talented Software Engineer Level 2 to join our dynamic team responsible for developing a suite of innovative tools. These tools are essential in automating and streamlining communication processes with our clients. If you are passionate about solving complex problems and improving user experiences, we want you on our team.",https://mx.linkedin.com/jobs/view/data-engineer-at-in-all-media-3933079737,3933079737,"The objective of this role is to deliver solutions needed to grow the business, such as applications, APIs, and data pipelines. This includes simplifying data on active points and delivering measurable recommendations based on their impact.","Python, Flask, SQLAlchemy, PyMySQL, MongoDB, GitLab CI/CD, Docker, Kubernetes, AWS",,,True,,0,1,0,1,1,0,0,0,0,1,0,1,0,0,1,0,0
Data Engineer,Cognizant,Guadalajara,ON-SITE,Entry level,Full-time,IT Services and IT Consulting,2024-08-16 11:32:47.028901,25,Information Technology,,,"Cognizant is always looking for top talent. We are searching for candidates to fill future needs within the business. This job posting represents potential future employment opportunities with Cognizant. Although the position is not currently available, we want to provide you with the opportunity to express your interest in future employment opportunities with Cognizant. If a job opportunity that you may be qualified for becomes available in the future, we will notify you. At that time you can determine whether you would like to apply for the specific open position. Thank you for your interest in Cognizant career opportunities. We’re hiring! At Cognizant we have an ideal opportunity for you to be part of one of the largest companies in the digital sector worldwide. A Great Place To Work where we look for people who contribute new ideas, experiencing a dynamic and growing environment. At Cognizant we promote an inclusive culture, where we value different perspectives providing career growth and development opportunities. #WelcomeToCognizant! We have an exciting opportunity for an exceptional individual to work supporting one of our clients as Data Engineer What you’ll do: Responsibilities: Develop and operate the data processing platform and analytical platforms Develop new functionalities in current pipelines of data Find anomalies in current reports and existing databases Understand requirements to create new ETLs Monitor current processes and troubleshoot any possible failure Build data pipelines to support development, verification/validation and monitoring models Qualifications: Bachelor's degree in Computer Science or related technical field, or equivalent practical experience 5+ years' experience as Data Engineer working with ETL projects with SQL and Scala/PySpark Hands on experience in development & optimization of data pipelines Solid SQL skills and understanding of Data Partitioning SQL Queries and Calculations Transformations and aggregations Understanding of structure and semi-structure data sources Good understanding of control version systems (Git, etc) Unit testing skills Experience working within SCRUM methodology and/or Kanban Self-motivated, proactive, adaptable, with teamwork and learning skills Excellent analytical, written and verbal communication skills (skills) Why Cognizant? Improve your career in one of the largest and fastest growing IT services providers worldwide Receive ongoing support and funding with training and development plans Have a highly competitive benefits and salary package Get the opportunity to work for leading global companies We are committed to respecting human rights and build a better future by helping your minds and the environment We invest in people and their wellbeing. We create conditions for everyone to thrive. We do not discriminate based on race, religion, color, sex, age, disability, nationality, sexual orientation, gender identity or expression, or for any other reason covered. At Cognizant we believe than our culture make us stronger! Join us now! #BeCognizant #IntuitionEngineered Igualdad de Empleo y Política de Acción Afirmativa: Cognizant es un empleador que ofrece igualdad de oportunidades. Todos los solicitantes calificados recibirán consideración para el empleo sin distinción de sexo, identidad de género, orientación sexual, raza, color, religión, origen nacional, discapacidad, estado de veterano protegido, edad o cualquier otra característica protegida por la ley. Employee Status : Full Time Employee Shift : Day Job Job Posting : Jan 03 2024 About Cognizant Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @Cognizant. 43441",https://mx.linkedin.com/jobs/view/data-engineer-at-cognizant-4017704396,4017704396,"We have an exciting opportunity for an exceptional individual to work supporting one of our clients as a Data Engineer. Responsibilities include developing and operating the data processing platform, finding anomalies in current reports and databases, understanding requirements to create new ETLs, monitoring processes, and troubleshooting failures. Qualifications include a Bachelor's degree in Computer Science or related technical field, with 5+ years' experience as a Data Engineer working with ETL projects using SQL and Scala/PySpark, solid SQL skills, and experience with control version systems and SCRUM methodology.","SQL, Scala, PySpark, ETL, Git, SCRUM, Kanban",5+ years,Bachelor,True,5.0,1,0,1,0,0,0,1,0,0,1,0,1,0,0,0,0,0
Data & Advanced Process Analytics Engineer,AstraZeneca,Guadalajara,ON-SITE,Associate,Full-time,Pharmaceutical Manufacturing,2024-09-13 11:32:47.028901,25,Information Technology,,,"AstraZeneca is a global, science-led, patient-focused pharmaceutical company that focuses on the discovery, development, and commercialization of prescription medicines for some of the world’s most serious diseases. But we’re more than one of the world’s leading pharmaceutical companies. As a high-performing team, we are united and motivated by our shared purpose – to push the boundaries of science to deliver life-changing medicines. We come to work each day to make a difference – to patients, society, and our company. Here you will experience a fast paced and agile environment as we continue to support the business on a journey of evolution and growth, driven by new, exciting technology and digital innovations. It’s challenging and sometimes demanding, and that’s why we love it. About The Role Join the Process Mining COE within Global Business Services (GBS) at AstraZeneca, a team that has established itself as a pivotal advanced analytics capability. We unlock processing capacity and value through automated process discovery, analytics, and automated decision-support workflows. We are looking for a Process Mining Consultant to join the Process Mining team as we scale the capability and deliver Process Mining (Celonis) solutions across AstraZeneca. Main duties and responsibilities Working alongside the Senior Managers within the Process Mining team, the role will be responsible for the following activities: Work closely with stakeholders to help answer key business questions about the process Identify required data sources and set up data acquisition pipelines to the process mining platform Develop custom process models using process mining techniques Leverage both regular business intelligence dashboard reporting and more sophisticated programmatic techniques to deliver process insights to stakeholders Build automated workflows to facilitate pro-active process interventions Essential Requirements 3-8 years of hands-on experience in Data Engineering, Analytics, or Process Mining projects. Hands-on experience in a Process Mining Tool: Celonis (or similar: UiPath, QPR, Minit, Signavio etc.) will be a strong advantage Fluency with relational databases using SQL queries Experience in producing data visualisations to communicate process data effectively in a data visualisation tool Analytical skills to be able to discover, analyse and draw insight from complex data sets Knowledge of at least 1 functional area processes (Finance, HR etc.) and related Source System datasets is nice to have Excellent communication skills to work with stakeholders daily Energetic, organised and self-motivated Experience with source code version control and issue tracking (Bitbucket, JIRA, Confluence) Python programming skills appreciated Nice to Know: Experience with Databricks appreciated. If you're interested in delivering real business value through data-driven process optimization, we'd love to hear from you. This role offers the opportunity to directly impact AstraZeneca's operational efficiency and bottom line through innovative process mining solutions. Education Requirements: Degree in Computer Science, Business Informatics or a comparable degree Why AstraZeneca? At AstraZeneca when we see an opportunity for change, we seize it and make it happen, because any opportunity no matter how small, can be the start of something big. Delivering life-changing medicines is about being entrepreneurial - finding those moments and recognising their potential. Join us on our journey of building a new kind of organisation to reset expectations of what a bio-pharmaceutical company can be. This means we’re opening new ways to work, pioneering cutting edge methods and bringing unexpected teams together. So, what’s next! Are you already imagining yourself joining our team? Good, because we can’t wait to hear from you. Where can I find out more? Follow AstraZeneca on LinkedIn https://www.linkedin.com/company/1603/ Follow AstraZeneca on Facebook https://www.facebook.com/astrazenecacareers/ Follow AstraZeneca on Instagram https://www.instagram.com/astrazeneca_careers/?hl=en AstraZeneca is an equal opportunity employer. AstraZeneca will consider all qualified applicants for employment without discrimination on grounds of disability, sex or sexual orientation, pregnancy or maternity leave status, race or national or ethnic origin, age, religion or belief, gender identity or re-assignment, marital or civil partnership status, protected veteran status (if applicable) or any other characteristic protected by law. AstraZeneca only employs individuals with the right to work in the country/ies where the role is advertised. 📌Strong English Communication Skills Required. 📌 Positions are open to Mexican Citizens and official residents of Mexico. 📍 Location: Guadalajara (hybrid - Expectation of working in the office 3 days a week) When we put unexpected teams in the same room, we unleash bold thinking with the power to inspire life-changing medicines. In-person working give us the platform we need to connect, work at pace and challenge perceptions. That’s why we w",https://mx.linkedin.com/jobs/view/data-advanced-process-analytics-engineer-at-astrazeneca-4007362296,4007362296,"Join the Process Mining COE within Global Business Services at AstraZeneca as a Process Mining Consultant. The role involves working with stakeholders to answer key business questions, identifying data sources, setting up data acquisition pipelines for process mining, and developing custom process models. Responsibilities include delivering insights through business intelligence dashboards, building automated workflows for proactive interventions, and producing visualizations of complex data sets.","Celonis, Python, SQL, Bitbucket, JIRA, Confluence, Databricks",3-8 years,,True,3.0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,1,0,0
Data Engineer - AWS/ETL/Python,IBM,Guadalajara,ON-SITE,,Full-time,IT Services and IT Consulting,2024-09-08 11:32:47.028901,35,Other,,,"Introduction At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk. Your Role and Responsibilities Day-to-day troubleshooting of forecasting systems, mainly working through data anomalies that cause inaccurate forecasts or prevent forecasts' generation. Collaborate with the data science team to enhance existing forecasting systems for the trade floors. Create dynamic object-oriented methods, full stack solutions, and integrations to existing code solutions. Develop individual Python classes, methods, functions that support the data flow of existing and new projects. Work on code additions to seamlessly support projects for data flows, including logging and support, with little to no supervision. Experience in modifying packages, testing, and repository instances to support CI/CD. Required Technical and Professional Expertise Design, develop, test, and deploy Python applications on AWS, ensuring high availability, scalability, and security Develop and maintain technical documentation for Python applications and AWS infrastructure Optimize application performance, scalability, and reliability using AWS services such as: Serverless technologies (Lambda, API Gateway, Step Functions) S3 for data storage and retrieval Glue for data integration and ETL SQS and SNS for message queuing and notification Cognito for user authentication and authorization CloudWatch for monitoring and logging Preferred Technical And Professional Expertise Implement automated testing, deployment, and monitoring using tools like Jenkins, Docker, and CloudWatch Troubleshoot and resolve technical issues in Python applications and AWS infrastructure Stay up-to-date with the latest developments in Python and AWS, and apply this knowledge to improve our applications and infrastructure Design and develop Serverless front-end applications using AWS services such as API Gateway, Lambda, and S3 Implement PDS Proxy to handle data processing and analytics workloads Integrate AWS services with external systems and APIs using APIs, SDKs, and other integration tools Implement Row Level Security (RLS) to segregate data and ensure secure access to sensitive information Design and implement data models and database schemas for DynamoDB and PostgreSQL Design and develop data ingestion pipelines using AWS Lambda, Glue, AWS Batch and restful API’s Thorough understanding of AWS cloud concepts and related technologies like AWS VPC, Subnets, AZ’s, SG, IAM policies & Roles, EC2, AWS ALB, API Gateway, ECS, RDS, AWS MSK, Kinesis, SQS, SNS, S3, DynamoDB, Secret Manager, Cloud Watch, Cloud Formation scrips(yaml/json), AWS CDK. Collaborate with cross-functional teams to identify and prioritize project requirements Knowledge of API unit & performance testing tools like postman, JMeter, SOAP UI is a plus. Stay up to date with emerging technologies and trends, evaluating their potential impact on our projects. Mentor and provide technical guidance to junior developers, fostering their growth and helping them overcome challenges. Collaborate with cross-functional teams to integrate web applications with existing systems and third-party services. Ensure compliance with development standards, security guidelines, and best practices. Conduct code reviews to maintain high code quality, consistency, and adherence to coding standards. About Business Unit IBM Consulting is IBM’s consulting and global professional services business, with market leading capabilities in business and technology transformation. With deep expertise in many industries, we offer strategy, experience, technology, and operations services to many of the most innovative and valuable companies in the world. Our people are focused on accelerating our clients’ businesses through the power of collaboration. We believe in the power of technology responsibly used to help people, partners and the planet. Your Life @ IBM In a world where technology never stands still, we understand that, dedication to our clients success, innovation that matters, and trust and personal responsibility in all our relationships, lives in what we do as IBMers as we strive to be the catalyst that makes the world work better. Being an IBMer means you’ll be able to learn and develop yourself and your career, you’ll be encouraged to be courageous and experiment everyday, all whilst having continuous trust and support in an environment where everyone can thrive whatever their personal or professional background. Our IBMers are growth minded, always staying curious, open to feedback and learning new information and skills to constantly transform themselves and our company. They are trusted to provide on-going feedback to help other IBMers grow, as well as collaborate with colleagues keeping in mind a team focused approach to include different perspectives to drive exceptional outcomes for our customers. The courage our IBMers have to make critical decisions everyday is essential to IBM becoming the catalyst for progress, always embracing challenges with resources they have to hand, a can-do attitude and always striving for an outcome focused approach within everything that they do. Are you ready to be an IBMer? About IBM IBM's greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world. Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business. At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world. Location Statement For additional information about location requirements, please discuss with the recruiter following submission of your application. Being You @ IBM IBM is committed to creating a diverse environment and is proud to be an equal-opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender, gender identity or expression, sexual orientation, national origin, caste, genetics, pregnancy, disability, neurodivergence, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",https://mx.linkedin.com/jobs/view/data-engineer-aws-etl-python-at-ibm-3996904465,3996904465,"The role involves troubleshooting forecasting systems, collaborating with the data science team to enhance these systems, and developing dynamic object-oriented methods and full stack solutions. Responsibilities include designing, developing, testing, and deploying Python applications on AWS, optimizing application performance using various AWS services, maintaining technical documentation, and implementing automated testing and deployment tools. Candidates will also work on the integration of AWS services with external systems, design data models for databases, develop data ingestion pipelines, and mentor junior developers.","Python, AWS, Lambda, API Gateway, S3, Glue, DynamoDB, PostgreSQL, Jenkins, Docker, CloudWatch, CI/CD, API, SDK, JMeter, SOAP UI",,,True,,0,0,0,1,1,0,0,0,0,1,0,0,0,0,1,1,0
Data Engineer - AWS,IBM,Guadalajara,ON-SITE,,Full-time,IT Services and IT Consulting,2024-09-08 11:32:47.028901,25,Other,,,"Introduction In this role, you'll work in one of our IBM Consulting Client Innovation Centers (Delivery Centers), where we deliver deep technical and industry expertise to a wide range of public and private sector clients around the world. Our delivery centers offer our clients locally based skills and technical expertise to drive innovation and adoption of new technology. Your Role and Responsibilities Day-to-day troubleshooting of forecasting systems, mainly working through data anomalies that cause inaccurate forecasts or prevent forecasts' generation. Collaborate with the data science team to enhance existing forecasting systems for the trade floors. Create dynamic object-oriented methods, full stack solutions, and integrations to existing code solutions. Develop individual Python classes, methods, functions that support the data flow of existing and new projects. Work on code additions to seamlessly support projects for data flows, including logging and support, with little to no supervision. Experience in modifying packages, testing, and repository instances to support CI/CD. Required Technical and Professional Expertise AWS Cloud Data Engineer, you will be responsible for designing, implementing, and managing our data solutions on the AWS platform. AWS GLUE Primary focus will be on building and optimizing data pipelines, ETL processes, and data models to support our data analytics initiatives Preferred Technical And Professional Expertise Experience in automation and scripting, including programming languages such as Python, JavaScript, or PowerShell Strong knowledge and experience in cloud computing platforms Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform (GCP), or other cloud providers. Proficient in cloud infrastructurn, deployment, and management, as well as cloud security and compliance. About Business Unit IBM Consulting is IBM’s consulting and global professional services business, with market leading capabilities in business and technology transformation. With deep expertise in many industries, we offer strategy, experience, technology, and operations services to many of the most innovative and valuable companies in the world. Our people are focused on accelerating our clients’ businesses through the power of collaboration. We believe in the power of technology responsibly used to help people, partners and the planet. Your Life @ IBM In a world where technology never stands still, we understand that, dedication to our clients success, innovation that matters, and trust and personal responsibility in all our relationships, lives in what we do as IBMers as we strive to be the catalyst that makes the world work better. Being an IBMer means you’ll be able to learn and develop yourself and your career, you’ll be encouraged to be courageous and experiment everyday, all whilst having continuous trust and support in an environment where everyone can thrive whatever their personal or professional background. Our IBMers are growth minded, always staying curious, open to feedback and learning new information and skills to constantly transform themselves and our company. They are trusted to provide on-going feedback to help other IBMers grow, as well as collaborate with colleagues keeping in mind a team focused approach to include different perspectives to drive exceptional outcomes for our customers. The courage our IBMers have to make critical decisions everyday is essential to IBM becoming the catalyst for progress, always embracing challenges with resources they have to hand, a can-do attitude and always striving for an outcome focused approach within everything that they do. Are you ready to be an IBMer? About IBM IBM's greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world. Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business. At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world. Location Statement For additional information about location requirements, please discuss with the recruiter following submission of your application. Being You @ IBM IBM is committed to creating a diverse environment and is proud to be an equal-opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender, gender identity or expression, sexual orientation, national origin, caste, genetics, pregnancy, disability, neurodivergence, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",https://mx.linkedin.com/jobs/view/data-engineer-aws-at-ibm-4000282236,4000282236,"In this role, you will troubleshoot forecasting systems, working through data anomalies that cause inaccurate forecasts. You will collaborate with the data science team to enhance forecasting systems for trade floors, create dynamic object-oriented methods, develop Python classes to support data flow, and modify packages for CI/CD. As an AWS Cloud Data Engineer, you will design, implement, and manage data solutions on the AWS platform, focusing on building and optimizing data pipelines and ETL processes.","Python, JavaScript, PowerShell, AWS, AWS GLUE, ETL, Cloud Computing, CI/CD",,,True,,0,0,0,1,0,0,1,0,0,0,0,0,0,0,1,0,0
Data Engineer,Wizeline,Guadalajara,ON-SITE,Entry level,Full-time,IT Services and IT Consulting,2024-09-11 11:32:47.028901,25,Information Technology,,,"The Company Wizeline is a global digital services company helping mid-size to Fortune 500 companies build, scale, and deliver high-quality digital products and services. We thrive in solving our customer’s challenges through human-centered experiences, digital core modernization, and intelligence everywhere (AI/ML and data). We help them succeed in building digital capabilities that bring technology to the core of their business. Your Day-to-Day This job posting is for Data Engineer on our team. Here's what you'll be doing in your day-to-day work: Design and implement product features in collaboration with product owners, report developers, product analysts, architects, and business partners within an Agile / Scrum methodology. Design and implement data platforms for large-scale, high-performance, and scalable requirements, integrating data from several data sources, and managing structured and unstructured data while melding existing warehouse structures. Analyze, diagnose and identify bottlenecks in data workflows Participate in demos to clients and requirements elicitation and translation to systems requirements (functional and nonfunctional). Constantly monitor, refine and report on the performance of data management systems. Are You a Fit? To Be Successful In This Role, You Must Have Strong General Programming Skills Solid experience with Python. If not proficient in Python, we expect the candidate to be proficient in other languages and prove their ability to learn new ones very quickly. Experience with Spark. Solid engineering foundations (good coding practices, good architectural design skills) Experience working with SQL in advanced scenarios that require heavy optimization 5+ years of experience with large-scale data engineering with an emphasis on analytics and reporting 3+ years of experience developing on Hadoop-like Ecosystem Experience building cloud-scalable, real-time and high-performance Data Lake solutions. Proficiency in designing and implementing ETL (Extract, Transform, load) processes, dealing with big volumes of data (terabytes of data which required distributed processing) Experience developing solutions within Cloud Services (AWS, GCP, or Azure) Experience with NoSQL databases such as Apache HBase, MongoDB, or Cassandra. Experience in data streams processing technologies including Kafka, Spark Streaming, etc Advanced English level. About Us Wizeline prioritizes a culture of diversity and development for its nearly 2,000 person team spread across the globe. We believe great technology comes from a mix of talents and perspectives. Our core values of ownership, innovation, community, and inclusivity are central to our work. Wizeline is invested in its employees' growth, offering opportunities to create personalized career paths and develop in-demand skills. We even have a free education program, Wizeline Academy, to help both employees and the broader community upskill in tech. Please note that by submitting your application, you agree with the terms and conditions of our Privacy Policy. Apply now!",https://mx.linkedin.com/jobs/view/data-engineer-at-wizeline-4022155483,4022155483,"This job posting is for a Data Engineer role where you will design and implement product features in collaboration with product owners and business partners using Agile/Scrum methodology. You will be responsible for designing data platforms for large-scale and scalable requirements, integrating data from multiple sources, analyzing data workflows, and monitoring data management systems.","Python, Spark, SQL, Hadoop, AWS, GCP, Azure, Apache HBase, MongoDB, Cassandra, Kafka, Spark Streaming, ETL",5+ years,,True,5.0,0,0,1,1,0,0,1,0,0,1,0,0,0,0,1,0,0
Data Integration Engineer,EPAM Systems,Guadalajara,ON-SITE,Entry level,Full-time,Software Development and IT Services and IT Consulting,2024-09-13 11:32:47.028901,25,Information Technology,,,"Join EPAM as a Data Integration Engineer. In this role, you'll use your strong SQL knowledge to design and implement Data Integration solutions, model databases, and contribute to building enterprise data platforms. If you're an experienced and highly self-motivated professional with outstanding analytical and problem-solving skills, and have experience with Agile methodologies, we'd love to hear from you. Responsibilities Strong SQL knowledge is required Good knowledge of Databases (SQL optimization, Relations, Stored Procedures, Transactions, Isolation Levels, etc.) is a plus Expected experience working with at least one Relational Database (RDBMS: MS SQL Server, Oracle, MySQL, PostgreSQL) is a plus Designing and implementing Data Integration solutions, modeling databases, and contribute to building enterprise data platforms using classic Data technologies and tools (Databases, ETL/ELT technology & tools) - is a plus Experience in direct customer communications is a plus English proficiency Requirements Experienced and highly self-motivated professional with outstanding analytical and problem-solving skills Able to play a Developer role on a project and ensure that delivered solutions meet product requirements Working with modern Agile developing methodologies and tools We offer Career plan and real growth opportunities Unlimited access to LinkedIn learning solutions International Mobility Plan within 25 countries Constant training, mentoring, online corporate courses, eLearning and more English classes with a certified teacher Support for employee’s initiatives (Algorithms club, toastmasters, agile club and more) Enjoyable working environment (Gaming room, napping area, amenities, events, sport teams and more) Flexible work schedule and dress code Collaborate in a multicultural environment and share best practices from around the globe Hired directly by EPAM & 100% under payroll Law benefits (IMSS, INFONAVIT, 25% vacation bonus) Major medical expenses insurance: Life, Major medical expenses with dental & visual coverage (for the employee and direct family members) 13 % employee savings fund, capped to the law limit Grocery coupons 30 days December bonus Employee Stock Purchase Plan 12 vacations days plus 4 floating days Official Mexican holidays, plus 5 extra holidays (Maundry Thursday and Friday, November 2nd, December 24th & 31st) Relocation bonus: transportation, 2 weeks of accommodation for you and your family and more By applying to our role, you are agreeing that your personal data may be used as in set out in EPAM´s Privacy Notice and Policy. EPAM is a leading global provider of digital platform engineering and development services. We are committed to having a positive impact on our customers, our employees, and our communities. We embrace a dynamic and inclusive culture. Here you will collaborate with multi-national teams, contribute to a myriad of innovative projects that deliver the most creative and cutting-edge solutions, and have an opportunity to continuously learn and grow. No matter where you are located, you will join a dedicated, creative, and diverse community that will help you discover your fullest potential.",https://mx.linkedin.com/jobs/view/data-integration-engineer-at-epam-systems-4024921596,4024921596,"Join EPAM as a Data Integration Engineer, where you'll use your strong SQL knowledge to design and implement Data Integration solutions, model databases, and contribute to building enterprise data platforms. Responsibilities include strong SQL knowledge, good knowledge of databases such as SQL optimization and relations, and experience with at least one Relational Database. You will also design and implement Data Integration solutions and work with classic Data technologies and tools. Effective communication skills in English are required.","SQL, RDBMS: MS SQL Server, Oracle, MySQL, PostgreSQL, ETL/ELT technologies, Agile Methodologies",,,True,,1,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0
Snowflake Data Engineer,Cognizant,Guadalajara,ON-SITE,Entry level,Full-time,IT Services and IT Consulting,2024-08-16 11:32:47.028901,25,Information Technology,,,"Cognizant is always looking for top talent. We are searching for candidates to fill future needs within the business. This job posting represents potential future employment opportunities with Cognizant. Although the position is not currently available, we want to provide you with the opportunity to express your interest in future employment opportunities with Cognizant. If a job opportunity that you may be qualified for becomes available in the future, we will notify you. At that time you can determine whether you would like to apply for the specific open position. Thank you for your interest in Cognizant career opportunities. We’re hiring! At Cognizant we have an ideal opportunity for you to be part of one of the largest companies in the digital sector worldwide. A Great Place To Work where we look for people who contribute new ideas, experiencing a dynamic and growing environment. At Cognizant we promote an inclusive culture, where we value different perspectives providing career growth and development opportunities. #WelcomeToCognizant! We have an exciting opportunity for an exceptional individual to work supporting one of our clients as a Snowflake Data Engineer What you’ll do: Experience on building an ETL pipeline using python, pandas, AWS services. Good knowledge on Oracle database, SQLite. Well known of code deployment activities in QA, stage, and production server. Good knowledge of GITHUB tool for version control of the codes. Well versed of creating pull request, merge the pull request. Well known of release management activities. Experienced in python, multithreading and multiprocessing, socket server module and Bluetooth module since our scanning application’s hardware is implemented using these. Well versed in AWS, with hands on experience on services like EC2, S3, SQS, SNS, Cloud Watch, Lambda, ECS, Code Commit, Code Deploy, Code Pipeline, Code. Worked on Django for a POC project to make internal blog site for our company. Good Knowledge in Shell Scripting, Core Java, Java script and HTML, SQL. Worked on Snowflake and dbt for ETL pipeline. Preferred experience: Operating Systems: Linux/Windows Languages: Python, Shell scripting, JavaScript, HTML Databases: Oracle, DynamoDB, AWS RDS, SQLite Software Tools: Visual Studio Code, PyCharm, Jupyter Notebook, GIT bash and GUI, Putty, WinSCP SAAS Software’s and tools: Snowflake (data warehousing tool based on cloud), dbt(data build tool) Cloud Platforms: AWS Why Cognizant? Improve your career in one of the largest and fastest growing IT services providers worldwide Receive ongoing support and funding with training and development plans Have a highly competitive benefits and salary package Get the opportunity to work for leading global companies We are committed to respecting human rights and build a better future by helping your minds and the environment We invest in people and their wellbeing. We create conditions for everyone to thrive. We do not discriminate based on race, religion, color, sex, age, disability, nationality, sexual orientation, gender identity or expression, or for any other reason covered. At Cognizant we believe than our culture make us stronger! Join us now! #BeCognizant #IntuitionEngineered Employee Status : Full Time Employee Shift : Day Job Job Posting : Jan 03 2024 About Cognizant Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @Cognizant. 43486",https://mx.linkedin.com/jobs/view/snowflake-data-engineer-at-cognizant-4006643680,4006643680,"We have an exciting opportunity for an exceptional individual to work supporting one of our clients as a Snowflake Data Engineer. The role involves building an ETL pipeline using Python, Pandas, and AWS services. Knowledge of Oracle databases, SQLite, GITHUB for version control, and release management activities is required. Experience in Python, multithreading, multiprocessing, socket server module, and Bluetooth module is necessary. Skills in AWS services including EC2, S3, SQS, SNS, Cloud Watch, Lambda, ECS, and Code services are also part of the duties. Familiarity with Django, Shell Scripting, Core Java, JavaScript, HTML, SQL, Snowflake, and dbt for ETL pipelines is preferred.","Python, Pandas, AWS, EC2, S3, SQS, SNS, Cloud Watch, Lambda, ECS, Code Commit, Code Deploy, Code Pipeline, Django, Shell Scripting, Core Java, JavaScript, HTML, SQL, Oracle, DynamoDB, AWS RDS, SQLite, Snowflake, dbt, Visual Studio Code, PyCharm, Jupyter Notebook, GIT bash, Putty, WinSCP",,,True,,0,1,0,1,1,0,0,0,0,1,1,0,0,0,1,0,0
Azure Data Engineer,Infosys,Guadalajara,ON-SITE,Entry level,Full-time,IT Services and IT Consulting,2024-08-16 11:32:47.028901,25,Information Technology,,,"Job Description We are looking for an Azure Data Eng to work on hybrid model on any of Infosys Locations (Mexico City, Gdl and Mty) in a Production Support + Development project with one of the top companies in Silicon Valley . Expertise Required Very good communication skills + English Level. At least 3 years of experience in designing, implementing, and maintaining robust and scalable data pipelines on Azure using services such as Azure Data Factory, Azure SQL Data Warehouse, Azure Analysis Services or any of the Azure Databricks/Synapse/Fabric. At least 2 years of experience in data platforms – with multi layered approach, Design/Architecture setup is needed. At least 2 years of experience in troubleshooting performance issues, identifying root cause and applying fixes. At least 3 years of experience in SQL. Ability to implement and manage CI/CD pipelines for data engineering projects, leveraging tools like Azure DevOps. About Us Infosys is a global leader in next-generation digital services and consulting. We enable clients in more than 50 countries to navigate their digital transformation. With over four decades of experience in managing the systems and workings of global enterprises, we expertly steer our clients through their digital journey. We do it by enabling the enterprise with an AI-powered core that helps prioritize the execution of change. We also empower the business with agile digital at scale to deliver unprecedented levels of performance and customer delight. Our always-on learning agenda drives their continuous improvement through building and transferring digital skills, expertise, and ideas from our innovation ecosystem. Infosys provides equal employment opportunities to applicants and employees without regard to race; color; sex; gender identity; sexual orientation; religious practices and observances; national origin; pregnancy, childbirth, or related medical conditions; status as a protected veteran or spouse/family member of a protected veteran; or disability.",https://mx.linkedin.com/jobs/view/azure-data-engineer-at-infosys-3985874139,3985874139,"We are looking for an Azure Data Engineer to work on a hybrid model in various Infosys locations (Mexico City, Gdl, and Mty) on a Production Support and Development project. The position requires excellent communication skills and at least 3 years of experience in designing, implementing, and maintaining robust and scalable data pipelines on Azure using services such as Azure Data Factory, Azure SQL Data Warehouse, and Azure Analysis Services or Azure Databricks/Synapse/Fabric. Additionally, a minimum of 2 years of experience in multi-layered data platforms and troubleshooting performance issues is needed, along with at least 3 years of experience in SQL and the ability to manage CI/CD pipelines for data engineering projects using Azure DevOps.","Azure Data Factory, Azure SQL Data Warehouse, Azure Analysis Services, Azure Databricks, Azure Synapse, Azure DevOps, SQL",At least 3 years in data pipelines; 2 years in data platforms and performance troubleshooting; 3 years in SQL.,,True,2.0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,0,0,0
Data Integration SQL Engineer,EPAM Systems,Guadalajara,ON-SITE,Entry level,Full-time,Software Development and IT Services and IT Consulting,2024-09-13 11:32:47.028901,25,Engineering,Information Technology,,"Join EPAM as a Data Integration SQL Engineer. In this role, you'll use your SQL expertise to create value for our clients, transform the way they use data, and design robust and scalable scripts and workflows that automate data collection, enrichment, and delivery. If you have strong SQL knowledge, good understanding of databases, and experience in designing and implementing Data Integration solutions, we'd love to hear from you. Responsibilities Play a Developer role on a project and ensure that delivered solutions meet product requirements Work with modern Agile developing methodologies and tools Foster cross-functional collaboration to align database solutions with project goals Contribute to enterprise data platforms and data integration strategies Communicate effectively with stakeholders for requirements gathering and progress updates Design and engineer data solutions using SQL to build robust and scalable scripts and workflows that automate data collection, enrichment, and delivery Work independently to identify and solve problems, and collaborate effectively within a team to develop comprehensive solutions Requirements Strong SQL knowledge is required Good knowledge of Databases (SQL optimization, Relations, Stored Procedures, Transactions, Isolation Levels, etc.) is a plus Expected experience working with at least one Relational Database (RDBMS: MS SQL Server, Oracle, MySQL, PostgreSQL) is a plus Experience in designing and implementing Data Integration solutions, modeling databases, and contributing to building enterprise data platforms using classic Data technologies and tools (Databases, ETL/ELT technology & tools) - is a plus Experience in direct customer communications is a plus English proficiency We offer Career plan and real growth opportunities Unlimited access to LinkedIn learning solutions International Mobility Plan within 25 countries Constant training, mentoring, online corporate courses, eLearning and more English classes with a certified teacher Support for employee’s initiatives (Algorithms club, toastmasters, agile club and more) Enjoyable working environment (Gaming room, napping area, amenities, events, sport teams and more) Flexible work schedule and dress code Collaborate in a multicultural environment and share best practices from around the globe Hired directly by EPAM & 100% under payroll Law benefits (IMSS, INFONAVIT, 25% vacation bonus) Major medical expenses insurance: Life, Major medical expenses with dental & visual coverage (for the employee and direct family members) 13 % employee savings fund, capped to the law limit Grocery coupons 30 days December bonus Employee Stock Purchase Plan 12 vacations days plus 4 floating days Official Mexican holidays, plus 5 extra holidays (Maundry Thursday and Friday, November 2nd, December 24th & 31st) Relocation bonus: transportation, 2 weeks of accommodation for you and your family and more By applying to our role, you are agreeing that your personal data may be used as in set out in EPAM´s Privacy Notice and Policy. EPAM is a leading global provider of digital platform engineering and development services. We are committed to having a positive impact on our customers, our employees, and our communities. We embrace a dynamic and inclusive culture. Here you will collaborate with multi-national teams, contribute to a myriad of innovative projects that deliver the most creative and cutting-edge solutions, and have an opportunity to continuously learn and grow. No matter where you are located, you will join a dedicated, creative, and diverse community that will help you discover your fullest potential.",https://mx.linkedin.com/jobs/view/data-integration-sql-engineer-at-epam-systems-4024919702,4024919702,"Join EPAM as a Data Integration SQL Engineer. In this role, you'll use your SQL expertise to create value for clients, transform data usage, and design robust and scalable scripts and workflows that automate data collection, enrichment, and delivery. Responsibilities include ensuring solutions meet product requirements, working with Agile methodologies, designing data solutions using SQL, and contributing to enterprise data platforms. Strong SQL knowledge and understanding of databases are required.","SQL, Relational Databases (MS SQL Server, Oracle, MySQL, PostgreSQL), ETL/ELT tools, Agile Methodologies",,,True,,1,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0
"Senior Data Engineer, DataBricks Platform",CloudGeometry,Guadalajara,REMOTE,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-16 15:11:23.705162,25,Information Technology,,,"CloudGeometry is a Silicon Valley-based cloud-native system integrator with deep expertise in AWS and the CNCF technology stack. We partner with industry leaders like AWS, Google and Databricks to deliver solutions across all layers of the modern technology stack, from generative UI to Kubernetes-powered MLOps workloads. Our distributed team of top technology experts from the US, Europe, and LATAM collaborates on innovative commercial and open-source projects. Our commitment to innovation and excellence makes us a trusted partner for leading technology companies and VC-funded startups. We are looking for a Senior Data Engineer with extensive hands-on experience in the Databricks ecosystem and exceptional communication skills to join our flagship project: a cutting-edge Data Platform for the life sciences industry. This platform supports industry leaders such as Pfizer, Moderna, and Novartis in developing innovative RNA-based solutions, leveraging data-driven research, cloud computing, and advanced AI capabilities. This role offers a unique opportunity for an experienced data engineer to take the next step in their career, playing a key technical leadership role in the rapidly evolving world of AI-driven solutions Responsibility Design, develop, and optimize data pipelines and workflows within the Databricks platform. Take part in architecture discussion with engineering, product managers and data scientists to implement advanced analytics solutions that drive business insights. Build, optimize, and fine-tune Databricks workflows to improve performance and reliability. Work closely with data scientists and analysts to i Ensure the integrity, accuracy, and security of data across all processing stages. Implement data ingestion from various sources into Databricks, ensuring data quality and reliability. Participate in daily Scrum ceremonies and collaborate with team members in the US and Europe with required online presence from 9 AM to 5 PM EST Qualifications Bachelor’s degree in Computer Science, Engineering, or a related field; Master’s degree preferred. 8+ years of experience in the software development industry, preferably in data engineering, data warehousing or data analytics companies and teams. 1+ year of experience with the DataBricks ecosystem. Expert level of Python and Typescript. Expert level of understanding and hands-on experience with Lake House architecture. Expert level of experience with Spark/Glue and Delta tables/iseberg. Experienced in designing and implementing complex, scalable data pipelines/ETL processes using Databricks. Skilled in cloud-based data storage and processing technologies, particularly AWS services such as S3, Step Functions, Lambda, and Airflow. Familiar with CI/CD practices, version control (Git), automated testing, and Agile environments. Experience with the Agile development process in a distributed engineering team. Ability to articulate ideas clearly, present findings persuasively, and build rapport with clients and team members. Experience working in US-led high-tech companies and startups. Nice to Have DataBricks certifications AWS or Azure DevOps or SA certifications Knowledge of basic DevOps and MLOps principles Experience in working with Data Scientists and ML Developers Experience in management and lead developer roles from technology services companies What we commit to you Comprehensive compensation and benefits package. Opportunity to work with cutting-edge technologies; no legacy systems. Extensive training opportunities including certifications, hackathons, remote conference attendance, and free access to Udemy and other digital learning platforms. Collaborative and supportive environment with top global experts to help you reach new professional heights and advance in your career.",https://mx.linkedin.com/jobs/view/senior-data-engineer-databricks-platform-at-cloudgeometry-4025245553,4025245553,"We are looking for a Senior Data Engineer with extensive hands-on experience in the Databricks ecosystem to design, develop, and optimize data pipelines and workflows. The role includes participating in architecture discussions and building complex analytics solutions. Responsibilities involve ensuring data integrity and quality through ingestion and processing stages, and collaborating in Agile Scrum ceremonies.","Databricks, Python, TypeScript, Apache Spark, AWS, S3, Step Functions, Lambda, Airflow, Git",8+ years,Bachelor,True,8.0,0,0,1,1,0,0,0,0,0,0,0,1,0,0,1,0,0
Machine Learning Engineer,Nortal,Guadalajara,ON-SITE,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-16 15:11:37.092628,25,Engineering,Information Technology,,"Overview About Pwrteams Join our fast-growing and diverse team at Pwrteams, where we provide premium IT and engineering nearshore solutions to our global customers. Since 2007, we pursue to become the market leader in assembling cross-border IT and engineering teams for customers. Our operations are strategically positioned within Eastern Europe’s dynamic tech ecosystems, from where we cater the global business landscape. We’re at the forefront of travel, media and fintech innovation, healthcare efficiency enhancements, and others. Our goal? To connect interesting customer projects and skilled talent alike. Become a part of our team and take the next step on your personal career journey. About Our Client Our client is a global leader in manufacturing digital cutting machines that allow millions of people to get amazing experiences in creating craft artwork. To use the cutters, makers apply the company’s own powerful design software, available both for web and mobile devices. So that they can produce their own personalized masterpiece just with a few clicks. About The Project You'll get a chance to work on a graphical editor that allows millions of people to create custom and hand-made pieces of art. This project is not about plain code, it's about bringing change and making life more colourful, so don't stand by and apply!As a Machine Learning Engineer, you will play a pivotal role in developing and deploying state-of-the-art models and algorithms for tasks such as image generation, recommender engines, prediction models, and more. Your work will directly contribute to advancing our cutting-edge machine learning capabilities. Responsibilities Analyze and preprocess large-scale datasets for training and evaluation purposes Experiment with different architectures, loss functions, and data augmentation techniques to improve model performance Collaborate with cross-functional teams to define project requirements and deliver innovative solutions Stay up-to-date with the latest advancements in machine learning and computer vision, and apply them to solve complex problems Troubleshoot and debug issues related to model training, performance, and scalability. Integrate the training software into our continuous integration cluster to support metrics persistence across experiments, weekly/nightly neural network builds, and other unit / throughput tests Collaborate with software engineers to integrate machine learning models into production systems Document research findings, experiments, and algorithms in technical reports and presentations Qualifications Proven industry experience (2+ years) in developing and deploying deep learning machine learning models Solid understanding of deep learning concepts, convolutional neural networks (CNNs), recurrent neural networks (RNNs), and/or graph neural networks (GNNs) Strong programming skills in Python, including proficiency in one or more deep learning frameworks (TensorFlow, PyTorch, Keras). PyTorch preferred Experience with image processing techniques, computer vision libraries (OpenCV), and related tools Familiarity with AWS infrastructure and toolchain (SageMaker, CloudFormation, CloudWatch, etc.) Ability to preprocess and manipulate large datasets using tools such as NumPy, Pandas, and scikit-learn Knowledge of software engineering principles, including version control (Git) and agile development methodologies Excellent problem-solving skills, with the ability to work on complex machine learning challenges independently Strong written and verbal communication skills, with the ability to effectively collaborate with team members and present findings to stakeholders",https://mx.linkedin.com/jobs/view/machine-learning-engineer-at-nortal-4027616198,4027616198,"As a Machine Learning Engineer, you will develop and deploy state-of-the-art models for tasks such as image generation and prediction. You will analyze and preprocess large datasets, experiment with various architectures, and collaborate with teams to define project requirements. You will also troubleshoot issues related to model training and integrate models into production systems.","Python, TensorFlow, PyTorch, Keras, OpenCV, NumPy, Pandas, scikit-learn, AWS, Git",2+ years,,True,2.0,0,0,0,1,0,0,0,0,0,0,0,1,1,0,1,0,0
"Manager, Machine Learning",Pfizer,Guadalajara,ON-SITE,Mid-Senior level,Full-time,Pharmaceutical Manufacturing,2024-09-16 15:11:37.092628,25,Engineering,Information Technology,,"Role Summary Do you want to make an impact on patient health around the world? Do you thrive in a fast-paced environment that brings together scientific and clinical domains together through data and analytics? Then join Pfizer Digital’s AI & Data Analytics (AIDA) organization where you can leverage cutting-edge technology including AI and ML to inform critical business decisions and improve customer experiences for our patients and physicians. Our collection of global teams drives insights to action for some of the most critical business questions for the company. Our analytics professionals are based in over 30 countries around the world and come from diverse backgrounds including: software engineering, data science, digital analytics, finance, investment banking, corporate development, and consulting. Join one of our teams and be at the forefront of Pfizer’s digital transformation, driving innovation and bringing advance analytics to change patients’ lives. As an AI/ML Engineer, you will be part of a team to develop new capabilities that leverages AI to solve complex problems across the enterprise. In this role, you will be responsible for overseeing the design, implementation, and deployment of AI and machine learning models and algorithms, ensuring their accuracy, scalability, and effectiveness. The ideal candidate will have a strong technical background in machine learning and/or software engineering and a passion for innovation, bridging the gap between data, technology, and people, to deliver the promise of AI/ML to improve patients’ lives. Role Responsibilities Design, develop and deploy machine learning products & approaches to solve business problems across multiple domains, including commercial, medical affairs, and R&D. Engage with stakeholders across the enterprise to understand and solve complex problems through AI/ML (including generative AI methods where appropriate) to inform business strategy and decisions Design and execute advanced analytics and predictive modeling projects using rigorous statistical methods and machine learning techniques Design, develop, deploy and maintain reusable assets and custom pipelines to optimize operational efficiencies in analytics execution Research, identify, and apply new algorithms and technologies to solve complex problems and systematize solutions into reusable assets and capabilities Practice Agile-based project management standards (i.e. daily check-in procedures, workload status, and cost overruns/projections) Identify emerging technologies, evaluate their potential impact, and make informed decisions on adopting new tools, frameworks, and methodologies. Basic Qualifications Proven experience (5+ years) as a software engineer, ML engineer, or data scientist and project lead for a diverse range of projects, with a focus on developing and deploying production-grade solutions. Bachelor’s degree in STEM (Science, Technology, Engineering, Mathematics) majors with quantitative emphasis – Statistics, Computer Science, Economics, Engineering etc. Strong programming skills in languages such as Python, Java, or C++, and proficiency with AI and machine learning frameworks and libraries (e.g., TensorFlow, PyTorch, scikit-learn). Applied knowledge of statistical analysis, experience with R, Excel, etc. Strong background in computer science: algorithms, data structures, machine learning, and distributed systems. Superior analytical skills required; Strong verbal and written communication skills Demonstrated experience interfacing with other internal and external teams to incorporate their innovations and vice versa Preferred Qualifications Advanced understanding of machine learning algorithms, deep learning architectures, and statistical techniques. Experience with foundation models, LLMs, and generative AI. Proficiency in data preprocessing, feature engineering, and dimensionality reduction. Familiarity with software engineering principles (e.g. version control, testing, and deployment) Experience with cloud platforms (e.g., AWS, Azure, GCP) and distributed computing frameworks is a plus. A passion for staying up-to-date with the latest advancements in AI and machine learning technologies and a commitment to continuous learning. Experience working in Agile processes and practices. EEO (Equal Employment Opportunity) & Employment Eligibility Pfizer is committed to equal opportunity in the terms and conditions of employment for all employees and job applicants without regard to race, color, religion, sex, sexual orientation, age, gender identity or gender expression, national origin, or disability. Information & Business Tech",https://mx.linkedin.com/jobs/view/manager-machine-learning-at-pfizer-4027621104,4027621104,"As an AI/ML Engineer, you will design, develop, and deploy machine learning products to solve business problems across multiple domains, utilizing AI and machine learning technologies to inform critical business decisions and improve customer experiences. You will engage with stakeholders to address complex problems through AI/ML, execute advanced analytics and predictive modeling projects, and maintain reusable assets to optimize operational efficiencies.","Python, Java, C++, TensorFlow, PyTorch, scikit-learn, R, Excel, AWS, Azure, GCP",5+ years,Bachelor,True,5.0,0,0,0,1,0,0,0,0,1,0,0,0,1,0,1,0,0
"Machine Learning Engineer, IgniteTech (Remote) - $60,000/year USD",Crossover,Guadalajara,REMOTE,Associate,Full-time,"Software Development, IT Services and IT Consulting, and Technology, Information and Internet",2024-09-18 07:37:24.163709,25,Education,"Engineering,",Information Technology,"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, IgniteTech. Have you got what it takes? Are you a forward-thinking developer eager to harness the power of GenAI to redefine business standards and enhance productivity? Are you bored of solving the same customer support tickets or resolving the same bugs over and over again? The majority of companies struggle with integrating AI into existing workflows, often resulting in underutilization and disappointing outcomes. At IgniteTech, we set ourselves apart by focusing on the practical application advanced AI technologies to transform business operations. Our approach isn't just about making incremental improvements; it's about leveraging AI to develop, support, and optimize tools that enhance both the workflow processes and the quality of service provided to our clients. This role IgniteTech is far from a conventional customer support or software engineer job. It is designed for those who are passionate about deploying GenAI to create robust support solutions, significantly improving productivity and customer satisfaction. Ideal for innovators who thrive in a dynamic environment, this position will place you at the helm of integrating revolutionary AI technologies. In this role, you’ll lead the charge in experimenting with and integrating cutting-edge AI technologies. You will play a pivotal role in shaping the future of AI-driven tools, from their inception to their optimization. If you're ready to be at the forefront of the AI revolution and transform how businesses operate, we invite you to apply today. Join us at IgniteTech, where we're not just changing the game—we’re defining it. Let’s innovate together and make a lasting impact. What You Will Be Doing Create and improve autonomous support platforms using LLMs. This includes not only development but also troubleshooting, maintaining, and updating tools based on user feedback and support tickets. One example would be creating an assistant able to guide customers through an upgrade process. Test and integrate state-of-the-art AI technologies, like GPT-4 Vision and Amazon CodeWhisperer, while providing support and guidance for internal teams on how to best utilize these technologies within their workflows. Evaluate and enhance the performance and integration of AI solutions across different infrastructures, notably AWS, and ensures support is available for end-users experiencing issues, focusing on maintaining high service quality and satisfaction. Machine Learning Engineer Key Responsibilities Improve support for both internal and external clients, significantly boosting the company’s innovation capacity and service quality Basic Requirements Advanced generative AI proficiency (i.e., use of multiple AI tools, ability to automate workflows and custom GPTs); if you've only used LLMs for research, learning, brainstorming, or content generation, that will be deemed insufficient At least 2 years of experience in B2B software customer support Proficiency in Python The ability to use AI to code in additional languages you are not very familiar with About IgniteTech If you want to work hard at a company where you can grow and be a part of a dynamic team, join IgniteTech! Through our portfolio of leading enterprise software solutions, we ignite business performance for thousands of customers globally. We’re doing it in an entirely remote workplace that is focused on building teams of top talent and operating in a model that provides challenging opportunities and personal flexibility. A career with IgniteTech is challenging and fast-paced. We are always looking for energetic and enthusiastic employees to join our world-class team. We offer opportunities for personal contribution and promote career development. IgniteTech is an Affirmative Action, Equal Opportunity Employer that values the strength that diversity brings to the workplace. There is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you! Working with Crossover This is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $30 USD/hour, which equates to $60,000 USD/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com/help-and-faqs for more details on this topic. What to expect next: You will receive an email with a link to start your self-paced, online job application. Our hiring platform will guide you through a series of online “screening” assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments. Important! If you do not receive an email from us: First, emails may take up to 15 minutes to send, refresh and check again. Second, check your spam and junk folders for an email from Crossover.com, mark as “Not Spam” since you will receive other emails as well. Third, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked. If all else fails, just reset your password by visiting https://www.crossover.com/auth/password-recovery if you already applied using LinkedIn EasyApply. Crossover Job Code: LJ-5267-MX-Guadalaj-MachineLearnin.002",https://mx.linkedin.com/jobs/view/machine-learning-engineer-ignitetech-remote-%2460-000-year-usd-at-crossover-4028887843,4028887843,"The position involves creating and improving autonomous support platforms using large language models (LLMs) and integrating cutting-edge AI technologies to enhance productivity and customer satisfaction. Responsibilities include troubleshooting, maintaining, and updating tools based on user feedback, evaluating AI solutions' performance, and improving support for both internal and external clients. Advanced generative AI proficiency is required, along with at least 2 years of experience in software customer support and proficiency in Python.","Python, AI tools, LLMs, GPT-4 Vision, Amazon CodeWhisperer, AWS",2,,True,2.0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0
Data Engineer,Listopro,Guadalajara,HYBRID,Entry level,Full-time,Research Services,2024-09-18 07:37:40.772871,25,Engineering,Analyst,,"About The Position We are seeking a skilled Data Analyst with a strong background in Automation and Mechanical Engineering to join our team. The successful candidate will be responsible for analyzing machine data, developing data pipelines and models, and collaborating with cross-functional teams to ensure optimal machine performance and support. This role involves a hands-on approach to understanding machine operations and applying data-driven insights to improve efficiency and performance. Requirements Candidate Requirements: Data Analysis: Proficiency in analyzing data to extract actionable insights and make informed decisions. Reporting & Data Analytics: Capability to prepare detailed reports and apply data analytics, with machine learning experience being a plus, to solve complex issues. Automation & Mechanical Engineering: Familiarity with data analysis in automation. Ability to monitor and control machine data related to performance, energy usage, maintenance, and process quality across the Americas. Skilled in identifying deviations and understanding root causes. Collaboration: Strong ability to work with Central and Regional Product Support and Service teams to provide optimal support and maintain line conditions. Qualifications: Degree in Engineering, Data Science, or a related field. Familiarity with engineering management and mechanical or automation engineering principles. Proven experience in data analysis and reporting. Excellent problem-solving and communication skills Ability to work collaboratively in a team environment. Knowledge of Python and SQL database are a plus Good English written and spoken is mandatory Previous experience as production lines analyst is a plus. Benefits Vacaciones / Flexibilidad de Trabajo ½ Medio día libre para tu cumpleaños 12 días el primer año 9 días libres extraordinarios Salud / Seguros Seguro de Gastos Médicos Mayores Días pagados para maternidad y paternidad de acuerdo a lo establecido en la LFT Apoyo en defunción familiar En caso de contraer matrimonio se podrá gozar de 5 días con goce de sueldo. Seguro de vida Beneficios salariales Esquema 100% vía nómina Fondo de ahorro 25 días de aguinaldo Vales de despensa Beneficios Extras + Educación Se otorga un servicio de transportación colectiva con rutas y paradas definidas. Comedor Tendrás acceso a cursos virtuales y con valor curricular a través de LinkedIn Learning, Capacitaciones internas que impulsan tu desarrollo profesional y personal 7372-18092024",https://mx.linkedin.com/jobs/view/data-engineer-at-listopro-4027178839,4027178839,"We are seeking a skilled Data Analyst with a strong background in Automation and Mechanical Engineering to join our team. The successful candidate will be responsible for analyzing machine data, developing data pipelines and models, and collaborating with cross-functional teams to ensure optimal machine performance. This role involves applying data-driven insights to improve efficiency and performance.","Data Analysis, Machine Learning, Automation, Mechanical Engineering, Python, SQL",,,True,,0,0,0,0,0,1,0,0,0,1,0,1,1,0,1,0,0
Data Analyst (Marketing background),MezTal,Guadalajara,HYBRID,Mid-Senior level,Full-time,Data Infrastructure and Analytics,2024-09-18 07:37:40.772871,25,Marketing,Analyst,,"Responsibilities: Analyze complex data sets, including marketing data, to identify trends, patterns, and actionable insights. Generate data-driven insights to support marketing strategies and decision-making processes. Develop and maintain dashboards and reports using data visualization tools to track and optimize marketing performance. Collaborate with cross-functional teams, including marketing, sales, and product teams, to understand data requirements and deliver analytical solutions tailored to marketing needs. Conduct statistical analyses to interpret marketing data and inform business strategies. Ensure data accuracy and integrity in all marketing analyses and reports. Communicate findings and recommendations to marketing stakeholders in a clear and concise manner. Continuously improve processes and methodologies for data analysis and reporting, with a focus on marketing data. Requirements Bachelor's degree in Data Science, Statistics, Computer Science, Marketing, or a related field. 5+ years of experience in a data analysis role, with a focus on marketing analytics. Proficiency in SQL for querying and managing data. Strong skills in Python for data analysis and statistical modeling. Experience with data visualization tools such as Tableau or Power BI, particularly in creating marketing dashboards. Excellent analytical and problem-solving skills, with a deep understanding of marketing metrics. Strong attention to detail and accuracy in handling marketing data. Ability to work independently and as part of a team. Effective communication skills, both written and verbal, with an ability to translate complex data insights into marketing strategies. Familiarity with data warehousing concepts and ETL processes is a plus. Knowledge of machine learning techniques and tools is an advantage. Background in digital marketing, SEO/SEM, or marketing automation tools. Preferred Skills: Experience with advanced statistical analysis and predictive modeling in the context of marketing. Familiarity with big data technologies and tools (e.g., Hadoop, Spark), especially as they relate to marketing data. Understanding of business intelligence, data warehousing concepts, and their application in marketing. Knowledge of other programming languages such as R or JavaScript, with experience in marketing analytics. Experience with cloud platforms (e.g., AWS, Azure, Google Cloud) for data analysis and storage, particularly in marketing contexts. Benefits Awesome Benefits for Our Team! Christmas Bonus: 30 days, to be paid in December. Major Medical Expense Insurance: Coverage up to $20,000,000.00 MXN. Minor Medical Insurance: VRIM membership with special discounts on doctor’s appointments and accident reimbursements. Dental Insurance: Always smile with confidence! Life Insurance: (Death and MXN Disability) Vacation Days: 12 vacation days in accordance with Federal Labor Law, with prior approval from your manager. + Floating Holidays: 3 floating holidays in addition to the 7 official holidays in Mexico. Cell Phone Reimbursement & Transportation Subsidy. Hybrid Scheme: Enjoy the best of both worlds, remote and in-office work. Multicultural Exposure: Work with operations within Mexico and United Satates. MezTal Internal Events: Strike a healthy balance between your professional and personal goals. Exclusive Discounts: Benefits with different companies for being part of MezTal. Academic Agreements: Access to national universities and language schools.",https://mx.linkedin.com/jobs/view/data-analyst-marketing-background-at-meztal-4028849871,4028849871,"Responsibilities include analyzing complex marketing data sets to identify trends and actionable insights, generating data-driven insights for marketing strategies, developing dashboards and reports, collaborating with cross-functional teams to meet data requirements, conducting statistical analyses, ensuring data accuracy, and communicating findings to stakeholders. The role requires continuous improvement of data analysis processes focused on marketing data.","SQL, Python, Tableau, Power BI, Hadoop, Spark, R, JavaScript, AWS, Azure, Google Cloud",5+ years,Bachelor,True,5.0,0,0,1,1,0,0,0,0,1,1,0,0,0,0,1,0,0
GCP Data Engineer - R01541146,Brillio,Guadalajara,HYBRID,Entry level,Temporary,Information Technology & Services,2024-09-18 07:37:40.772871,25,Information Technology,,,"About Brillio: Brillio is one of the fastest growing digital technology service providers and a partner of choice for many Fortune 1000 companies seeking to turn disruption into a competitive advantage through innovative digital adoption. Brillio, renowned for its world-class professionals, referred to as ""Brillians"", distinguishes itself through their capacity to seamlessly integrate cutting-edge digital and design thinking skills with an unwavering dedication to client satisfaction. Brillio takes pride in its status as an employer of choice, consistently attracting the most exceptional and talented individuals due to its unwavering emphasis on contemporary, groundbreaking technologies, and exclusive digital projects. Brillio's relentless commitment to providing an exceptional experience to its Brillians and nurturing their full potential consistently garners them the Great Place to Work® certification year after year. Role: GCP Data Engineer - R01541146 Functional Area: Data And AI Employment Type: Full Time / Permanent Location: México Job Summary: With 6 years of experience in software design and development, this role focuses on creating and maintaining large-scale data architectures and analytics platforms. The ideal candidate will have extensive experience in data engineering, particularly within the Google Cloud Platform (GCP) ecosystem and be capable of leading projects from conceptualization to operationalization. Key Responsibilities: Design & Development: Lead the design and development of scalable software solutions, with a strong focus on data engineering and cloud-based technologies. Data Architecture: Architect and implement data warehouses, data lakes, and analytics platforms that can handle very large datasets efficiently. GCP Cloud Implementation: Apply hands-on expertise with GCP’s data tools including BigQuery, Pub/Sub, DataFlow/Apache Beam, Airflow/Composer, and Cloud Storage. Technology Proficiency: Utilize advanced skills in GBQ Query, Python, Apache Airflow, and SQL (with a preference for BigQuery). Agile Methodologies: Contribute to projects in an agile development environment, ensuring timely delivery and high-quality output. Cross-Cloud Expertise: Leverage knowledge of cloud functions and comparable skills in AWS and other cloud-based Big Data Engineering environments. Communication: Clearly present ideas, concepts, and technical solutions to both technical and non-technical stakeholders. Required Qualifications Experience: 6 years in software design and development, with 5 years preferred in data engineering, and 3 years in GCP cloud data implementation. Technical Skills: Strong experience with SQL and Python, particularly in the context of data engineering and cloud platforms. Additional experience with Apache Airflow and GCP tools is essential. Educational Background: Bachelor's Degree in Computer Science, Information Technology, or a closely related discipline. Communication Skills: Excellent verbal and written communication abilities, capable of conveying complex ideas clearly and effectively. Agile Development: Familiarity with agile development methodologies is highly desirable. Know what it’s like to work and grow at Brillio: Click here",https://mx.linkedin.com/jobs/view/gcp-data-engineer-r01541146-at-brillio-4008718799,4008718799,"This role focuses on creating and maintaining large-scale data architectures and analytics platforms. The ideal candidate will have extensive experience in data engineering, particularly within the Google Cloud Platform (GCP) ecosystem and be capable of leading projects from conceptualization to operationalization. Responsibilities include designing scalable software solutions, architecting data warehouses and lakes, applying hands-on GCP’s data tools like BigQuery, Pub/Sub, and DataFlow, and contributing to projects in an agile environment.","GCP, BigQuery, Pub/Sub, DataFlow, Apache Beam, Airflow, Cloud Storage, Python, SQL, Apache Airflow",6,Bachelor,True,6.0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0
"Data Support Analyst, Partner Managed Print Services",HP,Guadalajara,HYBRID,,Full-time,"Computer Hardware Manufacturing, Software Development, and IT Services and IT Consulting",2024-09-18 07:37:40.772871,25,Information Technology,,,"HP’s Partner Managed Print Services sales support team headquartered in Boise, Idaho is searching for a Partner Managed Print Services Datal Analyst. Primarily this role will support our US based Partner Managed Print Services team. No experience is required. Potential candidates must have strong communication skills and advanced Microsoft Excel skills. Applies Specialist level of subject matter knowledge to solve a variety of common business issues. Works on problems of moderately complex scope. Acts as an informed team member providing analysis of information and limited project direction input. Exercises independent judgment within defined practices and procedures to determine appropriate action. Follows established guidelines and interprets policies. Evaluates unique circumstances and makes recommendations. Qualifications Are As Follows Excellent organizational skills Excellent communication skills Attention-to-detail approach Great understanding of Microsoft Office products with a focus on Excel Uncompromising ability to meet deadlines Friendly and professional interpersonal skills In-depth research ability Ability to learn quickly and work hard in a fast-paced environment Willingness to be flexible with the work schedule Ability to focus on and work towards goal Demonstrates good questioning techniques and related communication skills. Developing and updating SharePoint sites will be required Developing and updating Power Automate flows Job Duties Will Include Pricing file maintenance Excel tools support Archiving contracts and amendments in DealSource Creating the financials for renewals Reporting for the business Partner reporting for business insights Partner validation on renewals Business planning preparation for major Partners Roster maintenance Contract reconciliation CBA Change Orders -utilizing MPC & DART to accomplish the CO same day or within 24 hours CBA Renewals - utilizing MPC & DART to accomplish the CO same day or within 24 hours Additional duties as determined Impact & Scope Impacts immediate team and acts as an informed team member providing analysis of information and limited project direction input. Complexity Responds to routine issues within established guidelines. Disclaimer This job description describes the general nature and level of work performed in this role. It is not intended to be an exhaustive list of all duties, skills, responsibilities, knowledge, etc. These may be subject to change and additional functions may be assigned as needed by management.",https://mx.linkedin.com/jobs/view/data-support-analyst-partner-managed-print-services-at-hp-4023788556,4023788556,"HP’s Partner Managed Print Services sales support team is searching for a Partner Managed Print Services Data Analyst. This role will support the US-based Partner Managed Print Services team. No experience is required, but candidates must have strong communication skills and advanced Microsoft Excel skills. The position involves providing analysis of information and limited project direction input, exercising independent judgment to determine appropriate actions, and following established guidelines. Responsibilities include maintaining pricing files, supporting Excel tools, archiving contracts, creating financials for renewals, and assisting with partner reporting and contract reconciliation.","Microsoft Excel, Microsoft Office, SharePoint, Power Automate",,,True,,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
Senior Data Scientist,AdventInfotech,Guadalajara,ON-SITE,Mid-Senior level,Full-time,"IT Services and IT Consulting, IT System Data Services, and Software Development",2024-09-18 07:37:58.348713,25,Consulting,"Analyst,",Engineering,"Data Scientist: We are seeking a highly motivated and skilled Data Scientist to join our dynamic team. The Data Scientist will play a crucial role in turning complex data into actionable insights that drive business decisions and innovation. This position involves analyzing large datasets, developing models, and delivering strategic recommendations to enhance our products and services. Skills Requirements: Bachelor's or Master's degree in Data Science, Statistics, Computer Science, Mathematics, or a related field. 6plus years experience in data analysis, machine learning, and predictive modeling. Proficiency in programming languages such as Python or R. Strong knowledge of machine learning frameworks and libraries (e.g., TensorFlow, scikit-learn, PyTorch). Experience with data visualization tools (e.g., Tableau, Power BI, Matplotlib, Seaborn). Excellent problem-solving skills and attention to detail. Effective communication and presentation skills. Ability to work in a collaborative team environment and independently. Experience with big data technologies and platforms (e.g., Hadoop, Spark, SQL, NoSQL). Knowledge of natural language processing (NLP) and deep learning. Familiarity with cloud computing platforms (e.g., AWS, Azure, Google Cloud). Previous industry experience in a data scientist or analytics role. What do we expect from you? Masters or Bachelor in CIS/ Engineering / Science / Mathematics / Statistics/ Design …etc Should have Cedula /Titulo Should have hands-on years of experience in any one of the above technology Advance English Speaking Ability to work independently Competitive Salary NOTE: We sponsor TN visas for qualified Mexican citizens. If you are interested in pursuing this opportunity then forward an updated Word copy of your resume in English. Our company runs on referrals and your referrals are always appreciated. If you can forward these emails to any of your friends that would be great. About Advent Infotech: Advent Infotech is a multinational IT services company with offices in 7 countries, including Mexico. Our clients mainly come from the United States. Our head office is located in New Jersey, USA Our delivery centers are located in six countries: India, Indonesia, Australia, Poland, Canada, and Mexico. Advent is led by great leadership with more than twenty years in the business. Our directors are highly ethical and come with a Harvard Business School education, serial entrepreneurs, and angel investors with long-standing business ethics. Advent's motto has always been to provide profitable technology solutions for our clients while creating value for our clients.",https://mx.linkedin.com/jobs/view/senior-data-scientist-at-adventinfotech-4028753234,4028753234,"We are seeking a highly motivated and skilled Data Scientist to analyze large datasets, develop models, and deliver strategic recommendations to enhance products and services, turning complex data into actionable insights that drive business decisions and innovation.","Python, R, TensorFlow, scikit-learn, PyTorch, Tableau, Power BI, Matplotlib, Seaborn, Hadoop, Spark, SQL, NoSQL, AWS, Azure, Google Cloud",6+ years,Bachelor,True,6.0,0,0,1,1,0,0,0,0,1,1,0,0,1,0,1,0,0
Principal Cloud Engineer- Oracle Analytics,Oracle,Guadalajara,ON-SITE,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-18 07:37:58.348713,25,Engineering,Information Technology,,"Job Description Applicants are required to read, write, and speak the following languages: English Role : Site Reliability Engineer Location : Guadalajara preferred Who are we looking for? The candidate will work with the skilled, highly motivated Oracle Analytics Service Excellence (OASE) team who embrace an agile work style. You will work alongside a software development team within the greater OAC organization where you will support existing features in the cloud as well as new operational processes, automation and content. You will play a key role in improving the processes supporting the OAC services, so the service functions more and more autonomously over time. Roles And Responsibilities Perform DevOps activities to support customers, engineers, and processes through our release cycles as well as production Participate in a follow-the-sun model for 24x7 support of Oracle Analytics services Respond to incidents, troubleshoot issues and drive to completion, driving and participate in root cause analysis Become expert in Analytic services, to prevent, resolve customer issues effectively and prevent regressions and repeats Document various processes & runbooks; update existing processes Execute, with excellence, delivery of interim patches and hotfixes as required Work with various teams to take ownership of and resolve service failure/outages. Monitor metrics and develop ways to improve the CI and CD tools utilized by the team Follow all best practices and procedures as established by the company Mentor and train other engineers and seek to continually improve processes Other duties as assigned The candidate must have knowledge and experience with: A BS or MS in Computer Science, or equivalent Knowledge of Oracle Analytics server, BI publisher, Oracle Analytics Cloud experience required. Providing cloud networking, infrastructure, and service support, configuration, operations, tools, and processes Understand networking, and TCP/IP fundamentals and services such as DNS, HTTP, etc. Linux/Unix system administration including system level knowledge of Linux on OCI Gen 2, creating and executing scripts Experience developing & operating cloud services or large distributed applications in production. Python, Ansible and other cloud Development skills are a plus Methodical approaches to troubleshooting and solving complex technical problems, reverse engineering existing applications. Producing documentation in support of developed work (KBs, run books, help guides) Utilizing agile methodologies Communicating effectively in a team environment Working with remote, global teams as well as individuals Working independently and in a self-directed manner Able to work extended week day and week-end shifts as required for on-call, after hours upgrades, and other duties as assigned. Responsibilities An ideal candidate will have the follow skillsets: 5+ years of experience of running large scale customer facing W eb Applications . Oracle Cloud Infrastructure (OCI) or AWS, Azure, GCP compute, storage, and network operational experience. Programming and scripting languages (Python, bash, Java Script - additional experience with PHP, Groovy, Java, and/or Go is a plus) Using CI/CD scripting tools such as Ansible, Puppet, or Chef Experience in Cloud Native application development using Containers and orchestration ( Kubernetes) independently scalable microservices Oracle database, Oracle Autonomous DB, MySQL (experience with MS SQL and/or NoSQL is a plus). Experience in REST API design and development using java technologies. Issue tracking and collaboration (Jira and Confluence). About Us As a world leader in cloud solutions, Oracle uses tomorrow’s technology to tackle today’s problems. True innovation starts with diverse perspectives and various abilities and backgrounds. When everyone’s voice is heard, we’re inspired to go beyond what’s been done before. It’s why we’re committed to expanding our inclusive workforce that promotes diverse insights and perspectives. We’ve partnered with industry-leaders in almost every sector—and continue to thrive after 40+ years of change by operating with integrity. Oracle careers open the door to global opportunities where work-life balance flourishes. We offer a highly competitive suite of employee benefits designed on the principles of parity and consistency. We put our people first with flexible medical, life insurance and retirement options. We also encourage employees to give back to their communities through our volunteer programs. We’re committed to including people with disabilities at all stages of the employment process. If you require accessibility assistance or accommodation for a disability at any point, let us know by calling +1 888 404 2494, option one. Disclaimer: Oracle is an Equal Employment Opportunity Employer*. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability and protected veterans’ status, or any other characteristic protected by law. Oracle will consider for employment qualified applicants with arrest and conviction records pursuant to applicable law. Which includes being a United States Affirmative Action Employer",https://mx.linkedin.com/jobs/view/principal-cloud-engineer-oracle-analytics-at-oracle-4027113204,4027113204,"The candidate will work with the Oracle Analytics Service Excellence (OASE) team, supporting existing features in the cloud, as well as new operational processes, automation, and content. Responsibilities include performing DevOps activities, participating in 24x7 support, troubleshooting incidents, documenting processes, monitoring metrics, and mentoring other engineers. A successful candidate will have knowledge of Oracle Analytics server, BI publisher, Oracle Cloud Infrastructure (OCI), programming languages such as Python and Bash, and experience in cloud native application development using containers and orchestration.","Python, Bash, JavaScript, Ansible, Oracle Analytics Server, Oracle Cloud Infrastructure, AWS, Azure, GCP, Kubernetes, Oracle Database, MySQL, REST API",5+ years,Bachelor,True,5.0,0,0,0,1,1,0,0,0,0,1,0,1,0,0,1,0,0
Principal Java Developer (Oracle Analytics),Oracle,Guadalajara,ON-SITE,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-18 07:37:58.348713,25,Engineering,Information Technology,,"Job Description Oracle Analytics is an industry-leading product that empowers entire organizations with a full range of business analytics tools, enterprise ready reporting and engaging, and easy-to-use self-service data visualizations. Our customers are business users that demand a software product that allows easy, fast navigation through the full spectrum of data scale from simple spreadsheets to analyzing enormous volumes of information in enterprise class data warehouses. Oracle Analytics is a comprehensive solution to meet the breadth of all analytics needs. Get the right data, to the right people, at the right time with analytics for everyone in your organization. With built-in security and governance, you can easily share insights and collaborate with your colleagues. By leveraging the cloud, you can scale up or down to suit your needs. The Oracle Analytics Cloud offering is a leading cloud service at Oracle built on Oracle Cloud Infrastructure. It runs with a Generation 2 offering and provides consistent high performance and unmatched governance and security controls. Self-service analytics drive business agility with faster time to insights. You no longer need help from IT to access, prepare, analyze, and collaborate on all your data. Easily create data visualizations with automated chart recommendations and optimize insights by collaborating with colleagues on analyses. Augmented analytics with embedded machine learning throughout the platform drive smarter and better insights. Always on—and always working in the background, machine learning is continuously learning from the data it takes in, making it smarter and more accurate as time goes by. Uncover deeper patterns and predict trends for impactful, unbiased recommendations. On the team we develop, deploy, and support the Oracle Analytics platform helping our customers succeed in their journey to drive business value. You will be working with experts in their field, exploring the latest technologies, you will be challenged while creating features that will be delivered to our customers, asked to be creative, and hopefully have some fun along the way. Members of our team are tasked to take on challenges along all aspect of our product. Key Qualifications : BS/MS in Computer Science or related major Exceptional analytic and problem-solving skills Solid understanding of object-oriented programming and MVVM principles Solid skills in Java and SQL programming. Good knowledge of data structures and operating systems. Prior experience with LLMs and generative AI technologies a plus. Experienced in distributed and scalable server-side software development. Knowledge in developing, implementing, and optimizing software algorithms. Prior experience utilizing JavaScript, HTML, CSS a plus. Basic understanding of Agile/Scrum development methodologies Hands-on experience using source control tools such as GIT Good written and verbal English communication skills. Self-motivated and passionate in developing high quality software. Strong Team Player. Other Qualifications : Knowledge of Business Intelligence or Analytics Experience using Python Familiarity with Cloud services such as OCI, AWS or Azure Career Level - IC4 Responsibilities Specific Responsibilities and Desired Qualifications As a member of the development team, you will design, code, debug, and deliver innovative analytic features that involve backend technologies such as Java/Python/C++ and frontend layers in JavaScript/HTML/CSS/SCSS. You will work closely with your peer developers located across the world, including Mexico, Europe, and the USA. Key responsibilities include: Design, develop, test and deliver new features on a world-class analytics platform suitable for deployment to both the Oracle Cloud and on-premise environments Lead the creation of formal design specifications and coding of complex systems Work closely with the Product Management on product requirements and functionality Build software applications following established coding standards Communicate continually with the project teams, explain progress on the development effort Contribute to continuous improvement by suggesting improvements to user interface, software architecture or recommending new technologies Ensure quality of work through development standards and QA procedures Perform maintenance and enhancements on existing software About Us As a world leader in cloud solutions, Oracle uses tomorrow’s technology to tackle today’s problems. True innovation starts with diverse perspectives and various abilities and backgrounds. When everyone’s voice is heard, we’re inspired to go beyond what’s been done before. It’s why we’re committed to expanding our inclusive workforce that promotes diverse insights and perspectives. We’ve partnered with industry-leaders in almost every sector—and continue to thrive after 40+ years of change by operating with integrity. Oracle careers open the door to global opportunities where work-life balance flourishes. We offer a highly competitive suite of employee benefits designed on the principles of parity and consistency. We put our people first with flexible medical, life insurance and retirement options. We also encourage employees to give back to their communities through our volunteer programs. We’re committed to including people with disabilities at all stages of the employment process. If you require accessibility assistance or accommodation for a disability at any point, let us know by calling +1 888 404 2494, option one. Disclaimer: Oracle is an Equal Employment Opportunity Employer*. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability and protected veterans’ status, or any other characteristic protected by law. Oracle will consider for employment qualified applicants with arrest and conviction records pursuant to applicable law. Which includes being a United States Affirmative Action Employer",https://mx.linkedin.com/jobs/view/principal-java-developer-oracle-analytics-at-oracle-4026506307,4026506307,"As a member of the development team, you will design, code, debug, and deliver innovative analytic features that involve backend technologies such as Java, Python, and C++, and frontend layers in JavaScript, HTML, CSS, and SCSS. Key responsibilities include designing, developing, testing, and delivering new features suitable for deployment to both the Oracle Cloud and on-premise environments. The role requires collaboration with peer developers globally and active engagement with product management on requirements and functionality.","Java, Python, C++, JavaScript, HTML, CSS, SCSS, SQL, GIT, Agile/Scrum, Machine Learning, Cloud services (OCI, AWS, Azure)",,Bachelor,True,,1,0,0,1,0,0,0,0,0,1,1,0,1,0,1,0,0
AI Solutions Developer (Python),Oowlish,Guadalajara,REMOTE,Entry level,Full-time,IT Services and IT Consulting,2024-09-19 02:10:45.124906,25,Engineering,Information Technology,N/A,"Join Our Team Oowlish, one of Latin America's rapidly expanding software development companies, is seeking experienced technology professionals to enhance our diverse and vibrant team. As a valued member of Oowlish, you will collaborate with premier clients from the United States and Europe, contributing to pioneering digital solutions. Our commitment to creating a nurturing work environment is recognized by our certification as a Great Place to Work, where you will have opportunities for professional development, growth, and a chance to make a significant international impact. We offer the convenience of remote work, allowing you to craft a work-life balance that suits your personal and professional needs. We're looking for candidates who are passionate about technology, proficient in English, and excited to engage in remote collaboration for a worldwide presence. We are seeking a highly skilled Senior Python Developer with experience in Machine Learning and Artificial Intelligence. The ideal candidate will have recent hands-on experience in these areas and a proven track record of delivering high-quality technical projects. Must Have Advanced English skills, both written and verbal. Over 5 years of experience in Python development. Hands-on experience with Generative AI technologies (Langchain, Bedrock, prompt engineering, RAG, etc.). Proven experience in designing and implementing AI-driven solutions. Strong problem-solving skills and attention to detail. Excellent communication and collaboration skills. Ability to work independently and as part of a team. Benefits & Perks Home office; Flexible Hours Competitive compensation based on experience; Career plans to allow for extensive growth in the company; International Projects; Oowlish English Program (Technical and Conversational); Oowlish Fitness with Total Pass; Connecting You (Internet allowance); Anniversary bonus; Wedding gift; Pet adoption incentive; New baby Oowl bonus; Back to School bonus; Streaming Subscription; PTO Bonus; Games and Competitions; Enjoy your national Holidays. You Can Also Apply Here Website: https://www.oowlish.com/work-with-us/ LinkedIn: https://www.linkedin.com/company/oowlish/jobs/ Instagram: https://www.instagram.com/oowlishtechnology/",https://mx.linkedin.com/jobs/view/ai-solutions-developer-python-at-oowlish-4029401058,4029401058,"Join Oowlish as a Senior Python Developer with expertise in Machine Learning and Artificial Intelligence. You will collaborate with clients from the United States and Europe to deliver high-quality digital solutions. The ideal candidate should possess over 5 years of experience in Python, hands-on experience with Generative AI technologies, and proven skills in designing and implementing AI-driven solutions. Strong problem-solving skills and excellent communication abilities are essential.","Python, Machine Learning, Artificial Intelligence, Generative AI, Langchain, Bedrock, Prompt Engineering, RAG",5+ years,N/A,True,5,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0
QA Engineer - Data,InfoVision Inc.,Guadalajara,HYBRID,Mid-Senior level,Full-time,"IT Services and IT Consulting, Information Services, and Technology, Information and Media",2024-09-19 02:11:01.738886,25,Information Technology,N/A,N/A,"We’re looking for detail-oriented testers to use our QA team that validates the Inscape data and alert us of critical bugs and errors before actual users are affected. Required skills: 5+ years of proven experience in software engineering. Bachelor’s degree in computer science, Engineering, or equivalent experience. Proven experience as a QA Engineer with focus data/ETL pipeline testing, regression data testing. Experience in designing, developing, and automating tools for testing ETL pipelines Demonstrated experience in validating data and ETL pipelines to integrate new data into a data warehouse. Proven experience with one of BigData technologies such Pyspark, Pandas, Spark, Hadoop, Hive. Experience in writing Python scripts using PySpark for data processing and manipulation. Experience with creation/maintenance of data validation tools and frameworks Proficient in Python as well as AWS tools. Knowledge of data modeling concepts and ETL processes. Familiarity with data integration and data warehousing technologies such as Databricks/Snowflake. Experience with system integration testing, end-to-end testing, databases, CI/CD pipelines Ability to document and troubleshoot errors. Strong attention to detail and patience to track down difficult issues. Possessing an analytical mind, critical-thinking skills, and problem solving aptitude. Strong organizational skills and ability to meticulously follow detailed steps. Experience in creating robust test plans/strategies and test status for Big Data product deliverables. Excellent verbal and written communication skills. Willing and able to go above and beyond. Ability to work collaboratively across different divisions.",https://mx.linkedin.com/jobs/view/qa-engineer-data-at-infovision-inc-4027395038,4027395038,"We’re looking for detail-oriented testers to validate Inscape data, alerting us of critical bugs and errors before actual users are affected. Required skills include 5+ years of experience in software engineering, and a Bachelor’s degree in computer science, Engineering, or equivalent experience. Proven experience as a QA Engineer with a focus on data/ETL pipeline testing and regression data testing. Candidates should have experience designing, developing, and automating tools for testing ETL pipelines, validating data and ETL pipelines for data warehouse integration, and writing Python scripts using PySpark for data processing. Familiarity with Big Data technologies such as Pyspark, Pandas, Spark, Hadoop, Hive, as well as AWS tools and data modeling concepts is necessary. Knowledge of data integration and data warehousing technologies like Databricks/Snowflake is also required. Experience in system integration testing, end-to-end testing, databases, and CI/CD pipelines is a plus. Excellent communication skills and the ability to work collaboratively are essential.","Python, PySpark, Pandas, Spark, Hadoop, Hive, AWS, Databricks, Snowflake, ETL, CI/CD",5+ years,Bachelor,True,5,0,0,1,1,0,0,1,0,0,0,0,0,0,0,1,0,0
Analyst Equipment Master Data,The Hershey Company,Guadalajara,ON-SITE,Entry level,Full-time,Manufacturing,2024-09-19 02:11:27.678646,25,Information Technology,N/A,N/A,"Job Title Equipment Master Data Analyst Reports to Master Data Owner, Transformation (HBP) Department TMO, Master Data Specialist Job Location Guadalajara Summary The Enterprise Master Data Management (EMDM) Equipment Master Data Specialist is accountable for two primary work streams in relation to new equipment / production line installation and existing equipment asset care strategy. The Equipment Master Data Specialist position is responsible for ensuring plants are equipped to minimize equipment downtime and increase asset life cycle by leading the development of equipment maintenance strategy, development of equipment bill of materials (BOM) and stocking strategy, as well as gathering and archieving equipment manuals and associated documentation. This role coordinates with the Plant Maintenance (Maintenance Planners, Reliability Leads, and Maintenance Managers) and Engineering PMO teams while being a steward of company policies, procedures, timelines and master data governance. For existing equipment, this role assists with the management of equipment data in order to improve and maintain timeliness and quality of the data. The role provides the specialist viewpoint when representing enterprise data and equipment strategy initiatives. This role specifically assists with the management SAP PM master data, technical objects, and equipment related documentation / attachments. The role will guide local and global resources to ensure the continuous improvement of business results through the implementation and management of standard processes, tools, and accountabilities. Responsibilities: Equipment Master Data Standards Governance Ensure adherence to the data governance policy for all equipment master data domains. Leverage existing and propose new technology solutions to improve workflow and master data creation, maintenance and archival. Oversight of maintaining equipment database in SAP to ensure equipment information, documentation, BOMs and PM Plans are standardized, accurate, and updated Supports by acting as “first line of defense” in fielding opportunities to improve data quality as well as resolving data issues. Targets opportunities to improve data quality, policy, and processes, and ownership. Identifies root causes of data quality problems within their assigned area of stewardship and identifies sustainable solutions. Ensures team members are kept informed of changes in data standards and processes. Incorporate industry best practices and tools based on emerging trends and changing business requirements. Benchmark and participate in sharegroups with other organizations in order to advance The Hershey Company’s capability Equipment Data Entry Setup and modify new and existing equipment to meet enterprise standards Work with Engineering and equipment OEM on projects during commissioning and validation to gather equipment specific data (i.e. OEM, Model, Serial #) and entering equipment numbers in SAP PM with linkage to Asset numbers. Assigning equipment numbers and descriptions and maintaining this equipment with the proper description and RAV. Create / process CARD forms, (Capital Asset Relocation & Disposal forms), in the system to remove equipment from plant Equipment Strategy Development Development / documentation of PM plans in SAP and attach the plans to the equipment Work with plants to ensure proper PM task list details (including work center, planner code, task frequency, and object lists) in relation to plant personnel structure, equipment maintainability, equipment production needs, and equipment environment. Obtain OEM recommended maintenance tasks, task steps, and frequency. The role should leverage existing PM plans to replicate and optimize like equipment strategy Propose new technology solutions to improve reliability or manufacturing equipment Coordinate with plants to ensure proper tools and training related to maintenance strategy deployment. Equipment Spare Parts Compile complete spare parts list with maintenance assembly (IBAU) structure. Obtain list of critical spares required for regular operation of equipment as recommended by OEM and plant maintenance personnel. Provide suggested plant stocking levels and subsequent HIBE requests Provide guidance for known obsolete parts Equipment Documentation Obtain OEM equipment manuals and troubleshooting guides Request addition plant specific guides and documentation related to equipment set up and maintenance Maintain equipment information libraries attached to equipment within SAP, enterprise document library, and/or local plant digital storage. Coordinate with Plant Maintenance to ensure documentation completeness. Minimum Knowledge And Skills Technical Skills General knowledge of manufacturing maintenance and reliability practices Strong computer skills with accuracy (Teams, Word, Outlook, Excel, Power BI) Microsoft Office skills (Excel analytics/pivot tables) Working knowledge of ERP (i.e. SAP PM) systems Knowledge of or ability to learn policies and procedures (i.e. Hershey Lean) Strong communication skills Strong attention to detail Analytical thinker Basic math skills Qualifications Intermediate knowledge level of ERP system, preferred SAP PM (ECC and S4/HANA) experience. Strong communication skills and tenacity (written and verbal). Must be willing and capable to support North American businesses real-time. (Eastern Time Zone) Capable of documenting and adhering to process discipline. Communication Skills Ability to work well with others as well as part of a team Sensitivity to other cultures and cultural differences Ability to handle multiple priorities Strong organizational skills Strong drive for results Education Accossiates's degree in a quantative field preferrable or equivalent relevant experience. Experience Minimum of 1-3 years with data maintenance of Customer, Vendor or Planner maintenance master data. Minimum of 1-3 years working in an ERP system.",https://mx.linkedin.com/jobs/view/analyst-equipment-master-data-at-the-hershey-company-4027894671,4027894671,"The Equipment Master Data Analyst is responsible for managing equipment master data and ensuring the accuracy and timeliness of data in relation to new equipment installations and existing equipment asset care strategies. This role involves developing maintenance strategies, managing equipment data within SAP PM, and coordinating with various teams to improve data quality and processes. The position requires strong analytical skills, attention to detail, and the ability to work collaboratively across different functions to support data governance and continuous improvement.","SAP PM, Microsoft Office, Excel, Power BI, ERP Systems",1-3 years,N/A,True,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
Business Intelligence Analyst,F5,Guadalajara,ON-SITE,Mid-Senior level,Full-time,IT Services and IT Consulting,2024-09-19 02:11:27.678646,25,Research,"Analyst,",Information Technology,"At F5, we strive to bring a better digital world to life. Our teams empower organizations across the globe to create, secure, and run applications that enhance how we experience our evolving digital world. We are passionate about cybersecurity, from protecting consumers from fraud to enabling companies to focus on innovation. Everything we do centers around people. That means we obsess over how to make the lives of our customers, and their customers, better. And it means we prioritize a diverse F5 community where each individual can thrive. Job Summary: We are seeking a detail-oriented and data-driven Business Intelligence Analyst to join our team. In this role, you will be responsible for analyzing complex data, generating insightful reports, and supporting decision-making processes across the organization. You will work closely with various departments to identify business needs, develop analytical solutions, and drive strategic initiatives that enhance business performance. Key Responsibilities: Develop, implement, and maintain BI solutions using tools such as Tableau, Power BI, and Snowflake, ensuring the delivery of accurate and timely business insights. Design and manage complex SQL queries, stored procedures, and functions to support diverse business needs, ensuring optimal performance and data integrity. Perform data extraction, transformation, and loading (ETL) processes, integrating data from various sources into data warehouses, including Snowflake, for comprehensive reporting. Collaborate with cross-functional teams to gather business requirements, translating them into effective data models, reports, and dashboards that drive decision-making. Ensure the integrity, accuracy, and consistency of data by implementing best practices in relational database design, optimization, and data validation. Utilize APIs and scripting languages to automate data processes, streamline workflows, and enhance data manipulation capabilities. Provide advanced data analysis to identify trends, opportunities, and areas for improvement. Work with Microsoft Power Apps, Dataverse, and Microsoft Power Automate to support and enhance business process automation and data management. Continuously monitor and evaluate BI solutions, making improvements to meet evolving business needs and ensure the highest level of data quality. Support and train team members and stakeholders on the use of BI tools, fostering a data-driven culture within the organization. Qualifications: Bachelor’s degree in Software Engineering, Data Science, Computer Science, or a related field. Demonstrated experience as a Business Intelligence Analyst or in a similar analytical role, with the ability to handle large datasets and conduct complex data analyses. Proficiency in BI tools such as Tableau and Power BI. Strong SQL skills, with experience in data querying, manipulation, and management. Expertise in writing complex queries, stored procedures, and functions tailored to various business requirements. Solid understanding of relational database design and optimization. Familiarity with APIs and scripting for efficient data manipulation and transfer. Hands-on experience with ETL processes and data warehousing. Experience working with cloud-based data platforms such as Snowflake. Experience working with Microsoft Power Apps, Dataverse, and Microsoft Power Automate. Proficiency in programming languages such as Python. Exceptional analytical and problem-solving skills. Experience with advanced statistical analysis and predictive modeling is a plus. The Job Description is intended to be a general representation of the responsibilities and requirements of the job. However, the description may not be all-inclusive, and responsibilities and requirements are subject to change. Please note that F5 only contacts candidates through F5 email address (ending with @f5.com) or auto email notification from Workday (ending with f5.com or @myworkday.com) . Equal Employment Opportunity It is the policy of F5 to provide equal employment opportunities to all employees and employment applicants without regard to unlawful considerations of race, religion, color, national origin, sex, sexual orientation, gender identity or expression, age, sensory, physical, or mental disability, marital status, veteran or military status, genetic information, or any other classification protected by applicable local, state, or federal laws. This policy applies to all aspects of employment, including, but not limited to, hiring, job assignment, compensation, promotion, benefits, training, discipline, and termination. F5 offers a variety of reasonable accommodations for candidates. Requesting an accommodation is completely voluntary. F5 will assess the need for accommodations in the application process separately from those that may be needed to perform the job. Request by contacting accommodations@f5.com.",https://mx.linkedin.com/jobs/view/business-intelligence-analyst-at-f5-4029295900,4029295900,"We are seeking a detail-oriented and data-driven Business Intelligence Analyst to analyze complex data, generate insightful reports, and support decision-making processes. You will develop, implement, and maintain BI solutions using tools like Tableau, Power BI, and Snowflake, design and manage SQL queries, and perform data ETL processes. Collaboration with cross-functional teams to gather business requirements and translating them into data models is essential. The role involves ensuring data integrity, utilizing APIs for automation, and training stakeholders on BI tools.","Tableau, Power BI, Snowflake, SQL, ETL, Python, Microsoft Power Apps, Dataverse, Microsoft Power Automate, APIs",N/A,Bachelor,True,N/A,0,0,0,0,0,0,1,0,1,1,0,0,0,0,1,0,0
