{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: openai in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.43.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (0.26.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.3)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests pandas beautifulsoup4 openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import pandas as pd\n",
    "import requests\n",
    "import random\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from OpenAI.openai_handler import OpenAIHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Location                                        Title           Company  \\\n",
      "0  Monterrey                           Jr. Data Scientist  Arca Continental   \n",
      "1  Monterrey  ML Engineer (Engineer Software Development)            NEORIS   \n",
      "2  Monterrey                                  AI Engineer            NEORIS   \n",
      "3  Monterrey                               Data Scientist             Chubb   \n",
      "4  Monterrey               AI/ML and MLOps Field Engineer         Canonical   \n",
      "\n",
      "                                                 Url       JobID      Category  \n",
      "0  https://mx.linkedin.com/jobs/view/jr-data-scie...  4002846143  Data Science  \n",
      "1  https://mx.linkedin.com/jobs/view/ml-engineer-...  4002146229  Data Science  \n",
      "2  https://mx.linkedin.com/jobs/view/ai-engineer-...  3984233060         AI/ML  \n",
      "3  https://mx.linkedin.com/jobs/view/data-scienti...  3987318831  Data Science  \n",
      "4  https://mx.linkedin.com/jobs/view/ai-ml-and-ml...  4013780012  Data Science  \n"
     ]
    }
   ],
   "source": [
    "file_name = \"LinkedIn_Jobs_Data_Scientist_Monterrey_2024-09-04_clean.csv\"\n",
    "df_jobs = pd.read_csv(file_name)\n",
    "print(df_jobs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 119 entries, 0 to 118\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Location  119 non-null    object\n",
      " 1   Title     119 non-null    object\n",
      " 2   Company   119 non-null    object\n",
      " 3   Url       119 non-null    object\n",
      " 4   JobID     119 non-null    int64 \n",
      " 5   Category  119 non-null    object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 5.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_jobs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_user_agent():\n",
    "\n",
    "    headers = [\n",
    "        {'User-Agent': 'Mozilla/5.0'},\n",
    "        {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.84 Safari/537.36'},\n",
    "        {'User-Agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Mobile Safari/537.36'},\n",
    "        {'User-Agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Mobile Safari/537.36'},\n",
    "        {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.84 Safari/537.36'}\n",
    "    ]\n",
    "\n",
    "    selected_header = random.choice(headers)\n",
    "    return selected_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_jobs_until_success(url):\n",
    "    got_200 = False\n",
    "    while not got_200:\n",
    "        response = requests.get(url, headers=get_random_user_agent())\n",
    "        got_200 = response.status_code == 200\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jobid_information(jobid):\n",
    "   \n",
    "    # Base URL for LinkedIn job search\n",
    "    base_url = 'https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/'\n",
    "    \n",
    "    url_search = base_url + jobid\n",
    "    \n",
    "    return url_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4002846143'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobID = str(df_jobs['JobID'][0])\n",
    "target_url = get_jobid_information(jobID)\n",
    "target_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get job description for 119 postings\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(F\"Get job description for {df_jobs.shape[0]} postings\")\n",
    "extracted_data = []\n",
    "for i in range(0, df_jobs.shape[0]):\n",
    "    jobID = str(df_jobs['JobID'][i])\n",
    "    target_url = get_jobid_information(jobID)\n",
    "    response = fetch_jobs_until_success(target_url)\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find the criteria list first\n",
    "    criteria_list = soup.find('ul', class_='description__job-criteria-list')\n",
    "\n",
    "    # Initialize values as 'N/A'\n",
    "    seniority_level = 'N/A'\n",
    "    employment_type = 'N/A'\n",
    "    job_function = 'N/A'\n",
    "    industries = 'N/A'\n",
    "\n",
    "    if criteria_list:\n",
    "        criteria_items = criteria_list.find_all('li', class_='description__job-criteria-item')\n",
    "        for item in criteria_items:\n",
    "            # Check for Seniority level\n",
    "            if 'Seniority level' in item.get_text():\n",
    "                seniority_level = item.find('span', class_='description__job-criteria-text').get_text(strip=True)\n",
    "            # Check for Employment type\n",
    "            elif 'Employment type' in item.get_text():\n",
    "                employment_type = item.find('span', class_='description__job-criteria-text').get_text(strip=True)\n",
    "            # Check for Job function\n",
    "            elif 'Job function' in item.get_text():\n",
    "                job_function = item.find('span', class_='description__job-criteria-text').get_text(strip=True)\n",
    "            # Check for Industries\n",
    "            elif 'Industries' in item.get_text():\n",
    "                industries = item.find('span', class_='description__job-criteria-text').get_text(strip=True)\n",
    "\n",
    "    # Extract number of applicants (with multiple class check)\n",
    "    num_applicants = 'N/A'\n",
    "    num_applicants_tag = soup.find('figcaption', class_='num-applicants__caption') or \\\n",
    "                         soup.find('span', class_='num-applicants__caption topcard__flavor--metadata topcard__flavor--bullet')\n",
    "    if num_applicants_tag:\n",
    "        num_applicants = num_applicants_tag.get_text(strip=True)\n",
    "\n",
    "\n",
    "    # Extract posted time\n",
    "    posted_time = soup.find('span', class_='posted-time-ago__text')\n",
    "    posted_time = posted_time.get_text(strip=True) if posted_time else 'N/A'\n",
    "\n",
    "    # Extract job description text\n",
    "    description_tag = soup.find('div', class_='show-more-less-html__markup')\n",
    "    description = description_tag.get_text(separator=' ', strip=True) if description_tag else 'N/A'\n",
    "\n",
    "    # Append the data to the list\n",
    "    extracted_data.append({\n",
    "        'SeniorityLevel': seniority_level,\n",
    "        'EmploymentType': employment_type,\n",
    "        'JobFunction': job_function,\n",
    "        'Industries': industries,\n",
    "        'PostedTime': posted_time,\n",
    "        'NumApplicants': num_applicants,\n",
    "        'Description': description\n",
    "    })\n",
    "\n",
    "# Convert the extracted data into a DataFrame\n",
    "extracted_df = pd.DataFrame(extracted_data)\n",
    "\n",
    "# Combine with the original dataframe\n",
    "df_jobs = pd.concat([df_jobs, extracted_df], axis=1)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Category' column to a categorical data type\n",
    "categories = ['AI/ML', 'Data Science', 'Data Engineering', 'Data Analysis']\n",
    "df_jobs['Category'] = pd.Categorical(df_jobs['Category'], categories=categories)\n",
    "df_jobs.rename(columns={'Category': 'JobCategory'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['SeniorityLevel'] = df_jobs['SeniorityLevel'].apply(lambda x: 'N/A' if 'Not Applicable' in x else x)\n",
    "categories = ['Entry level', 'Mid-Senior level', 'Executive', 'N/A', 'Associate',\n",
    "       'Internship']\n",
    "df_jobs['SeniorityLevel'] = pd.Categorical(df_jobs['SeniorityLevel'], categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['EmploymentType'] = pd.Categorical(df_jobs['EmploymentType'], categories=df_jobs['EmploymentType'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and standardize the number of applicants\n",
    "def extract_num_applicants(text):\n",
    "    match = re.search(r'\\d+', text)\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    elif \"Be among the first 25\" in text:\n",
    "        return 25\n",
    "    elif \"Over 200 applicants\" in text:\n",
    "        return 200\n",
    "    else:\n",
    "        return 'N/A'\n",
    "\n",
    "df_jobs['NumApplicants'] = df_jobs['NumApplicants'].apply(extract_num_applicants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['JobFunction'] = df_jobs['JobFunction'].replace({\n",
    "    'Research and Design': 'R&D',\n",
    "    'Design and Product Management': 'Product Management'\n",
    "})\n",
    "\n",
    "# Standardize job functions\n",
    "def standardize_job_function(text):\n",
    "    # Replace 'and' with commas for two-element values\n",
    "    if ' and ' in text:\n",
    "        text = text.replace(' and ', ', ')\n",
    "    \n",
    "    # Split by commas and limit to the first 3 elements\n",
    "    job_functions = text.split(', ')\n",
    "    \n",
    "    # If more than 3 functions, keep only the first three\n",
    "    if len(job_functions) > 3:\n",
    "        job_functions = job_functions[:3]\n",
    "    \n",
    "    # Join back the elements with commas\n",
    "    return ', '.join(job_functions)\n",
    "\n",
    "# Apply the function to standardize the JobFunction column\n",
    "df_jobs['JobFunction'] = df_jobs['JobFunction'].apply(standardize_job_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_job_functions(text):\n",
    "    # Split the job functions\n",
    "    job_functions = text.split(', ')\n",
    "    \n",
    "    # Return the first 3 job functions, or None if not available\n",
    "    job_function_1 = job_functions[0] if len(job_functions) > 0 else None\n",
    "    job_function_2 = job_functions[1] if len(job_functions) > 1 else None\n",
    "    job_function_3 = job_functions[2] if len(job_functions) > 2 else None\n",
    "    \n",
    "    return pd.Series([job_function_1, job_function_2, job_function_3])\n",
    "\n",
    "# Apply the splitting function and assign new columns\n",
    "df_jobs[['JobFunction1', 'JobFunction2', 'JobFunction3']] = df_jobs['JobFunction'].apply(split_job_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the None values with 'N/A' by re-assigning the columns\n",
    "df_jobs['JobFunction1'] = df_jobs['JobFunction1'].fillna('N/A')\n",
    "df_jobs['JobFunction2'] = df_jobs['JobFunction2'].fillna('N/A')\n",
    "df_jobs['JobFunction3'] = df_jobs['JobFunction3'].fillna('N/A')\n",
    "\n",
    "# Extract unique values from each JobFunction column, excluding None values\n",
    "job_function_categories = list(set(\n",
    "    df_jobs['JobFunction1'].unique().tolist() + \n",
    "    df_jobs['JobFunction2'].unique().tolist() + \n",
    "    df_jobs['JobFunction3'].unique().tolist()))\n",
    "\n",
    "# Remove any None from the category list (just in case)\n",
    "job_function_categories = [x for x in job_function_categories if x is not None]\n",
    "\n",
    "# Convert JobFunction1, JobFunction2, JobFunction3 to categorical data types using the merged categories\n",
    "df_jobs['JobFunction1'] = pd.Categorical(df_jobs['JobFunction1'], categories=job_function_categories)\n",
    "df_jobs['JobFunction2'] = pd.Categorical(df_jobs['JobFunction2'], categories=job_function_categories)\n",
    "df_jobs['JobFunction3'] = pd.Categorical(df_jobs['JobFunction3'], categories=job_function_categories)\n",
    "\n",
    "# Drop the 'JobFunction' column if it's not needed\n",
    "df_jobs.drop(columns=['JobFunction'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_posted_time(text):\n",
    "    if 'hour' in text:\n",
    "        return 0\n",
    "    \n",
    "    if 'day' in text:\n",
    "        days = int(re.search(r'\\d+', text).group()) if re.search(r'\\d+', text) else 1  # Default to 1 if no number\n",
    "        return days\n",
    "    \n",
    "    elif 'week' in text:\n",
    "        weeks = int(re.search(r'\\d+', text).group()) if re.search(r'\\d+', text) else 1  # Default to 1 if no number\n",
    "        return weeks * 7\n",
    "    \n",
    "    elif 'month' in text:\n",
    "        months = int(re.search(r'\\d+', text).group()) if re.search(r'\\d+', text) else 1  # Default to 1 if no number\n",
    "        return months * 30\n",
    "    \n",
    "    return text\n",
    "\n",
    "df_jobs['PostedTime'] = df_jobs['PostedTime'].apply(convert_posted_time)\n",
    "\n",
    "df_jobs.rename(columns={'PostedTime': 'DaysSincePosted'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_order = [\n",
    "    'Title', 'Company', 'Location', 'JobID', 'JobCategory', \n",
    "    'SeniorityLevel', 'EmploymentType', 'Industries', \n",
    "    'DaysSincePosted', 'NumApplicants', \n",
    "    'JobFunction1', 'JobFunction2', 'JobFunction3', \n",
    "    'Description', 'Url'\n",
    "]\n",
    "df_jobs = df_jobs[new_column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 119 entries, 0 to 118\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype   \n",
      "---  ------           --------------  -----   \n",
      " 0   Title            119 non-null    object  \n",
      " 1   Company          119 non-null    object  \n",
      " 2   Location         119 non-null    object  \n",
      " 3   JobID            119 non-null    int64   \n",
      " 4   JobCategory      119 non-null    category\n",
      " 5   SeniorityLevel   119 non-null    category\n",
      " 6   EmploymentType   119 non-null    category\n",
      " 7   Industries       119 non-null    object  \n",
      " 8   DaysSincePosted  119 non-null    int64   \n",
      " 9   NumApplicants    119 non-null    int64   \n",
      " 10  JobFunction1     119 non-null    category\n",
      " 11  JobFunction2     119 non-null    category\n",
      " 12  JobFunction3     119 non-null    category\n",
      " 13  Description      119 non-null    object  \n",
      " 14  Url              119 non-null    object  \n",
      "dtypes: category(6), int64(3), object(6)\n",
      "memory usage: 12.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_jobs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing OpenAI Handler\n",
      "Configuring OpenAI Client\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "openai_handler = OpenAIHandler()\n",
    "for index, row in df_jobs.iterrows():\n",
    "    description = row['Description']\n",
    "    \n",
    "    messages = openai_handler.create_messages(description)\n",
    "    \n",
    "    response = openai_handler.generate_chat_completion(messages)\n",
    "        \n",
    "    # Add the parsed JSON fields into the DataFrame as new columns\n",
    "    df_jobs.at[index, 'Workscheme'] = response.get('Workscheme', 'N/A')\n",
    "    df_jobs.at[index, 'ShortDescription'] = response.get('Description', 'N/A')\n",
    "    df_jobs.at[index, 'TechStack'] = ', '.join(response.get('TechStack', []))\n",
    "    df_jobs.at[index, 'YoE'] = response.get('YoE', 'N/A')\n",
    "    df_jobs.at[index, 'MinLevelStudies'] = response.get('MinLevelStudies', 'N/A')\n",
    "    df_jobs.at[index, 'English'] = response.get('English', 'N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "workscheme_mapping = {\n",
    "    'On-site': ['On-site', 'Onsite'],\n",
    "    'Remote': ['Remote', 'Fully Remote', 'Fully remote', 'Full-time remote', 'Remote with travel 2 to 4 weeks for events', \n",
    "               'Remote with global travel', 'Flexible/Remote', 'part-time, flexible work-from-home', \n",
    "               'Part-time, work from home', 'Flexible'],\n",
    "    'Hybrid': ['Hybrid', 'Hybrid / Remote', 'Full-time, hybrid', 'Hybrid (Mon-Thur onsite, Fri remote)', \n",
    "               'Hybrid', 'In-person or hybrid', 'In-office (Tuesdays and Wednesdays)']\n",
    "}\n",
    "reverse_mapping = {value: key for key, values in workscheme_mapping.items() for value in values}\n",
    "df_jobs['Workscheme'] = df_jobs['Workscheme'].map(lambda x: reverse_mapping.get(x, 'N/A'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_min_years(experience_str):\n",
    "    # Ensure experience_str is a string\n",
    "    experience_str = str(experience_str)\n",
    "    \n",
    "    # Handle 'N/A' and non-numeric cases\n",
    "    if 'N/A' in experience_str or 'Professional software development experience required' in experience_str:\n",
    "        return 'N/A'\n",
    "    \n",
    "    # Find all numeric values in the string\n",
    "    numbers = re.findall(r'\\d+', experience_str)\n",
    "    \n",
    "    # If no numbers found, return 'N/A'\n",
    "    if not numbers:\n",
    "        return 'N/A'\n",
    "    \n",
    "    # Convert found numbers to integers and return the minimum\n",
    "    return min(map(int, numbers))\n",
    "\n",
    "# Apply the function to the 'YoE' column and create a new 'MinYoE' column\n",
    "df_jobs['MinYoE'] = df_jobs['YoE'].apply(extract_min_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_studies(level):\n",
    "    level = level.lower()\n",
    "    if any(keyword in level for keyword in [\"student\", \"undergraduate\"]):\n",
    "        return \"Undergraduate Student\"\n",
    "    elif any(keyword in level for keyword in [\"bachelor\", \"bs\", \"b.sc\", \"bachelor's\"]):\n",
    "        return \"Bachelor\"\n",
    "    elif any(keyword in level for keyword in [\"master\", \"ms\", \"m.sc\", \"master's\"]):\n",
    "        return \"Masters\"\n",
    "    elif \"phd\" in level:\n",
    "        return \"PhD\"\n",
    "    else:\n",
    "        return \"N/A\"\n",
    "df_jobs['MinLevelStudies'] = df_jobs['MinLevelStudies'].apply(categorize_studies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_stack_categories = {\n",
    "    'Agile Methodologies': [\n",
    "        'Scrum', 'SAFe', 'Agile', 'Agile SDLC', 'Kanban', 'Agile'\n",
    "    ],\n",
    "    'Back-End Development': [\n",
    "        'Node.js', 'ASP.NET', 'Spring Boot', 'Django', 'Flask', 'Ruby on Rails', \n",
    "        '.NET Core', 'FastAPI', 'Golang', 'C#'\n",
    "    ],\n",
    "    'Big Data Tools': [\n",
    "        'Hadoop', 'Spark', 'Hive', 'Databricks', 'Airflow', 'BigQuery', \n",
    "        'Teradata', 'ClickHouse', 'AWS Glue', 'Big Data', 'Big Data Stack', \n",
    "        'SnapLogic', 'DataDog', 'Alteryx', 'Talend ETL'\n",
    "    ],\n",
    "    'Cloud Platforms': [\n",
    "        'AWS', 'Azure', 'GCP', 'Google Cloud Platform (GCP)', \n",
    "        'Cloud Computing', 'Microsoft Azure', 'AWS Redshift', \n",
    "        'AWS S3', 'Azure SQL Databases', 'Google BigQuery', 'Azure Data Factory',\n",
    "        'Azure Synapse', 'Azure API App Services', 'Azure Data Bricks', \n",
    "        'Azure Data Lake', 'Azure ADLS Gen2', 'AWS Lambda', 'Google Cloud', \n",
    "        'Azure Data Lake Storage', 'Amazon Web Services', 'Cloud Infrastructure'\n",
    "    ],\n",
    "    'Containerization and Orchestration': [\n",
    "        'Docker', 'Kubernetes', 'Containerization', 'ECS', 'LXD'\n",
    "    ],\n",
    "    'Data Analysis': [\n",
    "        'Data Analysis', 'Statistical Modeling', 'Statistical Analysis', \n",
    "        'Data Analytics', 'Data Mining', 'Data Quality', 'Data Cleansing', \n",
    "        'Data Normalization', 'Data Sanitization', 'Statistical Techniques', \n",
    "        'Statistical Methods', 'Analytical Tools', 'Data Management', \n",
    "        'Data Science', 'Data Science Tools', 'Data Modeling', 'Data Queries', \n",
    "        'Data Flows', 'Data Manipulation', 'Data Platforms', 'Data Warehousing', \n",
    "        'Data Engineering', 'Data Visualization', 'Data Visualization Tools'\n",
    "    ],\n",
    "    'Data Engineering': [\n",
    "        'Data Engineering', 'Data Warehousing', 'ETL', 'Data Lakes', \n",
    "        'Data Flows', 'Data Migrations', 'Data Integration', 'Data Processing', \n",
    "        'Data Platforms', 'Data Quality', 'Data Management'\n",
    "    ],\n",
    "    'Data Modeling': [\n",
    "        'Data Modeling', 'Data Architectures', 'Data Structures', 'Data Schema Design', \n",
    "        'Database Modeling', 'Conceptual Data Models', 'Logical Data Models', \n",
    "        'Physical Data Models'\n",
    "    ],\n",
    "    'Data Visualization': [\n",
    "        'Power BI', 'Tableau', 'Qlik', 'Matplotlib', 'Plotly', 'D3.js', \n",
    "        'Excel', 'Looker', 'Apache Superset', 'Data Visualization Tools', \n",
    "        'BI Tools', 'Dashboard Development', 'Visualization Tools'\n",
    "    ],\n",
    "    'Database Management': [\n",
    "        'SQL', 'NoSQL', 'MongoDB', 'SQL Server', 'CosmosDB', 'MySQL', \n",
    "        'PostgreSQL', 'Oracle', 'SAP HANA', 'SAP ECC', 'SAP S/4HANA', \n",
    "        'Non-SQL Databases', 'DB2', 'PL/SQL', 'Cassandra', 'Redis', 'Sybase', \n",
    "        'Data Lake', 'Database', 'Database Management', 'Data Warehouses', \n",
    "        'Database Schema Design', 'Stored Procedures', 'Data Migrations', \n",
    "        'SQL DW', 'PostgresSQL'\n",
    "    ],\n",
    "    'Front-End Development': [\n",
    "        'React', 'Angular', 'Bootstrap', 'Vue.js', 'CSS', 'HTML', 'SwiftUI', \n",
    "        'Front End Development'\n",
    "    ],\n",
    "    'Infrastructure as Code (IaC) and Automation': [\n",
    "        'Terraform', 'Ansible', 'Helm', 'OpenStack', 'Infrastructure-as-Code', \n",
    "        'ARM Templates', 'Automation', 'Git', 'CI/CD pipelines'\n",
    "    ],\n",
    "    'Machine Learning': [\n",
    "        'Scikit-Learn', 'TensorFlow', 'PyTorch', 'Keras', 'MLFlow', \n",
    "        'Spark ML', 'XGBoost', 'LightGBM', 'Feature Engineering', \n",
    "        'A/B Testing', 'Machine Learning', 'Algorithms', 'Google AutoML', \n",
    "        'Hugging Face', 'Kubeflow', 'SciPy', 'ML Models'\n",
    "    ],\n",
    "    'Networking': [\n",
    "        'WiFi', 'Networking', 'VPC', 'Network Security', 'Cloud Security'\n",
    "    ],\n",
    "    'Python': [\n",
    "        'Python'\n",
    "    ],\n",
    "    'Testing and Quality Assurance': [\n",
    "        'Unit Testing', 'Integration Testing', 'Feature Testing', 'Performance Tuning', \n",
    "        'Load Testing', 'Testing Tools', 'SOAP UI', 'Quality Assurance'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_jobs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize columns with 0s\n",
    "for category in tech_stack_categories:\n",
    "    df[category] = 0\n",
    "\n",
    "# Add 'Other' category\n",
    "df['Other'] = 0\n",
    "\n",
    "# Function to categorize tech stack\n",
    "def categorize_tech_stack(tech_stack):\n",
    "    tech_stack_elements = [element.strip() for element in tech_stack.split(',')]\n",
    "    category_found = False\n",
    "\n",
    "    for category, items in tech_stack_categories.items():\n",
    "        for item in items:\n",
    "            if any(item in element for element in tech_stack_elements):\n",
    "                df.at[index, category] = 1\n",
    "                category_found = True\n",
    "    \n",
    "    if not category_found:\n",
    "        df.at[index, 'Other'] = 1\n",
    "\n",
    "# Apply categorization\n",
    "for index, row in df.iterrows():\n",
    "    categorize_tech_stack(row['TechStack'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  # None means no limit\n",
    "pd.set_option('display.max_rows', None)  # None means no limit\n",
    "pd.set_option('display.max_colwidth', 50)  # Default value for max_colwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['JobID', 'Industries', 'DaysSincePosted', 'NumApplicants', 'Description','JobFunction1', 'JobFunction2', 'JobFunction3',\n",
    "                   'Agile Methodologies', 'Back-End Development', 'Containerization and Orchestration', 'Front-End Development', \n",
    "                   'Infrastructure as Code (IaC) and Automation', 'Networking', 'Testing and Quality Assurance']\n",
    "df_new = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>JobCategory</th>\n",
       "      <th>SeniorityLevel</th>\n",
       "      <th>EmploymentType</th>\n",
       "      <th>Url</th>\n",
       "      <th>Workscheme</th>\n",
       "      <th>ShortDescription</th>\n",
       "      <th>TechStack</th>\n",
       "      <th>YoE</th>\n",
       "      <th>MinLevelStudies</th>\n",
       "      <th>English</th>\n",
       "      <th>MinYoE</th>\n",
       "      <th>Big Data Tools</th>\n",
       "      <th>Cloud Platforms</th>\n",
       "      <th>Data Analysis</th>\n",
       "      <th>Data Engineering</th>\n",
       "      <th>Data Modeling</th>\n",
       "      <th>Data Visualization</th>\n",
       "      <th>Database Management</th>\n",
       "      <th>Machine Learning</th>\n",
       "      <th>Python</th>\n",
       "      <th>Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jr. Data Scientist</td>\n",
       "      <td>Arca Continental</td>\n",
       "      <td>Monterrey</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://mx.linkedin.com/jobs/view/jr-data-scie...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>We are looking for a Junior Data Scientist wit...</td>\n",
       "      <td>Python, Machine Learning, Algorithms, Data Ana...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>True</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Title           Company   Location   JobCategory  \\\n",
       "0  Jr. Data Scientist  Arca Continental  Monterrey  Data Science   \n",
       "\n",
       "  SeniorityLevel EmploymentType  \\\n",
       "0      Associate      Full-time   \n",
       "\n",
       "                                                 Url Workscheme  \\\n",
       "0  https://mx.linkedin.com/jobs/view/jr-data-scie...        N/A   \n",
       "\n",
       "                                    ShortDescription  \\\n",
       "0  We are looking for a Junior Data Scientist wit...   \n",
       "\n",
       "                                           TechStack  YoE MinLevelStudies  \\\n",
       "0  Python, Machine Learning, Algorithms, Data Ana...  N/A        Bachelor   \n",
       "\n",
       "  English MinYoE  Big Data Tools  Cloud Platforms  Data Analysis  \\\n",
       "0    True    N/A               0                0              1   \n",
       "\n",
       "   Data Engineering  Data Modeling  Data Visualization  Database Management  \\\n",
       "0                 0              0                   0                    0   \n",
       "\n",
       "   Machine Learning  Python  Other  \n",
       "0                 1       1      0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['MinYoE'] = pd.to_numeric(df['MinYoE'], errors='coerce')\n",
    "\n",
    "filtered_df = df_new[\n",
    "     ((df_new['MinYoE'] < 5) | pd.isna(df_new['MinYoE'])) &\n",
    "    (df_new['MinLevelStudies'] == 'Bachelor') & \n",
    "    (df_new['English'] == True) & \n",
    "    (df_new['EmploymentType'] == 'Full-time') &\n",
    "    (df_new['Workscheme'].isin(['Remote', 'N/A']))\n",
    "].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>JobCategory</th>\n",
       "      <th>SeniorityLevel</th>\n",
       "      <th>EmploymentType</th>\n",
       "      <th>Url</th>\n",
       "      <th>Workscheme</th>\n",
       "      <th>ShortDescription</th>\n",
       "      <th>TechStack</th>\n",
       "      <th>YoE</th>\n",
       "      <th>MinLevelStudies</th>\n",
       "      <th>English</th>\n",
       "      <th>MinYoE</th>\n",
       "      <th>Big Data Tools</th>\n",
       "      <th>Cloud Platforms</th>\n",
       "      <th>Data Analysis</th>\n",
       "      <th>Data Engineering</th>\n",
       "      <th>Data Modeling</th>\n",
       "      <th>Data Visualization</th>\n",
       "      <th>Database Management</th>\n",
       "      <th>Machine Learning</th>\n",
       "      <th>Python</th>\n",
       "      <th>Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jr. Data Scientist</td>\n",
       "      <td>Arca Continental</td>\n",
       "      <td>Monterrey</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://mx.linkedin.com/jobs/view/jr-data-scie...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>We are looking for a Junior Data Scientist wit...</td>\n",
       "      <td>Python, Machine Learning, Algorithms, Data Ana...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ML Engineer (Engineer Software Development)</td>\n",
       "      <td>NEORIS</td>\n",
       "      <td>Monterrey</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://mx.linkedin.com/jobs/view/ml-engineer-...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>We are looking for an ML Engineer to support t...</td>\n",
       "      <td>Python, Snowflake, SQL, FastAPI, Django, Flask...</td>\n",
       "      <td>4+ years in Development, 4+ years in storage t...</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI Engineer</td>\n",
       "      <td>NEORIS</td>\n",
       "      <td>Monterrey</td>\n",
       "      <td>AI/ML</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://mx.linkedin.com/jobs/view/ai-engineer-...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>We are looking for an AI Engineer in Monterrey...</td>\n",
       "      <td>Python, Scikit Learn, TensorFlow, PyTorch, Ker...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Chubb</td>\n",
       "      <td>Monterrey</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://mx.linkedin.com/jobs/view/data-scienti...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>We are seeking a talented and motivated Machin...</td>\n",
       "      <td>Python, R, Java, TensorFlow, PyTorch, scikit-l...</td>\n",
       "      <td>3</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AI Developer</td>\n",
       "      <td>SAP</td>\n",
       "      <td>San Pedro</td>\n",
       "      <td>AI/ML</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>https://mx.linkedin.com/jobs/view/ai-developer...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>As an GCID SRRC AI Developer, you will contrib...</td>\n",
       "      <td>Python, Go, Cloud Computing, Big Data, Front E...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Title           Company   Location  \\\n",
       "0                           Jr. Data Scientist  Arca Continental  Monterrey   \n",
       "1  ML Engineer (Engineer Software Development)            NEORIS  Monterrey   \n",
       "2                                  AI Engineer            NEORIS  Monterrey   \n",
       "3                               Data Scientist             Chubb  Monterrey   \n",
       "4                                 AI Developer               SAP  San Pedro   \n",
       "\n",
       "    JobCategory SeniorityLevel EmploymentType  \\\n",
       "0  Data Science      Associate      Full-time   \n",
       "1  Data Science    Entry level      Full-time   \n",
       "2         AI/ML    Entry level      Full-time   \n",
       "3  Data Science    Entry level      Full-time   \n",
       "4         AI/ML            N/A      Full-time   \n",
       "\n",
       "                                                 Url Workscheme  \\\n",
       "0  https://mx.linkedin.com/jobs/view/jr-data-scie...        N/A   \n",
       "1  https://mx.linkedin.com/jobs/view/ml-engineer-...        N/A   \n",
       "2  https://mx.linkedin.com/jobs/view/ai-engineer-...        N/A   \n",
       "3  https://mx.linkedin.com/jobs/view/data-scienti...        N/A   \n",
       "4  https://mx.linkedin.com/jobs/view/ai-developer...        N/A   \n",
       "\n",
       "                                    ShortDescription  \\\n",
       "0  We are looking for a Junior Data Scientist wit...   \n",
       "1  We are looking for an ML Engineer to support t...   \n",
       "2  We are looking for an AI Engineer in Monterrey...   \n",
       "3  We are seeking a talented and motivated Machin...   \n",
       "4  As an GCID SRRC AI Developer, you will contrib...   \n",
       "\n",
       "                                           TechStack  \\\n",
       "0  Python, Machine Learning, Algorithms, Data Ana...   \n",
       "1  Python, Snowflake, SQL, FastAPI, Django, Flask...   \n",
       "2  Python, Scikit Learn, TensorFlow, PyTorch, Ker...   \n",
       "3  Python, R, Java, TensorFlow, PyTorch, scikit-l...   \n",
       "4  Python, Go, Cloud Computing, Big Data, Front E...   \n",
       "\n",
       "                                                 YoE MinLevelStudies English  \\\n",
       "0                                                N/A        Bachelor    True   \n",
       "1  4+ years in Development, 4+ years in storage t...        Bachelor    True   \n",
       "2                                                N/A        Bachelor    True   \n",
       "3                                                  3        Bachelor    True   \n",
       "4                                                N/A        Bachelor    True   \n",
       "\n",
       "   MinYoE  Big Data Tools  Cloud Platforms  Data Analysis  Data Engineering  \\\n",
       "0     NaN               0                0              1                 0   \n",
       "1     2.0               0                1              0                 0   \n",
       "2     NaN               0                1              0                 0   \n",
       "3     3.0               1                1              0                 0   \n",
       "4     NaN               1                1              0                 0   \n",
       "\n",
       "   Data Modeling  Data Visualization  Database Management  Machine Learning  \\\n",
       "0              0                   0                    0                 1   \n",
       "1              0                   0                    1                 0   \n",
       "2              0                   0                    1                 1   \n",
       "3              0                   0                    1                 1   \n",
       "4              0                   0                    0                 1   \n",
       "\n",
       "   Python  Other  \n",
       "0       1      0  \n",
       "1       1      0  \n",
       "2       1      0  \n",
       "3       1      0  \n",
       "4       1      0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"LinkedIn_Jobs_Data_Scientist_Monterrey_2024-09-04_FullInfo_Stack.csv\", index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
