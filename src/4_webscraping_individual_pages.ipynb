{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests pandas beautifulsoup4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import pandas as pd\n",
    "import requests\n",
    "import random\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Location                                        Title           Company  \\\n",
      "0  Monterrey                           Jr. Data Scientist  Arca Continental   \n",
      "1  Monterrey  ML Engineer (Engineer Software Development)            NEORIS   \n",
      "2  Monterrey                                  AI Engineer            NEORIS   \n",
      "3  Monterrey                               Data Scientist             Chubb   \n",
      "4  Monterrey               AI/ML and MLOps Field Engineer         Canonical   \n",
      "\n",
      "                                                 Url       JobID      Category  \n",
      "0  https://mx.linkedin.com/jobs/view/jr-data-scie...  4002846143  Data Science  \n",
      "1  https://mx.linkedin.com/jobs/view/ml-engineer-...  4002146229  Data Science  \n",
      "2  https://mx.linkedin.com/jobs/view/ai-engineer-...  3984233060         AI/ML  \n",
      "3  https://mx.linkedin.com/jobs/view/data-scienti...  3987318831  Data Science  \n",
      "4  https://mx.linkedin.com/jobs/view/ai-ml-and-ml...  4013780012  Data Science  \n"
     ]
    }
   ],
   "source": [
    "file_name = \"LinkedIn_Jobs_Data_Scientist_Monterrey_2024-09-04_clean.csv\"\n",
    "df_jobs = pd.read_csv(file_name)\n",
    "print(df_jobs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_user_agent():\n",
    "\n",
    "    headers = [\n",
    "        {'User-Agent': 'Mozilla/5.0'},\n",
    "        {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.84 Safari/537.36'},\n",
    "        {'User-Agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Mobile Safari/537.36'},\n",
    "        {'User-Agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Mobile Safari/537.36'},\n",
    "        {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.84 Safari/537.36'}\n",
    "    ]\n",
    "\n",
    "    selected_header = random.choice(headers)\n",
    "    return selected_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_jobs_until_success(url):\n",
    "    got_200 = False\n",
    "    while not got_200:\n",
    "        response = requests.get(url, headers=get_random_user_agent())\n",
    "        got_200 = response.status_code == 200\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jobid_information(jobid):\n",
    "   \n",
    "    # Base URL for LinkedIn job search\n",
    "    base_url = 'https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/'\n",
    "    \n",
    "    url_search = base_url + jobid\n",
    "    \n",
    "    return url_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "extracted_data = []\n",
    "for i in range(0, df_jobs.shape[0]):\n",
    "    #print(F\"Get job description {i+1}/{df_jobs.shape[0]}\")\n",
    "    jobID = str(df_jobs['JobID'][i])\n",
    "    target_url = get_jobid_information(jobID)\n",
    "    response = fetch_jobs_until_success(target_url)\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find the criteria list first\n",
    "    criteria_list = soup.find('ul', class_='description__job-criteria-list')\n",
    "\n",
    "    # Initialize values as 'N/A'\n",
    "    seniority_level = 'N/A'\n",
    "    employment_type = 'N/A'\n",
    "    job_function = 'N/A'\n",
    "    industries = 'N/A'\n",
    "\n",
    "    if criteria_list:\n",
    "        criteria_items = criteria_list.find_all('li', class_='description__job-criteria-item')\n",
    "        for item in criteria_items:\n",
    "            # Check for Seniority level\n",
    "            if 'Seniority level' in item.get_text():\n",
    "                seniority_level = item.find('span', class_='description__job-criteria-text').get_text(strip=True)\n",
    "            # Check for Employment type\n",
    "            elif 'Employment type' in item.get_text():\n",
    "                employment_type = item.find('span', class_='description__job-criteria-text').get_text(strip=True)\n",
    "            # Check for Job function\n",
    "            elif 'Job function' in item.get_text():\n",
    "                job_function = item.find('span', class_='description__job-criteria-text').get_text(strip=True)\n",
    "            # Check for Industries\n",
    "            elif 'Industries' in item.get_text():\n",
    "                industries = item.find('span', class_='description__job-criteria-text').get_text(strip=True)\n",
    "\n",
    "    # Extract number of applicants (with multiple class check)\n",
    "    num_applicants = 'N/A'\n",
    "    num_applicants_tag = soup.find('figcaption', class_='num-applicants__caption') or \\\n",
    "                         soup.find('span', class_='num-applicants__caption topcard__flavor--metadata topcard__flavor--bullet')\n",
    "    if num_applicants_tag:\n",
    "        num_applicants = num_applicants_tag.get_text(strip=True)\n",
    "\n",
    "\n",
    "    # Extract posted time\n",
    "    posted_time = soup.find('span', class_='posted-time-ago__text')\n",
    "    posted_time = posted_time.get_text(strip=True) if posted_time else 'N/A'\n",
    "\n",
    "    # Extract job description text\n",
    "    description_tag = soup.find('div', class_='show-more-less-html__markup')\n",
    "    description = description_tag.get_text(separator=' ', strip=True) if description_tag else 'N/A'\n",
    "\n",
    "    # Append the data to the list\n",
    "    extracted_data.append({\n",
    "        'SeniorityLevel': seniority_level,\n",
    "        'EmploymentType': employment_type,\n",
    "        'JobFunction': job_function,\n",
    "        'Industries': industries,\n",
    "        'PostedTime': posted_time,\n",
    "        'NumApplicants': num_applicants,\n",
    "        'Description': description\n",
    "    })\n",
    "\n",
    "# Convert the extracted data into a DataFrame\n",
    "extracted_df = pd.DataFrame(extracted_data)\n",
    "\n",
    "# Combine with the original dataframe\n",
    "df_jobs = pd.concat([df_jobs, extracted_df], axis=1)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Category' column to a categorical data type\n",
    "categories = ['AI/ML', 'Data Science', 'Data Engineering', 'Data Analysis']\n",
    "df_jobs['Category'] = pd.Categorical(df_jobs['Category'], categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and standardize the number of applicants\n",
    "def extract_num_applicants(text):\n",
    "    match = re.search(r'\\d+', text)\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    elif \"Be among the first 25\" in text:\n",
    "        return 25\n",
    "    elif \"Over 200 applicants\" in text:\n",
    "        return 200\n",
    "    else:\n",
    "        return 'N/A'\n",
    "\n",
    "df_jobs['NumApplicants'] = df_jobs['NumApplicants'].apply(extract_num_applicants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['SeniorityLevel'] = df_jobs['SeniorityLevel'].apply(lambda x: 'N/A' if 'Not Applicable' in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['Entry level', 'Mid-Senior level', 'Executive', 'N/A', 'Associate',\n",
    "       'Internship']\n",
    "df_jobs['SeniorityLevel'] = pd.Categorical(df_jobs['SeniorityLevel'], categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['EmploymentType'] = pd.Categorical(df_jobs['EmploymentType'], categories=df_jobs['EmploymentType'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['JobFunction'] = df_jobs['JobFunction'].replace({\n",
    "    'Research and Design': 'R&D',\n",
    "    'Design and Product Management': 'Product Management'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize job functions\n",
    "def standardize_job_function(text):\n",
    "    # Replace 'and' with commas for two-element values\n",
    "    if ' and ' in text:\n",
    "        text = text.replace(' and ', ', ')\n",
    "    \n",
    "    # Split by commas and limit to the first 3 elements\n",
    "    job_functions = text.split(', ')\n",
    "    \n",
    "    # If more than 3 functions, keep only the first three\n",
    "    if len(job_functions) > 3:\n",
    "        job_functions = job_functions[:3]\n",
    "    \n",
    "    # Join back the elements with commas\n",
    "    return ', '.join(job_functions)\n",
    "\n",
    "# Apply the function to standardize the JobFunction column\n",
    "df_jobs['JobFunction'] = df_jobs['JobFunction'].apply(standardize_job_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_job_functions(text):\n",
    "    # Split the job functions\n",
    "    job_functions = text.split(', ')\n",
    "    \n",
    "    # Return the first 3 job functions, or None if not available\n",
    "    job_function_1 = job_functions[0] if len(job_functions) > 0 else None\n",
    "    job_function_2 = job_functions[1] if len(job_functions) > 1 else None\n",
    "    job_function_3 = job_functions[2] if len(job_functions) > 2 else None\n",
    "    \n",
    "    return pd.Series([job_function_1, job_function_2, job_function_3])\n",
    "\n",
    "# Apply the splitting function and assign new columns\n",
    "df_jobs[['JobFunction1', 'JobFunction2', 'JobFunction3']] = df_jobs['JobFunction'].apply(split_job_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Replace the None values with 'N/A' by re-assigning the columns\n",
    "df_jobs['JobFunction1'] = df_jobs['JobFunction1'].fillna('N/A')\n",
    "df_jobs['JobFunction2'] = df_jobs['JobFunction2'].fillna('N/A')\n",
    "df_jobs['JobFunction3'] = df_jobs['JobFunction3'].fillna('N/A')\n",
    "\n",
    "# Step 2: Extract unique values from each JobFunction column, excluding None values\n",
    "job_function_categories = list(set(\n",
    "    df_jobs['JobFunction1'].unique().tolist() + \n",
    "    df_jobs['JobFunction2'].unique().tolist() + \n",
    "    df_jobs['JobFunction3'].unique().tolist()))\n",
    "\n",
    "# Step 3: Remove any None from the category list (just in case)\n",
    "job_function_categories = [x for x in job_function_categories if x is not None]\n",
    "\n",
    "# Step 4: Convert JobFunction1, JobFunction2, JobFunction3 to categorical data types using the merged categories\n",
    "df_jobs['JobFunction1'] = pd.Categorical(df_jobs['JobFunction1'], categories=job_function_categories)\n",
    "df_jobs['JobFunction2'] = pd.Categorical(df_jobs['JobFunction2'], categories=job_function_categories)\n",
    "df_jobs['JobFunction3'] = pd.Categorical(df_jobs['JobFunction3'], categories=job_function_categories)\n",
    "\n",
    "# Drop the 'JobFunction' column if it's not needed\n",
    "df_jobs.drop(columns=['JobFunction'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_posted_time(text):\n",
    "    if 'hour' in text:\n",
    "        return 0\n",
    "    \n",
    "    if 'day' in text:\n",
    "        days = int(re.search(r'\\d+', text).group()) if re.search(r'\\d+', text) else 1  # Default to 1 if no number\n",
    "        return days\n",
    "    \n",
    "    elif 'week' in text:\n",
    "        weeks = int(re.search(r'\\d+', text).group()) if re.search(r'\\d+', text) else 1  # Default to 1 if no number\n",
    "        return weeks * 7\n",
    "    \n",
    "    elif 'month' in text:\n",
    "        months = int(re.search(r'\\d+', text).group()) if re.search(r'\\d+', text) else 1  # Default to 1 if no number\n",
    "        return months * 30\n",
    "    \n",
    "    return text\n",
    "\n",
    "df_jobs['PostedTime'] = df_jobs['PostedTime'].apply(convert_posted_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs.rename(columns={'PostedTime': 'DaysSincePosted'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs.rename(columns={'Category': 'JobCategory'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_order = [\n",
    "    'Title', 'Company', 'Location', 'JobID', 'JobCategory', \n",
    "    'SeniorityLevel', 'EmploymentType', 'Industries', \n",
    "    'DaysSincePosted', 'NumApplicants', \n",
    "    'JobFunction1', 'JobFunction2', 'JobFunction3', \n",
    "    'Description', 'Url'\n",
    "]\n",
    "df_jobs = df_jobs[new_column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>JobID</th>\n",
       "      <th>JobCategory</th>\n",
       "      <th>SeniorityLevel</th>\n",
       "      <th>EmploymentType</th>\n",
       "      <th>Industries</th>\n",
       "      <th>DaysSincePosted</th>\n",
       "      <th>NumApplicants</th>\n",
       "      <th>JobFunction1</th>\n",
       "      <th>JobFunction2</th>\n",
       "      <th>JobFunction3</th>\n",
       "      <th>Description</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jr. Data Scientist</td>\n",
       "      <td>Arca Continental</td>\n",
       "      <td>Monterrey</td>\n",
       "      <td>4002846143</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Food and Beverage Services</td>\n",
       "      <td>14</td>\n",
       "      <td>198</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Sales</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Nuestra compañía Arca Continental es una empre...</td>\n",
       "      <td>https://mx.linkedin.com/jobs/view/jr-data-scie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Title           Company   Location       JobID   JobCategory  \\\n",
       "0  Jr. Data Scientist  Arca Continental  Monterrey  4002846143  Data Science   \n",
       "\n",
       "  SeniorityLevel EmploymentType                  Industries  DaysSincePosted  \\\n",
       "0      Associate      Full-time  Food and Beverage Services               14   \n",
       "\n",
       "   NumApplicants            JobFunction1 JobFunction2 JobFunction3  \\\n",
       "0            198  Information Technology        Sales          N/A   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Nuestra compañía Arca Continental es una empre...   \n",
       "\n",
       "                                                 Url  \n",
       "0  https://mx.linkedin.com/jobs/view/jr-data-scie...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jobs.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs.to_csv(\"LinkedIn_Jobs_Data_Scientist_Monterrey_2024-08-15_FullInfo.csv\", index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
