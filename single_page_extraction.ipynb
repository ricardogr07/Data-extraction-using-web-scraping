{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "217c631d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T10:15:50.057728Z",
     "iopub.status.busy": "2024-08-07T10:15:50.057287Z",
     "iopub.status.idle": "2024-08-07T10:16:36.312149Z",
     "shell.execute_reply": "2024-08-07T10:16:36.310931Z"
    },
    "papermill": {
     "duration": 46.266055,
     "end_time": "2024-08-07T10:16:36.315172",
     "exception": false,
     "start_time": "2024-08-07T10:15:50.049117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2024.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4) (2.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ricar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries if they are not present\n",
    "!pip install requests\n",
    "!pip install beautifulsoup4\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2b1ae1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T10:16:36.331023Z",
     "iopub.status.busy": "2024-08-07T10:16:36.329899Z",
     "iopub.status.idle": "2024-08-07T10:16:37.603845Z",
     "shell.execute_reply": "2024-08-07T10:16:37.602721Z"
    },
    "id": "Fl7zUUWBV6mS",
    "papermill": {
     "duration": 1.285256,
     "end_time": "2024-08-07T10:16:37.606849",
     "exception": false,
     "start_time": "2024-08-07T10:16:36.321593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricar\\AppData\\Local\\Temp\\ipykernel_14788\\1374655100.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# Import relevant packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdcf79e",
   "metadata": {
    "id": "HFn7QeLu3xOO",
    "papermill": {
     "duration": 0.005984,
     "end_time": "2024-08-07T10:16:37.619281",
     "exception": false,
     "start_time": "2024-08-07T10:16:37.613297",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Extraction through Web Scraping.\n",
    "\n",
    "## Introduction.\n",
    "\n",
    "Almost 10 years ago, the job of a data scientist was labeled by Harvard Business Review as \"the sexiest job of the 21st century\" [(Davenport & Patil 2012)](https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century). Since then, there has been a steady increase in the demand for data experts, and it is expected that both job creation and salaries will continue to rise in the coming years.\n",
    "\n",
    "The objective of this tutorial is to use web scraping techniques to extract data on job offers for data scientists published on an open job portal (www.linkedin.com/jobs).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218d67ec",
   "metadata": {
    "id": "9PBdfKE4xUYJ",
    "papermill": {
     "duration": 0.005965,
     "end_time": "2024-08-07T10:16:37.643948",
     "exception": false,
     "start_time": "2024-08-07T10:16:37.637983",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Extract the list of job postings returned by your search on LinkedIn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4c00ba8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T10:16:37.658981Z",
     "iopub.status.busy": "2024-08-07T10:16:37.657969Z",
     "iopub.status.idle": "2024-08-07T10:16:37.664956Z",
     "shell.execute_reply": "2024-08-07T10:16:37.663916Z"
    },
    "id": "knsl-A5cxUYK",
    "papermill": {
     "duration": 0.017539,
     "end_time": "2024-08-07T10:16:37.667688",
     "exception": false,
     "start_time": "2024-08-07T10:16:37.650149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.linkedin.com/jobs/search/?keywords=data%20scientist&location=Monterrey&start=25\n"
     ]
    }
   ],
   "source": [
    "# Define the position and location to scrape\n",
    "position = 'data scientist'\n",
    "url_friendly_position = position.replace(\" \",\"%20\")\n",
    "location = 'Monterrey'\n",
    "url_search = 'https://www.linkedin.com/jobs/search/?keywords=%s&location=%s&start=%s'%(url_friendly_position, location,\"25\")\n",
    "print(url_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fcc899c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T10:16:37.682162Z",
     "iopub.status.busy": "2024-08-07T10:16:37.681765Z",
     "iopub.status.idle": "2024-08-07T10:16:37.688879Z",
     "shell.execute_reply": "2024-08-07T10:16:37.687825Z"
    },
    "id": "6jJqLmYP3Ux5",
    "papermill": {
     "duration": 0.017893,
     "end_time": "2024-08-07T10:16:37.691993",
     "exception": false,
     "start_time": "2024-08-07T10:16:37.674100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using header: {'User-Agent': 'Mozilla/5.0'}\n"
     ]
    }
   ],
   "source": [
    "# To prevent the website from thinking you are a bot, use one of the following headers when making the request:\n",
    "\n",
    "# List of headers\n",
    "headers = [\n",
    "    {'User-Agent': 'Mozilla/5.0'},\n",
    "    {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.84 Safari/537.36'},\n",
    "    {'User-Agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Mobile Safari/537.36'},\n",
    "    {'User-Agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Mobile Safari/537.36'},\n",
    "    {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.84 Safari/537.36'}\n",
    "]\n",
    "\n",
    "# Randomly select one header\n",
    "head = random.choice(headers)\n",
    "\n",
    "# Print the selected header\n",
    "print(f\"Using header: {head}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e374d0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T10:16:37.707358Z",
     "iopub.status.busy": "2024-08-07T10:16:37.706396Z",
     "iopub.status.idle": "2024-08-07T10:16:39.313913Z",
     "shell.execute_reply": "2024-08-07T10:16:39.312447Z"
    },
    "id": "BqChn4MZxUYL",
    "papermill": {
     "duration": 1.617989,
     "end_time": "2024-08-07T10:16:39.316419",
     "exception": false,
     "start_time": "2024-08-07T10:16:37.698430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [429]>\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "# Obtain a list of jobs related to the position and location\n",
    "got_200 = False\n",
    "while not got_200:\n",
    "    response = requests.get(url_search, headers=head)\n",
    "    print(response)\n",
    "    got_200 = response.status_code == 200\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "joblist = soup.find('ul', class_=\"jobs-search__results-list\")\n",
    "alljobs = joblist.find_all('li')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8001eee1",
   "metadata": {
    "id": "W5AERO-kxUYM",
    "papermill": {
     "duration": 0.006502,
     "end_time": "2024-08-07T10:16:39.330183",
     "exception": false,
     "start_time": "2024-08-07T10:16:39.323681",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Select only the first job posting from the list and extract the following information: job title, company name, location, and job URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4abde6c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T10:16:39.373370Z",
     "iopub.status.busy": "2024-08-07T10:16:39.372975Z",
     "iopub.status.idle": "2024-08-07T10:16:39.383270Z",
     "shell.execute_reply": "2024-08-07T10:16:39.381818Z"
    },
    "papermill": {
     "duration": 0.022109,
     "end_time": "2024-08-07T10:16:39.386101",
     "exception": false,
     "start_time": "2024-08-07T10:16:39.363992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Desarrollador IA (Inteligencia Artificial)\n",
      "Company: Tecnológico de Monterrey\n",
      "Location: Monterrey, Nuevo León, Mexico\n",
      "URL: https://mx.linkedin.com/jobs/view/desarrollador-ia-inteligencia-artificial-at-tecnol%C3%B3gico-de-monterrey-3996580560?position=1&pageNum=0&refId=DBY2uKBxPK%2F5%2BnObUvyYuQ%3D%3D&trackingId=delcIwlAwTHgl0UaBPUHwg%3D%3D&trk=public_jobs_jserp-result_search-card\n"
     ]
    }
   ],
   "source": [
    "info = alljobs[0].find('div', class_=\"base-search-card__info\")\n",
    "title = info.find('h3', class_=\"base-search-card__title\").text.strip()\n",
    "company = info.find('h4', class_=\"base-search-card__subtitle\").text.strip()\n",
    "metadata = alljobs[0].find('div', class_=\"base-search-card__metadata\")\n",
    "location_element = metadata.find('span', class_=\"job-search-card__location\")\n",
    "location_job = location_element.text.strip()\n",
    "\n",
    "joburl = alljobs[0].find('a', class_=\"base-card__full-link\")['href']\n",
    "\n",
    "# Information about the first job\n",
    "print(f'Title: {title}')\n",
    "print(f'Company: {company}')\n",
    "print(f'Location: {location_job}')\n",
    "print(f'URL: {joburl}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39ac491a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T10:16:39.402551Z",
     "iopub.status.busy": "2024-08-07T10:16:39.402125Z",
     "iopub.status.idle": "2024-08-07T10:16:39.436326Z",
     "shell.execute_reply": "2024-08-07T10:16:39.435121Z"
    },
    "id": "pOcOSwFuxUYN",
    "papermill": {
     "duration": 0.045808,
     "end_time": "2024-08-07T10:16:39.439130",
     "exception": false,
     "start_time": "2024-08-07T10:16:39.393322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Título: Desarrollador IA (Inteligencia Artificial)\n",
      "Empresa: Tecnológico de Monterrey\n",
      "Ubicación: Monterrey, Nuevo León, Mexico\n",
      "URL del trabajo: https://mx.linkedin.com/jobs/view/desarrollador-ia-inteligencia-artificial-at-tecnol%C3%B3gico-de-monterrey-3996580560?position=1&pageNum=0&refId=DBY2uKBxPK%2F5%2BnObUvyYuQ%3D%3D&trackingId=delcIwlAwTHgl0UaBPUHwg%3D%3D&trk=public_jobs_jserp-result_search-card\n"
     ]
    }
   ],
   "source": [
    "# Create a list of dictionaries with job information\n",
    "\n",
    "jobs = []\n",
    "\n",
    "for job in alljobs:\n",
    "    info = job.find('div', class_=\"base-search-card__info\")\n",
    "    title = info.find('h3', class_=\"base-search-card__title\").text.strip()\n",
    "    company = info.find('h4', class_=\"base-search-card__subtitle\").text.strip()\n",
    "    \n",
    "    metadata = job.find('div', class_=\"base-search-card__metadata\")\n",
    "    location_element = metadata.find('span', class_=\"job-search-card__location\")\n",
    "    location_job = location_element.text.strip()\n",
    "    \n",
    "    joburl = job.find('a', class_=\"base-card__full-link\")['href']\n",
    "    \n",
    "    job_info = {\n",
    "        'Location': location_job,\n",
    "        'Title': title,\n",
    "        'Company': company,\n",
    "        'Url': joburl\n",
    "    }\n",
    "\n",
    "    jobs.append(job_info)\n",
    "\n",
    "# Select the first job from the list and extract the relevant information\n",
    "first_job = jobs[0]\n",
    "location_job = first_job['Location']\n",
    "title_job = first_job['Title']\n",
    "company_job = first_job['Company']\n",
    "joburl_job = first_job['Url']\n",
    "\n",
    "# Print the information of the first job\n",
    "print(f'Title: {title_job}')\n",
    "print(f'Company: {company_job}')\n",
    "print(f'Location: {location_job}')\n",
    "print(f'URL: {joburl_job}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4113ceed",
   "metadata": {
    "id": "Uf1pPnWTxUYO",
    "papermill": {
     "duration": 0.00719,
     "end_time": "2024-08-07T10:16:39.453967",
     "exception": false,
     "start_time": "2024-08-07T10:16:39.446777",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Based on the previous points, write a routine to extract the information for location, job title, company name, and job URL for all the job postings returned by your LinkedIn search, and store the data in a pandas dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b0f0233",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T10:16:39.471127Z",
     "iopub.status.busy": "2024-08-07T10:16:39.470722Z",
     "iopub.status.idle": "2024-08-07T10:16:39.490179Z",
     "shell.execute_reply": "2024-08-07T10:16:39.489007Z"
    },
    "id": "yajotXq1xUYO",
    "papermill": {
     "duration": 0.031341,
     "end_time": "2024-08-07T10:16:39.492845",
     "exception": false,
     "start_time": "2024-08-07T10:16:39.461504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Location                                       Title  \\\n",
      "0  Monterrey, Nuevo León, Mexico  Desarrollador IA (Inteligencia Artificial)   \n",
      "\n",
      "                    Company                                                Url  \n",
      "0  Tecnológico de Monterrey  https://mx.linkedin.com/jobs/view/desarrollado...  \n"
     ]
    }
   ],
   "source": [
    "df_jobs = pd.DataFrame(jobs, columns=['Location', 'Title', 'Company', 'Url'])\n",
    "print(df_jobs.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d38028",
   "metadata": {
    "id": "5AzJvKlxxUYP",
    "papermill": {
     "duration": 0.007288,
     "end_time": "2024-08-07T10:16:39.507615",
     "exception": false,
     "start_time": "2024-08-07T10:16:39.500327",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Export your dataframe to a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba4983a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T10:16:39.524621Z",
     "iopub.status.busy": "2024-08-07T10:16:39.524173Z",
     "iopub.status.idle": "2024-08-07T10:16:39.538006Z",
     "shell.execute_reply": "2024-08-07T10:16:39.536728Z"
    },
    "id": "dL4-uR9_QQOL",
    "papermill": {
     "duration": 0.02597,
     "end_time": "2024-08-07T10:16:39.541137",
     "exception": false,
     "start_time": "2024-08-07T10:16:39.515167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Export DataFrame to CSV\n",
    "date = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "position = position.replace(\" \", \"_\")\n",
    "file_name = f'LinkedIn_{position}_{location}_{date}.csv'\n",
    "df_jobs.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9391839b",
   "metadata": {
    "id": "qi4sOfg6xUYP",
    "papermill": {
     "duration": 0.008371,
     "end_time": "2024-08-07T10:16:39.557311",
     "exception": false,
     "start_time": "2024-08-07T10:16:39.548940",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### How many job postings does your dataframe contain, and how many results are there in total from the LinkedIn search?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7521267",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T10:16:39.576699Z",
     "iopub.status.busy": "2024-08-07T10:16:39.576227Z",
     "iopub.status.idle": "2024-08-07T10:16:39.587980Z",
     "shell.execute_reply": "2024-08-07T10:16:39.586591Z"
    },
    "id": "Tg8fwWroxUYP",
    "papermill": {
     "duration": 0.024863,
     "end_time": "2024-08-07T10:16:39.591011",
     "exception": false,
     "start_time": "2024-08-07T10:16:39.566148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of job postings in the DataFrame is 60, while the total number of results on LinkedIn is 632.\n"
     ]
    }
   ],
   "source": [
    "number_jobs = df_jobs['Url'].count()\n",
    "all_jobs_linkedin = int(soup.find('span', {'class': 'results-context-header__job-count'}).text)\n",
    "print(f'The number of job postings in the DataFrame is {number_jobs}, while the total number of results on LinkedIn is {all_jobs_linkedin}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2797813d",
   "metadata": {
    "papermill": {
     "duration": 0.007966,
     "end_time": "2024-08-07T10:16:39.606964",
     "exception": false,
     "start_time": "2024-08-07T10:16:39.598998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If there is a discrepancy between these two results, it is likely because I have only extracted the job postings from the first page of LinkedIn results. LinkedIn displays a limited number of postings per page, and if there are more postings, they are shown on subsequent pages.\n",
    "\n",
    "To extract all available results from LinkedIn, you would need to implement a loop that iterates through all the result pages. This would involve extracting the URL for the next page from the current page, then performing web scraping on that page and adding the information to the dataframe, and so on, until there are no more pages or results."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 53.254837,
   "end_time": "2024-08-07T10:16:40.136970",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-07T10:15:46.882133",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
