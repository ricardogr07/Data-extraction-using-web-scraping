{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "217c631d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T10:15:50.057728Z",
     "iopub.status.busy": "2024-08-07T10:15:50.057287Z",
     "iopub.status.idle": "2024-08-07T10:16:36.312149Z",
     "shell.execute_reply": "2024-08-07T10:16:36.310931Z"
    },
    "papermill": {
     "duration": 46.266055,
     "end_time": "2024-08-07T10:16:36.315172",
     "exception": false,
     "start_time": "2024-08-07T10:15:50.049117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (2.32.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests) (2024.7.4)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (4.12.2)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4) (2.5)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\r\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.4)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\r\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries if they are not present\n",
    "!pip install requests\n",
    "!pip install beautifulsoup4\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2b1ae1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T10:16:36.331023Z",
     "iopub.status.busy": "2024-08-07T10:16:36.329899Z",
     "iopub.status.idle": "2024-08-07T10:16:37.603845Z",
     "shell.execute_reply": "2024-08-07T10:16:37.602721Z"
    },
    "id": "Fl7zUUWBV6mS",
    "papermill": {
     "duration": 1.285256,
     "end_time": "2024-08-07T10:16:37.606849",
     "exception": false,
     "start_time": "2024-08-07T10:16:36.321593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdcf79e",
   "metadata": {
    "id": "HFn7QeLu3xOO",
    "papermill": {
     "duration": 0.005984,
     "end_time": "2024-08-07T10:16:37.619281",
     "exception": false,
     "start_time": "2024-08-07T10:16:37.613297",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Extraction through Web Scraping.\n",
    "\n",
    "## Introduction.\n",
    "\n",
    "Almost 10 years ago, the job of a data scientist was labeled by Harvard Business Review as \"the sexiest job of the 21st century\" [(Davenport & Patil 2012)](https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century). Since then, there has been a steady increase in the demand for data experts, and it is expected that both job creation and salaries will continue to rise in the coming years. The following articles illustrate this situation:\n",
    "\n",
    "https://www.smithhanley.com/2022/01/04/data-science-in-2022/\n",
    "https://www.bbva.com/en/big-data-the-demand-for-expert-talent-continues-to-grow/\n",
    "\n",
    "The cited studies refer to labor markets in Europe and the United States. Suppose you are in charge of developing a study of the labor market for data scientists in Latin America, for which you need to build a database with job offers published in different countries of the region.\n",
    "\n",
    "The objective of this task is to use web scraping techniques to extract data on job offers for data scientists published on an open job portal (www.linkedin.com/jobs).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270ac895",
   "metadata": {
    "id": "M_ICRQTPxUYI",
    "papermill": {
     "duration": 0.006117,
     "end_time": "2024-08-07T10:16:37.631628",
     "exception": false,
     "start_time": "2024-08-07T10:16:37.625511",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 1. Go to the website www.linkedin.com/jobs, click on the `Search Jobs` button, and search for jobs for *data scientist* in your country's capital (or another city of interest). Inspect and analyze the source code of the results page to understand the structure of its HTML code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218d67ec",
   "metadata": {
    "id": "9PBdfKE4xUYJ",
    "papermill": {
     "duration": 0.005965,
     "end_time": "2024-08-07T10:16:37.643948",
     "exception": false,
     "start_time": "2024-08-07T10:16:37.637983",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 2. Extract the list of job postings returned by your search on LinkedIn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4c00ba8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T10:16:37.658981Z",
     "iopub.status.busy": "2024-08-07T10:16:37.657969Z",
     "iopub.status.idle": "2024-08-07T10:16:37.664956Z",
     "shell.execute_reply": "2024-08-07T10:16:37.663916Z"
    },
    "id": "knsl-A5cxUYK",
    "papermill": {
     "duration": 0.017539,
     "end_time": "2024-08-07T10:16:37.667688",
     "exception": false,
     "start_time": "2024-08-07T10:16:37.650149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.linkedin.com/jobs/search/?keywords=data%20scientist&location=Monterrey\n"
     ]
    }
   ],
   "source": [
    "# Define the position and location to scrape\n",
    "position = 'data scientist'\n",
    "url_friendly_position = position.replace(\" \",\"%20\")\n",
    "location = 'Monterrey'\n",
    "url_search = 'https://www.linkedin.com/jobs/search/?keywords=%s&location=%s'%(url_friendly_position, location)\n",
    "print(url_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fcc899c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T10:16:37.682162Z",
     "iopub.status.busy": "2024-08-07T10:16:37.681765Z",
     "iopub.status.idle": "2024-08-07T10:16:37.688879Z",
     "shell.execute_reply": "2024-08-07T10:16:37.687825Z"
    },
    "id": "6jJqLmYP3Ux5",
    "papermill": {
     "duration": 0.017893,
     "end_time": "2024-08-07T10:16:37.691993",
     "exception": false,
     "start_time": "2024-08-07T10:16:37.674100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using header: {'User-Agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Mobile Safari/537.36'}\n"
     ]
    }
   ],
   "source": [
    "# To prevent the website from thinking you are a bot, use one of the following headers when making the request:\n",
    "\n",
    "# List of headers\n",
    "headers = [\n",
    "    {'User-Agent': 'Mozilla/5.0'},\n",
    "    {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.84 Safari/537.36'},\n",
    "    {'User-Agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Mobile Safari/537.36'},\n",
    "    {'User-Agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Mobile Safari/537.36'},\n",
    "    {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.84 Safari/537.36'}\n",
    "]\n",
    "\n",
    "# Randomly select one header\n",
    "head = random.choice(headers)\n",
    "\n",
    "# Print the selected header\n",
    "print(f\"Using header: {head}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e374d0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T10:16:37.707358Z",
     "iopub.status.busy": "2024-08-07T10:16:37.706396Z",
     "iopub.status.idle": "2024-08-07T10:16:39.313913Z",
     "shell.execute_reply": "2024-08-07T10:16:39.312447Z"
    },
    "id": "BqChn4MZxUYL",
    "papermill": {
     "duration": 1.617989,
     "end_time": "2024-08-07T10:16:39.316419",
     "exception": false,
     "start_time": "2024-08-07T10:16:37.698430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "# Obtain a list of jobs related to the position and location\n",
    "response = requests.get(url_search, headers=head)\n",
    "print(response)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "joblist = soup.find('ul', class_=\"jobs-search__results-list\")\n",
    "alljobs = joblist.find_all('li')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8001eee1",
   "metadata": {
    "id": "W5AERO-kxUYM",
    "papermill": {
     "duration": 0.006502,
     "end_time": "2024-08-07T10:16:39.330183",
     "exception": false,
     "start_time": "2024-08-07T10:16:39.323681",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 3. Select only the first job posting from the list and extract the following information: job title, company name, location, and job URL.\n",
    "\n",
    "Note: By location, we mean the city, district, or municipality specified in the posting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2ac68d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T10:16:39.346186Z",
     "iopub.status.busy": "2024-08-07T10:16:39.345758Z",
     "iopub.status.idle": "2024-08-07T10:16:39.353377Z",
     "shell.execute_reply": "2024-08-07T10:16:39.352107Z"
    },
    "papermill": {
     "duration": 0.019229,
     "end_time": "2024-08-07T10:16:39.356626",
     "exception": false,
     "start_time": "2024-08-07T10:16:39.337397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<li>\n",
      "<div class=\"base-card relative w-full hover:no-underline focus:no-underline base-card--link base-search-card base-search-card--link job-search-card\" data-column=\"1\" data-entity-urn=\"urn:li:jobPosting:3979385708\" data-impression-id=\"jobs-search-mobile-0\" data-reference-id=\"q/tu8eGHf9i/eoHCiTScqw==\" data-row=\"1\" data-tracking-id=\"+Ik0gwXmDNJmNEY1XRrsvw==\">\n",
      "<a class=\"base-card__full-link absolute top-0 right-0 bottom-0 left-0 p-0 z-[2]\" data-tracking-client-ingraph=\"\" data-tracking-control-name=\"public_jobs_jserp-result_search-card\" data-tracking-will-navigate=\"\" href=\"https://mx.linkedin.com/jobs/view/data-science-analyst-at-steelcase-3979385708?position=1&amp;pageNum=0&amp;refId=q%2Ftu8eGHf9i%2FeoHCiTScqw%3D%3D&amp;trackingId=%2BIk0gwXmDNJmNEY1XRrsvw%3D%3D&amp;trk=public_jobs_jserp-result_search-card\">\n",
      "<span class=\"sr-only\">\n",
      "              \n",
      "        \n",
      "        Data Science Analyst\n",
      "      \n",
      "      \n",
      "          </span>\n",
      "</a>\n",
      "<div class=\"search-entity-media\">\n",
      "<img alt=\"\" class=\"artdeco-entity-image artdeco-entity-image--square-4\" data-delayed-url=\"https://media.licdn.com/dms/image/C4D0BAQHk8kL-hx_POw/company-logo_100_100/0/1630579891276/steelcase_logo?e=2147483647&amp;v=beta&amp;t=eKen0R0y9bVJTzGapUv9pjJNRPdXm1Lt2klzVR8bhbk\" data-ghost-classes=\"artdeco-entity-image--ghost\" data-ghost-url=\"https://static.licdn.com/aero-v1/sc/h/6puxblwmhnodu6fjircz4dn4h\"/>\n",
      "</div>\n",
      "<div class=\"base-search-card__info\">\n",
      "<h3 class=\"base-search-card__title\">\n",
      "            \n",
      "        Data Science Analyst\n",
      "      \n",
      "          </h3>\n",
      "<h4 class=\"base-search-card__subtitle\">\n",
      "<a class=\"hidden-nested-link\" data-tracking-client-ingraph=\"\" data-tracking-control-name=\"public_jobs_jserp-result_job-search-card-subtitle\" data-tracking-will-navigate=\"\" href=\"https://www.linkedin.com/company/steelcase?trk=public_jobs_jserp-result_job-search-card-subtitle\">\n",
      "            Steelcase\n",
      "          </a>\n",
      "</h4>\n",
      "<!-- -->\n",
      "<div class=\"base-search-card__metadata\">\n",
      "<span class=\"job-search-card__location\">\n",
      "            San Pedro Garza García, Nuevo León, Mexico\n",
      "          </span>\n",
      "<div class=\"job-posting-benefits text-sm\">\n",
      "<icon class=\"job-posting-benefits__icon\" data-delayed-url=\"https://static.licdn.com/aero-v1/sc/h/3p1v0uhy7uq0cm5zdvzp4eo18\" data-svg-class-name=\"job-posting-benefits__icon-svg\"></icon>\n",
      "<span class=\"job-posting-benefits__text\">\n",
      "          Actively Hiring\n",
      "<!-- --> </span>\n",
      "</div>\n",
      "<time class=\"job-search-card__listdate\" datetime=\"2024-07-18\">\n",
      "            \n",
      "\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "\n",
      "      2 weeks ago\n",
      "  \n",
      "          </time>\n",
      "<!-- -->\n",
      "</div>\n",
      "</div>\n",
      "<!-- -->\n",
      "</div>\n",
      "</li>\n"
     ]
    }
   ],
   "source": [
    "print(alljobs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4abde6c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T10:16:39.373370Z",
     "iopub.status.busy": "2024-08-07T10:16:39.372975Z",
     "iopub.status.idle": "2024-08-07T10:16:39.383270Z",
     "shell.execute_reply": "2024-08-07T10:16:39.381818Z"
    },
    "papermill": {
     "duration": 0.022109,
     "end_time": "2024-08-07T10:16:39.386101",
     "exception": false,
     "start_time": "2024-08-07T10:16:39.363992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Título: Data Science Analyst\n",
      "Empresa: Steelcase\n",
      "Ubicación: San Pedro Garza García, Nuevo León, Mexico\n",
      "URL del trabajo: https://mx.linkedin.com/jobs/view/data-science-analyst-at-steelcase-3979385708?position=1&pageNum=0&refId=q%2Ftu8eGHf9i%2FeoHCiTScqw%3D%3D&trackingId=%2BIk0gwXmDNJmNEY1XRrsvw%3D%3D&trk=public_jobs_jserp-result_search-card\n"
     ]
    }
   ],
   "source": [
    "info = alljobs[0].find('div', class_=\"base-search-card__info\")\n",
    "title = info.find('h3', class_=\"base-search-card__title\").text.strip()\n",
    "company = info.find('h4', class_=\"base-search-card__subtitle\").text.strip()\n",
    "metadata = alljobs[0].find('div', class_=\"base-search-card__metadata\")\n",
    "location_element = metadata.find('span', class_=\"job-search-card__location\")\n",
    "location_job = location_element.text.strip()\n",
    "\n",
    "joburl = alljobs[0].find('a', class_=\"base-card__full-link\")['href']\n",
    "\n",
    "# Information about the first job\n",
    "print(f'Título: {title}')\n",
    "print(f'Empresa: {company}')\n",
    "print(f'Ubicación: {location_job}')\n",
    "print(f'URL del trabajo: {joburl}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39ac491a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T10:16:39.402551Z",
     "iopub.status.busy": "2024-08-07T10:16:39.402125Z",
     "iopub.status.idle": "2024-08-07T10:16:39.436326Z",
     "shell.execute_reply": "2024-08-07T10:16:39.435121Z"
    },
    "id": "pOcOSwFuxUYN",
    "papermill": {
     "duration": 0.045808,
     "end_time": "2024-08-07T10:16:39.439130",
     "exception": false,
     "start_time": "2024-08-07T10:16:39.393322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Título: Data Science Analyst\n",
      "Empresa: Steelcase\n",
      "Ubicación: San Pedro Garza García, Nuevo León, Mexico\n",
      "URL del trabajo: https://mx.linkedin.com/jobs/view/data-science-analyst-at-steelcase-3979385708?position=1&pageNum=0&refId=q%2Ftu8eGHf9i%2FeoHCiTScqw%3D%3D&trackingId=%2BIk0gwXmDNJmNEY1XRrsvw%3D%3D&trk=public_jobs_jserp-result_search-card\n"
     ]
    }
   ],
   "source": [
    "# Create a list of dictionaries with job information\n",
    "\n",
    "jobs = []\n",
    "\n",
    "for job in alljobs:\n",
    "    info = job.find('div', class_=\"base-search-card__info\")\n",
    "    title = info.find('h3', class_=\"base-search-card__title\").text.strip()\n",
    "    company = info.find('h4', class_=\"base-search-card__subtitle\").text.strip()\n",
    "    \n",
    "    metadata = job.find('div', class_=\"base-search-card__metadata\")\n",
    "    location_element = metadata.find('span', class_=\"job-search-card__location\")\n",
    "    location_job = location_element.text.strip()\n",
    "    \n",
    "    joburl = job.find('a', class_=\"base-card__full-link\")['href']\n",
    "    \n",
    "    job_info = {\n",
    "        'Location': location_job,\n",
    "        'Title': title,\n",
    "        'Company': company,\n",
    "        'Url': joburl\n",
    "    }\n",
    "\n",
    "    jobs.append(job_info)\n",
    "\n",
    "# Select the first job from the list and extract the relevant information\n",
    "first_job = jobs[0]\n",
    "location_job = first_job['Location']\n",
    "title_job = first_job['Title']\n",
    "company_job = first_job['Company']\n",
    "joburl_job = first_job['Url']\n",
    "\n",
    "# Print the information of the first job\n",
    "print(f'Título: {title_job}')\n",
    "print(f'Empresa: {company_job}')\n",
    "print(f'Ubicación: {location_job}')\n",
    "print(f'URL del trabajo: {joburl_job}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4113ceed",
   "metadata": {
    "id": "Uf1pPnWTxUYO",
    "papermill": {
     "duration": 0.00719,
     "end_time": "2024-08-07T10:16:39.453967",
     "exception": false,
     "start_time": "2024-08-07T10:16:39.446777",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 4. Based on the previous points, write a routine to extract the information for location, job title, company name, and job URL for all the job postings returned by your LinkedIn search, and store the data in a pandas dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b0f0233",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T10:16:39.471127Z",
     "iopub.status.busy": "2024-08-07T10:16:39.470722Z",
     "iopub.status.idle": "2024-08-07T10:16:39.490179Z",
     "shell.execute_reply": "2024-08-07T10:16:39.489007Z"
    },
    "id": "yajotXq1xUYO",
    "papermill": {
     "duration": 0.031341,
     "end_time": "2024-08-07T10:16:39.492845",
     "exception": false,
     "start_time": "2024-08-07T10:16:39.461504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Location                 Title  \\\n",
      "0  San Pedro Garza García, Nuevo León, Mexico  Data Science Analyst   \n",
      "\n",
      "     Company                                                Url  \n",
      "0  Steelcase  https://mx.linkedin.com/jobs/view/data-science...  \n"
     ]
    }
   ],
   "source": [
    "df_jobs = pd.DataFrame(jobs, columns=['Location', 'Title', 'Company', 'Url'])\n",
    "print(df_jobs.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d38028",
   "metadata": {
    "id": "5AzJvKlxxUYP",
    "papermill": {
     "duration": 0.007288,
     "end_time": "2024-08-07T10:16:39.507615",
     "exception": false,
     "start_time": "2024-08-07T10:16:39.500327",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 5. Export your dataframe to a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba4983a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T10:16:39.524621Z",
     "iopub.status.busy": "2024-08-07T10:16:39.524173Z",
     "iopub.status.idle": "2024-08-07T10:16:39.538006Z",
     "shell.execute_reply": "2024-08-07T10:16:39.536728Z"
    },
    "id": "dL4-uR9_QQOL",
    "papermill": {
     "duration": 0.02597,
     "end_time": "2024-08-07T10:16:39.541137",
     "exception": false,
     "start_time": "2024-08-07T10:16:39.515167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Exportar el DataFrame a un archivo CSV\n",
    "date = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "position = position.replace(\" \", \"_\")\n",
    "nombre_archivo = f'LinkedIn_{position}_{location}_{date}.csv'\n",
    "df_jobs.to_csv(nombre_archivo, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9391839b",
   "metadata": {
    "id": "qi4sOfg6xUYP",
    "papermill": {
     "duration": 0.008371,
     "end_time": "2024-08-07T10:16:39.557311",
     "exception": false,
     "start_time": "2024-08-07T10:16:39.548940",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 6. How many job postings does your dataframe contain, and how many results are there in total from the LinkedIn search? Comment on the differences or matches, and explain what you would need to do to extract all available results from LinkedIn (in words, implementation is not necessary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7521267",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T10:16:39.576699Z",
     "iopub.status.busy": "2024-08-07T10:16:39.576227Z",
     "iopub.status.idle": "2024-08-07T10:16:39.587980Z",
     "shell.execute_reply": "2024-08-07T10:16:39.586591Z"
    },
    "id": "Tg8fwWroxUYP",
    "papermill": {
     "duration": 0.024863,
     "end_time": "2024-08-07T10:16:39.591011",
     "exception": false,
     "start_time": "2024-08-07T10:16:39.566148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of job postings in the DataFrame is 59, while the total number of results on LinkedIn is 659.\n"
     ]
    }
   ],
   "source": [
    "ofertas_df = df_jobs['Url'].count()\n",
    "ofertas_linkedin = int(soup.find('span', {'class': 'results-context-header__job-count'}).text)\n",
    "print(f'The number of job postings in the DataFrame is {ofertas_df}, while the total number of results on LinkedIn is {ofertas_linkedin}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2797813d",
   "metadata": {
    "papermill": {
     "duration": 0.007966,
     "end_time": "2024-08-07T10:16:39.606964",
     "exception": false,
     "start_time": "2024-08-07T10:16:39.598998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If there is a discrepancy between these two results, it is likely because I have only extracted the job postings from the first page of LinkedIn results. LinkedIn displays a limited number of postings per page, and if there are more postings, they are shown on subsequent pages.\n",
    "\n",
    "To extract all available results from LinkedIn, you would need to implement a loop that iterates through all the result pages. This would involve extracting the URL for the next page from the current page, then performing web scraping on that page and adding the information to the dataframe, and so on, until there are no more pages or results.\n",
    "\n",
    "However, this process can be complex and require careful handling to avoid being blocked by LinkedIn due to generating too many requests in a short period of time. It is important to mention that web scraping LinkedIn is against their terms of service, so this would likely be considered a bad practice.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 53.254837,
   "end_time": "2024-08-07T10:16:40.136970",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-07T10:15:46.882133",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
