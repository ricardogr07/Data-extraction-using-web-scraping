{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217c631d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T10:15:50.057728Z",
     "iopub.status.busy": "2024-08-07T10:15:50.057287Z",
     "iopub.status.idle": "2024-08-07T10:16:36.312149Z",
     "shell.execute_reply": "2024-08-07T10:16:36.310931Z"
    },
    "papermill": {
     "duration": 46.266055,
     "end_time": "2024-08-07T10:16:36.315172",
     "exception": false,
     "start_time": "2024-08-07T10:15:50.049117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install necessary libraries if they are not present\n",
    "!pip install requests\n",
    "!pip install beautifulsoup4\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b1ae1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T10:16:36.331023Z",
     "iopub.status.busy": "2024-08-07T10:16:36.329899Z",
     "iopub.status.idle": "2024-08-07T10:16:37.603845Z",
     "shell.execute_reply": "2024-08-07T10:16:37.602721Z"
    },
    "id": "Fl7zUUWBV6mS",
    "papermill": {
     "duration": 1.285256,
     "end_time": "2024-08-07T10:16:37.606849",
     "exception": false,
     "start_time": "2024-08-07T10:16:36.321593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdcf79e",
   "metadata": {
    "id": "HFn7QeLu3xOO",
    "papermill": {
     "duration": 0.005984,
     "end_time": "2024-08-07T10:16:37.619281",
     "exception": false,
     "start_time": "2024-08-07T10:16:37.613297",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Extraction through Web Scraping.\n",
    "\n",
    "## Introduction.\n",
    "\n",
    "Almost 10 years ago, the job of a data scientist was labeled by Harvard Business Review as \"the sexiest job of the 21st century\" [(Davenport & Patil 2012)](https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century). Since then, there has been a steady increase in the demand for data experts, and it is expected that both job creation and salaries will continue to rise in the coming years.\n",
    "\n",
    "The objective of this tutorial is to use web scraping techniques to extract data on job offers for data scientists published on an open job portal (www.linkedin.com/jobs).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218d67ec",
   "metadata": {
    "id": "9PBdfKE4xUYJ",
    "papermill": {
     "duration": 0.005965,
     "end_time": "2024-08-07T10:16:37.643948",
     "exception": false,
     "start_time": "2024-08-07T10:16:37.637983",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Extract the list of job postings returned by your search on LinkedIn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c00ba8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T10:16:37.658981Z",
     "iopub.status.busy": "2024-08-07T10:16:37.657969Z",
     "iopub.status.idle": "2024-08-07T10:16:37.664956Z",
     "shell.execute_reply": "2024-08-07T10:16:37.663916Z"
    },
    "id": "knsl-A5cxUYK",
    "papermill": {
     "duration": 0.017539,
     "end_time": "2024-08-07T10:16:37.667688",
     "exception": false,
     "start_time": "2024-08-07T10:16:37.650149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the position and location to scrape\n",
    "position = 'data scientist'\n",
    "url_friendly_position = position.replace(\" \",\"%20\")\n",
    "location = 'Monterrey'\n",
    "url_search = 'https://www.linkedin.com/jobs/search/?keywords=%s&location=%s'%(url_friendly_position, location)\n",
    "print(url_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcc899c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T10:16:37.682162Z",
     "iopub.status.busy": "2024-08-07T10:16:37.681765Z",
     "iopub.status.idle": "2024-08-07T10:16:37.688879Z",
     "shell.execute_reply": "2024-08-07T10:16:37.687825Z"
    },
    "id": "6jJqLmYP3Ux5",
    "papermill": {
     "duration": 0.017893,
     "end_time": "2024-08-07T10:16:37.691993",
     "exception": false,
     "start_time": "2024-08-07T10:16:37.674100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To prevent the website from thinking you are a bot, use one of the following headers when making the request:\n",
    "\n",
    "# List of headers\n",
    "headers = [\n",
    "    {'User-Agent': 'Mozilla/5.0'},\n",
    "    {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.84 Safari/537.36'},\n",
    "    {'User-Agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Mobile Safari/537.36'},\n",
    "    {'User-Agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Mobile Safari/537.36'},\n",
    "    {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.84 Safari/537.36'}\n",
    "]\n",
    "\n",
    "# Randomly select one header\n",
    "head = random.choice(headers)\n",
    "\n",
    "# Print the selected header\n",
    "print(f\"Using header: {head}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e374d0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T10:16:37.707358Z",
     "iopub.status.busy": "2024-08-07T10:16:37.706396Z",
     "iopub.status.idle": "2024-08-07T10:16:39.313913Z",
     "shell.execute_reply": "2024-08-07T10:16:39.312447Z"
    },
    "id": "BqChn4MZxUYL",
    "papermill": {
     "duration": 1.617989,
     "end_time": "2024-08-07T10:16:39.316419",
     "exception": false,
     "start_time": "2024-08-07T10:16:37.698430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtain a list of jobs related to the position and location\n",
    "response = requests.get(url_search, headers=head)\n",
    "print(response)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "joblist = soup.find('ul', class_=\"jobs-search__results-list\")\n",
    "alljobs = joblist.find_all('li')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8001eee1",
   "metadata": {
    "id": "W5AERO-kxUYM",
    "papermill": {
     "duration": 0.006502,
     "end_time": "2024-08-07T10:16:39.330183",
     "exception": false,
     "start_time": "2024-08-07T10:16:39.323681",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Select only the first job posting from the list and extract the following information: job title, company name, location, and job URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abde6c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T10:16:39.373370Z",
     "iopub.status.busy": "2024-08-07T10:16:39.372975Z",
     "iopub.status.idle": "2024-08-07T10:16:39.383270Z",
     "shell.execute_reply": "2024-08-07T10:16:39.381818Z"
    },
    "papermill": {
     "duration": 0.022109,
     "end_time": "2024-08-07T10:16:39.386101",
     "exception": false,
     "start_time": "2024-08-07T10:16:39.363992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "info = alljobs[0].find('div', class_=\"base-search-card__info\")\n",
    "title = info.find('h3', class_=\"base-search-card__title\").text.strip()\n",
    "company = info.find('h4', class_=\"base-search-card__subtitle\").text.strip()\n",
    "metadata = alljobs[0].find('div', class_=\"base-search-card__metadata\")\n",
    "location_element = metadata.find('span', class_=\"job-search-card__location\")\n",
    "location_job = location_element.text.strip()\n",
    "\n",
    "joburl = alljobs[0].find('a', class_=\"base-card__full-link\")['href']\n",
    "\n",
    "# Information about the first job\n",
    "print(f'Title: {title}')\n",
    "print(f'Company: {company}')\n",
    "print(f'Location: {location_job}')\n",
    "print(f'URL: {joburl}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ac491a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T10:16:39.402551Z",
     "iopub.status.busy": "2024-08-07T10:16:39.402125Z",
     "iopub.status.idle": "2024-08-07T10:16:39.436326Z",
     "shell.execute_reply": "2024-08-07T10:16:39.435121Z"
    },
    "id": "pOcOSwFuxUYN",
    "papermill": {
     "duration": 0.045808,
     "end_time": "2024-08-07T10:16:39.439130",
     "exception": false,
     "start_time": "2024-08-07T10:16:39.393322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a list of dictionaries with job information\n",
    "\n",
    "jobs = []\n",
    "\n",
    "for job in alljobs:\n",
    "    info = job.find('div', class_=\"base-search-card__info\")\n",
    "    title = info.find('h3', class_=\"base-search-card__title\").text.strip()\n",
    "    company = info.find('h4', class_=\"base-search-card__subtitle\").text.strip()\n",
    "    \n",
    "    metadata = job.find('div', class_=\"base-search-card__metadata\")\n",
    "    location_element = metadata.find('span', class_=\"job-search-card__location\")\n",
    "    location_job = location_element.text.strip()\n",
    "    \n",
    "    joburl = job.find('a', class_=\"base-card__full-link\")['href']\n",
    "    \n",
    "    job_info = {\n",
    "        'Location': location_job,\n",
    "        'Title': title,\n",
    "        'Company': company,\n",
    "        'Url': joburl\n",
    "    }\n",
    "\n",
    "    jobs.append(job_info)\n",
    "\n",
    "# Select the first job from the list and extract the relevant information\n",
    "first_job = jobs[0]\n",
    "location_job = first_job['Location']\n",
    "title_job = first_job['Title']\n",
    "company_job = first_job['Company']\n",
    "joburl_job = first_job['Url']\n",
    "\n",
    "# Print the information of the first job\n",
    "print(f'Título: {title_job}')\n",
    "print(f'Empresa: {company_job}')\n",
    "print(f'Ubicación: {location_job}')\n",
    "print(f'URL del trabajo: {joburl_job}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4113ceed",
   "metadata": {
    "id": "Uf1pPnWTxUYO",
    "papermill": {
     "duration": 0.00719,
     "end_time": "2024-08-07T10:16:39.453967",
     "exception": false,
     "start_time": "2024-08-07T10:16:39.446777",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Based on the previous points, write a routine to extract the information for location, job title, company name, and job URL for all the job postings returned by your LinkedIn search, and store the data in a pandas dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0f0233",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T10:16:39.471127Z",
     "iopub.status.busy": "2024-08-07T10:16:39.470722Z",
     "iopub.status.idle": "2024-08-07T10:16:39.490179Z",
     "shell.execute_reply": "2024-08-07T10:16:39.489007Z"
    },
    "id": "yajotXq1xUYO",
    "papermill": {
     "duration": 0.031341,
     "end_time": "2024-08-07T10:16:39.492845",
     "exception": false,
     "start_time": "2024-08-07T10:16:39.461504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_jobs = pd.DataFrame(jobs, columns=['Location', 'Title', 'Company', 'Url'])\n",
    "print(df_jobs.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d38028",
   "metadata": {
    "id": "5AzJvKlxxUYP",
    "papermill": {
     "duration": 0.007288,
     "end_time": "2024-08-07T10:16:39.507615",
     "exception": false,
     "start_time": "2024-08-07T10:16:39.500327",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Export your dataframe to a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4983a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T10:16:39.524621Z",
     "iopub.status.busy": "2024-08-07T10:16:39.524173Z",
     "iopub.status.idle": "2024-08-07T10:16:39.538006Z",
     "shell.execute_reply": "2024-08-07T10:16:39.536728Z"
    },
    "id": "dL4-uR9_QQOL",
    "papermill": {
     "duration": 0.02597,
     "end_time": "2024-08-07T10:16:39.541137",
     "exception": false,
     "start_time": "2024-08-07T10:16:39.515167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Exportar el DataFrame a un archivo CSV\n",
    "date = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "position = position.replace(\" \", \"_\")\n",
    "nombre_archivo = f'LinkedIn_{position}_{location}_{date}.csv'\n",
    "df_jobs.to_csv(nombre_archivo, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9391839b",
   "metadata": {
    "id": "qi4sOfg6xUYP",
    "papermill": {
     "duration": 0.008371,
     "end_time": "2024-08-07T10:16:39.557311",
     "exception": false,
     "start_time": "2024-08-07T10:16:39.548940",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### How many job postings does your dataframe contain, and how many results are there in total from the LinkedIn search?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7521267",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T10:16:39.576699Z",
     "iopub.status.busy": "2024-08-07T10:16:39.576227Z",
     "iopub.status.idle": "2024-08-07T10:16:39.587980Z",
     "shell.execute_reply": "2024-08-07T10:16:39.586591Z"
    },
    "id": "Tg8fwWroxUYP",
    "papermill": {
     "duration": 0.024863,
     "end_time": "2024-08-07T10:16:39.591011",
     "exception": false,
     "start_time": "2024-08-07T10:16:39.566148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "number_jobs = df_jobs['Url'].count()\n",
    "all_jobs_linkedin = int(soup.find('span', {'class': 'results-context-header__job-count'}).text)\n",
    "print(f'The number of job postings in the DataFrame is {number_jobs}, while the total number of results on LinkedIn is {all_jobs_linkedin}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2797813d",
   "metadata": {
    "papermill": {
     "duration": 0.007966,
     "end_time": "2024-08-07T10:16:39.606964",
     "exception": false,
     "start_time": "2024-08-07T10:16:39.598998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If there is a discrepancy between these two results, it is likely because I have only extracted the job postings from the first page of LinkedIn results. LinkedIn displays a limited number of postings per page, and if there are more postings, they are shown on subsequent pages.\n",
    "\n",
    "To extract all available results from LinkedIn, you would need to implement a loop that iterates through all the result pages. This would involve extracting the URL for the next page from the current page, then performing web scraping on that page and adding the information to the dataframe, and so on, until there are no more pages or results."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 53.254837,
   "end_time": "2024-08-07T10:16:40.136970",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-07T10:15:46.882133",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
